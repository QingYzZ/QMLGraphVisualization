{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "Epoch [1/1], Step [100/300], Loss: 0.3984\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "Epoch [1/1], Step [200/300], Loss: 0.2486\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "Epoch [1/1], Step [300/300], Loss: 0.2443\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "Accuracy on the train set: 94.87%\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "torch.Size([200, 1, 28, 28])\n",
      "Accuracy on the test set: 95.43%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "## Distributed training\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# # Pennylane\n",
    "# import pennylane as qml\n",
    "# from pennylane import numpy as np\n",
    "import torchquantum as tq\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "# OpenMP: number of parallel threads.\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "### Classical target model initialization ###\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 200\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(12*4*4, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # [N, 32 * 8 * 8]\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate the model and loss function\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "train_steps = []\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss\n",
    "        train_losses.append(loss.item())\n",
    "        train_steps.append(epoch * len(train_loader) + i)\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "\n",
    "plt.plot(train_steps, train_losses)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"training_loss.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of NN parameters:  6690\n",
      "Required qubit number:  13\n"
     ]
    }
   ],
   "source": [
    "### required qubits estimation ##############\n",
    "# NN weights\n",
    "\n",
    "numpy_weights = {}\n",
    "nw_list = [] \n",
    "nw_list_normal = []\n",
    "for name, param in model.state_dict().items():\n",
    "    numpy_weights[name] = param.cpu().numpy()\n",
    "for i in numpy_weights:\n",
    "    nw_list.append(list(numpy_weights[i].flatten()))\n",
    "for i in nw_list:\n",
    "    for j in i:\n",
    "        nw_list_normal.append(j)\n",
    "print(\"# of NN parameters: \", len(nw_list_normal))\n",
    "n_qubits = int(np.ceil(np.log2(len(nw_list_normal))))\n",
    "print(\"Required qubit number: \", n_qubits)\n",
    "\n",
    "n_qubit = n_qubits\n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Some tool function definition ###########\n",
    "def probs_to_weights(probs_):\n",
    "\n",
    "    new_state_dict = {}\n",
    "    data_iterator = probs_.view(-1)\n",
    "\n",
    "    for name, param in CNNModel().state_dict().items():\n",
    "        shape = param.shape\n",
    "        num_elements = param.numel()\n",
    "        chunk = data_iterator[:num_elements].reshape(shape)\n",
    "        new_state_dict[name] = chunk\n",
    "        data_iterator = data_iterator[num_elements:]\n",
    "        \n",
    "    return new_state_dict\n",
    "\n",
    "def generate_qubit_states_torch(n_qubit):\n",
    "    # Create a tensor of shape (2**n_qubit, n_qubit) with all possible combinations of 0 and 1\n",
    "    all_states = torch.cartesian_prod(*[torch.tensor([-1, 1]) for _ in range(n_qubit)])\n",
    "    return all_states\n",
    "\n",
    "#############################################\n",
    "\n",
    "### Main Learning-wise Hybridization model ##\n",
    "\n",
    "class LewHybridNN(nn.Module):\n",
    "    class QLayer(nn.Module):\n",
    "        def __init__(self, n_blocks):\n",
    "            super().__init__()\n",
    "            self.n_wires = int(np.ceil(np.log2(len(nw_list_normal)))),\n",
    "            self.n_wires = self.n_wires[0]\n",
    "            self.n_blocks = n_blocks\n",
    "            self.u3_layers = tq.QuantumModuleList()\n",
    "            self.cu3_layers = tq.QuantumModuleList()\n",
    "            # self.measure = tq.MeasureAll(tq.PauliZ)\n",
    "            for _ in range(self.n_blocks):\n",
    "                self.u3_layers.append(\n",
    "                    tq.Op1QAllLayer(\n",
    "                        op=tq.U3,\n",
    "                        n_wires=self.n_wires,\n",
    "                        has_params=True,\n",
    "                        trainable=True,\n",
    "                    )\n",
    "                )\n",
    "                self.cu3_layers.append(\n",
    "                    tq.Op2QAllLayer(\n",
    "                        op=tq.CU3,\n",
    "                        n_wires=self.n_wires,\n",
    "                        has_params=True,\n",
    "                        trainable=True,\n",
    "                        circular=True,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "        def forward(self):\n",
    "            qdev = tq.QuantumDevice(\n",
    "                n_wires=self.n_wires, bsz=1, device=next(self.parameters()).device\n",
    "            )\n",
    "            easy_scale_coeff = 2**(n_qubit-1)\n",
    "            gamma = 0.1\n",
    "            beta  = 0.8\n",
    "            alpha = 0.3\n",
    "            for k in range(self.n_blocks):\n",
    "                self.u3_layers[k](qdev)\n",
    "                self.cu3_layers[k](qdev)\n",
    "                \n",
    "            state_mag = qdev.get_states_1d().abs()[0] \n",
    "            state_mag = state_mag[:len(nw_list_normal)]\n",
    "            x = torch.abs(state_mag) ** 2\n",
    "\n",
    "            state_mag = state_mag[:len(nw_list_normal)]\n",
    "            x = torch.abs(state_mag) ** 2\n",
    "            # x = torch.log(x)\n",
    "            x = x.reshape(len(nw_list_normal),1)\n",
    "            x = (beta*torch.tanh(gamma*easy_scale_coeff*x))**(alpha) \n",
    "            x = x - torch.mean(x)\n",
    "            x.to(device)\n",
    "            return x\n",
    "\n",
    "    def train_with_shots(shots, epochs=1):\n",
    "    model = LewHybridNN(shots=shots).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "\n",
    "    acc_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "\n",
    "            loss = criterion(outputs, labels_one_hot)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        acc_list.append(acc)\n",
    "        print(f\"[Shots={shots}] Epoch {epoch+1}: Accuracy = {acc:.2f}%\")\n",
    "\n",
    "    return acc_list[-1]\n",
    "\n",
    "        \n",
    "    class MappingModel(nn.Module):\n",
    "        def __init__(self, input_size, hidden_sizes, output_size):\n",
    "            super().__init__()\n",
    "            # Initialize layers: an input layer, multiple hidden layers, and an output layer\n",
    "            self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)])\n",
    "            self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "            \n",
    "        def forward(self, X):\n",
    "            # Ensure the input tensor is the same type as the weights\n",
    "            X = X.type_as(self.input_layer.weight)\n",
    "\n",
    "            # Input layer with ReLU activation\n",
    "            X = self.input_layer(X)\n",
    "\n",
    "            # Hidden layers with ReLU activation\n",
    "            for hidden in self.hidden_layers:\n",
    "                X = hidden(X)\n",
    "\n",
    "            # Output layer with linear activation\n",
    "            output = self.output_layer(X)\n",
    "            # output = F.tanh(output)  # It's often better to use ReLU or similar; tanh is used here as it was in the original model.\n",
    "            return output\n",
    "\n",
    "    def __init__(self, shots=8192):  # ← allow external config\n",
    "    super().__init__()\n",
    "    self.MappingNetwork = self.MappingModel(n_qubit + 1, [4, 20, 4], 1).to(device)\n",
    "    self.QuantumNN = self.QLayer(q_depth, shots=shots).to(device)  # ← pass shots in\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defining how tensors are supposed to move through the *dressed* quantum\n",
    "        net.\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "\n",
    "        probs_ = self.QuantumNN()\n",
    "        probs_ = probs_[:len(nw_list_normal)]\n",
    "        \n",
    "        # Generate qubit states using PyTorch\n",
    "        qubit_states_torch = generate_qubit_states_torch(n_qubit)[:len(nw_list_normal)]\n",
    "        qubit_states_torch = qubit_states_torch.to(device)\n",
    "\n",
    "        # Combine qubit states with probability values using PyTorch\n",
    "        combined_data_torch = torch.cat((qubit_states_torch, probs_), dim=1)\n",
    "        combined_data_torch = combined_data_torch.reshape(len(nw_list_normal), 1, n_qubit+1)\n",
    "        \n",
    "        prob_val_post_processed = self.MappingNetwork(combined_data_torch)\n",
    "        prob_val_post_processed = prob_val_post_processed - prob_val_post_processed.mean()\n",
    "        \n",
    "        state_dict = probs_to_weights(prob_val_post_processed)\n",
    "\n",
    "        ######## \n",
    "            \n",
    "        dtype = torch.float32  # Ensure all tensors are of this type\n",
    "        \n",
    "        # Convolution layer 1 parameters\n",
    "        conv1_weight = state_dict['conv1.weight'].to(device).type(dtype)\n",
    "        conv1_bias = state_dict['conv1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Convolution layer 2 parameters\n",
    "        conv2_weight = state_dict['conv2.weight'].to(device).type(dtype)\n",
    "        conv2_bias = state_dict['conv2.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 1 parameters\n",
    "        fc1_weight = state_dict['fc1.weight'].to(device).type(dtype)\n",
    "        fc1_bias = state_dict['fc1.bias'].to(device).type(dtype)\n",
    "\n",
    "        # Fully connected layer 2 parameters\n",
    "        fc2_weight = state_dict['fc2.weight'].to(device).type(dtype)\n",
    "        fc2_bias = state_dict['fc2.bias'].to(device).type(dtype)\n",
    "        \n",
    "        \n",
    "        # Convolution 1\n",
    "        x = F.conv2d(x, conv1_weight, conv1_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Convolution 2\n",
    "        x = F.conv2d(x, conv2_weight, conv2_bias, stride=1)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected 1\n",
    "        x = F.linear(x, fc1_weight, fc1_bias)\n",
    "\n",
    "        # Fully connected 2\n",
    "        x = F.linear(x, fc2_weight, fc2_bias)\n",
    "\n",
    "    \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameter in Mapping model:  249\n",
      "# of trainable parameter in QNN model:  312\n",
      "# of trainable parameter in full model:  561\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Training setting ########################\n",
    "\n",
    "step = 1e-4                 # Learning rate\n",
    "batch_size = 32       # Number of samples for each training step\n",
    "num_epochs = 5             # Number of training epochs\n",
    "q_depth = 4             # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.1              # Initial spread of random quantum weights\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, move it to GPU, and set up loss function and optimizer\n",
    "model = LewHybridNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=step, weight_decay=1e-5, eps=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 5, factor = 0.5)  # 'min' because we're minimizing loss\n",
    "\n",
    "num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.MappingModel(n_qubit+1,  [4, 20, 4], 1).parameters() if p.requires_grad)\n",
    "# num_trainable_params_MM = sum(p.numel() for p in LewHybridNN.ConvMappingModel().parameters() if p.requires_grad)\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"# of trainable parameter in Mapping model: \", num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in QNN model: \", num_trainable_params - num_trainable_params_MM)\n",
    "print(\"# of trainable parameter in full model: \", num_trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/1875], Loss: 59.1729, batch time: 1.68\n",
      "Epoch [1/5], Step [2/1875], Loss: 62.1174, batch time: 0.11\n",
      "Epoch [1/5], Step [3/1875], Loss: 58.3071, batch time: 0.13\n",
      "Epoch [1/5], Step [4/1875], Loss: 50.4235, batch time: 0.10\n",
      "Epoch [1/5], Step [5/1875], Loss: 38.0613, batch time: 0.13\n",
      "Epoch [1/5], Step [6/1875], Loss: 49.6909, batch time: 0.12\n",
      "Epoch [1/5], Step [7/1875], Loss: 51.6529, batch time: 0.13\n",
      "Epoch [1/5], Step [8/1875], Loss: 42.9288, batch time: 0.18\n",
      "Epoch [1/5], Step [9/1875], Loss: 44.1946, batch time: 0.11\n",
      "Epoch [1/5], Step [10/1875], Loss: 39.4623, batch time: 0.12\n",
      "Epoch [1/5], Step [11/1875], Loss: 46.2461, batch time: 0.14\n",
      "Epoch [1/5], Step [12/1875], Loss: 44.4344, batch time: 0.12\n",
      "Epoch [1/5], Step [13/1875], Loss: 36.4923, batch time: 0.12\n",
      "Epoch [1/5], Step [14/1875], Loss: 32.1761, batch time: 0.11\n",
      "Epoch [1/5], Step [15/1875], Loss: 37.4950, batch time: 0.19\n",
      "Epoch [1/5], Step [16/1875], Loss: 34.1649, batch time: 0.10\n",
      "Epoch [1/5], Step [17/1875], Loss: 31.4190, batch time: 0.12\n",
      "Epoch [1/5], Step [18/1875], Loss: 29.8377, batch time: 0.11\n",
      "Epoch [1/5], Step [19/1875], Loss: 26.1036, batch time: 0.13\n",
      "Epoch [1/5], Step [20/1875], Loss: 30.8213, batch time: 0.17\n",
      "Epoch [1/5], Step [21/1875], Loss: 24.3712, batch time: 0.14\n",
      "Epoch [1/5], Step [22/1875], Loss: 28.1814, batch time: 0.15\n",
      "Epoch [1/5], Step [23/1875], Loss: 28.6449, batch time: 0.10\n",
      "Epoch [1/5], Step [24/1875], Loss: 26.6900, batch time: 0.12\n",
      "Epoch [1/5], Step [25/1875], Loss: 23.3815, batch time: 0.12\n",
      "Epoch [1/5], Step [26/1875], Loss: 22.2925, batch time: 0.12\n",
      "Epoch [1/5], Step [27/1875], Loss: 19.6697, batch time: 0.19\n",
      "Epoch [1/5], Step [28/1875], Loss: 21.9860, batch time: 0.14\n",
      "Epoch [1/5], Step [29/1875], Loss: 20.5919, batch time: 0.14\n",
      "Epoch [1/5], Step [30/1875], Loss: 17.7242, batch time: 0.13\n",
      "Epoch [1/5], Step [31/1875], Loss: 17.5780, batch time: 0.11\n",
      "Epoch [1/5], Step [32/1875], Loss: 19.2371, batch time: 0.15\n",
      "Epoch [1/5], Step [33/1875], Loss: 16.1074, batch time: 0.10\n",
      "Epoch [1/5], Step [34/1875], Loss: 17.9197, batch time: 0.12\n",
      "Epoch [1/5], Step [35/1875], Loss: 15.5757, batch time: 0.19\n",
      "Epoch [1/5], Step [36/1875], Loss: 15.9538, batch time: 0.20\n",
      "Epoch [1/5], Step [37/1875], Loss: 17.1676, batch time: 0.10\n",
      "Epoch [1/5], Step [38/1875], Loss: 13.5108, batch time: 0.10\n",
      "Epoch [1/5], Step [39/1875], Loss: 14.8912, batch time: 0.25\n",
      "Epoch [1/5], Step [40/1875], Loss: 13.8793, batch time: 0.14\n",
      "Epoch [1/5], Step [41/1875], Loss: 14.8903, batch time: 0.10\n",
      "Epoch [1/5], Step [42/1875], Loss: 11.8820, batch time: 0.10\n",
      "Epoch [1/5], Step [43/1875], Loss: 13.4425, batch time: 0.10\n",
      "Epoch [1/5], Step [44/1875], Loss: 11.3599, batch time: 0.11\n",
      "Epoch [1/5], Step [45/1875], Loss: 9.7444, batch time: 0.11\n",
      "Epoch [1/5], Step [46/1875], Loss: 10.0408, batch time: 0.14\n",
      "Epoch [1/5], Step [47/1875], Loss: 9.8003, batch time: 0.19\n",
      "Epoch [1/5], Step [48/1875], Loss: 12.0814, batch time: 0.10\n",
      "Epoch [1/5], Step [49/1875], Loss: 10.2489, batch time: 0.10\n",
      "Epoch [1/5], Step [50/1875], Loss: 9.6168, batch time: 0.14\n",
      "Epoch [1/5], Step [51/1875], Loss: 11.6816, batch time: 0.13\n",
      "Epoch [1/5], Step [52/1875], Loss: 8.3233, batch time: 0.10\n",
      "Epoch [1/5], Step [53/1875], Loss: 7.9694, batch time: 0.10\n",
      "Epoch [1/5], Step [54/1875], Loss: 9.5844, batch time: 0.20\n",
      "Epoch [1/5], Step [55/1875], Loss: 7.7553, batch time: 0.11\n",
      "Epoch [1/5], Step [56/1875], Loss: 8.6499, batch time: 0.16\n",
      "Epoch [1/5], Step [57/1875], Loss: 8.7999, batch time: 0.16\n",
      "Epoch [1/5], Step [58/1875], Loss: 7.1549, batch time: 0.12\n",
      "Epoch [1/5], Step [59/1875], Loss: 7.3856, batch time: 0.10\n",
      "Epoch [1/5], Step [60/1875], Loss: 7.1840, batch time: 0.12\n",
      "Epoch [1/5], Step [61/1875], Loss: 6.4564, batch time: 0.17\n",
      "Epoch [1/5], Step [62/1875], Loss: 6.1250, batch time: 0.10\n",
      "Epoch [1/5], Step [63/1875], Loss: 6.5897, batch time: 0.10\n",
      "Epoch [1/5], Step [64/1875], Loss: 7.0678, batch time: 0.13\n",
      "Epoch [1/5], Step [65/1875], Loss: 5.9360, batch time: 0.10\n",
      "Epoch [1/5], Step [66/1875], Loss: 5.3350, batch time: 0.10\n",
      "Epoch [1/5], Step [67/1875], Loss: 4.8972, batch time: 0.11\n",
      "Epoch [1/5], Step [68/1875], Loss: 5.2694, batch time: 0.12\n",
      "Epoch [1/5], Step [69/1875], Loss: 5.3734, batch time: 0.13\n",
      "Epoch [1/5], Step [70/1875], Loss: 4.6314, batch time: 0.18\n",
      "Epoch [1/5], Step [71/1875], Loss: 5.3085, batch time: 0.14\n",
      "Epoch [1/5], Step [72/1875], Loss: 4.1725, batch time: 0.13\n",
      "Epoch [1/5], Step [73/1875], Loss: 3.7927, batch time: 0.10\n",
      "Epoch [1/5], Step [74/1875], Loss: 3.9385, batch time: 0.10\n",
      "Epoch [1/5], Step [75/1875], Loss: 3.9565, batch time: 0.14\n",
      "Epoch [1/5], Step [76/1875], Loss: 4.0100, batch time: 0.12\n",
      "Epoch [1/5], Step [77/1875], Loss: 3.7597, batch time: 0.10\n",
      "Epoch [1/5], Step [78/1875], Loss: 3.9273, batch time: 0.12\n",
      "Epoch [1/5], Step [79/1875], Loss: 3.3618, batch time: 0.17\n",
      "Epoch [1/5], Step [80/1875], Loss: 4.1019, batch time: 0.16\n",
      "Epoch [1/5], Step [81/1875], Loss: 3.7236, batch time: 0.13\n",
      "Epoch [1/5], Step [82/1875], Loss: 3.7534, batch time: 0.10\n",
      "Epoch [1/5], Step [83/1875], Loss: 3.5290, batch time: 0.14\n",
      "Epoch [1/5], Step [84/1875], Loss: 3.3783, batch time: 0.10\n",
      "Epoch [1/5], Step [85/1875], Loss: 3.1334, batch time: 0.17\n",
      "Epoch [1/5], Step [86/1875], Loss: 3.4256, batch time: 0.12\n",
      "Epoch [1/5], Step [87/1875], Loss: 3.5884, batch time: 0.11\n",
      "Epoch [1/5], Step [88/1875], Loss: 3.3201, batch time: 0.10\n",
      "Epoch [1/5], Step [89/1875], Loss: 2.9521, batch time: 0.14\n",
      "Epoch [1/5], Step [90/1875], Loss: 3.5208, batch time: 0.10\n",
      "Epoch [1/5], Step [91/1875], Loss: 3.7239, batch time: 0.14\n",
      "Epoch [1/5], Step [92/1875], Loss: 2.8495, batch time: 0.10\n",
      "Epoch [1/5], Step [93/1875], Loss: 3.6332, batch time: 0.10\n",
      "Epoch [1/5], Step [94/1875], Loss: 2.9980, batch time: -2.82\n",
      "Epoch [1/5], Step [95/1875], Loss: 3.1526, batch time: 0.10\n",
      "Epoch [1/5], Step [96/1875], Loss: 3.1048, batch time: 0.10\n",
      "Epoch [1/5], Step [97/1875], Loss: 3.0368, batch time: 0.13\n",
      "Epoch [1/5], Step [98/1875], Loss: 3.3876, batch time: 0.13\n",
      "Epoch [1/5], Step [99/1875], Loss: 3.1650, batch time: 0.13\n",
      "Epoch [1/5], Step [100/1875], Loss: 3.5427, batch time: 0.10\n",
      "Epoch [1/5], Step [101/1875], Loss: 2.9064, batch time: 0.13\n",
      "Epoch [1/5], Step [102/1875], Loss: 3.0438, batch time: 0.14\n",
      "Epoch [1/5], Step [103/1875], Loss: 3.3767, batch time: 0.13\n",
      "Epoch [1/5], Step [104/1875], Loss: 3.0667, batch time: 0.10\n",
      "Epoch [1/5], Step [105/1875], Loss: 3.0679, batch time: 0.16\n",
      "Epoch [1/5], Step [106/1875], Loss: 2.8101, batch time: 0.13\n",
      "Epoch [1/5], Step [107/1875], Loss: 3.0363, batch time: 0.11\n",
      "Epoch [1/5], Step [108/1875], Loss: 2.8810, batch time: 0.12\n",
      "Epoch [1/5], Step [109/1875], Loss: 3.1827, batch time: 0.11\n",
      "Epoch [1/5], Step [110/1875], Loss: 3.2149, batch time: 0.13\n",
      "Epoch [1/5], Step [111/1875], Loss: 2.7987, batch time: 0.13\n",
      "Epoch [1/5], Step [112/1875], Loss: 3.0528, batch time: 0.14\n",
      "Epoch [1/5], Step [113/1875], Loss: 2.8937, batch time: 0.14\n",
      "Epoch [1/5], Step [114/1875], Loss: 3.0181, batch time: 0.14\n",
      "Epoch [1/5], Step [115/1875], Loss: 3.0014, batch time: 0.16\n",
      "Epoch [1/5], Step [116/1875], Loss: 3.1730, batch time: 0.13\n",
      "Epoch [1/5], Step [117/1875], Loss: 2.7773, batch time: 0.14\n",
      "Epoch [1/5], Step [118/1875], Loss: 2.8157, batch time: 0.11\n",
      "Epoch [1/5], Step [119/1875], Loss: 2.7434, batch time: 0.10\n",
      "Epoch [1/5], Step [120/1875], Loss: 2.8524, batch time: 0.24\n",
      "Epoch [1/5], Step [121/1875], Loss: 2.6935, batch time: 0.11\n",
      "Epoch [1/5], Step [122/1875], Loss: 2.5779, batch time: 0.10\n",
      "Epoch [1/5], Step [123/1875], Loss: 2.8018, batch time: 0.14\n",
      "Epoch [1/5], Step [124/1875], Loss: 3.0475, batch time: 0.11\n",
      "Epoch [1/5], Step [125/1875], Loss: 2.5978, batch time: 0.12\n",
      "Epoch [1/5], Step [126/1875], Loss: 2.5629, batch time: 0.11\n",
      "Epoch [1/5], Step [127/1875], Loss: 2.9474, batch time: 0.10\n",
      "Epoch [1/5], Step [128/1875], Loss: 2.8467, batch time: 0.12\n",
      "Epoch [1/5], Step [129/1875], Loss: 2.9520, batch time: 0.12\n",
      "Epoch [1/5], Step [130/1875], Loss: 2.7744, batch time: 0.12\n",
      "Epoch [1/5], Step [131/1875], Loss: 2.6331, batch time: 0.10\n",
      "Epoch [1/5], Step [132/1875], Loss: 2.5760, batch time: 0.10\n",
      "Epoch [1/5], Step [133/1875], Loss: 2.9696, batch time: 0.13\n",
      "Epoch [1/5], Step [134/1875], Loss: 2.4616, batch time: 0.14\n",
      "Epoch [1/5], Step [135/1875], Loss: 2.7504, batch time: 0.10\n",
      "Epoch [1/5], Step [136/1875], Loss: 2.9600, batch time: 0.10\n",
      "Epoch [1/5], Step [137/1875], Loss: 2.6772, batch time: 0.10\n",
      "Epoch [1/5], Step [138/1875], Loss: 2.6111, batch time: 0.10\n",
      "Epoch [1/5], Step [139/1875], Loss: 2.7548, batch time: 0.12\n",
      "Epoch [1/5], Step [140/1875], Loss: 2.6744, batch time: 0.10\n",
      "Epoch [1/5], Step [141/1875], Loss: 2.7166, batch time: 0.11\n",
      "Epoch [1/5], Step [142/1875], Loss: 2.6397, batch time: 0.10\n",
      "Epoch [1/5], Step [143/1875], Loss: 2.6517, batch time: 0.10\n",
      "Epoch [1/5], Step [144/1875], Loss: 2.5413, batch time: 0.10\n",
      "Epoch [1/5], Step [145/1875], Loss: 2.2418, batch time: 0.10\n",
      "Epoch [1/5], Step [146/1875], Loss: 2.4542, batch time: 0.10\n",
      "Epoch [1/5], Step [147/1875], Loss: 2.6328, batch time: 0.11\n",
      "Epoch [1/5], Step [148/1875], Loss: 2.5015, batch time: 0.13\n",
      "Epoch [1/5], Step [149/1875], Loss: 2.7010, batch time: 0.10\n",
      "Epoch [1/5], Step [150/1875], Loss: 2.5379, batch time: 0.10\n",
      "Epoch [1/5], Step [151/1875], Loss: 2.5261, batch time: 0.13\n",
      "Epoch [1/5], Step [152/1875], Loss: 2.6444, batch time: 0.10\n",
      "Epoch [1/5], Step [153/1875], Loss: 2.5519, batch time: 0.10\n",
      "Epoch [1/5], Step [154/1875], Loss: 2.7047, batch time: 0.11\n",
      "Epoch [1/5], Step [155/1875], Loss: 2.9819, batch time: 0.10\n",
      "Epoch [1/5], Step [156/1875], Loss: 2.7493, batch time: 0.12\n",
      "Epoch [1/5], Step [157/1875], Loss: 2.6087, batch time: 0.10\n",
      "Epoch [1/5], Step [158/1875], Loss: 2.4792, batch time: 0.13\n",
      "Epoch [1/5], Step [159/1875], Loss: 2.7428, batch time: 0.10\n",
      "Epoch [1/5], Step [160/1875], Loss: 2.5540, batch time: 0.12\n",
      "Epoch [1/5], Step [161/1875], Loss: 2.5048, batch time: 0.16\n",
      "Epoch [1/5], Step [162/1875], Loss: 2.5877, batch time: 0.10\n",
      "Epoch [1/5], Step [163/1875], Loss: 2.7188, batch time: 0.11\n",
      "Epoch [1/5], Step [164/1875], Loss: 2.6676, batch time: 0.15\n",
      "Epoch [1/5], Step [165/1875], Loss: 2.7339, batch time: 0.17\n",
      "Epoch [1/5], Step [166/1875], Loss: 2.7281, batch time: 0.12\n",
      "Epoch [1/5], Step [167/1875], Loss: 2.9471, batch time: 0.10\n",
      "Epoch [1/5], Step [168/1875], Loss: 2.5250, batch time: 0.10\n",
      "Epoch [1/5], Step [169/1875], Loss: 2.4575, batch time: 0.10\n",
      "Epoch [1/5], Step [170/1875], Loss: 2.8886, batch time: 0.13\n",
      "Epoch [1/5], Step [171/1875], Loss: 2.4409, batch time: 0.18\n",
      "Epoch [1/5], Step [172/1875], Loss: 2.5133, batch time: 0.12\n",
      "Epoch [1/5], Step [173/1875], Loss: 2.4210, batch time: 0.10\n",
      "Epoch [1/5], Step [174/1875], Loss: 2.4984, batch time: 0.12\n",
      "Epoch [1/5], Step [175/1875], Loss: 2.6112, batch time: 0.12\n",
      "Epoch [1/5], Step [176/1875], Loss: 2.3621, batch time: 0.10\n",
      "Epoch [1/5], Step [177/1875], Loss: 2.7197, batch time: 0.12\n",
      "Epoch [1/5], Step [178/1875], Loss: 2.7974, batch time: 0.10\n",
      "Epoch [1/5], Step [179/1875], Loss: 2.5189, batch time: 0.12\n",
      "Epoch [1/5], Step [180/1875], Loss: 2.5833, batch time: 0.10\n",
      "Epoch [1/5], Step [181/1875], Loss: 2.4168, batch time: 0.13\n",
      "Epoch [1/5], Step [182/1875], Loss: 2.5470, batch time: 0.10\n",
      "Epoch [1/5], Step [183/1875], Loss: 2.6590, batch time: 0.14\n",
      "Epoch [1/5], Step [184/1875], Loss: 2.5767, batch time: 0.10\n",
      "Epoch [1/5], Step [185/1875], Loss: 2.3516, batch time: 0.11\n",
      "Epoch [1/5], Step [186/1875], Loss: 2.5179, batch time: 0.11\n",
      "Epoch [1/5], Step [187/1875], Loss: 2.7665, batch time: 0.10\n",
      "Epoch [1/5], Step [188/1875], Loss: 2.6129, batch time: 0.17\n",
      "Epoch [1/5], Step [189/1875], Loss: 2.7518, batch time: 0.10\n",
      "Epoch [1/5], Step [190/1875], Loss: 2.5872, batch time: 0.11\n",
      "Epoch [1/5], Step [191/1875], Loss: 2.6971, batch time: 0.10\n",
      "Epoch [1/5], Step [192/1875], Loss: 2.3885, batch time: 0.11\n",
      "Epoch [1/5], Step [193/1875], Loss: 2.5855, batch time: 0.11\n",
      "Epoch [1/5], Step [194/1875], Loss: 2.3923, batch time: 0.11\n",
      "Epoch [1/5], Step [195/1875], Loss: 2.4775, batch time: 0.12\n",
      "Epoch [1/5], Step [196/1875], Loss: 2.7588, batch time: 0.10\n",
      "Epoch [1/5], Step [197/1875], Loss: 2.5309, batch time: 0.10\n",
      "Epoch [1/5], Step [198/1875], Loss: 2.4516, batch time: 0.10\n",
      "Epoch [1/5], Step [199/1875], Loss: 2.4451, batch time: 0.13\n",
      "Epoch [1/5], Step [200/1875], Loss: 2.4207, batch time: 0.10\n",
      "Epoch [1/5], Step [201/1875], Loss: 2.5793, batch time: 0.10\n",
      "Epoch [1/5], Step [202/1875], Loss: 2.5297, batch time: 0.10\n",
      "Epoch [1/5], Step [203/1875], Loss: 2.4247, batch time: 0.13\n",
      "Epoch [1/5], Step [204/1875], Loss: 2.5540, batch time: 0.10\n",
      "Epoch [1/5], Step [205/1875], Loss: 2.5979, batch time: 0.12\n",
      "Epoch [1/5], Step [206/1875], Loss: 2.2683, batch time: 0.14\n",
      "Epoch [1/5], Step [207/1875], Loss: 2.4318, batch time: 0.10\n",
      "Epoch [1/5], Step [208/1875], Loss: 2.6745, batch time: 0.10\n",
      "Epoch [1/5], Step [209/1875], Loss: 2.6459, batch time: 0.11\n",
      "Epoch [1/5], Step [210/1875], Loss: 2.5381, batch time: 0.16\n",
      "Epoch [1/5], Step [211/1875], Loss: 2.5341, batch time: 0.12\n",
      "Epoch [1/5], Step [212/1875], Loss: 2.4930, batch time: 0.14\n",
      "Epoch [1/5], Step [213/1875], Loss: 2.3264, batch time: 0.12\n",
      "Epoch [1/5], Step [214/1875], Loss: 2.3586, batch time: 0.10\n",
      "Epoch [1/5], Step [215/1875], Loss: 2.5081, batch time: 0.10\n",
      "Epoch [1/5], Step [216/1875], Loss: 2.4269, batch time: 0.10\n",
      "Epoch [1/5], Step [217/1875], Loss: 2.3751, batch time: 0.17\n",
      "Epoch [1/5], Step [218/1875], Loss: 2.5060, batch time: 0.10\n",
      "Epoch [1/5], Step [219/1875], Loss: 2.5256, batch time: 0.13\n",
      "Epoch [1/5], Step [220/1875], Loss: 2.3007, batch time: 0.37\n",
      "Epoch [1/5], Step [221/1875], Loss: 2.4404, batch time: 0.12\n",
      "Epoch [1/5], Step [222/1875], Loss: 2.8311, batch time: 0.10\n",
      "Epoch [1/5], Step [223/1875], Loss: 2.5741, batch time: 0.11\n",
      "Epoch [1/5], Step [224/1875], Loss: 2.5373, batch time: 0.10\n",
      "Epoch [1/5], Step [225/1875], Loss: 2.5414, batch time: 0.10\n",
      "Epoch [1/5], Step [226/1875], Loss: 2.3895, batch time: 0.10\n",
      "Epoch [1/5], Step [227/1875], Loss: 2.4036, batch time: 0.17\n",
      "Epoch [1/5], Step [228/1875], Loss: 2.5050, batch time: 0.12\n",
      "Epoch [1/5], Step [229/1875], Loss: 2.4691, batch time: 0.11\n",
      "Epoch [1/5], Step [230/1875], Loss: 2.5519, batch time: 0.11\n",
      "Epoch [1/5], Step [231/1875], Loss: 2.5960, batch time: 0.13\n",
      "Epoch [1/5], Step [232/1875], Loss: 2.6100, batch time: 0.10\n",
      "Epoch [1/5], Step [233/1875], Loss: 2.6071, batch time: 0.10\n",
      "Epoch [1/5], Step [234/1875], Loss: 2.5985, batch time: 0.10\n",
      "Epoch [1/5], Step [235/1875], Loss: 2.4089, batch time: 0.13\n",
      "Epoch [1/5], Step [236/1875], Loss: 2.7449, batch time: 0.10\n",
      "Epoch [1/5], Step [237/1875], Loss: 2.3893, batch time: 0.18\n",
      "Epoch [1/5], Step [238/1875], Loss: 2.5065, batch time: 0.11\n",
      "Epoch [1/5], Step [239/1875], Loss: 2.4907, batch time: 0.13\n",
      "Epoch [1/5], Step [240/1875], Loss: 2.5014, batch time: 0.14\n",
      "Epoch [1/5], Step [241/1875], Loss: 2.4766, batch time: 0.10\n",
      "Epoch [1/5], Step [242/1875], Loss: 2.5193, batch time: 0.10\n",
      "Epoch [1/5], Step [243/1875], Loss: 2.4612, batch time: 0.10\n",
      "Epoch [1/5], Step [244/1875], Loss: 2.2898, batch time: 0.10\n",
      "Epoch [1/5], Step [245/1875], Loss: 2.4962, batch time: 0.11\n",
      "Epoch [1/5], Step [246/1875], Loss: 2.4361, batch time: 0.10\n",
      "Epoch [1/5], Step [247/1875], Loss: 2.5710, batch time: 0.18\n",
      "Epoch [1/5], Step [248/1875], Loss: 2.4054, batch time: 0.09\n",
      "Epoch [1/5], Step [249/1875], Loss: 2.6577, batch time: 0.11\n",
      "Epoch [1/5], Step [250/1875], Loss: 2.5854, batch time: 0.10\n",
      "Epoch [1/5], Step [251/1875], Loss: 2.3645, batch time: 0.10\n",
      "Epoch [1/5], Step [252/1875], Loss: 2.3757, batch time: 0.10\n",
      "Epoch [1/5], Step [253/1875], Loss: 2.4290, batch time: 0.11\n",
      "Epoch [1/5], Step [254/1875], Loss: 2.4642, batch time: 0.10\n",
      "Epoch [1/5], Step [255/1875], Loss: 2.4224, batch time: 0.15\n",
      "Epoch [1/5], Step [256/1875], Loss: 2.3135, batch time: 0.10\n",
      "Epoch [1/5], Step [257/1875], Loss: 2.4595, batch time: 0.10\n",
      "Epoch [1/5], Step [258/1875], Loss: 2.4247, batch time: 0.13\n",
      "Epoch [1/5], Step [259/1875], Loss: 2.4035, batch time: 0.14\n",
      "Epoch [1/5], Step [260/1875], Loss: 2.5170, batch time: 0.10\n",
      "Epoch [1/5], Step [261/1875], Loss: 2.3013, batch time: 0.10\n",
      "Epoch [1/5], Step [262/1875], Loss: 2.4173, batch time: 0.10\n",
      "Epoch [1/5], Step [263/1875], Loss: 2.5107, batch time: 0.10\n",
      "Epoch [1/5], Step [264/1875], Loss: 2.4133, batch time: 0.10\n",
      "Epoch [1/5], Step [265/1875], Loss: 2.5676, batch time: 0.10\n",
      "Epoch [1/5], Step [266/1875], Loss: 2.4716, batch time: 0.10\n",
      "Epoch [1/5], Step [267/1875], Loss: 2.3672, batch time: 0.11\n",
      "Epoch [1/5], Step [268/1875], Loss: 2.3804, batch time: 0.10\n",
      "Epoch [1/5], Step [269/1875], Loss: 2.4204, batch time: 0.11\n",
      "Epoch [1/5], Step [270/1875], Loss: 2.6314, batch time: 0.10\n",
      "Epoch [1/5], Step [271/1875], Loss: 2.5602, batch time: 0.15\n",
      "Epoch [1/5], Step [272/1875], Loss: 2.3638, batch time: 0.17\n",
      "Epoch [1/5], Step [273/1875], Loss: 2.5116, batch time: 0.10\n",
      "Epoch [1/5], Step [274/1875], Loss: 2.5498, batch time: 0.10\n",
      "Epoch [1/5], Step [275/1875], Loss: 2.4038, batch time: 0.12\n",
      "Epoch [1/5], Step [276/1875], Loss: 2.5064, batch time: 0.10\n",
      "Epoch [1/5], Step [277/1875], Loss: 2.7032, batch time: 0.10\n",
      "Epoch [1/5], Step [278/1875], Loss: 2.4355, batch time: 0.13\n",
      "Epoch [1/5], Step [279/1875], Loss: 2.4697, batch time: 0.12\n",
      "Epoch [1/5], Step [280/1875], Loss: 2.2666, batch time: 0.12\n",
      "Epoch [1/5], Step [281/1875], Loss: 2.4747, batch time: 0.10\n",
      "Epoch [1/5], Step [282/1875], Loss: 2.3844, batch time: 0.09\n",
      "Epoch [1/5], Step [283/1875], Loss: 2.4581, batch time: 0.10\n",
      "Epoch [1/5], Step [284/1875], Loss: 2.5309, batch time: 0.10\n",
      "Epoch [1/5], Step [285/1875], Loss: 2.4376, batch time: 0.10\n",
      "Epoch [1/5], Step [286/1875], Loss: 2.3780, batch time: 0.10\n",
      "Epoch [1/5], Step [287/1875], Loss: 2.6655, batch time: 0.14\n",
      "Epoch [1/5], Step [288/1875], Loss: 2.4722, batch time: 0.17\n",
      "Epoch [1/5], Step [289/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [1/5], Step [290/1875], Loss: 2.3495, batch time: 0.15\n",
      "Epoch [1/5], Step [291/1875], Loss: 2.3554, batch time: 0.11\n",
      "Epoch [1/5], Step [292/1875], Loss: 2.3636, batch time: 0.10\n",
      "Epoch [1/5], Step [293/1875], Loss: 2.4441, batch time: 0.10\n",
      "Epoch [1/5], Step [294/1875], Loss: 2.4541, batch time: 0.22\n",
      "Epoch [1/5], Step [295/1875], Loss: 2.3900, batch time: 0.13\n",
      "Epoch [1/5], Step [296/1875], Loss: 2.3731, batch time: 0.10\n",
      "Epoch [1/5], Step [297/1875], Loss: 2.4307, batch time: 0.17\n",
      "Epoch [1/5], Step [298/1875], Loss: 2.4477, batch time: 0.10\n",
      "Epoch [1/5], Step [299/1875], Loss: 2.4759, batch time: 0.10\n",
      "Epoch [1/5], Step [300/1875], Loss: 2.3833, batch time: 0.10\n",
      "Epoch [1/5], Step [301/1875], Loss: 2.3828, batch time: 0.10\n",
      "Epoch [1/5], Step [302/1875], Loss: 2.5634, batch time: 0.10\n",
      "Epoch [1/5], Step [303/1875], Loss: 2.4048, batch time: 0.10\n",
      "Epoch [1/5], Step [304/1875], Loss: 2.4706, batch time: 0.10\n",
      "Epoch [1/5], Step [305/1875], Loss: 2.1774, batch time: 0.10\n",
      "Epoch [1/5], Step [306/1875], Loss: 2.5475, batch time: 0.10\n",
      "Epoch [1/5], Step [307/1875], Loss: 2.3951, batch time: 0.10\n",
      "Epoch [1/5], Step [308/1875], Loss: 2.4572, batch time: 0.10\n",
      "Epoch [1/5], Step [309/1875], Loss: 2.3470, batch time: 0.10\n",
      "Epoch [1/5], Step [310/1875], Loss: 2.5267, batch time: 0.10\n",
      "Epoch [1/5], Step [311/1875], Loss: 2.2936, batch time: 0.10\n",
      "Epoch [1/5], Step [312/1875], Loss: 2.4728, batch time: 0.10\n",
      "Epoch [1/5], Step [313/1875], Loss: 2.3107, batch time: 0.10\n",
      "Epoch [1/5], Step [314/1875], Loss: 2.4705, batch time: 0.11\n",
      "Epoch [1/5], Step [315/1875], Loss: 2.3327, batch time: 0.09\n",
      "Epoch [1/5], Step [316/1875], Loss: 2.5102, batch time: 0.11\n",
      "Epoch [1/5], Step [317/1875], Loss: 2.4469, batch time: 0.10\n",
      "Epoch [1/5], Step [318/1875], Loss: 2.4845, batch time: 0.11\n",
      "Epoch [1/5], Step [319/1875], Loss: 2.4777, batch time: 0.10\n",
      "Epoch [1/5], Step [320/1875], Loss: 2.4129, batch time: 0.11\n",
      "Epoch [1/5], Step [321/1875], Loss: 2.3252, batch time: 0.11\n",
      "Epoch [1/5], Step [322/1875], Loss: 2.3631, batch time: 0.10\n",
      "Epoch [1/5], Step [323/1875], Loss: 2.4183, batch time: 0.10\n",
      "Epoch [1/5], Step [324/1875], Loss: 2.3676, batch time: 0.10\n",
      "Epoch [1/5], Step [325/1875], Loss: 2.3575, batch time: 0.10\n",
      "Epoch [1/5], Step [326/1875], Loss: 2.6022, batch time: 0.10\n",
      "Epoch [1/5], Step [327/1875], Loss: 2.3234, batch time: 0.12\n",
      "Epoch [1/5], Step [328/1875], Loss: 2.4767, batch time: 0.10\n",
      "Epoch [1/5], Step [329/1875], Loss: 2.5100, batch time: 0.10\n",
      "Epoch [1/5], Step [330/1875], Loss: 2.5193, batch time: 0.10\n",
      "Epoch [1/5], Step [331/1875], Loss: 2.4510, batch time: 0.10\n",
      "Epoch [1/5], Step [332/1875], Loss: 2.3633, batch time: 0.10\n",
      "Epoch [1/5], Step [333/1875], Loss: 2.3536, batch time: 0.10\n",
      "Epoch [1/5], Step [334/1875], Loss: 2.3994, batch time: 0.10\n",
      "Epoch [1/5], Step [335/1875], Loss: 2.3618, batch time: 0.12\n",
      "Epoch [1/5], Step [336/1875], Loss: 2.5722, batch time: 0.24\n",
      "Epoch [1/5], Step [337/1875], Loss: 2.4911, batch time: 0.10\n",
      "Epoch [1/5], Step [338/1875], Loss: 2.4054, batch time: 0.10\n",
      "Epoch [1/5], Step [339/1875], Loss: 2.4999, batch time: 0.10\n",
      "Epoch [1/5], Step [340/1875], Loss: 2.2628, batch time: 0.10\n",
      "Epoch [1/5], Step [341/1875], Loss: 2.4821, batch time: 0.10\n",
      "Epoch [1/5], Step [342/1875], Loss: 2.3287, batch time: 0.11\n",
      "Epoch [1/5], Step [343/1875], Loss: 2.4796, batch time: 0.10\n",
      "Epoch [1/5], Step [344/1875], Loss: 2.4610, batch time: 0.10\n",
      "Epoch [1/5], Step [345/1875], Loss: 2.4468, batch time: 0.12\n",
      "Epoch [1/5], Step [346/1875], Loss: 2.4827, batch time: 0.10\n",
      "Epoch [1/5], Step [347/1875], Loss: 2.4308, batch time: 0.10\n",
      "Epoch [1/5], Step [348/1875], Loss: 2.4015, batch time: 0.10\n",
      "Epoch [1/5], Step [349/1875], Loss: 2.2646, batch time: 0.10\n",
      "Epoch [1/5], Step [350/1875], Loss: 2.4873, batch time: 0.10\n",
      "Epoch [1/5], Step [351/1875], Loss: 2.3447, batch time: 0.11\n",
      "Epoch [1/5], Step [352/1875], Loss: 2.3391, batch time: 0.10\n",
      "Epoch [1/5], Step [353/1875], Loss: 2.3741, batch time: 0.10\n",
      "Epoch [1/5], Step [354/1875], Loss: 2.4217, batch time: 0.17\n",
      "Epoch [1/5], Step [355/1875], Loss: 2.3853, batch time: 0.10\n",
      "Epoch [1/5], Step [356/1875], Loss: 2.3852, batch time: 0.10\n",
      "Epoch [1/5], Step [357/1875], Loss: 2.2859, batch time: 0.14\n",
      "Epoch [1/5], Step [358/1875], Loss: 2.4150, batch time: 0.13\n",
      "Epoch [1/5], Step [359/1875], Loss: 2.4963, batch time: 0.14\n",
      "Epoch [1/5], Step [360/1875], Loss: 2.4917, batch time: 0.11\n",
      "Epoch [1/5], Step [361/1875], Loss: 2.5354, batch time: 0.13\n",
      "Epoch [1/5], Step [362/1875], Loss: 2.4310, batch time: 0.19\n",
      "Epoch [1/5], Step [363/1875], Loss: 2.4537, batch time: 0.11\n",
      "Epoch [1/5], Step [364/1875], Loss: 2.4786, batch time: 0.10\n",
      "Epoch [1/5], Step [365/1875], Loss: 2.3252, batch time: 0.10\n",
      "Epoch [1/5], Step [366/1875], Loss: 2.4033, batch time: 0.10\n",
      "Epoch [1/5], Step [367/1875], Loss: 2.4928, batch time: 0.10\n",
      "Epoch [1/5], Step [368/1875], Loss: 2.4232, batch time: 0.10\n",
      "Epoch [1/5], Step [369/1875], Loss: 2.4512, batch time: 0.13\n",
      "Epoch [1/5], Step [370/1875], Loss: 2.5372, batch time: -2.80\n",
      "Epoch [1/5], Step [371/1875], Loss: 2.4049, batch time: 0.12\n",
      "Epoch [1/5], Step [372/1875], Loss: 2.3690, batch time: 0.10\n",
      "Epoch [1/5], Step [373/1875], Loss: 2.4227, batch time: 0.10\n",
      "Epoch [1/5], Step [374/1875], Loss: 2.5285, batch time: 0.10\n",
      "Epoch [1/5], Step [375/1875], Loss: 2.3359, batch time: 0.10\n",
      "Epoch [1/5], Step [376/1875], Loss: 2.6004, batch time: 0.10\n",
      "Epoch [1/5], Step [377/1875], Loss: 2.4510, batch time: 0.10\n",
      "Epoch [1/5], Step [378/1875], Loss: 2.3298, batch time: 0.10\n",
      "Epoch [1/5], Step [379/1875], Loss: 2.4696, batch time: 0.12\n",
      "Epoch [1/5], Step [380/1875], Loss: 2.4381, batch time: 0.10\n",
      "Epoch [1/5], Step [381/1875], Loss: 2.3428, batch time: 0.10\n",
      "Epoch [1/5], Step [382/1875], Loss: 2.5412, batch time: 0.12\n",
      "Epoch [1/5], Step [383/1875], Loss: 2.4918, batch time: 0.10\n",
      "Epoch [1/5], Step [384/1875], Loss: 2.3543, batch time: 0.10\n",
      "Epoch [1/5], Step [385/1875], Loss: 2.2361, batch time: 0.10\n",
      "Epoch [1/5], Step [386/1875], Loss: 2.2569, batch time: 0.10\n",
      "Epoch [1/5], Step [387/1875], Loss: 2.4520, batch time: 0.11\n",
      "Epoch [1/5], Step [388/1875], Loss: 2.4239, batch time: 0.10\n",
      "Epoch [1/5], Step [389/1875], Loss: 2.2934, batch time: 0.10\n",
      "Epoch [1/5], Step [390/1875], Loss: 2.4228, batch time: 0.10\n",
      "Epoch [1/5], Step [391/1875], Loss: 2.6087, batch time: 0.10\n",
      "Epoch [1/5], Step [392/1875], Loss: 2.3964, batch time: 0.13\n",
      "Epoch [1/5], Step [393/1875], Loss: 2.4955, batch time: 0.10\n",
      "Epoch [1/5], Step [394/1875], Loss: 2.3459, batch time: 0.10\n",
      "Epoch [1/5], Step [395/1875], Loss: 2.4179, batch time: 0.11\n",
      "Epoch [1/5], Step [396/1875], Loss: 2.4316, batch time: 0.10\n",
      "Epoch [1/5], Step [397/1875], Loss: 2.4928, batch time: 0.10\n",
      "Epoch [1/5], Step [398/1875], Loss: 2.2766, batch time: 0.12\n",
      "Epoch [1/5], Step [399/1875], Loss: 2.5231, batch time: 0.10\n",
      "Epoch [1/5], Step [400/1875], Loss: 2.3763, batch time: 0.10\n",
      "Epoch [1/5], Step [401/1875], Loss: 2.4898, batch time: 0.10\n",
      "Epoch [1/5], Step [402/1875], Loss: 2.4382, batch time: 0.10\n",
      "Epoch [1/5], Step [403/1875], Loss: 2.4781, batch time: 0.10\n",
      "Epoch [1/5], Step [404/1875], Loss: 2.4063, batch time: 0.10\n",
      "Epoch [1/5], Step [405/1875], Loss: 2.3617, batch time: 0.11\n",
      "Epoch [1/5], Step [406/1875], Loss: 2.3955, batch time: 0.10\n",
      "Epoch [1/5], Step [407/1875], Loss: 2.3867, batch time: 0.18\n",
      "Epoch [1/5], Step [408/1875], Loss: 2.4069, batch time: 0.10\n",
      "Epoch [1/5], Step [409/1875], Loss: 2.5033, batch time: 0.10\n",
      "Epoch [1/5], Step [410/1875], Loss: 2.4472, batch time: 0.19\n",
      "Epoch [1/5], Step [411/1875], Loss: 2.3636, batch time: 0.14\n",
      "Epoch [1/5], Step [412/1875], Loss: 2.3581, batch time: 0.10\n",
      "Epoch [1/5], Step [413/1875], Loss: 2.4325, batch time: 0.10\n",
      "Epoch [1/5], Step [414/1875], Loss: 2.3712, batch time: 0.12\n",
      "Epoch [1/5], Step [415/1875], Loss: 2.3835, batch time: 0.10\n",
      "Epoch [1/5], Step [416/1875], Loss: 2.4165, batch time: 0.17\n",
      "Epoch [1/5], Step [417/1875], Loss: 2.3878, batch time: 0.10\n",
      "Epoch [1/5], Step [418/1875], Loss: 2.4168, batch time: 0.11\n",
      "Epoch [1/5], Step [419/1875], Loss: 2.4185, batch time: 0.18\n",
      "Epoch [1/5], Step [420/1875], Loss: 2.4270, batch time: 0.10\n",
      "Epoch [1/5], Step [421/1875], Loss: 2.3289, batch time: 0.09\n",
      "Epoch [1/5], Step [422/1875], Loss: 2.2978, batch time: 0.10\n",
      "Epoch [1/5], Step [423/1875], Loss: 2.3705, batch time: 0.10\n",
      "Epoch [1/5], Step [424/1875], Loss: 2.4473, batch time: 0.14\n",
      "Epoch [1/5], Step [425/1875], Loss: 2.5064, batch time: 0.10\n",
      "Epoch [1/5], Step [426/1875], Loss: 2.3426, batch time: 0.10\n",
      "Epoch [1/5], Step [427/1875], Loss: 2.4481, batch time: 0.10\n",
      "Epoch [1/5], Step [428/1875], Loss: 2.3086, batch time: 0.10\n",
      "Epoch [1/5], Step [429/1875], Loss: 2.3685, batch time: 0.10\n",
      "Epoch [1/5], Step [430/1875], Loss: 2.2979, batch time: 0.10\n",
      "Epoch [1/5], Step [431/1875], Loss: 2.3265, batch time: 0.10\n",
      "Epoch [1/5], Step [432/1875], Loss: 2.3781, batch time: 0.09\n",
      "Epoch [1/5], Step [433/1875], Loss: 2.3943, batch time: 0.10\n",
      "Epoch [1/5], Step [434/1875], Loss: 2.3923, batch time: 0.09\n",
      "Epoch [1/5], Step [435/1875], Loss: 2.4756, batch time: 0.10\n",
      "Epoch [1/5], Step [436/1875], Loss: 2.3697, batch time: 0.10\n",
      "Epoch [1/5], Step [437/1875], Loss: 2.3642, batch time: 0.10\n",
      "Epoch [1/5], Step [438/1875], Loss: 2.2577, batch time: 0.09\n",
      "Epoch [1/5], Step [439/1875], Loss: 2.4985, batch time: 0.10\n",
      "Epoch [1/5], Step [440/1875], Loss: 2.4584, batch time: 0.12\n",
      "Epoch [1/5], Step [441/1875], Loss: 2.3040, batch time: 0.10\n",
      "Epoch [1/5], Step [442/1875], Loss: 2.3935, batch time: 0.11\n",
      "Epoch [1/5], Step [443/1875], Loss: 2.4284, batch time: 0.10\n",
      "Epoch [1/5], Step [444/1875], Loss: 2.4089, batch time: 0.10\n",
      "Epoch [1/5], Step [445/1875], Loss: 2.4388, batch time: 0.10\n",
      "Epoch [1/5], Step [446/1875], Loss: 2.4048, batch time: 0.10\n",
      "Epoch [1/5], Step [447/1875], Loss: 2.5275, batch time: 0.10\n",
      "Epoch [1/5], Step [448/1875], Loss: 2.2833, batch time: 0.10\n",
      "Epoch [1/5], Step [449/1875], Loss: 2.4345, batch time: 0.10\n",
      "Epoch [1/5], Step [450/1875], Loss: 2.4474, batch time: 0.16\n",
      "Epoch [1/5], Step [451/1875], Loss: 2.3511, batch time: 0.10\n",
      "Epoch [1/5], Step [452/1875], Loss: 2.3490, batch time: 0.10\n",
      "Epoch [1/5], Step [453/1875], Loss: 2.4069, batch time: 0.10\n",
      "Epoch [1/5], Step [454/1875], Loss: 2.3089, batch time: 0.10\n",
      "Epoch [1/5], Step [455/1875], Loss: 2.3411, batch time: 0.10\n",
      "Epoch [1/5], Step [456/1875], Loss: 2.3165, batch time: 0.10\n",
      "Epoch [1/5], Step [457/1875], Loss: 2.2968, batch time: 0.10\n",
      "Epoch [1/5], Step [458/1875], Loss: 2.3012, batch time: 0.10\n",
      "Epoch [1/5], Step [459/1875], Loss: 2.3990, batch time: 0.10\n",
      "Epoch [1/5], Step [460/1875], Loss: 2.4221, batch time: 0.10\n",
      "Epoch [1/5], Step [461/1875], Loss: 2.5010, batch time: 0.14\n",
      "Epoch [1/5], Step [462/1875], Loss: 2.4255, batch time: 0.18\n",
      "Epoch [1/5], Step [463/1875], Loss: 2.4183, batch time: 0.11\n",
      "Epoch [1/5], Step [464/1875], Loss: 2.3383, batch time: 0.10\n",
      "Epoch [1/5], Step [465/1875], Loss: 2.4674, batch time: 0.10\n",
      "Epoch [1/5], Step [466/1875], Loss: 2.3292, batch time: 0.10\n",
      "Epoch [1/5], Step [467/1875], Loss: 2.3993, batch time: 0.10\n",
      "Epoch [1/5], Step [468/1875], Loss: 2.3443, batch time: 0.10\n",
      "Epoch [1/5], Step [469/1875], Loss: 2.4390, batch time: 0.14\n",
      "Epoch [1/5], Step [470/1875], Loss: 2.3540, batch time: 0.10\n",
      "Epoch [1/5], Step [471/1875], Loss: 2.3097, batch time: 0.10\n",
      "Epoch [1/5], Step [472/1875], Loss: 2.3665, batch time: 0.10\n",
      "Epoch [1/5], Step [473/1875], Loss: 2.3735, batch time: 0.10\n",
      "Epoch [1/5], Step [474/1875], Loss: 2.4598, batch time: 0.10\n",
      "Epoch [1/5], Step [475/1875], Loss: 2.3375, batch time: 0.17\n",
      "Epoch [1/5], Step [476/1875], Loss: 2.3883, batch time: 0.10\n",
      "Epoch [1/5], Step [477/1875], Loss: 2.3809, batch time: 0.10\n",
      "Epoch [1/5], Step [478/1875], Loss: 2.3870, batch time: 0.13\n",
      "Epoch [1/5], Step [479/1875], Loss: 2.2845, batch time: 0.10\n",
      "Epoch [1/5], Step [480/1875], Loss: 2.3313, batch time: 0.10\n",
      "Epoch [1/5], Step [481/1875], Loss: 2.3730, batch time: 0.10\n",
      "Epoch [1/5], Step [482/1875], Loss: 2.2366, batch time: 0.10\n",
      "Epoch [1/5], Step [483/1875], Loss: 2.4237, batch time: 0.11\n",
      "Epoch [1/5], Step [484/1875], Loss: 2.3854, batch time: 0.12\n",
      "Epoch [1/5], Step [485/1875], Loss: 2.2549, batch time: 0.10\n",
      "Epoch [1/5], Step [486/1875], Loss: 2.2920, batch time: 0.11\n",
      "Epoch [1/5], Step [487/1875], Loss: 2.3685, batch time: 0.14\n",
      "Epoch [1/5], Step [488/1875], Loss: 2.4290, batch time: 0.10\n",
      "Epoch [1/5], Step [489/1875], Loss: 2.4361, batch time: 0.10\n",
      "Epoch [1/5], Step [490/1875], Loss: 2.4291, batch time: 0.10\n",
      "Epoch [1/5], Step [491/1875], Loss: 2.3905, batch time: 0.10\n",
      "Epoch [1/5], Step [492/1875], Loss: 2.4965, batch time: 0.14\n",
      "Epoch [1/5], Step [493/1875], Loss: 2.2434, batch time: 0.10\n",
      "Epoch [1/5], Step [494/1875], Loss: 2.2887, batch time: 0.10\n",
      "Epoch [1/5], Step [495/1875], Loss: 2.3873, batch time: 0.10\n",
      "Epoch [1/5], Step [496/1875], Loss: 2.4242, batch time: 0.10\n",
      "Epoch [1/5], Step [497/1875], Loss: 2.4053, batch time: 0.10\n",
      "Epoch [1/5], Step [498/1875], Loss: 2.3440, batch time: 0.11\n",
      "Epoch [1/5], Step [499/1875], Loss: 2.4361, batch time: 0.14\n",
      "Epoch [1/5], Step [500/1875], Loss: 2.2605, batch time: 0.14\n",
      "Epoch [1/5], Step [501/1875], Loss: 2.3748, batch time: 0.13\n",
      "Epoch [1/5], Step [502/1875], Loss: 2.4176, batch time: 0.10\n",
      "Epoch [1/5], Step [503/1875], Loss: 2.3907, batch time: 0.10\n",
      "Epoch [1/5], Step [504/1875], Loss: 2.4076, batch time: 0.10\n",
      "Epoch [1/5], Step [505/1875], Loss: 2.4737, batch time: 0.10\n",
      "Epoch [1/5], Step [506/1875], Loss: 2.3782, batch time: 0.10\n",
      "Epoch [1/5], Step [507/1875], Loss: 2.4035, batch time: 0.10\n",
      "Epoch [1/5], Step [508/1875], Loss: 2.3693, batch time: 0.10\n",
      "Epoch [1/5], Step [509/1875], Loss: 2.3338, batch time: 0.13\n",
      "Epoch [1/5], Step [510/1875], Loss: 2.3527, batch time: 0.10\n",
      "Epoch [1/5], Step [511/1875], Loss: 2.2696, batch time: 0.10\n",
      "Epoch [1/5], Step [512/1875], Loss: 2.3323, batch time: 0.15\n",
      "Epoch [1/5], Step [513/1875], Loss: 2.4437, batch time: 0.10\n",
      "Epoch [1/5], Step [514/1875], Loss: 2.3714, batch time: 0.14\n",
      "Epoch [1/5], Step [515/1875], Loss: 2.2864, batch time: 0.14\n",
      "Epoch [1/5], Step [516/1875], Loss: 2.3514, batch time: 0.17\n",
      "Epoch [1/5], Step [517/1875], Loss: 2.4012, batch time: 0.10\n",
      "Epoch [1/5], Step [518/1875], Loss: 2.4262, batch time: 0.10\n",
      "Epoch [1/5], Step [519/1875], Loss: 2.4060, batch time: 0.10\n",
      "Epoch [1/5], Step [520/1875], Loss: 2.2380, batch time: 0.10\n",
      "Epoch [1/5], Step [521/1875], Loss: 2.4614, batch time: 0.19\n",
      "Epoch [1/5], Step [522/1875], Loss: 2.4622, batch time: 0.12\n",
      "Epoch [1/5], Step [523/1875], Loss: 2.3915, batch time: 0.14\n",
      "Epoch [1/5], Step [524/1875], Loss: 2.4380, batch time: 0.10\n",
      "Epoch [1/5], Step [525/1875], Loss: 2.3097, batch time: 0.12\n",
      "Epoch [1/5], Step [526/1875], Loss: 2.3904, batch time: 0.14\n",
      "Epoch [1/5], Step [527/1875], Loss: 2.3819, batch time: 0.14\n",
      "Epoch [1/5], Step [528/1875], Loss: 2.3544, batch time: 0.10\n",
      "Epoch [1/5], Step [529/1875], Loss: 2.3823, batch time: 0.14\n",
      "Epoch [1/5], Step [530/1875], Loss: 2.3701, batch time: 0.11\n",
      "Epoch [1/5], Step [531/1875], Loss: 2.3975, batch time: 0.12\n",
      "Epoch [1/5], Step [532/1875], Loss: 2.3639, batch time: 0.10\n",
      "Epoch [1/5], Step [533/1875], Loss: 2.3833, batch time: 0.10\n",
      "Epoch [1/5], Step [534/1875], Loss: 2.3804, batch time: 0.12\n",
      "Epoch [1/5], Step [535/1875], Loss: 2.3643, batch time: 0.11\n",
      "Epoch [1/5], Step [536/1875], Loss: 2.4828, batch time: 0.10\n",
      "Epoch [1/5], Step [537/1875], Loss: 2.2604, batch time: 0.10\n",
      "Epoch [1/5], Step [538/1875], Loss: 2.2655, batch time: 0.18\n",
      "Epoch [1/5], Step [539/1875], Loss: 2.3573, batch time: 0.10\n",
      "Epoch [1/5], Step [540/1875], Loss: 2.4264, batch time: 0.10\n",
      "Epoch [1/5], Step [541/1875], Loss: 2.2882, batch time: 0.10\n",
      "Epoch [1/5], Step [542/1875], Loss: 2.3458, batch time: 0.10\n",
      "Epoch [1/5], Step [543/1875], Loss: 2.3456, batch time: 0.10\n",
      "Epoch [1/5], Step [544/1875], Loss: 2.3776, batch time: 0.12\n",
      "Epoch [1/5], Step [545/1875], Loss: 2.4198, batch time: 0.10\n",
      "Epoch [1/5], Step [546/1875], Loss: 2.3851, batch time: 0.12\n",
      "Epoch [1/5], Step [547/1875], Loss: 2.3128, batch time: 0.10\n",
      "Epoch [1/5], Step [548/1875], Loss: 2.2798, batch time: 0.10\n",
      "Epoch [1/5], Step [549/1875], Loss: 2.3983, batch time: 0.22\n",
      "Epoch [1/5], Step [550/1875], Loss: 2.4109, batch time: 0.11\n",
      "Epoch [1/5], Step [551/1875], Loss: 2.3992, batch time: 0.14\n",
      "Epoch [1/5], Step [552/1875], Loss: 2.3530, batch time: 0.13\n",
      "Epoch [1/5], Step [553/1875], Loss: 2.3871, batch time: 0.10\n",
      "Epoch [1/5], Step [554/1875], Loss: 2.3081, batch time: 0.10\n",
      "Epoch [1/5], Step [555/1875], Loss: 2.3564, batch time: 0.24\n",
      "Epoch [1/5], Step [556/1875], Loss: 2.4117, batch time: 0.10\n",
      "Epoch [1/5], Step [557/1875], Loss: 2.3625, batch time: 0.14\n",
      "Epoch [1/5], Step [558/1875], Loss: 2.2155, batch time: 0.12\n",
      "Epoch [1/5], Step [559/1875], Loss: 2.4196, batch time: 0.13\n",
      "Epoch [1/5], Step [560/1875], Loss: 2.4031, batch time: 0.10\n",
      "Epoch [1/5], Step [561/1875], Loss: 2.3262, batch time: 0.16\n",
      "Epoch [1/5], Step [562/1875], Loss: 2.3707, batch time: 0.10\n",
      "Epoch [1/5], Step [563/1875], Loss: 2.4305, batch time: 0.10\n",
      "Epoch [1/5], Step [564/1875], Loss: 2.4186, batch time: 0.10\n",
      "Epoch [1/5], Step [565/1875], Loss: 2.3492, batch time: 0.13\n",
      "Epoch [1/5], Step [566/1875], Loss: 2.3146, batch time: 0.13\n",
      "Epoch [1/5], Step [567/1875], Loss: 2.3515, batch time: 0.11\n",
      "Epoch [1/5], Step [568/1875], Loss: 2.4093, batch time: 0.10\n",
      "Epoch [1/5], Step [569/1875], Loss: 2.3790, batch time: 0.10\n",
      "Epoch [1/5], Step [570/1875], Loss: 2.3732, batch time: 0.10\n",
      "Epoch [1/5], Step [571/1875], Loss: 2.4073, batch time: 0.30\n",
      "Epoch [1/5], Step [572/1875], Loss: 2.3244, batch time: 0.11\n",
      "Epoch [1/5], Step [573/1875], Loss: 2.3600, batch time: 0.10\n",
      "Epoch [1/5], Step [574/1875], Loss: 2.2526, batch time: 0.11\n",
      "Epoch [1/5], Step [575/1875], Loss: 2.3991, batch time: 0.10\n",
      "Epoch [1/5], Step [576/1875], Loss: 2.3938, batch time: 0.10\n",
      "Epoch [1/5], Step [577/1875], Loss: 2.3627, batch time: 0.18\n",
      "Epoch [1/5], Step [578/1875], Loss: 2.3056, batch time: 0.11\n",
      "Epoch [1/5], Step [579/1875], Loss: 2.3367, batch time: 0.11\n",
      "Epoch [1/5], Step [580/1875], Loss: 2.4677, batch time: 0.12\n",
      "Epoch [1/5], Step [581/1875], Loss: 2.3218, batch time: 0.10\n",
      "Epoch [1/5], Step [582/1875], Loss: 2.4433, batch time: 0.10\n",
      "Epoch [1/5], Step [583/1875], Loss: 2.3576, batch time: 0.10\n",
      "Epoch [1/5], Step [584/1875], Loss: 2.3690, batch time: 0.19\n",
      "Epoch [1/5], Step [585/1875], Loss: 2.3322, batch time: 0.14\n",
      "Epoch [1/5], Step [586/1875], Loss: 2.3095, batch time: 0.13\n",
      "Epoch [1/5], Step [587/1875], Loss: 2.3468, batch time: 0.10\n",
      "Epoch [1/5], Step [588/1875], Loss: 2.4383, batch time: 0.10\n",
      "Epoch [1/5], Step [589/1875], Loss: 2.3307, batch time: 0.10\n",
      "Epoch [1/5], Step [590/1875], Loss: 2.3709, batch time: 0.10\n",
      "Epoch [1/5], Step [591/1875], Loss: 2.3574, batch time: 0.10\n",
      "Epoch [1/5], Step [592/1875], Loss: 2.3320, batch time: 0.10\n",
      "Epoch [1/5], Step [593/1875], Loss: 2.4379, batch time: 0.10\n",
      "Epoch [1/5], Step [594/1875], Loss: 2.3779, batch time: 0.11\n",
      "Epoch [1/5], Step [595/1875], Loss: 2.3531, batch time: 0.10\n",
      "Epoch [1/5], Step [596/1875], Loss: 2.3227, batch time: 0.10\n",
      "Epoch [1/5], Step [597/1875], Loss: 2.4658, batch time: 0.10\n",
      "Epoch [1/5], Step [598/1875], Loss: 2.3778, batch time: 0.10\n",
      "Epoch [1/5], Step [599/1875], Loss: 2.3044, batch time: 0.10\n",
      "Epoch [1/5], Step [600/1875], Loss: 2.3218, batch time: 0.10\n",
      "Epoch [1/5], Step [601/1875], Loss: 2.3704, batch time: 0.10\n",
      "Epoch [1/5], Step [602/1875], Loss: 2.3751, batch time: 0.10\n",
      "Epoch [1/5], Step [603/1875], Loss: 2.3529, batch time: 0.10\n",
      "Epoch [1/5], Step [604/1875], Loss: 2.3052, batch time: 0.10\n",
      "Epoch [1/5], Step [605/1875], Loss: 2.3760, batch time: 0.10\n",
      "Epoch [1/5], Step [606/1875], Loss: 2.3177, batch time: 0.10\n",
      "Epoch [1/5], Step [607/1875], Loss: 2.3421, batch time: 0.11\n",
      "Epoch [1/5], Step [608/1875], Loss: 2.2995, batch time: 0.10\n",
      "Epoch [1/5], Step [609/1875], Loss: 2.3831, batch time: 0.10\n",
      "Epoch [1/5], Step [610/1875], Loss: 2.3131, batch time: 0.10\n",
      "Epoch [1/5], Step [611/1875], Loss: 2.3362, batch time: 0.10\n",
      "Epoch [1/5], Step [612/1875], Loss: 2.2918, batch time: 0.17\n",
      "Epoch [1/5], Step [613/1875], Loss: 2.3477, batch time: 0.15\n",
      "Epoch [1/5], Step [614/1875], Loss: 2.3947, batch time: 0.10\n",
      "Epoch [1/5], Step [615/1875], Loss: 2.3643, batch time: 0.10\n",
      "Epoch [1/5], Step [616/1875], Loss: 2.3697, batch time: 0.10\n",
      "Epoch [1/5], Step [617/1875], Loss: 2.2899, batch time: 0.10\n",
      "Epoch [1/5], Step [618/1875], Loss: 2.3726, batch time: 0.10\n",
      "Epoch [1/5], Step [619/1875], Loss: 2.4680, batch time: 0.11\n",
      "Epoch [1/5], Step [620/1875], Loss: 2.3329, batch time: 0.10\n",
      "Epoch [1/5], Step [621/1875], Loss: 2.3197, batch time: 0.10\n",
      "Epoch [1/5], Step [622/1875], Loss: 2.3051, batch time: 0.11\n",
      "Epoch [1/5], Step [623/1875], Loss: 2.3444, batch time: 0.11\n",
      "Epoch [1/5], Step [624/1875], Loss: 2.3752, batch time: 0.11\n",
      "Epoch [1/5], Step [625/1875], Loss: 2.3312, batch time: 0.11\n",
      "Epoch [1/5], Step [626/1875], Loss: 2.4009, batch time: 0.20\n",
      "Epoch [1/5], Step [627/1875], Loss: 2.2978, batch time: 0.11\n",
      "Epoch [1/5], Step [628/1875], Loss: 2.3598, batch time: 0.10\n",
      "Epoch [1/5], Step [629/1875], Loss: 2.3443, batch time: 0.15\n",
      "Epoch [1/5], Step [630/1875], Loss: 2.3614, batch time: 0.10\n",
      "Epoch [1/5], Step [631/1875], Loss: 2.3340, batch time: 0.10\n",
      "Epoch [1/5], Step [632/1875], Loss: 2.3663, batch time: 0.10\n",
      "Epoch [1/5], Step [633/1875], Loss: 2.3831, batch time: 0.13\n",
      "Epoch [1/5], Step [634/1875], Loss: 2.3831, batch time: 0.11\n",
      "Epoch [1/5], Step [635/1875], Loss: 2.3507, batch time: 0.12\n",
      "Epoch [1/5], Step [636/1875], Loss: 2.4195, batch time: 0.10\n",
      "Epoch [1/5], Step [637/1875], Loss: 2.3281, batch time: 0.10\n",
      "Epoch [1/5], Step [638/1875], Loss: 2.2556, batch time: 0.13\n",
      "Epoch [1/5], Step [639/1875], Loss: 2.3185, batch time: 0.12\n",
      "Epoch [1/5], Step [640/1875], Loss: 2.3873, batch time: 0.14\n",
      "Epoch [1/5], Step [641/1875], Loss: 2.3865, batch time: 0.10\n",
      "Epoch [1/5], Step [642/1875], Loss: 2.4099, batch time: 0.10\n",
      "Epoch [1/5], Step [643/1875], Loss: 2.3895, batch time: 0.10\n",
      "Epoch [1/5], Step [644/1875], Loss: 2.4072, batch time: 0.12\n",
      "Epoch [1/5], Step [645/1875], Loss: 2.2618, batch time: 0.10\n",
      "Epoch [1/5], Step [646/1875], Loss: 2.4098, batch time: 0.13\n",
      "Epoch [1/5], Step [647/1875], Loss: 2.3240, batch time: 0.10\n",
      "Epoch [1/5], Step [648/1875], Loss: 2.3309, batch time: 0.10\n",
      "Epoch [1/5], Step [649/1875], Loss: 2.4642, batch time: 0.10\n",
      "Epoch [1/5], Step [650/1875], Loss: 2.2975, batch time: 0.11\n",
      "Epoch [1/5], Step [651/1875], Loss: 2.3936, batch time: 0.10\n",
      "Epoch [1/5], Step [652/1875], Loss: 2.3833, batch time: 0.10\n",
      "Epoch [1/5], Step [653/1875], Loss: 2.3257, batch time: 0.10\n",
      "Epoch [1/5], Step [654/1875], Loss: 2.3546, batch time: -2.80\n",
      "Epoch [1/5], Step [655/1875], Loss: 2.3406, batch time: 0.11\n",
      "Epoch [1/5], Step [656/1875], Loss: 2.3315, batch time: 0.15\n",
      "Epoch [1/5], Step [657/1875], Loss: 2.3286, batch time: 0.10\n",
      "Epoch [1/5], Step [658/1875], Loss: 2.3108, batch time: 0.10\n",
      "Epoch [1/5], Step [659/1875], Loss: 2.2410, batch time: 0.10\n",
      "Epoch [1/5], Step [660/1875], Loss: 2.3511, batch time: 0.10\n",
      "Epoch [1/5], Step [661/1875], Loss: 2.2148, batch time: 0.13\n",
      "Epoch [1/5], Step [662/1875], Loss: 2.4292, batch time: 0.12\n",
      "Epoch [1/5], Step [663/1875], Loss: 2.2885, batch time: 0.10\n",
      "Epoch [1/5], Step [664/1875], Loss: 2.3267, batch time: 0.10\n",
      "Epoch [1/5], Step [665/1875], Loss: 2.4229, batch time: 0.10\n",
      "Epoch [1/5], Step [666/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [1/5], Step [667/1875], Loss: 2.4095, batch time: 0.10\n",
      "Epoch [1/5], Step [668/1875], Loss: 2.3567, batch time: 0.10\n",
      "Epoch [1/5], Step [669/1875], Loss: 2.3704, batch time: 0.10\n",
      "Epoch [1/5], Step [670/1875], Loss: 2.3146, batch time: 0.10\n",
      "Epoch [1/5], Step [671/1875], Loss: 2.3297, batch time: 0.10\n",
      "Epoch [1/5], Step [672/1875], Loss: 2.2649, batch time: 0.14\n",
      "Epoch [1/5], Step [673/1875], Loss: 2.3223, batch time: 0.10\n",
      "Epoch [1/5], Step [674/1875], Loss: 2.3573, batch time: 0.10\n",
      "Epoch [1/5], Step [675/1875], Loss: 2.2791, batch time: 0.17\n",
      "Epoch [1/5], Step [676/1875], Loss: 2.4148, batch time: 0.10\n",
      "Epoch [1/5], Step [677/1875], Loss: 2.3199, batch time: 0.11\n",
      "Epoch [1/5], Step [678/1875], Loss: 2.3793, batch time: 0.10\n",
      "Epoch [1/5], Step [679/1875], Loss: 2.3299, batch time: 0.11\n",
      "Epoch [1/5], Step [680/1875], Loss: 2.3469, batch time: 0.10\n",
      "Epoch [1/5], Step [681/1875], Loss: 2.2966, batch time: 0.10\n",
      "Epoch [1/5], Step [682/1875], Loss: 2.3882, batch time: 0.10\n",
      "Epoch [1/5], Step [683/1875], Loss: 2.3628, batch time: 0.14\n",
      "Epoch [1/5], Step [684/1875], Loss: 2.3837, batch time: 0.10\n",
      "Epoch [1/5], Step [685/1875], Loss: 2.3373, batch time: 0.10\n",
      "Epoch [1/5], Step [686/1875], Loss: 2.2692, batch time: 0.10\n",
      "Epoch [1/5], Step [687/1875], Loss: 2.3740, batch time: 0.10\n",
      "Epoch [1/5], Step [688/1875], Loss: 2.3254, batch time: 0.11\n",
      "Epoch [1/5], Step [689/1875], Loss: 2.3008, batch time: 0.10\n",
      "Epoch [1/5], Step [690/1875], Loss: 2.3506, batch time: 0.13\n",
      "Epoch [1/5], Step [691/1875], Loss: 2.3060, batch time: 0.10\n",
      "Epoch [1/5], Step [692/1875], Loss: 2.3322, batch time: 0.10\n",
      "Epoch [1/5], Step [693/1875], Loss: 2.4190, batch time: 0.10\n",
      "Epoch [1/5], Step [694/1875], Loss: 2.3421, batch time: 0.10\n",
      "Epoch [1/5], Step [695/1875], Loss: 2.3199, batch time: 0.10\n",
      "Epoch [1/5], Step [696/1875], Loss: 2.3250, batch time: 0.11\n",
      "Epoch [1/5], Step [697/1875], Loss: 2.3224, batch time: 0.12\n",
      "Epoch [1/5], Step [698/1875], Loss: 2.2932, batch time: 0.10\n",
      "Epoch [1/5], Step [699/1875], Loss: 2.3578, batch time: 0.11\n",
      "Epoch [1/5], Step [700/1875], Loss: 2.3676, batch time: 0.12\n",
      "Epoch [1/5], Step [701/1875], Loss: 2.3490, batch time: 0.13\n",
      "Epoch [1/5], Step [702/1875], Loss: 2.3513, batch time: 0.11\n",
      "Epoch [1/5], Step [703/1875], Loss: 2.3238, batch time: 0.10\n",
      "Epoch [1/5], Step [704/1875], Loss: 2.3517, batch time: 0.10\n",
      "Epoch [1/5], Step [705/1875], Loss: 2.3719, batch time: 0.13\n",
      "Epoch [1/5], Step [706/1875], Loss: 2.3673, batch time: 0.10\n",
      "Epoch [1/5], Step [707/1875], Loss: 2.3046, batch time: 0.10\n",
      "Epoch [1/5], Step [708/1875], Loss: 2.3648, batch time: 0.13\n",
      "Epoch [1/5], Step [709/1875], Loss: 2.3550, batch time: 0.10\n",
      "Epoch [1/5], Step [710/1875], Loss: 2.3573, batch time: 0.12\n",
      "Epoch [1/5], Step [711/1875], Loss: 2.3201, batch time: 0.10\n",
      "Epoch [1/5], Step [712/1875], Loss: 2.1840, batch time: 0.10\n",
      "Epoch [1/5], Step [713/1875], Loss: 2.3120, batch time: 0.10\n",
      "Epoch [1/5], Step [714/1875], Loss: 2.3474, batch time: 0.10\n",
      "Epoch [1/5], Step [715/1875], Loss: 2.3677, batch time: 0.10\n",
      "Epoch [1/5], Step [716/1875], Loss: 2.3714, batch time: 0.12\n",
      "Epoch [1/5], Step [717/1875], Loss: 2.3645, batch time: 0.11\n",
      "Epoch [1/5], Step [718/1875], Loss: 2.3707, batch time: 0.13\n",
      "Epoch [1/5], Step [719/1875], Loss: 2.4154, batch time: 0.10\n",
      "Epoch [1/5], Step [720/1875], Loss: 2.3270, batch time: 0.10\n",
      "Epoch [1/5], Step [721/1875], Loss: 2.3573, batch time: 0.10\n",
      "Epoch [1/5], Step [722/1875], Loss: 2.4084, batch time: 0.13\n",
      "Epoch [1/5], Step [723/1875], Loss: 2.2621, batch time: 0.10\n",
      "Epoch [1/5], Step [724/1875], Loss: 2.3639, batch time: 0.10\n",
      "Epoch [1/5], Step [725/1875], Loss: 2.4065, batch time: 0.13\n",
      "Epoch [1/5], Step [726/1875], Loss: 2.2695, batch time: 0.20\n",
      "Epoch [1/5], Step [727/1875], Loss: 2.3298, batch time: 0.10\n",
      "Epoch [1/5], Step [728/1875], Loss: 2.3284, batch time: 0.18\n",
      "Epoch [1/5], Step [729/1875], Loss: 2.3649, batch time: 0.12\n",
      "Epoch [1/5], Step [730/1875], Loss: 2.3262, batch time: 0.10\n",
      "Epoch [1/5], Step [731/1875], Loss: 2.4038, batch time: 0.10\n",
      "Epoch [1/5], Step [732/1875], Loss: 2.3052, batch time: 0.10\n",
      "Epoch [1/5], Step [733/1875], Loss: 2.3132, batch time: 0.10\n",
      "Epoch [1/5], Step [734/1875], Loss: 2.3215, batch time: 0.14\n",
      "Epoch [1/5], Step [735/1875], Loss: 2.3069, batch time: 0.10\n",
      "Epoch [1/5], Step [736/1875], Loss: 2.2995, batch time: 0.10\n",
      "Epoch [1/5], Step [737/1875], Loss: 2.4074, batch time: 0.11\n",
      "Epoch [1/5], Step [738/1875], Loss: 2.3628, batch time: 0.10\n",
      "Epoch [1/5], Step [739/1875], Loss: 2.3028, batch time: 0.10\n",
      "Epoch [1/5], Step [740/1875], Loss: 2.3198, batch time: 0.18\n",
      "Epoch [1/5], Step [741/1875], Loss: 2.2909, batch time: 0.10\n",
      "Epoch [1/5], Step [742/1875], Loss: 2.3937, batch time: 0.12\n",
      "Epoch [1/5], Step [743/1875], Loss: 2.2320, batch time: 0.10\n",
      "Epoch [1/5], Step [744/1875], Loss: 2.3015, batch time: 0.13\n",
      "Epoch [1/5], Step [745/1875], Loss: 2.3289, batch time: 0.10\n",
      "Epoch [1/5], Step [746/1875], Loss: 2.3375, batch time: 0.15\n",
      "Epoch [1/5], Step [747/1875], Loss: 2.3265, batch time: 0.14\n",
      "Epoch [1/5], Step [748/1875], Loss: 2.3274, batch time: 0.12\n",
      "Epoch [1/5], Step [749/1875], Loss: 2.3204, batch time: 0.10\n",
      "Epoch [1/5], Step [750/1875], Loss: 2.4067, batch time: 0.10\n",
      "Epoch [1/5], Step [751/1875], Loss: 2.3216, batch time: 0.10\n",
      "Epoch [1/5], Step [752/1875], Loss: 2.3142, batch time: 0.19\n",
      "Epoch [1/5], Step [753/1875], Loss: 2.3849, batch time: 0.10\n",
      "Epoch [1/5], Step [754/1875], Loss: 2.2982, batch time: 0.10\n",
      "Epoch [1/5], Step [755/1875], Loss: 2.3386, batch time: 0.14\n",
      "Epoch [1/5], Step [756/1875], Loss: 2.3794, batch time: 0.13\n",
      "Epoch [1/5], Step [757/1875], Loss: 2.2855, batch time: 0.12\n",
      "Epoch [1/5], Step [758/1875], Loss: 2.2721, batch time: 0.11\n",
      "Epoch [1/5], Step [759/1875], Loss: 2.3326, batch time: 0.10\n",
      "Epoch [1/5], Step [760/1875], Loss: 2.3404, batch time: 0.11\n",
      "Epoch [1/5], Step [761/1875], Loss: 2.3715, batch time: 0.13\n",
      "Epoch [1/5], Step [762/1875], Loss: 2.2489, batch time: 0.20\n",
      "Epoch [1/5], Step [763/1875], Loss: 2.2962, batch time: 0.21\n",
      "Epoch [1/5], Step [764/1875], Loss: 2.2918, batch time: 0.10\n",
      "Epoch [1/5], Step [765/1875], Loss: 2.3725, batch time: 0.11\n",
      "Epoch [1/5], Step [766/1875], Loss: 2.3622, batch time: 0.13\n",
      "Epoch [1/5], Step [767/1875], Loss: 2.3085, batch time: 0.11\n",
      "Epoch [1/5], Step [768/1875], Loss: 2.3436, batch time: 0.10\n",
      "Epoch [1/5], Step [769/1875], Loss: 2.3357, batch time: 0.10\n",
      "Epoch [1/5], Step [770/1875], Loss: 2.3089, batch time: 0.12\n",
      "Epoch [1/5], Step [771/1875], Loss: 2.3725, batch time: 0.10\n",
      "Epoch [1/5], Step [772/1875], Loss: 2.3987, batch time: 0.13\n",
      "Epoch [1/5], Step [773/1875], Loss: 2.3289, batch time: 0.11\n",
      "Epoch [1/5], Step [774/1875], Loss: 2.2331, batch time: 0.13\n",
      "Epoch [1/5], Step [775/1875], Loss: 2.2842, batch time: 0.17\n",
      "Epoch [1/5], Step [776/1875], Loss: 2.3293, batch time: 0.10\n",
      "Epoch [1/5], Step [777/1875], Loss: 2.2731, batch time: 0.10\n",
      "Epoch [1/5], Step [778/1875], Loss: 2.4158, batch time: 0.10\n",
      "Epoch [1/5], Step [779/1875], Loss: 2.4237, batch time: 0.11\n",
      "Epoch [1/5], Step [780/1875], Loss: 2.3281, batch time: 0.11\n",
      "Epoch [1/5], Step [781/1875], Loss: 2.3226, batch time: 0.11\n",
      "Epoch [1/5], Step [782/1875], Loss: 2.3744, batch time: 0.16\n",
      "Epoch [1/5], Step [783/1875], Loss: 2.2559, batch time: 0.14\n",
      "Epoch [1/5], Step [784/1875], Loss: 2.3043, batch time: 0.12\n",
      "Epoch [1/5], Step [785/1875], Loss: 2.3091, batch time: 0.12\n",
      "Epoch [1/5], Step [786/1875], Loss: 2.3531, batch time: 0.13\n",
      "Epoch [1/5], Step [787/1875], Loss: 2.3025, batch time: 0.12\n",
      "Epoch [1/5], Step [788/1875], Loss: 2.4006, batch time: 0.12\n",
      "Epoch [1/5], Step [789/1875], Loss: 2.3414, batch time: 0.16\n",
      "Epoch [1/5], Step [790/1875], Loss: 2.3833, batch time: 0.11\n",
      "Epoch [1/5], Step [791/1875], Loss: 2.3425, batch time: 0.10\n",
      "Epoch [1/5], Step [792/1875], Loss: 2.3516, batch time: 0.14\n",
      "Epoch [1/5], Step [793/1875], Loss: 2.3513, batch time: 0.10\n",
      "Epoch [1/5], Step [794/1875], Loss: 2.3441, batch time: 0.11\n",
      "Epoch [1/5], Step [795/1875], Loss: 2.3080, batch time: 0.10\n",
      "Epoch [1/5], Step [796/1875], Loss: 2.3254, batch time: 0.11\n",
      "Epoch [1/5], Step [797/1875], Loss: 2.3428, batch time: 0.10\n",
      "Epoch [1/5], Step [798/1875], Loss: 2.3396, batch time: 0.10\n",
      "Epoch [1/5], Step [799/1875], Loss: 2.2952, batch time: 0.10\n",
      "Epoch [1/5], Step [800/1875], Loss: 2.3837, batch time: 0.13\n",
      "Epoch [1/5], Step [801/1875], Loss: 2.2753, batch time: 0.13\n",
      "Epoch [1/5], Step [802/1875], Loss: 2.3060, batch time: 0.12\n",
      "Epoch [1/5], Step [803/1875], Loss: 2.2790, batch time: 0.10\n",
      "Epoch [1/5], Step [804/1875], Loss: 2.2857, batch time: 0.13\n",
      "Epoch [1/5], Step [805/1875], Loss: 2.3780, batch time: 0.10\n",
      "Epoch [1/5], Step [806/1875], Loss: 2.3404, batch time: 0.13\n",
      "Epoch [1/5], Step [807/1875], Loss: 2.3161, batch time: 0.14\n",
      "Epoch [1/5], Step [808/1875], Loss: 2.3306, batch time: 0.13\n",
      "Epoch [1/5], Step [809/1875], Loss: 2.3474, batch time: 0.11\n",
      "Epoch [1/5], Step [810/1875], Loss: 2.3599, batch time: 0.15\n",
      "Epoch [1/5], Step [811/1875], Loss: 2.3763, batch time: 0.12\n",
      "Epoch [1/5], Step [812/1875], Loss: 2.3675, batch time: 0.10\n",
      "Epoch [1/5], Step [813/1875], Loss: 2.3337, batch time: 0.13\n",
      "Epoch [1/5], Step [814/1875], Loss: 2.3796, batch time: 0.12\n",
      "Epoch [1/5], Step [815/1875], Loss: 2.3495, batch time: 0.15\n",
      "Epoch [1/5], Step [816/1875], Loss: 2.3832, batch time: 0.16\n",
      "Epoch [1/5], Step [817/1875], Loss: 2.3293, batch time: 0.10\n",
      "Epoch [1/5], Step [818/1875], Loss: 2.3158, batch time: 0.10\n",
      "Epoch [1/5], Step [819/1875], Loss: 2.3420, batch time: 0.11\n",
      "Epoch [1/5], Step [820/1875], Loss: 2.3459, batch time: 0.11\n",
      "Epoch [1/5], Step [821/1875], Loss: 2.2538, batch time: 0.13\n",
      "Epoch [1/5], Step [822/1875], Loss: 2.3455, batch time: 0.13\n",
      "Epoch [1/5], Step [823/1875], Loss: 2.3833, batch time: 0.13\n",
      "Epoch [1/5], Step [824/1875], Loss: 2.3768, batch time: 0.12\n",
      "Epoch [1/5], Step [825/1875], Loss: 2.2703, batch time: 0.13\n",
      "Epoch [1/5], Step [826/1875], Loss: 2.3608, batch time: 0.14\n",
      "Epoch [1/5], Step [827/1875], Loss: 2.3085, batch time: 0.12\n",
      "Epoch [1/5], Step [828/1875], Loss: 2.3193, batch time: 0.10\n",
      "Epoch [1/5], Step [829/1875], Loss: 2.3261, batch time: 0.11\n",
      "Epoch [1/5], Step [830/1875], Loss: 2.3439, batch time: 0.16\n",
      "Epoch [1/5], Step [831/1875], Loss: 2.3376, batch time: 0.12\n",
      "Epoch [1/5], Step [832/1875], Loss: 2.3223, batch time: 0.10\n",
      "Epoch [1/5], Step [833/1875], Loss: 2.3371, batch time: 0.14\n",
      "Epoch [1/5], Step [834/1875], Loss: 2.3749, batch time: 0.14\n",
      "Epoch [1/5], Step [835/1875], Loss: 2.3310, batch time: 0.13\n",
      "Epoch [1/5], Step [836/1875], Loss: 2.3321, batch time: 0.14\n",
      "Epoch [1/5], Step [837/1875], Loss: 2.3174, batch time: 0.14\n",
      "Epoch [1/5], Step [838/1875], Loss: 2.3409, batch time: 0.14\n",
      "Epoch [1/5], Step [839/1875], Loss: 2.3291, batch time: 0.13\n",
      "Epoch [1/5], Step [840/1875], Loss: 2.3125, batch time: 0.10\n",
      "Epoch [1/5], Step [841/1875], Loss: 2.4042, batch time: 0.13\n",
      "Epoch [1/5], Step [842/1875], Loss: 2.2880, batch time: 0.10\n",
      "Epoch [1/5], Step [843/1875], Loss: 2.3181, batch time: 0.14\n",
      "Epoch [1/5], Step [844/1875], Loss: 2.3013, batch time: 0.11\n",
      "Epoch [1/5], Step [845/1875], Loss: 2.3048, batch time: 0.13\n",
      "Epoch [1/5], Step [846/1875], Loss: 2.3491, batch time: 0.14\n",
      "Epoch [1/5], Step [847/1875], Loss: 2.3124, batch time: 0.14\n",
      "Epoch [1/5], Step [848/1875], Loss: 2.2857, batch time: 0.12\n",
      "Epoch [1/5], Step [849/1875], Loss: 2.3535, batch time: 0.10\n",
      "Epoch [1/5], Step [850/1875], Loss: 2.2945, batch time: 0.12\n",
      "Epoch [1/5], Step [851/1875], Loss: 2.3382, batch time: 0.13\n",
      "Epoch [1/5], Step [852/1875], Loss: 2.4146, batch time: 0.14\n",
      "Epoch [1/5], Step [853/1875], Loss: 2.4239, batch time: 0.13\n",
      "Epoch [1/5], Step [854/1875], Loss: 2.3801, batch time: 0.10\n",
      "Epoch [1/5], Step [855/1875], Loss: 2.3032, batch time: 0.13\n",
      "Epoch [1/5], Step [856/1875], Loss: 2.3551, batch time: 0.11\n",
      "Epoch [1/5], Step [857/1875], Loss: 2.2667, batch time: 0.12\n",
      "Epoch [1/5], Step [858/1875], Loss: 2.3372, batch time: 0.15\n",
      "Epoch [1/5], Step [859/1875], Loss: 2.3355, batch time: 0.11\n",
      "Epoch [1/5], Step [860/1875], Loss: 2.3379, batch time: 0.18\n",
      "Epoch [1/5], Step [861/1875], Loss: 2.3794, batch time: 0.10\n",
      "Epoch [1/5], Step [862/1875], Loss: 2.3566, batch time: 0.10\n",
      "Epoch [1/5], Step [863/1875], Loss: 2.3250, batch time: 0.12\n",
      "Epoch [1/5], Step [864/1875], Loss: 2.2950, batch time: 0.10\n",
      "Epoch [1/5], Step [865/1875], Loss: 2.3605, batch time: 0.10\n",
      "Epoch [1/5], Step [866/1875], Loss: 2.3095, batch time: 0.14\n",
      "Epoch [1/5], Step [867/1875], Loss: 2.3407, batch time: 0.11\n",
      "Epoch [1/5], Step [868/1875], Loss: 2.3610, batch time: 0.12\n",
      "Epoch [1/5], Step [869/1875], Loss: 2.3260, batch time: 0.12\n",
      "Epoch [1/5], Step [870/1875], Loss: 2.3144, batch time: 0.12\n",
      "Epoch [1/5], Step [871/1875], Loss: 2.3390, batch time: 0.10\n",
      "Epoch [1/5], Step [872/1875], Loss: 2.3142, batch time: 0.10\n",
      "Epoch [1/5], Step [873/1875], Loss: 2.2763, batch time: 0.10\n",
      "Epoch [1/5], Step [874/1875], Loss: 2.3427, batch time: 0.10\n",
      "Epoch [1/5], Step [875/1875], Loss: 2.3429, batch time: 0.10\n",
      "Epoch [1/5], Step [876/1875], Loss: 2.2889, batch time: 0.15\n",
      "Epoch [1/5], Step [877/1875], Loss: 2.2781, batch time: 0.20\n",
      "Epoch [1/5], Step [878/1875], Loss: 2.3688, batch time: 0.10\n",
      "Epoch [1/5], Step [879/1875], Loss: 2.3452, batch time: 0.10\n",
      "Epoch [1/5], Step [880/1875], Loss: 2.2964, batch time: 0.17\n",
      "Epoch [1/5], Step [881/1875], Loss: 2.3125, batch time: 0.10\n",
      "Epoch [1/5], Step [882/1875], Loss: 2.3145, batch time: 0.10\n",
      "Epoch [1/5], Step [883/1875], Loss: 2.3125, batch time: 0.10\n",
      "Epoch [1/5], Step [884/1875], Loss: 2.3157, batch time: 0.10\n",
      "Epoch [1/5], Step [885/1875], Loss: 2.3133, batch time: 0.10\n",
      "Epoch [1/5], Step [886/1875], Loss: 2.3319, batch time: 0.10\n",
      "Epoch [1/5], Step [887/1875], Loss: 2.3563, batch time: 0.09\n",
      "Epoch [1/5], Step [888/1875], Loss: 2.3281, batch time: 0.10\n",
      "Epoch [1/5], Step [889/1875], Loss: 2.3176, batch time: 0.10\n",
      "Epoch [1/5], Step [890/1875], Loss: 2.3179, batch time: 0.10\n",
      "Epoch [1/5], Step [891/1875], Loss: 2.3668, batch time: 0.10\n",
      "Epoch [1/5], Step [892/1875], Loss: 2.3669, batch time: 0.18\n",
      "Epoch [1/5], Step [893/1875], Loss: 2.4272, batch time: 0.10\n",
      "Epoch [1/5], Step [894/1875], Loss: 2.2690, batch time: 0.10\n",
      "Epoch [1/5], Step [895/1875], Loss: 2.3147, batch time: 0.10\n",
      "Epoch [1/5], Step [896/1875], Loss: 2.3620, batch time: 0.10\n",
      "Epoch [1/5], Step [897/1875], Loss: 2.2966, batch time: 0.11\n",
      "Epoch [1/5], Step [898/1875], Loss: 2.3734, batch time: 0.13\n",
      "Epoch [1/5], Step [899/1875], Loss: 2.3401, batch time: 0.14\n",
      "Epoch [1/5], Step [900/1875], Loss: 2.3293, batch time: 0.12\n",
      "Epoch [1/5], Step [901/1875], Loss: 2.3081, batch time: 0.11\n",
      "Epoch [1/5], Step [902/1875], Loss: 2.2772, batch time: 0.10\n",
      "Epoch [1/5], Step [903/1875], Loss: 2.3322, batch time: 0.12\n",
      "Epoch [1/5], Step [904/1875], Loss: 2.3450, batch time: 0.09\n",
      "Epoch [1/5], Step [905/1875], Loss: 2.2682, batch time: 0.19\n",
      "Epoch [1/5], Step [906/1875], Loss: 2.3549, batch time: 0.10\n",
      "Epoch [1/5], Step [907/1875], Loss: 2.2711, batch time: 0.13\n",
      "Epoch [1/5], Step [908/1875], Loss: 2.2951, batch time: 0.14\n",
      "Epoch [1/5], Step [909/1875], Loss: 2.2838, batch time: 0.10\n",
      "Epoch [1/5], Step [910/1875], Loss: 2.3334, batch time: 0.12\n",
      "Epoch [1/5], Step [911/1875], Loss: 2.3045, batch time: 0.11\n",
      "Epoch [1/5], Step [912/1875], Loss: 2.3073, batch time: 0.11\n",
      "Epoch [1/5], Step [913/1875], Loss: 2.3566, batch time: 0.11\n",
      "Epoch [1/5], Step [914/1875], Loss: 2.3738, batch time: 0.13\n",
      "Epoch [1/5], Step [915/1875], Loss: 2.3434, batch time: 0.10\n",
      "Epoch [1/5], Step [916/1875], Loss: 2.3294, batch time: 0.12\n",
      "Epoch [1/5], Step [917/1875], Loss: 2.3351, batch time: 0.10\n",
      "Epoch [1/5], Step [918/1875], Loss: 2.3173, batch time: 0.14\n",
      "Epoch [1/5], Step [919/1875], Loss: 2.3260, batch time: 0.11\n",
      "Epoch [1/5], Step [920/1875], Loss: 2.3280, batch time: 0.11\n",
      "Epoch [1/5], Step [921/1875], Loss: 2.4066, batch time: 0.09\n",
      "Epoch [1/5], Step [922/1875], Loss: 2.2665, batch time: 0.13\n",
      "Epoch [1/5], Step [923/1875], Loss: 2.3136, batch time: 0.10\n",
      "Epoch [1/5], Step [924/1875], Loss: 2.2954, batch time: 0.12\n",
      "Epoch [1/5], Step [925/1875], Loss: 2.3098, batch time: -2.81\n",
      "Epoch [1/5], Step [926/1875], Loss: 2.3097, batch time: 0.12\n",
      "Epoch [1/5], Step [927/1875], Loss: 2.2839, batch time: 0.14\n",
      "Epoch [1/5], Step [928/1875], Loss: 2.2664, batch time: 0.12\n",
      "Epoch [1/5], Step [929/1875], Loss: 2.3580, batch time: 0.12\n",
      "Epoch [1/5], Step [930/1875], Loss: 2.3090, batch time: 0.10\n",
      "Epoch [1/5], Step [931/1875], Loss: 2.3108, batch time: 0.11\n",
      "Epoch [1/5], Step [932/1875], Loss: 2.2764, batch time: 0.10\n",
      "Epoch [1/5], Step [933/1875], Loss: 2.2784, batch time: 0.11\n",
      "Epoch [1/5], Step [934/1875], Loss: 2.3311, batch time: 0.13\n",
      "Epoch [1/5], Step [935/1875], Loss: 2.3336, batch time: 0.10\n",
      "Epoch [1/5], Step [936/1875], Loss: 2.3121, batch time: 0.23\n",
      "Epoch [1/5], Step [937/1875], Loss: 2.2482, batch time: 0.10\n",
      "Epoch [1/5], Step [938/1875], Loss: 2.4053, batch time: 0.11\n",
      "Epoch [1/5], Step [939/1875], Loss: 2.3331, batch time: 0.10\n",
      "Epoch [1/5], Step [940/1875], Loss: 2.3182, batch time: 0.11\n",
      "Epoch [1/5], Step [941/1875], Loss: 2.3500, batch time: 0.09\n",
      "Epoch [1/5], Step [942/1875], Loss: 2.3305, batch time: 0.10\n",
      "Epoch [1/5], Step [943/1875], Loss: 2.3399, batch time: 0.10\n",
      "Epoch [1/5], Step [944/1875], Loss: 2.3401, batch time: 0.12\n",
      "Epoch [1/5], Step [945/1875], Loss: 2.3037, batch time: 0.10\n",
      "Epoch [1/5], Step [946/1875], Loss: 2.3063, batch time: 0.10\n",
      "Epoch [1/5], Step [947/1875], Loss: 2.3533, batch time: 0.11\n",
      "Epoch [1/5], Step [948/1875], Loss: 2.3654, batch time: 0.10\n",
      "Epoch [1/5], Step [949/1875], Loss: 2.3823, batch time: 0.10\n",
      "Epoch [1/5], Step [950/1875], Loss: 2.3170, batch time: 0.10\n",
      "Epoch [1/5], Step [951/1875], Loss: 2.3115, batch time: 0.10\n",
      "Epoch [1/5], Step [952/1875], Loss: 2.3515, batch time: 0.10\n",
      "Epoch [1/5], Step [953/1875], Loss: 2.3655, batch time: 0.12\n",
      "Epoch [1/5], Step [954/1875], Loss: 2.3108, batch time: 0.10\n",
      "Epoch [1/5], Step [955/1875], Loss: 2.3227, batch time: 0.10\n",
      "Epoch [1/5], Step [956/1875], Loss: 2.3159, batch time: 0.10\n",
      "Epoch [1/5], Step [957/1875], Loss: 2.2908, batch time: 0.24\n",
      "Epoch [1/5], Step [958/1875], Loss: 2.3159, batch time: 0.10\n",
      "Epoch [1/5], Step [959/1875], Loss: 2.3259, batch time: 0.12\n",
      "Epoch [1/5], Step [960/1875], Loss: 2.3435, batch time: 0.15\n",
      "Epoch [1/5], Step [961/1875], Loss: 2.3124, batch time: 0.13\n",
      "Epoch [1/5], Step [962/1875], Loss: 2.3049, batch time: 0.10\n",
      "Epoch [1/5], Step [963/1875], Loss: 2.3553, batch time: 0.11\n",
      "Epoch [1/5], Step [964/1875], Loss: 2.2954, batch time: 0.11\n",
      "Epoch [1/5], Step [965/1875], Loss: 2.3657, batch time: 0.11\n",
      "Epoch [1/5], Step [966/1875], Loss: 2.3311, batch time: 0.10\n",
      "Epoch [1/5], Step [967/1875], Loss: 2.3275, batch time: 0.10\n",
      "Epoch [1/5], Step [968/1875], Loss: 2.2784, batch time: 0.10\n",
      "Epoch [1/5], Step [969/1875], Loss: 2.3093, batch time: 0.12\n",
      "Epoch [1/5], Step [970/1875], Loss: 2.3279, batch time: 0.10\n",
      "Epoch [1/5], Step [971/1875], Loss: 2.3504, batch time: 0.10\n",
      "Epoch [1/5], Step [972/1875], Loss: 2.3480, batch time: 0.16\n",
      "Epoch [1/5], Step [973/1875], Loss: 2.3024, batch time: 0.12\n",
      "Epoch [1/5], Step [974/1875], Loss: 2.3328, batch time: 0.15\n",
      "Epoch [1/5], Step [975/1875], Loss: 2.3079, batch time: 0.13\n",
      "Epoch [1/5], Step [976/1875], Loss: 2.3805, batch time: 0.12\n",
      "Epoch [1/5], Step [977/1875], Loss: 2.3447, batch time: 0.10\n",
      "Epoch [1/5], Step [978/1875], Loss: 2.3343, batch time: 0.10\n",
      "Epoch [1/5], Step [979/1875], Loss: 2.2989, batch time: 0.11\n",
      "Epoch [1/5], Step [980/1875], Loss: 2.3197, batch time: 0.10\n",
      "Epoch [1/5], Step [981/1875], Loss: 2.2745, batch time: 0.10\n",
      "Epoch [1/5], Step [982/1875], Loss: 2.3371, batch time: 0.10\n",
      "Epoch [1/5], Step [983/1875], Loss: 2.3780, batch time: 0.13\n",
      "Epoch [1/5], Step [984/1875], Loss: 2.3335, batch time: 0.10\n",
      "Epoch [1/5], Step [985/1875], Loss: 2.3695, batch time: 0.12\n",
      "Epoch [1/5], Step [986/1875], Loss: 2.3033, batch time: 0.10\n",
      "Epoch [1/5], Step [987/1875], Loss: 2.2689, batch time: 0.14\n",
      "Epoch [1/5], Step [988/1875], Loss: 2.3286, batch time: 0.10\n",
      "Epoch [1/5], Step [989/1875], Loss: 2.3383, batch time: 0.12\n",
      "Epoch [1/5], Step [990/1875], Loss: 2.3351, batch time: 0.11\n",
      "Epoch [1/5], Step [991/1875], Loss: 2.2955, batch time: 0.10\n",
      "Epoch [1/5], Step [992/1875], Loss: 2.2510, batch time: 0.10\n",
      "Epoch [1/5], Step [993/1875], Loss: 2.3467, batch time: 0.10\n",
      "Epoch [1/5], Step [994/1875], Loss: 2.2830, batch time: 0.14\n",
      "Epoch [1/5], Step [995/1875], Loss: 2.2878, batch time: 0.14\n",
      "Epoch [1/5], Step [996/1875], Loss: 2.3518, batch time: 0.14\n",
      "Epoch [1/5], Step [997/1875], Loss: 2.3156, batch time: 0.12\n",
      "Epoch [1/5], Step [998/1875], Loss: 2.3773, batch time: 0.10\n",
      "Epoch [1/5], Step [999/1875], Loss: 2.3341, batch time: 0.10\n",
      "Epoch [1/5], Step [1000/1875], Loss: 2.3391, batch time: 0.09\n",
      "Epoch [1/5], Step [1001/1875], Loss: 2.2890, batch time: 0.11\n",
      "Epoch [1/5], Step [1002/1875], Loss: 2.3424, batch time: 0.10\n",
      "Epoch [1/5], Step [1003/1875], Loss: 2.3255, batch time: 0.13\n",
      "Epoch [1/5], Step [1004/1875], Loss: 2.2994, batch time: 0.10\n",
      "Epoch [1/5], Step [1005/1875], Loss: 2.3051, batch time: 0.16\n",
      "Epoch [1/5], Step [1006/1875], Loss: 2.3414, batch time: 0.11\n",
      "Epoch [1/5], Step [1007/1875], Loss: 2.2524, batch time: 0.10\n",
      "Epoch [1/5], Step [1008/1875], Loss: 2.3139, batch time: 0.10\n",
      "Epoch [1/5], Step [1009/1875], Loss: 2.3146, batch time: 0.09\n",
      "Epoch [1/5], Step [1010/1875], Loss: 2.3011, batch time: 0.10\n",
      "Epoch [1/5], Step [1011/1875], Loss: 2.3471, batch time: 0.10\n",
      "Epoch [1/5], Step [1012/1875], Loss: 2.3434, batch time: 0.11\n",
      "Epoch [1/5], Step [1013/1875], Loss: 2.3241, batch time: 0.10\n",
      "Epoch [1/5], Step [1014/1875], Loss: 2.3607, batch time: 0.12\n",
      "Epoch [1/5], Step [1015/1875], Loss: 2.3297, batch time: 0.18\n",
      "Epoch [1/5], Step [1016/1875], Loss: 2.2762, batch time: 0.10\n",
      "Epoch [1/5], Step [1017/1875], Loss: 2.3465, batch time: 0.10\n",
      "Epoch [1/5], Step [1018/1875], Loss: 2.3701, batch time: 0.13\n",
      "Epoch [1/5], Step [1019/1875], Loss: 2.3616, batch time: 0.10\n",
      "Epoch [1/5], Step [1020/1875], Loss: 2.2993, batch time: 0.13\n",
      "Epoch [1/5], Step [1021/1875], Loss: 2.3203, batch time: 0.13\n",
      "Epoch [1/5], Step [1022/1875], Loss: 2.3418, batch time: 0.10\n",
      "Epoch [1/5], Step [1023/1875], Loss: 2.3776, batch time: 0.14\n",
      "Epoch [1/5], Step [1024/1875], Loss: 2.3591, batch time: 0.10\n",
      "Epoch [1/5], Step [1025/1875], Loss: 2.2448, batch time: 0.10\n",
      "Epoch [1/5], Step [1026/1875], Loss: 2.4059, batch time: 0.10\n",
      "Epoch [1/5], Step [1027/1875], Loss: 2.2469, batch time: 0.10\n",
      "Epoch [1/5], Step [1028/1875], Loss: 2.3142, batch time: 0.10\n",
      "Epoch [1/5], Step [1029/1875], Loss: 2.2771, batch time: 0.10\n",
      "Epoch [1/5], Step [1030/1875], Loss: 2.3004, batch time: 0.10\n",
      "Epoch [1/5], Step [1031/1875], Loss: 2.2897, batch time: 0.11\n",
      "Epoch [1/5], Step [1032/1875], Loss: 2.3311, batch time: 0.10\n",
      "Epoch [1/5], Step [1033/1875], Loss: 2.2701, batch time: 0.14\n",
      "Epoch [1/5], Step [1034/1875], Loss: 2.3371, batch time: 0.12\n",
      "Epoch [1/5], Step [1035/1875], Loss: 2.3252, batch time: 0.12\n",
      "Epoch [1/5], Step [1036/1875], Loss: 2.2501, batch time: 0.12\n",
      "Epoch [1/5], Step [1037/1875], Loss: 2.3153, batch time: 0.10\n",
      "Epoch [1/5], Step [1038/1875], Loss: 2.3003, batch time: 0.09\n",
      "Epoch [1/5], Step [1039/1875], Loss: 2.2854, batch time: 0.11\n",
      "Epoch [1/5], Step [1040/1875], Loss: 2.3453, batch time: 0.12\n",
      "Epoch [1/5], Step [1041/1875], Loss: 2.3059, batch time: 0.10\n",
      "Epoch [1/5], Step [1042/1875], Loss: 2.2706, batch time: 0.12\n",
      "Epoch [1/5], Step [1043/1875], Loss: 2.3134, batch time: 0.16\n",
      "Epoch [1/5], Step [1044/1875], Loss: 2.2873, batch time: 0.10\n",
      "Epoch [1/5], Step [1045/1875], Loss: 2.2835, batch time: 0.11\n",
      "Epoch [1/5], Step [1046/1875], Loss: 2.3189, batch time: 0.12\n",
      "Epoch [1/5], Step [1047/1875], Loss: 2.3628, batch time: 0.12\n",
      "Epoch [1/5], Step [1048/1875], Loss: 2.3203, batch time: 0.13\n",
      "Epoch [1/5], Step [1049/1875], Loss: 2.3046, batch time: 0.13\n",
      "Epoch [1/5], Step [1050/1875], Loss: 2.3876, batch time: 0.10\n",
      "Epoch [1/5], Step [1051/1875], Loss: 2.2859, batch time: 0.10\n",
      "Epoch [1/5], Step [1052/1875], Loss: 2.3258, batch time: 0.13\n",
      "Epoch [1/5], Step [1053/1875], Loss: 2.2825, batch time: 0.12\n",
      "Epoch [1/5], Step [1054/1875], Loss: 2.3359, batch time: 0.14\n",
      "Epoch [1/5], Step [1055/1875], Loss: 2.2991, batch time: 0.10\n",
      "Epoch [1/5], Step [1056/1875], Loss: 2.2848, batch time: 0.10\n",
      "Epoch [1/5], Step [1057/1875], Loss: 2.3265, batch time: 0.10\n",
      "Epoch [1/5], Step [1058/1875], Loss: 2.2815, batch time: 0.12\n",
      "Epoch [1/5], Step [1059/1875], Loss: 2.2827, batch time: 0.12\n",
      "Epoch [1/5], Step [1060/1875], Loss: 2.3317, batch time: 0.10\n",
      "Epoch [1/5], Step [1061/1875], Loss: 2.2892, batch time: 0.14\n",
      "Epoch [1/5], Step [1062/1875], Loss: 2.2780, batch time: 0.10\n",
      "Epoch [1/5], Step [1063/1875], Loss: 2.3401, batch time: 0.13\n",
      "Epoch [1/5], Step [1064/1875], Loss: 2.3521, batch time: 0.10\n",
      "Epoch [1/5], Step [1065/1875], Loss: 2.3648, batch time: 0.12\n",
      "Epoch [1/5], Step [1066/1875], Loss: 2.2388, batch time: 0.13\n",
      "Epoch [1/5], Step [1067/1875], Loss: 2.3612, batch time: 0.10\n",
      "Epoch [1/5], Step [1068/1875], Loss: 2.2689, batch time: 0.10\n",
      "Epoch [1/5], Step [1069/1875], Loss: 2.3531, batch time: 0.12\n",
      "Epoch [1/5], Step [1070/1875], Loss: 2.3437, batch time: 0.10\n",
      "Epoch [1/5], Step [1071/1875], Loss: 2.2761, batch time: 0.10\n",
      "Epoch [1/5], Step [1072/1875], Loss: 2.2775, batch time: 0.14\n",
      "Epoch [1/5], Step [1073/1875], Loss: 2.3186, batch time: 0.11\n",
      "Epoch [1/5], Step [1074/1875], Loss: 2.3267, batch time: 0.10\n",
      "Epoch [1/5], Step [1075/1875], Loss: 2.3372, batch time: 0.13\n",
      "Epoch [1/5], Step [1076/1875], Loss: 2.3354, batch time: 0.13\n",
      "Epoch [1/5], Step [1077/1875], Loss: 2.3074, batch time: 0.10\n",
      "Epoch [1/5], Step [1078/1875], Loss: 2.2665, batch time: 0.14\n",
      "Epoch [1/5], Step [1079/1875], Loss: 2.3192, batch time: 0.10\n",
      "Epoch [1/5], Step [1080/1875], Loss: 2.3148, batch time: 0.10\n",
      "Epoch [1/5], Step [1081/1875], Loss: 2.3211, batch time: 0.12\n",
      "Epoch [1/5], Step [1082/1875], Loss: 2.3451, batch time: 0.19\n",
      "Epoch [1/5], Step [1083/1875], Loss: 2.2532, batch time: 0.10\n",
      "Epoch [1/5], Step [1084/1875], Loss: 2.2624, batch time: 0.10\n",
      "Epoch [1/5], Step [1085/1875], Loss: 2.2526, batch time: 0.10\n",
      "Epoch [1/5], Step [1086/1875], Loss: 2.2408, batch time: 0.11\n",
      "Epoch [1/5], Step [1087/1875], Loss: 2.3316, batch time: 0.10\n",
      "Epoch [1/5], Step [1088/1875], Loss: 2.3750, batch time: 0.10\n",
      "Epoch [1/5], Step [1089/1875], Loss: 2.3529, batch time: 0.15\n",
      "Epoch [1/5], Step [1090/1875], Loss: 2.3797, batch time: 0.10\n",
      "Epoch [1/5], Step [1091/1875], Loss: 2.3595, batch time: 0.10\n",
      "Epoch [1/5], Step [1092/1875], Loss: 2.3112, batch time: 0.14\n",
      "Epoch [1/5], Step [1093/1875], Loss: 2.3705, batch time: 0.10\n",
      "Epoch [1/5], Step [1094/1875], Loss: 2.2901, batch time: 0.11\n",
      "Epoch [1/5], Step [1095/1875], Loss: 2.3396, batch time: 0.10\n",
      "Epoch [1/5], Step [1096/1875], Loss: 2.2755, batch time: 0.10\n",
      "Epoch [1/5], Step [1097/1875], Loss: 2.2950, batch time: 0.10\n",
      "Epoch [1/5], Step [1098/1875], Loss: 2.3072, batch time: 0.14\n",
      "Epoch [1/5], Step [1099/1875], Loss: 2.2835, batch time: 0.11\n",
      "Epoch [1/5], Step [1100/1875], Loss: 2.2931, batch time: 0.11\n",
      "Epoch [1/5], Step [1101/1875], Loss: 2.2672, batch time: 0.19\n",
      "Epoch [1/5], Step [1102/1875], Loss: 2.3236, batch time: 0.14\n",
      "Epoch [1/5], Step [1103/1875], Loss: 2.2532, batch time: 0.13\n",
      "Epoch [1/5], Step [1104/1875], Loss: 2.2392, batch time: 0.11\n",
      "Epoch [1/5], Step [1105/1875], Loss: 2.3073, batch time: 0.13\n",
      "Epoch [1/5], Step [1106/1875], Loss: 2.3163, batch time: 0.10\n",
      "Epoch [1/5], Step [1107/1875], Loss: 2.3214, batch time: 0.10\n",
      "Epoch [1/5], Step [1108/1875], Loss: 2.3054, batch time: 0.12\n",
      "Epoch [1/5], Step [1109/1875], Loss: 2.3426, batch time: 0.11\n",
      "Epoch [1/5], Step [1110/1875], Loss: 2.2739, batch time: 0.10\n",
      "Epoch [1/5], Step [1111/1875], Loss: 2.2752, batch time: 0.10\n",
      "Epoch [1/5], Step [1112/1875], Loss: 2.3253, batch time: 0.10\n",
      "Epoch [1/5], Step [1113/1875], Loss: 2.3071, batch time: 0.12\n",
      "Epoch [1/5], Step [1114/1875], Loss: 2.3248, batch time: 0.14\n",
      "Epoch [1/5], Step [1115/1875], Loss: 2.3398, batch time: 0.13\n",
      "Epoch [1/5], Step [1116/1875], Loss: 2.2915, batch time: 0.10\n",
      "Epoch [1/5], Step [1117/1875], Loss: 2.3276, batch time: 0.10\n",
      "Epoch [1/5], Step [1118/1875], Loss: 2.3022, batch time: 0.11\n",
      "Epoch [1/5], Step [1119/1875], Loss: 2.3449, batch time: 0.14\n",
      "Epoch [1/5], Step [1120/1875], Loss: 2.3199, batch time: 0.10\n",
      "Epoch [1/5], Step [1121/1875], Loss: 2.4282, batch time: 0.10\n",
      "Epoch [1/5], Step [1122/1875], Loss: 2.3408, batch time: 0.09\n",
      "Epoch [1/5], Step [1123/1875], Loss: 2.2977, batch time: 0.10\n",
      "Epoch [1/5], Step [1124/1875], Loss: 2.3372, batch time: 0.09\n",
      "Epoch [1/5], Step [1125/1875], Loss: 2.2731, batch time: 0.10\n",
      "Epoch [1/5], Step [1126/1875], Loss: 2.3061, batch time: 0.10\n",
      "Epoch [1/5], Step [1127/1875], Loss: 2.3169, batch time: 0.10\n",
      "Epoch [1/5], Step [1128/1875], Loss: 2.3223, batch time: 0.12\n",
      "Epoch [1/5], Step [1129/1875], Loss: 2.3426, batch time: 0.10\n",
      "Epoch [1/5], Step [1130/1875], Loss: 2.2984, batch time: 0.10\n",
      "Epoch [1/5], Step [1131/1875], Loss: 2.3033, batch time: 0.11\n",
      "Epoch [1/5], Step [1132/1875], Loss: 2.3108, batch time: 0.13\n",
      "Epoch [1/5], Step [1133/1875], Loss: 2.3026, batch time: 0.10\n",
      "Epoch [1/5], Step [1134/1875], Loss: 2.3057, batch time: 0.10\n",
      "Epoch [1/5], Step [1135/1875], Loss: 2.2683, batch time: 0.10\n",
      "Epoch [1/5], Step [1136/1875], Loss: 2.3675, batch time: 0.12\n",
      "Epoch [1/5], Step [1137/1875], Loss: 2.3199, batch time: 0.11\n",
      "Epoch [1/5], Step [1138/1875], Loss: 2.2965, batch time: 0.10\n",
      "Epoch [1/5], Step [1139/1875], Loss: 2.3046, batch time: 0.14\n",
      "Epoch [1/5], Step [1140/1875], Loss: 2.3414, batch time: 0.12\n",
      "Epoch [1/5], Step [1141/1875], Loss: 2.3119, batch time: 0.12\n",
      "Epoch [1/5], Step [1142/1875], Loss: 2.3490, batch time: 0.12\n",
      "Epoch [1/5], Step [1143/1875], Loss: 2.3355, batch time: 0.11\n",
      "Epoch [1/5], Step [1144/1875], Loss: 2.2890, batch time: 0.11\n",
      "Epoch [1/5], Step [1145/1875], Loss: 2.2666, batch time: 0.12\n",
      "Epoch [1/5], Step [1146/1875], Loss: 2.2904, batch time: 0.14\n",
      "Epoch [1/5], Step [1147/1875], Loss: 2.3569, batch time: 0.10\n",
      "Epoch [1/5], Step [1148/1875], Loss: 2.2656, batch time: 0.10\n",
      "Epoch [1/5], Step [1149/1875], Loss: 2.3550, batch time: 0.10\n",
      "Epoch [1/5], Step [1150/1875], Loss: 2.3283, batch time: 0.10\n",
      "Epoch [1/5], Step [1151/1875], Loss: 2.2964, batch time: 0.11\n",
      "Epoch [1/5], Step [1152/1875], Loss: 2.2895, batch time: 0.10\n",
      "Epoch [1/5], Step [1153/1875], Loss: 2.2094, batch time: 0.14\n",
      "Epoch [1/5], Step [1154/1875], Loss: 2.3179, batch time: 0.10\n",
      "Epoch [1/5], Step [1155/1875], Loss: 2.3723, batch time: 0.13\n",
      "Epoch [1/5], Step [1156/1875], Loss: 2.3181, batch time: 0.10\n",
      "Epoch [1/5], Step [1157/1875], Loss: 2.3403, batch time: 0.10\n",
      "Epoch [1/5], Step [1158/1875], Loss: 2.2888, batch time: 0.18\n",
      "Epoch [1/5], Step [1159/1875], Loss: 2.2721, batch time: 0.10\n",
      "Epoch [1/5], Step [1160/1875], Loss: 2.2667, batch time: 0.10\n",
      "Epoch [1/5], Step [1161/1875], Loss: 2.3817, batch time: 0.11\n",
      "Epoch [1/5], Step [1162/1875], Loss: 2.2840, batch time: 0.10\n",
      "Epoch [1/5], Step [1163/1875], Loss: 2.3451, batch time: 0.10\n",
      "Epoch [1/5], Step [1164/1875], Loss: 2.3323, batch time: 0.26\n",
      "Epoch [1/5], Step [1165/1875], Loss: 2.2934, batch time: 0.09\n",
      "Epoch [1/5], Step [1166/1875], Loss: 2.2765, batch time: 0.10\n",
      "Epoch [1/5], Step [1167/1875], Loss: 2.3018, batch time: 0.21\n",
      "Epoch [1/5], Step [1168/1875], Loss: 2.3089, batch time: 0.16\n",
      "Epoch [1/5], Step [1169/1875], Loss: 2.2752, batch time: 0.11\n",
      "Epoch [1/5], Step [1170/1875], Loss: 2.3007, batch time: 0.10\n",
      "Epoch [1/5], Step [1171/1875], Loss: 2.3638, batch time: 0.10\n",
      "Epoch [1/5], Step [1172/1875], Loss: 2.3061, batch time: 0.10\n",
      "Epoch [1/5], Step [1173/1875], Loss: 2.3230, batch time: 0.12\n",
      "Epoch [1/5], Step [1174/1875], Loss: 2.2592, batch time: 0.10\n",
      "Epoch [1/5], Step [1175/1875], Loss: 2.2960, batch time: 0.14\n",
      "Epoch [1/5], Step [1176/1875], Loss: 2.3096, batch time: 0.11\n",
      "Epoch [1/5], Step [1177/1875], Loss: 2.2560, batch time: 0.17\n",
      "Epoch [1/5], Step [1178/1875], Loss: 2.3335, batch time: 0.10\n",
      "Epoch [1/5], Step [1179/1875], Loss: 2.3041, batch time: 0.10\n",
      "Epoch [1/5], Step [1180/1875], Loss: 2.2759, batch time: 0.10\n",
      "Epoch [1/5], Step [1181/1875], Loss: 2.2794, batch time: 0.10\n",
      "Epoch [1/5], Step [1182/1875], Loss: 2.3341, batch time: 0.11\n",
      "Epoch [1/5], Step [1183/1875], Loss: 2.3375, batch time: 0.15\n",
      "Epoch [1/5], Step [1184/1875], Loss: 2.2899, batch time: 0.11\n",
      "Epoch [1/5], Step [1185/1875], Loss: 2.3623, batch time: 0.12\n",
      "Epoch [1/5], Step [1186/1875], Loss: 2.2888, batch time: 0.10\n",
      "Epoch [1/5], Step [1187/1875], Loss: 2.3379, batch time: 0.10\n",
      "Epoch [1/5], Step [1188/1875], Loss: 2.2732, batch time: 0.13\n",
      "Epoch [1/5], Step [1189/1875], Loss: 2.3163, batch time: 0.10\n",
      "Epoch [1/5], Step [1190/1875], Loss: 2.3285, batch time: 0.13\n",
      "Epoch [1/5], Step [1191/1875], Loss: 2.3165, batch time: 0.10\n",
      "Epoch [1/5], Step [1192/1875], Loss: 2.3108, batch time: 0.10\n",
      "Epoch [1/5], Step [1193/1875], Loss: 2.2774, batch time: 0.10\n",
      "Epoch [1/5], Step [1194/1875], Loss: 2.3050, batch time: 0.10\n",
      "Epoch [1/5], Step [1195/1875], Loss: 2.3263, batch time: 0.10\n",
      "Epoch [1/5], Step [1196/1875], Loss: 2.3007, batch time: 0.10\n",
      "Epoch [1/5], Step [1197/1875], Loss: 2.3178, batch time: 0.10\n",
      "Epoch [1/5], Step [1198/1875], Loss: 2.3066, batch time: 0.10\n",
      "Epoch [1/5], Step [1199/1875], Loss: 2.3302, batch time: 0.10\n",
      "Epoch [1/5], Step [1200/1875], Loss: 2.2993, batch time: 0.10\n",
      "Epoch [1/5], Step [1201/1875], Loss: 2.2445, batch time: 0.10\n",
      "Epoch [1/5], Step [1202/1875], Loss: 2.2986, batch time: 0.10\n",
      "Epoch [1/5], Step [1203/1875], Loss: 2.3065, batch time: 0.10\n",
      "Epoch [1/5], Step [1204/1875], Loss: 2.3171, batch time: 0.15\n",
      "Epoch [1/5], Step [1205/1875], Loss: 2.3104, batch time: -2.83\n",
      "Epoch [1/5], Step [1206/1875], Loss: 2.3841, batch time: 0.10\n",
      "Epoch [1/5], Step [1207/1875], Loss: 2.3220, batch time: 0.10\n",
      "Epoch [1/5], Step [1208/1875], Loss: 2.3270, batch time: 0.10\n",
      "Epoch [1/5], Step [1209/1875], Loss: 2.3291, batch time: 0.12\n",
      "Epoch [1/5], Step [1210/1875], Loss: 2.2821, batch time: 0.09\n",
      "Epoch [1/5], Step [1211/1875], Loss: 2.3384, batch time: 0.10\n",
      "Epoch [1/5], Step [1212/1875], Loss: 2.2908, batch time: 0.10\n",
      "Epoch [1/5], Step [1213/1875], Loss: 2.3099, batch time: 0.14\n",
      "Epoch [1/5], Step [1214/1875], Loss: 2.3394, batch time: 0.10\n",
      "Epoch [1/5], Step [1215/1875], Loss: 2.3345, batch time: 0.10\n",
      "Epoch [1/5], Step [1216/1875], Loss: 2.3599, batch time: 0.10\n",
      "Epoch [1/5], Step [1217/1875], Loss: 2.3004, batch time: 0.10\n",
      "Epoch [1/5], Step [1218/1875], Loss: 2.3923, batch time: 0.11\n",
      "Epoch [1/5], Step [1219/1875], Loss: 2.3210, batch time: 0.10\n",
      "Epoch [1/5], Step [1220/1875], Loss: 2.2816, batch time: 0.10\n",
      "Epoch [1/5], Step [1221/1875], Loss: 2.3384, batch time: 0.12\n",
      "Epoch [1/5], Step [1222/1875], Loss: 2.3203, batch time: 0.10\n",
      "Epoch [1/5], Step [1223/1875], Loss: 2.2646, batch time: 0.10\n",
      "Epoch [1/5], Step [1224/1875], Loss: 2.3244, batch time: 0.10\n",
      "Epoch [1/5], Step [1225/1875], Loss: 2.2746, batch time: 0.13\n",
      "Epoch [1/5], Step [1226/1875], Loss: 2.3001, batch time: 0.10\n",
      "Epoch [1/5], Step [1227/1875], Loss: 2.3075, batch time: 0.12\n",
      "Epoch [1/5], Step [1228/1875], Loss: 2.2671, batch time: 0.10\n",
      "Epoch [1/5], Step [1229/1875], Loss: 2.3888, batch time: 0.10\n",
      "Epoch [1/5], Step [1230/1875], Loss: 2.3121, batch time: 0.10\n",
      "Epoch [1/5], Step [1231/1875], Loss: 2.3074, batch time: 0.09\n",
      "Epoch [1/5], Step [1232/1875], Loss: 2.3141, batch time: 0.10\n",
      "Epoch [1/5], Step [1233/1875], Loss: 2.3174, batch time: 0.10\n",
      "Epoch [1/5], Step [1234/1875], Loss: 2.3087, batch time: 0.14\n",
      "Epoch [1/5], Step [1235/1875], Loss: 2.2847, batch time: 0.10\n",
      "Epoch [1/5], Step [1236/1875], Loss: 2.3368, batch time: 0.10\n",
      "Epoch [1/5], Step [1237/1875], Loss: 2.3550, batch time: 0.10\n",
      "Epoch [1/5], Step [1238/1875], Loss: 2.2377, batch time: 0.13\n",
      "Epoch [1/5], Step [1239/1875], Loss: 2.3235, batch time: 0.10\n",
      "Epoch [1/5], Step [1240/1875], Loss: 2.3104, batch time: 0.10\n",
      "Epoch [1/5], Step [1241/1875], Loss: 2.3270, batch time: 0.11\n",
      "Epoch [1/5], Step [1242/1875], Loss: 2.2964, batch time: 0.10\n",
      "Epoch [1/5], Step [1243/1875], Loss: 2.3229, batch time: 0.10\n",
      "Epoch [1/5], Step [1244/1875], Loss: 2.3207, batch time: 0.11\n",
      "Epoch [1/5], Step [1245/1875], Loss: 2.3687, batch time: 0.10\n",
      "Epoch [1/5], Step [1246/1875], Loss: 2.2801, batch time: 0.10\n",
      "Epoch [1/5], Step [1247/1875], Loss: 2.3140, batch time: 0.10\n",
      "Epoch [1/5], Step [1248/1875], Loss: 2.2805, batch time: 0.13\n",
      "Epoch [1/5], Step [1249/1875], Loss: 2.3046, batch time: 0.13\n",
      "Epoch [1/5], Step [1250/1875], Loss: 2.3322, batch time: 0.11\n",
      "Epoch [1/5], Step [1251/1875], Loss: 2.3066, batch time: 0.10\n",
      "Epoch [1/5], Step [1252/1875], Loss: 2.2797, batch time: 0.10\n",
      "Epoch [1/5], Step [1253/1875], Loss: 2.2718, batch time: 0.10\n",
      "Epoch [1/5], Step [1254/1875], Loss: 2.2995, batch time: 0.10\n",
      "Epoch [1/5], Step [1255/1875], Loss: 2.3019, batch time: 0.12\n",
      "Epoch [1/5], Step [1256/1875], Loss: 2.3330, batch time: 0.10\n",
      "Epoch [1/5], Step [1257/1875], Loss: 2.3055, batch time: 0.10\n",
      "Epoch [1/5], Step [1258/1875], Loss: 2.2995, batch time: 0.22\n",
      "Epoch [1/5], Step [1259/1875], Loss: 2.3084, batch time: 0.10\n",
      "Epoch [1/5], Step [1260/1875], Loss: 2.2961, batch time: 0.10\n",
      "Epoch [1/5], Step [1261/1875], Loss: 2.3029, batch time: 0.10\n",
      "Epoch [1/5], Step [1262/1875], Loss: 2.3428, batch time: 0.09\n",
      "Epoch [1/5], Step [1263/1875], Loss: 2.2998, batch time: 0.10\n",
      "Epoch [1/5], Step [1264/1875], Loss: 2.3513, batch time: 0.17\n",
      "Epoch [1/5], Step [1265/1875], Loss: 2.3223, batch time: 0.12\n",
      "Epoch [1/5], Step [1266/1875], Loss: 2.3046, batch time: 0.13\n",
      "Epoch [1/5], Step [1267/1875], Loss: 2.3305, batch time: 0.10\n",
      "Epoch [1/5], Step [1268/1875], Loss: 2.2993, batch time: 0.12\n",
      "Epoch [1/5], Step [1269/1875], Loss: 2.3281, batch time: 0.13\n",
      "Epoch [1/5], Step [1270/1875], Loss: 2.3242, batch time: 0.10\n",
      "Epoch [1/5], Step [1271/1875], Loss: 2.3010, batch time: 0.10\n",
      "Epoch [1/5], Step [1272/1875], Loss: 2.3171, batch time: 0.13\n",
      "Epoch [1/5], Step [1273/1875], Loss: 2.3294, batch time: 0.13\n",
      "Epoch [1/5], Step [1274/1875], Loss: 2.3148, batch time: 0.11\n",
      "Epoch [1/5], Step [1275/1875], Loss: 2.3492, batch time: 0.10\n",
      "Epoch [1/5], Step [1276/1875], Loss: 2.3224, batch time: 0.14\n",
      "Epoch [1/5], Step [1277/1875], Loss: 2.3328, batch time: 0.16\n",
      "Epoch [1/5], Step [1278/1875], Loss: 2.3041, batch time: 0.10\n",
      "Epoch [1/5], Step [1279/1875], Loss: 2.3143, batch time: 0.10\n",
      "Epoch [1/5], Step [1280/1875], Loss: 2.3674, batch time: 0.11\n",
      "Epoch [1/5], Step [1281/1875], Loss: 2.2573, batch time: 0.11\n",
      "Epoch [1/5], Step [1282/1875], Loss: 2.3042, batch time: 0.21\n",
      "Epoch [1/5], Step [1283/1875], Loss: 2.3297, batch time: 0.11\n",
      "Epoch [1/5], Step [1284/1875], Loss: 2.3148, batch time: 0.12\n",
      "Epoch [1/5], Step [1285/1875], Loss: 2.3306, batch time: 0.11\n",
      "Epoch [1/5], Step [1286/1875], Loss: 2.2915, batch time: 0.14\n",
      "Epoch [1/5], Step [1287/1875], Loss: 2.3102, batch time: 0.12\n",
      "Epoch [1/5], Step [1288/1875], Loss: 2.2841, batch time: 0.13\n",
      "Epoch [1/5], Step [1289/1875], Loss: 2.2951, batch time: 0.12\n",
      "Epoch [1/5], Step [1290/1875], Loss: 2.2814, batch time: 0.10\n",
      "Epoch [1/5], Step [1291/1875], Loss: 2.2881, batch time: 0.10\n",
      "Epoch [1/5], Step [1292/1875], Loss: 2.2892, batch time: 0.10\n",
      "Epoch [1/5], Step [1293/1875], Loss: 2.3256, batch time: 0.14\n",
      "Epoch [1/5], Step [1294/1875], Loss: 2.3301, batch time: 0.10\n",
      "Epoch [1/5], Step [1295/1875], Loss: 2.2906, batch time: 0.10\n",
      "Epoch [1/5], Step [1296/1875], Loss: 2.2913, batch time: 0.12\n",
      "Epoch [1/5], Step [1297/1875], Loss: 2.2329, batch time: 0.10\n",
      "Epoch [1/5], Step [1298/1875], Loss: 2.3123, batch time: 0.13\n",
      "Epoch [1/5], Step [1299/1875], Loss: 2.2804, batch time: 0.10\n",
      "Epoch [1/5], Step [1300/1875], Loss: 2.2730, batch time: 0.18\n",
      "Epoch [1/5], Step [1301/1875], Loss: 2.3299, batch time: 0.10\n",
      "Epoch [1/5], Step [1302/1875], Loss: 2.2840, batch time: 0.14\n",
      "Epoch [1/5], Step [1303/1875], Loss: 2.2806, batch time: 0.13\n",
      "Epoch [1/5], Step [1304/1875], Loss: 2.3868, batch time: 0.10\n",
      "Epoch [1/5], Step [1305/1875], Loss: 2.2674, batch time: 0.10\n",
      "Epoch [1/5], Step [1306/1875], Loss: 2.3155, batch time: 0.12\n",
      "Epoch [1/5], Step [1307/1875], Loss: 2.2947, batch time: 0.12\n",
      "Epoch [1/5], Step [1308/1875], Loss: 2.2887, batch time: 0.10\n",
      "Epoch [1/5], Step [1309/1875], Loss: 2.3384, batch time: 0.10\n",
      "Epoch [1/5], Step [1310/1875], Loss: 2.2832, batch time: 0.10\n",
      "Epoch [1/5], Step [1311/1875], Loss: 2.3018, batch time: 0.11\n",
      "Epoch [1/5], Step [1312/1875], Loss: 2.3075, batch time: 0.12\n",
      "Epoch [1/5], Step [1313/1875], Loss: 2.3173, batch time: 0.11\n",
      "Epoch [1/5], Step [1314/1875], Loss: 2.3515, batch time: 0.20\n",
      "Epoch [1/5], Step [1315/1875], Loss: 2.3067, batch time: 0.10\n",
      "Epoch [1/5], Step [1316/1875], Loss: 2.2781, batch time: 0.10\n",
      "Epoch [1/5], Step [1317/1875], Loss: 2.3225, batch time: 0.10\n",
      "Epoch [1/5], Step [1318/1875], Loss: 2.2887, batch time: 0.10\n",
      "Epoch [1/5], Step [1319/1875], Loss: 2.3227, batch time: 0.16\n",
      "Epoch [1/5], Step [1320/1875], Loss: 2.2833, batch time: 0.10\n",
      "Epoch [1/5], Step [1321/1875], Loss: 2.3510, batch time: 0.10\n",
      "Epoch [1/5], Step [1322/1875], Loss: 2.3257, batch time: 0.10\n",
      "Epoch [1/5], Step [1323/1875], Loss: 2.3192, batch time: 0.15\n",
      "Epoch [1/5], Step [1324/1875], Loss: 2.3114, batch time: 0.14\n",
      "Epoch [1/5], Step [1325/1875], Loss: 2.3070, batch time: 0.12\n",
      "Epoch [1/5], Step [1326/1875], Loss: 2.3904, batch time: 0.10\n",
      "Epoch [1/5], Step [1327/1875], Loss: 2.3567, batch time: 0.10\n",
      "Epoch [1/5], Step [1328/1875], Loss: 2.2921, batch time: 0.31\n",
      "Epoch [1/5], Step [1329/1875], Loss: 2.3422, batch time: 0.10\n",
      "Epoch [1/5], Step [1330/1875], Loss: 2.2935, batch time: 0.10\n",
      "Epoch [1/5], Step [1331/1875], Loss: 2.3036, batch time: 0.11\n",
      "Epoch [1/5], Step [1332/1875], Loss: 2.3056, batch time: 0.10\n",
      "Epoch [1/5], Step [1333/1875], Loss: 2.2828, batch time: 0.10\n",
      "Epoch [1/5], Step [1334/1875], Loss: 2.3297, batch time: 0.10\n",
      "Epoch [1/5], Step [1335/1875], Loss: 2.3009, batch time: 0.10\n",
      "Epoch [1/5], Step [1336/1875], Loss: 2.3030, batch time: 0.11\n",
      "Epoch [1/5], Step [1337/1875], Loss: 2.2931, batch time: 0.11\n",
      "Epoch [1/5], Step [1338/1875], Loss: 2.3367, batch time: 0.17\n",
      "Epoch [1/5], Step [1339/1875], Loss: 2.3319, batch time: 0.10\n",
      "Epoch [1/5], Step [1340/1875], Loss: 2.2909, batch time: 0.10\n",
      "Epoch [1/5], Step [1341/1875], Loss: 2.3104, batch time: 0.10\n",
      "Epoch [1/5], Step [1342/1875], Loss: 2.3309, batch time: 0.11\n",
      "Epoch [1/5], Step [1343/1875], Loss: 2.3073, batch time: 0.14\n",
      "Epoch [1/5], Step [1344/1875], Loss: 2.2880, batch time: 0.10\n",
      "Epoch [1/5], Step [1345/1875], Loss: 2.3274, batch time: 0.10\n",
      "Epoch [1/5], Step [1346/1875], Loss: 2.3495, batch time: 0.10\n",
      "Epoch [1/5], Step [1347/1875], Loss: 2.3035, batch time: 0.10\n",
      "Epoch [1/5], Step [1348/1875], Loss: 2.3175, batch time: 0.13\n",
      "Epoch [1/5], Step [1349/1875], Loss: 2.2948, batch time: 0.11\n",
      "Epoch [1/5], Step [1350/1875], Loss: 2.2854, batch time: 0.10\n",
      "Epoch [1/5], Step [1351/1875], Loss: 2.3238, batch time: 0.11\n",
      "Epoch [1/5], Step [1352/1875], Loss: 2.3033, batch time: 0.10\n",
      "Epoch [1/5], Step [1353/1875], Loss: 2.2951, batch time: 0.10\n",
      "Epoch [1/5], Step [1354/1875], Loss: 2.3332, batch time: 0.10\n",
      "Epoch [1/5], Step [1355/1875], Loss: 2.2679, batch time: 0.10\n",
      "Epoch [1/5], Step [1356/1875], Loss: 2.2859, batch time: 0.14\n",
      "Epoch [1/5], Step [1357/1875], Loss: 2.3531, batch time: 0.12\n",
      "Epoch [1/5], Step [1358/1875], Loss: 2.3513, batch time: 0.12\n",
      "Epoch [1/5], Step [1359/1875], Loss: 2.2842, batch time: 0.10\n",
      "Epoch [1/5], Step [1360/1875], Loss: 2.3502, batch time: 0.10\n",
      "Epoch [1/5], Step [1361/1875], Loss: 2.3136, batch time: 0.10\n",
      "Epoch [1/5], Step [1362/1875], Loss: 2.2822, batch time: 0.12\n",
      "Epoch [1/5], Step [1363/1875], Loss: 2.3047, batch time: 0.10\n",
      "Epoch [1/5], Step [1364/1875], Loss: 2.3131, batch time: 0.10\n",
      "Epoch [1/5], Step [1365/1875], Loss: 2.3084, batch time: 0.10\n",
      "Epoch [1/5], Step [1366/1875], Loss: 2.3021, batch time: 0.10\n",
      "Epoch [1/5], Step [1367/1875], Loss: 2.3307, batch time: 0.10\n",
      "Epoch [1/5], Step [1368/1875], Loss: 2.3274, batch time: 0.10\n",
      "Epoch [1/5], Step [1369/1875], Loss: 2.3156, batch time: 0.11\n",
      "Epoch [1/5], Step [1370/1875], Loss: 2.2677, batch time: 0.10\n",
      "Epoch [1/5], Step [1371/1875], Loss: 2.3018, batch time: 0.15\n",
      "Epoch [1/5], Step [1372/1875], Loss: 2.2908, batch time: 0.10\n",
      "Epoch [1/5], Step [1373/1875], Loss: 2.2960, batch time: 0.10\n",
      "Epoch [1/5], Step [1374/1875], Loss: 2.2989, batch time: 0.10\n",
      "Epoch [1/5], Step [1375/1875], Loss: 2.2773, batch time: 0.14\n",
      "Epoch [1/5], Step [1376/1875], Loss: 2.3229, batch time: 0.10\n",
      "Epoch [1/5], Step [1377/1875], Loss: 2.2866, batch time: 0.10\n",
      "Epoch [1/5], Step [1378/1875], Loss: 2.2800, batch time: 0.10\n",
      "Epoch [1/5], Step [1379/1875], Loss: 2.2675, batch time: 0.10\n",
      "Epoch [1/5], Step [1380/1875], Loss: 2.3313, batch time: 0.14\n",
      "Epoch [1/5], Step [1381/1875], Loss: 2.3281, batch time: 0.13\n",
      "Epoch [1/5], Step [1382/1875], Loss: 2.3434, batch time: 0.10\n",
      "Epoch [1/5], Step [1383/1875], Loss: 2.2696, batch time: 0.10\n",
      "Epoch [1/5], Step [1384/1875], Loss: 2.2756, batch time: 0.10\n",
      "Epoch [1/5], Step [1385/1875], Loss: 2.3190, batch time: 0.10\n",
      "Epoch [1/5], Step [1386/1875], Loss: 2.3073, batch time: 0.13\n",
      "Epoch [1/5], Step [1387/1875], Loss: 2.3142, batch time: 0.10\n",
      "Epoch [1/5], Step [1388/1875], Loss: 2.3026, batch time: 0.10\n",
      "Epoch [1/5], Step [1389/1875], Loss: 2.3894, batch time: 0.15\n",
      "Epoch [1/5], Step [1390/1875], Loss: 2.2893, batch time: 0.10\n",
      "Epoch [1/5], Step [1391/1875], Loss: 2.2907, batch time: 0.10\n",
      "Epoch [1/5], Step [1392/1875], Loss: 2.3679, batch time: 0.10\n",
      "Epoch [1/5], Step [1393/1875], Loss: 2.2931, batch time: 0.10\n",
      "Epoch [1/5], Step [1394/1875], Loss: 2.2513, batch time: 0.11\n",
      "Epoch [1/5], Step [1395/1875], Loss: 2.2784, batch time: 0.10\n",
      "Epoch [1/5], Step [1396/1875], Loss: 2.2671, batch time: 0.10\n",
      "Epoch [1/5], Step [1397/1875], Loss: 2.2721, batch time: 0.10\n",
      "Epoch [1/5], Step [1398/1875], Loss: 2.3192, batch time: 0.10\n",
      "Epoch [1/5], Step [1399/1875], Loss: 2.3047, batch time: 0.11\n",
      "Epoch [1/5], Step [1400/1875], Loss: 2.2894, batch time: 0.10\n",
      "Epoch [1/5], Step [1401/1875], Loss: 2.2772, batch time: 0.12\n",
      "Epoch [1/5], Step [1402/1875], Loss: 2.2804, batch time: 0.10\n",
      "Epoch [1/5], Step [1403/1875], Loss: 2.2957, batch time: 0.10\n",
      "Epoch [1/5], Step [1404/1875], Loss: 2.3248, batch time: 0.13\n",
      "Epoch [1/5], Step [1405/1875], Loss: 2.3209, batch time: 0.10\n",
      "Epoch [1/5], Step [1406/1875], Loss: 2.2988, batch time: 0.10\n",
      "Epoch [1/5], Step [1407/1875], Loss: 2.2895, batch time: 0.11\n",
      "Epoch [1/5], Step [1408/1875], Loss: 2.2638, batch time: 0.10\n",
      "Epoch [1/5], Step [1409/1875], Loss: 2.3069, batch time: 0.10\n",
      "Epoch [1/5], Step [1410/1875], Loss: 2.2382, batch time: 0.10\n",
      "Epoch [1/5], Step [1411/1875], Loss: 2.3579, batch time: 0.12\n",
      "Epoch [1/5], Step [1412/1875], Loss: 2.3181, batch time: 0.15\n",
      "Epoch [1/5], Step [1413/1875], Loss: 2.3455, batch time: 0.10\n",
      "Epoch [1/5], Step [1414/1875], Loss: 2.3028, batch time: 0.12\n",
      "Epoch [1/5], Step [1415/1875], Loss: 2.3059, batch time: 0.10\n",
      "Epoch [1/5], Step [1416/1875], Loss: 2.3409, batch time: 0.10\n",
      "Epoch [1/5], Step [1417/1875], Loss: 2.3184, batch time: 0.11\n",
      "Epoch [1/5], Step [1418/1875], Loss: 2.3131, batch time: 0.11\n",
      "Epoch [1/5], Step [1419/1875], Loss: 2.2996, batch time: 0.11\n",
      "Epoch [1/5], Step [1420/1875], Loss: 2.3360, batch time: 0.10\n",
      "Epoch [1/5], Step [1421/1875], Loss: 2.3462, batch time: 0.10\n",
      "Epoch [1/5], Step [1422/1875], Loss: 2.3373, batch time: 0.10\n",
      "Epoch [1/5], Step [1423/1875], Loss: 2.2583, batch time: 0.10\n",
      "Epoch [1/5], Step [1424/1875], Loss: 2.3262, batch time: 0.11\n",
      "Epoch [1/5], Step [1425/1875], Loss: 2.3169, batch time: 0.10\n",
      "Epoch [1/5], Step [1426/1875], Loss: 2.2718, batch time: 0.10\n",
      "Epoch [1/5], Step [1427/1875], Loss: 2.3349, batch time: 0.10\n",
      "Epoch [1/5], Step [1428/1875], Loss: 2.2695, batch time: 0.13\n",
      "Epoch [1/5], Step [1429/1875], Loss: 2.3047, batch time: 0.10\n",
      "Epoch [1/5], Step [1430/1875], Loss: 2.2609, batch time: 0.10\n",
      "Epoch [1/5], Step [1431/1875], Loss: 2.3188, batch time: 0.10\n",
      "Epoch [1/5], Step [1432/1875], Loss: 2.3084, batch time: 0.14\n",
      "Epoch [1/5], Step [1433/1875], Loss: 2.3548, batch time: 0.15\n",
      "Epoch [1/5], Step [1434/1875], Loss: 2.3249, batch time: 0.10\n",
      "Epoch [1/5], Step [1435/1875], Loss: 2.2978, batch time: 0.15\n",
      "Epoch [1/5], Step [1436/1875], Loss: 2.3185, batch time: 0.10\n",
      "Epoch [1/5], Step [1437/1875], Loss: 2.3400, batch time: 0.10\n",
      "Epoch [1/5], Step [1438/1875], Loss: 2.3066, batch time: 0.10\n",
      "Epoch [1/5], Step [1439/1875], Loss: 2.3191, batch time: 0.12\n",
      "Epoch [1/5], Step [1440/1875], Loss: 2.3217, batch time: 0.13\n",
      "Epoch [1/5], Step [1441/1875], Loss: 2.3048, batch time: 0.10\n",
      "Epoch [1/5], Step [1442/1875], Loss: 2.3117, batch time: 0.10\n",
      "Epoch [1/5], Step [1443/1875], Loss: 2.2545, batch time: 0.10\n",
      "Epoch [1/5], Step [1444/1875], Loss: 2.3051, batch time: 0.10\n",
      "Epoch [1/5], Step [1445/1875], Loss: 2.3063, batch time: 0.10\n",
      "Epoch [1/5], Step [1446/1875], Loss: 2.2820, batch time: 0.10\n",
      "Epoch [1/5], Step [1447/1875], Loss: 2.2714, batch time: 0.10\n",
      "Epoch [1/5], Step [1448/1875], Loss: 2.2654, batch time: 0.10\n",
      "Epoch [1/5], Step [1449/1875], Loss: 2.3046, batch time: 0.10\n",
      "Epoch [1/5], Step [1450/1875], Loss: 2.2687, batch time: 0.10\n",
      "Epoch [1/5], Step [1451/1875], Loss: 2.3061, batch time: 0.13\n",
      "Epoch [1/5], Step [1452/1875], Loss: 2.2835, batch time: 0.10\n",
      "Epoch [1/5], Step [1453/1875], Loss: 2.3362, batch time: 0.10\n",
      "Epoch [1/5], Step [1454/1875], Loss: 2.3010, batch time: 0.10\n",
      "Epoch [1/5], Step [1455/1875], Loss: 2.3238, batch time: 0.10\n",
      "Epoch [1/5], Step [1456/1875], Loss: 2.2941, batch time: 0.15\n",
      "Epoch [1/5], Step [1457/1875], Loss: 2.3000, batch time: 0.10\n",
      "Epoch [1/5], Step [1458/1875], Loss: 2.3277, batch time: 0.10\n",
      "Epoch [1/5], Step [1459/1875], Loss: 2.2957, batch time: 0.11\n",
      "Epoch [1/5], Step [1460/1875], Loss: 2.3352, batch time: 0.22\n",
      "Epoch [1/5], Step [1461/1875], Loss: 2.2843, batch time: 0.09\n",
      "Epoch [1/5], Step [1462/1875], Loss: 2.3024, batch time: 0.09\n",
      "Epoch [1/5], Step [1463/1875], Loss: 2.3113, batch time: 0.12\n",
      "Epoch [1/5], Step [1464/1875], Loss: 2.3537, batch time: 0.13\n",
      "Epoch [1/5], Step [1465/1875], Loss: 2.2963, batch time: 0.10\n",
      "Epoch [1/5], Step [1466/1875], Loss: 2.3020, batch time: 0.15\n",
      "Epoch [1/5], Step [1467/1875], Loss: 2.2874, batch time: 0.11\n",
      "Epoch [1/5], Step [1468/1875], Loss: 2.2955, batch time: 0.11\n",
      "Epoch [1/5], Step [1469/1875], Loss: 2.3230, batch time: 0.11\n",
      "Epoch [1/5], Step [1470/1875], Loss: 2.3152, batch time: 0.13\n",
      "Epoch [1/5], Step [1471/1875], Loss: 2.2774, batch time: 0.10\n",
      "Epoch [1/5], Step [1472/1875], Loss: 2.2775, batch time: 0.10\n",
      "Epoch [1/5], Step [1473/1875], Loss: 2.3369, batch time: 0.21\n",
      "Epoch [1/5], Step [1474/1875], Loss: 2.3075, batch time: 0.13\n",
      "Epoch [1/5], Step [1475/1875], Loss: 2.3132, batch time: 0.11\n",
      "Epoch [1/5], Step [1476/1875], Loss: 2.3213, batch time: 0.10\n",
      "Epoch [1/5], Step [1477/1875], Loss: 2.2944, batch time: 0.12\n",
      "Epoch [1/5], Step [1478/1875], Loss: 2.3282, batch time: 0.10\n",
      "Epoch [1/5], Step [1479/1875], Loss: 2.3251, batch time: 0.10\n",
      "Epoch [1/5], Step [1480/1875], Loss: 2.2763, batch time: 0.11\n",
      "Epoch [1/5], Step [1481/1875], Loss: 2.2748, batch time: 0.10\n",
      "Epoch [1/5], Step [1482/1875], Loss: 2.2747, batch time: 0.13\n",
      "Epoch [1/5], Step [1483/1875], Loss: 2.2992, batch time: 0.10\n",
      "Epoch [1/5], Step [1484/1875], Loss: 2.3639, batch time: 0.12\n",
      "Epoch [1/5], Step [1485/1875], Loss: 2.3038, batch time: 0.14\n",
      "Epoch [1/5], Step [1486/1875], Loss: 2.3107, batch time: 0.11\n",
      "Epoch [1/5], Step [1487/1875], Loss: 2.3333, batch time: 0.19\n",
      "Epoch [1/5], Step [1488/1875], Loss: 2.2909, batch time: 0.11\n",
      "Epoch [1/5], Step [1489/1875], Loss: 2.3054, batch time: -2.78\n",
      "Epoch [1/5], Step [1490/1875], Loss: 2.2710, batch time: 0.12\n",
      "Epoch [1/5], Step [1491/1875], Loss: 2.2826, batch time: 0.11\n",
      "Epoch [1/5], Step [1492/1875], Loss: 2.3002, batch time: 0.12\n",
      "Epoch [1/5], Step [1493/1875], Loss: 2.2972, batch time: 0.10\n",
      "Epoch [1/5], Step [1494/1875], Loss: 2.2764, batch time: 0.10\n",
      "Epoch [1/5], Step [1495/1875], Loss: 2.3147, batch time: 0.12\n",
      "Epoch [1/5], Step [1496/1875], Loss: 2.2887, batch time: 0.13\n",
      "Epoch [1/5], Step [1497/1875], Loss: 2.2994, batch time: 0.10\n",
      "Epoch [1/5], Step [1498/1875], Loss: 2.3016, batch time: 0.10\n",
      "Epoch [1/5], Step [1499/1875], Loss: 2.2825, batch time: 0.15\n",
      "Epoch [1/5], Step [1500/1875], Loss: 2.2981, batch time: 0.10\n",
      "Epoch [1/5], Step [1501/1875], Loss: 2.2916, batch time: 0.10\n",
      "Epoch [1/5], Step [1502/1875], Loss: 2.3042, batch time: 0.10\n",
      "Epoch [1/5], Step [1503/1875], Loss: 2.2424, batch time: 0.10\n",
      "Epoch [1/5], Step [1504/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [1/5], Step [1505/1875], Loss: 2.3517, batch time: 0.10\n",
      "Epoch [1/5], Step [1506/1875], Loss: 2.2963, batch time: 0.10\n",
      "Epoch [1/5], Step [1507/1875], Loss: 2.2877, batch time: 0.10\n",
      "Epoch [1/5], Step [1508/1875], Loss: 2.3166, batch time: 0.10\n",
      "Epoch [1/5], Step [1509/1875], Loss: 2.3302, batch time: 0.10\n",
      "Epoch [1/5], Step [1510/1875], Loss: 2.2777, batch time: 0.10\n",
      "Epoch [1/5], Step [1511/1875], Loss: 2.3303, batch time: 0.15\n",
      "Epoch [1/5], Step [1512/1875], Loss: 2.2760, batch time: 0.10\n",
      "Epoch [1/5], Step [1513/1875], Loss: 2.2607, batch time: 0.10\n",
      "Epoch [1/5], Step [1514/1875], Loss: 2.3246, batch time: 0.14\n",
      "Epoch [1/5], Step [1515/1875], Loss: 2.3406, batch time: 0.10\n",
      "Epoch [1/5], Step [1516/1875], Loss: 2.2601, batch time: 0.10\n",
      "Epoch [1/5], Step [1517/1875], Loss: 2.2968, batch time: 0.13\n",
      "Epoch [1/5], Step [1518/1875], Loss: 2.2520, batch time: 0.10\n",
      "Epoch [1/5], Step [1519/1875], Loss: 2.3122, batch time: 0.11\n",
      "Epoch [1/5], Step [1520/1875], Loss: 2.3015, batch time: 0.12\n",
      "Epoch [1/5], Step [1521/1875], Loss: 2.2847, batch time: 0.10\n",
      "Epoch [1/5], Step [1522/1875], Loss: 2.2870, batch time: 0.11\n",
      "Epoch [1/5], Step [1523/1875], Loss: 2.2852, batch time: 0.10\n",
      "Epoch [1/5], Step [1524/1875], Loss: 2.3194, batch time: 0.10\n",
      "Epoch [1/5], Step [1525/1875], Loss: 2.3091, batch time: 0.10\n",
      "Epoch [1/5], Step [1526/1875], Loss: 2.3517, batch time: 0.14\n",
      "Epoch [1/5], Step [1527/1875], Loss: 2.2745, batch time: 0.13\n",
      "Epoch [1/5], Step [1528/1875], Loss: 2.2792, batch time: 0.12\n",
      "Epoch [1/5], Step [1529/1875], Loss: 2.2633, batch time: 0.10\n",
      "Epoch [1/5], Step [1530/1875], Loss: 2.2837, batch time: 0.10\n",
      "Epoch [1/5], Step [1531/1875], Loss: 2.2370, batch time: 0.10\n",
      "Epoch [1/5], Step [1532/1875], Loss: 2.2953, batch time: 0.10\n",
      "Epoch [1/5], Step [1533/1875], Loss: 2.2789, batch time: 0.10\n",
      "Epoch [1/5], Step [1534/1875], Loss: 2.2819, batch time: 0.10\n",
      "Epoch [1/5], Step [1535/1875], Loss: 2.3414, batch time: 0.10\n",
      "Epoch [1/5], Step [1536/1875], Loss: 2.2786, batch time: 0.10\n",
      "Epoch [1/5], Step [1537/1875], Loss: 2.3365, batch time: 0.10\n",
      "Epoch [1/5], Step [1538/1875], Loss: 2.2812, batch time: 0.11\n",
      "Epoch [1/5], Step [1539/1875], Loss: 2.2844, batch time: 0.12\n",
      "Epoch [1/5], Step [1540/1875], Loss: 2.3409, batch time: 0.11\n",
      "Epoch [1/5], Step [1541/1875], Loss: 2.2825, batch time: 0.10\n",
      "Epoch [1/5], Step [1542/1875], Loss: 2.3350, batch time: 0.10\n",
      "Epoch [1/5], Step [1543/1875], Loss: 2.2784, batch time: 0.13\n",
      "Epoch [1/5], Step [1544/1875], Loss: 2.3009, batch time: 0.13\n",
      "Epoch [1/5], Step [1545/1875], Loss: 2.3256, batch time: 0.10\n",
      "Epoch [1/5], Step [1546/1875], Loss: 2.3242, batch time: 0.11\n",
      "Epoch [1/5], Step [1547/1875], Loss: 2.3459, batch time: 0.14\n",
      "Epoch [1/5], Step [1548/1875], Loss: 2.3034, batch time: 0.11\n",
      "Epoch [1/5], Step [1549/1875], Loss: 2.3381, batch time: 0.10\n",
      "Epoch [1/5], Step [1550/1875], Loss: 2.3357, batch time: 0.13\n",
      "Epoch [1/5], Step [1551/1875], Loss: 2.3289, batch time: 0.10\n",
      "Epoch [1/5], Step [1552/1875], Loss: 2.2819, batch time: 0.14\n",
      "Epoch [1/5], Step [1553/1875], Loss: 2.2888, batch time: 0.10\n",
      "Epoch [1/5], Step [1554/1875], Loss: 2.2963, batch time: 0.10\n",
      "Epoch [1/5], Step [1555/1875], Loss: 2.3251, batch time: 0.10\n",
      "Epoch [1/5], Step [1556/1875], Loss: 2.3119, batch time: 0.10\n",
      "Epoch [1/5], Step [1557/1875], Loss: 2.3020, batch time: 0.10\n",
      "Epoch [1/5], Step [1558/1875], Loss: 2.2771, batch time: 0.10\n",
      "Epoch [1/5], Step [1559/1875], Loss: 2.2940, batch time: 0.10\n",
      "Epoch [1/5], Step [1560/1875], Loss: 2.2979, batch time: 0.10\n",
      "Epoch [1/5], Step [1561/1875], Loss: 2.3204, batch time: 0.10\n",
      "Epoch [1/5], Step [1562/1875], Loss: 2.3144, batch time: 0.10\n",
      "Epoch [1/5], Step [1563/1875], Loss: 2.3498, batch time: 0.13\n",
      "Epoch [1/5], Step [1564/1875], Loss: 2.3190, batch time: 0.10\n",
      "Epoch [1/5], Step [1565/1875], Loss: 2.2924, batch time: 0.10\n",
      "Epoch [1/5], Step [1566/1875], Loss: 2.2963, batch time: 0.10\n",
      "Epoch [1/5], Step [1567/1875], Loss: 2.3150, batch time: 0.10\n",
      "Epoch [1/5], Step [1568/1875], Loss: 2.3055, batch time: 0.13\n",
      "Epoch [1/5], Step [1569/1875], Loss: 2.3297, batch time: 0.10\n",
      "Epoch [1/5], Step [1570/1875], Loss: 2.2987, batch time: 0.10\n",
      "Epoch [1/5], Step [1571/1875], Loss: 2.2730, batch time: 0.10\n",
      "Epoch [1/5], Step [1572/1875], Loss: 2.2944, batch time: 0.10\n",
      "Epoch [1/5], Step [1573/1875], Loss: 2.3246, batch time: 0.10\n",
      "Epoch [1/5], Step [1574/1875], Loss: 2.3054, batch time: 0.12\n",
      "Epoch [1/5], Step [1575/1875], Loss: 2.3143, batch time: 0.19\n",
      "Epoch [1/5], Step [1576/1875], Loss: 2.2491, batch time: 0.14\n",
      "Epoch [1/5], Step [1577/1875], Loss: 2.3179, batch time: 0.10\n",
      "Epoch [1/5], Step [1578/1875], Loss: 2.2818, batch time: 0.29\n",
      "Epoch [1/5], Step [1579/1875], Loss: 2.2553, batch time: 0.11\n",
      "Epoch [1/5], Step [1580/1875], Loss: 2.3087, batch time: 0.10\n",
      "Epoch [1/5], Step [1581/1875], Loss: 2.2928, batch time: 0.10\n",
      "Epoch [1/5], Step [1582/1875], Loss: 2.3172, batch time: 0.10\n",
      "Epoch [1/5], Step [1583/1875], Loss: 2.3145, batch time: 0.10\n",
      "Epoch [1/5], Step [1584/1875], Loss: 2.2854, batch time: 0.11\n",
      "Epoch [1/5], Step [1585/1875], Loss: 2.2560, batch time: 0.10\n",
      "Epoch [1/5], Step [1586/1875], Loss: 2.3061, batch time: 0.10\n",
      "Epoch [1/5], Step [1587/1875], Loss: 2.2556, batch time: 0.12\n",
      "Epoch [1/5], Step [1588/1875], Loss: 2.2875, batch time: 0.10\n",
      "Epoch [1/5], Step [1589/1875], Loss: 2.3233, batch time: 0.13\n",
      "Epoch [1/5], Step [1590/1875], Loss: 2.2663, batch time: 0.10\n",
      "Epoch [1/5], Step [1591/1875], Loss: 2.3433, batch time: 0.13\n",
      "Epoch [1/5], Step [1592/1875], Loss: 2.2636, batch time: 0.10\n",
      "Epoch [1/5], Step [1593/1875], Loss: 2.3092, batch time: 0.11\n",
      "Epoch [1/5], Step [1594/1875], Loss: 2.3255, batch time: 0.10\n",
      "Epoch [1/5], Step [1595/1875], Loss: 2.3089, batch time: 0.10\n",
      "Epoch [1/5], Step [1596/1875], Loss: 2.2547, batch time: 0.10\n",
      "Epoch [1/5], Step [1597/1875], Loss: 2.2968, batch time: 0.12\n",
      "Epoch [1/5], Step [1598/1875], Loss: 2.2844, batch time: 0.11\n",
      "Epoch [1/5], Step [1599/1875], Loss: 2.2879, batch time: 0.14\n",
      "Epoch [1/5], Step [1600/1875], Loss: 2.2942, batch time: 0.10\n",
      "Epoch [1/5], Step [1601/1875], Loss: 2.3079, batch time: 0.13\n",
      "Epoch [1/5], Step [1602/1875], Loss: 2.2972, batch time: 0.10\n",
      "Epoch [1/5], Step [1603/1875], Loss: 2.2887, batch time: 0.13\n",
      "Epoch [1/5], Step [1604/1875], Loss: 2.2568, batch time: 0.10\n",
      "Epoch [1/5], Step [1605/1875], Loss: 2.2782, batch time: 0.10\n",
      "Epoch [1/5], Step [1606/1875], Loss: 2.2907, batch time: 0.10\n",
      "Epoch [1/5], Step [1607/1875], Loss: 2.3165, batch time: 0.10\n",
      "Epoch [1/5], Step [1608/1875], Loss: 2.3398, batch time: 0.11\n",
      "Epoch [1/5], Step [1609/1875], Loss: 2.3013, batch time: 0.10\n",
      "Epoch [1/5], Step [1610/1875], Loss: 2.2658, batch time: 0.11\n",
      "Epoch [1/5], Step [1611/1875], Loss: 2.2720, batch time: 0.12\n",
      "Epoch [1/5], Step [1612/1875], Loss: 2.3142, batch time: 0.15\n",
      "Epoch [1/5], Step [1613/1875], Loss: 2.2893, batch time: 0.10\n",
      "Epoch [1/5], Step [1614/1875], Loss: 2.3096, batch time: 0.12\n",
      "Epoch [1/5], Step [1615/1875], Loss: 2.3240, batch time: 0.10\n",
      "Epoch [1/5], Step [1616/1875], Loss: 2.3072, batch time: 0.10\n",
      "Epoch [1/5], Step [1617/1875], Loss: 2.2697, batch time: 0.14\n",
      "Epoch [1/5], Step [1618/1875], Loss: 2.2992, batch time: 0.13\n",
      "Epoch [1/5], Step [1619/1875], Loss: 2.3353, batch time: 0.11\n",
      "Epoch [1/5], Step [1620/1875], Loss: 2.3029, batch time: 0.10\n",
      "Epoch [1/5], Step [1621/1875], Loss: 2.3120, batch time: 0.10\n",
      "Epoch [1/5], Step [1622/1875], Loss: 2.3637, batch time: 0.14\n",
      "Epoch [1/5], Step [1623/1875], Loss: 2.3371, batch time: 0.10\n",
      "Epoch [1/5], Step [1624/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [1/5], Step [1625/1875], Loss: 2.3035, batch time: 0.10\n",
      "Epoch [1/5], Step [1626/1875], Loss: 2.3174, batch time: 0.11\n",
      "Epoch [1/5], Step [1627/1875], Loss: 2.2695, batch time: 0.11\n",
      "Epoch [1/5], Step [1628/1875], Loss: 2.3077, batch time: 0.10\n",
      "Epoch [1/5], Step [1629/1875], Loss: 2.2826, batch time: 0.12\n",
      "Epoch [1/5], Step [1630/1875], Loss: 2.2518, batch time: 0.11\n",
      "Epoch [1/5], Step [1631/1875], Loss: 2.2569, batch time: 0.10\n",
      "Epoch [1/5], Step [1632/1875], Loss: 2.2861, batch time: 0.10\n",
      "Epoch [1/5], Step [1633/1875], Loss: 2.3022, batch time: 0.10\n",
      "Epoch [1/5], Step [1634/1875], Loss: 2.2891, batch time: 0.10\n",
      "Epoch [1/5], Step [1635/1875], Loss: 2.2804, batch time: 0.10\n",
      "Epoch [1/5], Step [1636/1875], Loss: 2.3182, batch time: 0.16\n",
      "Epoch [1/5], Step [1637/1875], Loss: 2.2731, batch time: 0.16\n",
      "Epoch [1/5], Step [1638/1875], Loss: 2.3298, batch time: 0.10\n",
      "Epoch [1/5], Step [1639/1875], Loss: 2.3208, batch time: 0.10\n",
      "Epoch [1/5], Step [1640/1875], Loss: 2.2621, batch time: 0.10\n",
      "Epoch [1/5], Step [1641/1875], Loss: 2.3304, batch time: 0.10\n",
      "Epoch [1/5], Step [1642/1875], Loss: 2.2241, batch time: 0.15\n",
      "Epoch [1/5], Step [1643/1875], Loss: 2.3411, batch time: 0.10\n",
      "Epoch [1/5], Step [1644/1875], Loss: 2.3201, batch time: 0.10\n",
      "Epoch [1/5], Step [1645/1875], Loss: 2.3278, batch time: 0.10\n",
      "Epoch [1/5], Step [1646/1875], Loss: 2.2602, batch time: 0.12\n",
      "Epoch [1/5], Step [1647/1875], Loss: 2.3015, batch time: 0.11\n",
      "Epoch [1/5], Step [1648/1875], Loss: 2.2861, batch time: 0.10\n",
      "Epoch [1/5], Step [1649/1875], Loss: 2.2669, batch time: 0.10\n",
      "Epoch [1/5], Step [1650/1875], Loss: 2.2906, batch time: 0.19\n",
      "Epoch [1/5], Step [1651/1875], Loss: 2.3019, batch time: 0.10\n",
      "Epoch [1/5], Step [1652/1875], Loss: 2.2936, batch time: 0.12\n",
      "Epoch [1/5], Step [1653/1875], Loss: 2.2624, batch time: 0.10\n",
      "Epoch [1/5], Step [1654/1875], Loss: 2.2538, batch time: 0.10\n",
      "Epoch [1/5], Step [1655/1875], Loss: 2.3453, batch time: 0.10\n",
      "Epoch [1/5], Step [1656/1875], Loss: 2.2857, batch time: 0.17\n",
      "Epoch [1/5], Step [1657/1875], Loss: 2.2747, batch time: 0.10\n",
      "Epoch [1/5], Step [1658/1875], Loss: 2.2759, batch time: 0.11\n",
      "Epoch [1/5], Step [1659/1875], Loss: 2.3023, batch time: 0.12\n",
      "Epoch [1/5], Step [1660/1875], Loss: 2.3123, batch time: 0.10\n",
      "Epoch [1/5], Step [1661/1875], Loss: 2.3269, batch time: 0.11\n",
      "Epoch [1/5], Step [1662/1875], Loss: 2.3094, batch time: 0.10\n",
      "Epoch [1/5], Step [1663/1875], Loss: 2.3007, batch time: 0.10\n",
      "Epoch [1/5], Step [1664/1875], Loss: 2.3097, batch time: 0.10\n",
      "Epoch [1/5], Step [1665/1875], Loss: 2.3288, batch time: 0.10\n",
      "Epoch [1/5], Step [1666/1875], Loss: 2.2781, batch time: 0.14\n",
      "Epoch [1/5], Step [1667/1875], Loss: 2.2875, batch time: 0.12\n",
      "Epoch [1/5], Step [1668/1875], Loss: 2.2998, batch time: 0.12\n",
      "Epoch [1/5], Step [1669/1875], Loss: 2.2662, batch time: 0.10\n",
      "Epoch [1/5], Step [1670/1875], Loss: 2.2931, batch time: 0.10\n",
      "Epoch [1/5], Step [1671/1875], Loss: 2.2936, batch time: 0.16\n",
      "Epoch [1/5], Step [1672/1875], Loss: 2.3249, batch time: 0.10\n",
      "Epoch [1/5], Step [1673/1875], Loss: 2.2537, batch time: 0.13\n",
      "Epoch [1/5], Step [1674/1875], Loss: 2.2787, batch time: 0.13\n",
      "Epoch [1/5], Step [1675/1875], Loss: 2.2907, batch time: 0.10\n",
      "Epoch [1/5], Step [1676/1875], Loss: 2.2783, batch time: 0.12\n",
      "Epoch [1/5], Step [1677/1875], Loss: 2.2795, batch time: 0.11\n",
      "Epoch [1/5], Step [1678/1875], Loss: 2.3224, batch time: 0.12\n",
      "Epoch [1/5], Step [1679/1875], Loss: 2.2943, batch time: 0.10\n",
      "Epoch [1/5], Step [1680/1875], Loss: 2.3462, batch time: 0.10\n",
      "Epoch [1/5], Step [1681/1875], Loss: 2.3132, batch time: 0.10\n",
      "Epoch [1/5], Step [1682/1875], Loss: 2.3200, batch time: 0.13\n",
      "Epoch [1/5], Step [1683/1875], Loss: 2.2868, batch time: 0.14\n",
      "Epoch [1/5], Step [1684/1875], Loss: 2.2813, batch time: 0.10\n",
      "Epoch [1/5], Step [1685/1875], Loss: 2.3038, batch time: 0.11\n",
      "Epoch [1/5], Step [1686/1875], Loss: 2.3202, batch time: 0.10\n",
      "Epoch [1/5], Step [1687/1875], Loss: 2.2961, batch time: 0.12\n",
      "Epoch [1/5], Step [1688/1875], Loss: 2.2988, batch time: 0.10\n",
      "Epoch [1/5], Step [1689/1875], Loss: 2.3244, batch time: 0.21\n",
      "Epoch [1/5], Step [1690/1875], Loss: 2.2506, batch time: 0.10\n",
      "Epoch [1/5], Step [1691/1875], Loss: 2.3093, batch time: 0.16\n",
      "Epoch [1/5], Step [1692/1875], Loss: 2.3256, batch time: 0.13\n",
      "Epoch [1/5], Step [1693/1875], Loss: 2.3239, batch time: 0.12\n",
      "Epoch [1/5], Step [1694/1875], Loss: 2.3005, batch time: 0.13\n",
      "Epoch [1/5], Step [1695/1875], Loss: 2.2838, batch time: 0.14\n",
      "Epoch [1/5], Step [1696/1875], Loss: 2.3042, batch time: 0.10\n",
      "Epoch [1/5], Step [1697/1875], Loss: 2.2933, batch time: 0.16\n",
      "Epoch [1/5], Step [1698/1875], Loss: 2.3270, batch time: 0.10\n",
      "Epoch [1/5], Step [1699/1875], Loss: 2.3146, batch time: 0.10\n",
      "Epoch [1/5], Step [1700/1875], Loss: 2.3123, batch time: 0.10\n",
      "Epoch [1/5], Step [1701/1875], Loss: 2.3184, batch time: 0.10\n",
      "Epoch [1/5], Step [1702/1875], Loss: 2.2533, batch time: 0.10\n",
      "Epoch [1/5], Step [1703/1875], Loss: 2.3036, batch time: 0.10\n",
      "Epoch [1/5], Step [1704/1875], Loss: 2.2588, batch time: 0.13\n",
      "Epoch [1/5], Step [1705/1875], Loss: 2.2765, batch time: 0.14\n",
      "Epoch [1/5], Step [1706/1875], Loss: 2.2851, batch time: 0.11\n",
      "Epoch [1/5], Step [1707/1875], Loss: 2.3013, batch time: 0.10\n",
      "Epoch [1/5], Step [1708/1875], Loss: 2.3018, batch time: 0.10\n",
      "Epoch [1/5], Step [1709/1875], Loss: 2.2816, batch time: 0.11\n",
      "Epoch [1/5], Step [1710/1875], Loss: 2.2856, batch time: 0.13\n",
      "Epoch [1/5], Step [1711/1875], Loss: 2.2931, batch time: 0.10\n",
      "Epoch [1/5], Step [1712/1875], Loss: 2.3064, batch time: 0.09\n",
      "Epoch [1/5], Step [1713/1875], Loss: 2.3142, batch time: 0.13\n",
      "Epoch [1/5], Step [1714/1875], Loss: 2.2979, batch time: 0.13\n",
      "Epoch [1/5], Step [1715/1875], Loss: 2.2901, batch time: 0.10\n",
      "Epoch [1/5], Step [1716/1875], Loss: 2.3041, batch time: 0.10\n",
      "Epoch [1/5], Step [1717/1875], Loss: 2.2279, batch time: 0.09\n",
      "Epoch [1/5], Step [1718/1875], Loss: 2.3138, batch time: 0.10\n",
      "Epoch [1/5], Step [1719/1875], Loss: 2.3288, batch time: 0.10\n",
      "Epoch [1/5], Step [1720/1875], Loss: 2.3110, batch time: 0.11\n",
      "Epoch [1/5], Step [1721/1875], Loss: 2.2942, batch time: 0.16\n",
      "Epoch [1/5], Step [1722/1875], Loss: 2.3230, batch time: 0.16\n",
      "Epoch [1/5], Step [1723/1875], Loss: 2.2917, batch time: 0.10\n",
      "Epoch [1/5], Step [1724/1875], Loss: 2.2907, batch time: 0.10\n",
      "Epoch [1/5], Step [1725/1875], Loss: 2.2800, batch time: 0.13\n",
      "Epoch [1/5], Step [1726/1875], Loss: 2.2672, batch time: 0.20\n",
      "Epoch [1/5], Step [1727/1875], Loss: 2.3084, batch time: 0.11\n",
      "Epoch [1/5], Step [1728/1875], Loss: 2.2859, batch time: 0.13\n",
      "Epoch [1/5], Step [1729/1875], Loss: 2.3049, batch time: 0.13\n",
      "Epoch [1/5], Step [1730/1875], Loss: 2.2964, batch time: 0.10\n",
      "Epoch [1/5], Step [1731/1875], Loss: 2.2814, batch time: 0.10\n",
      "Epoch [1/5], Step [1732/1875], Loss: 2.2785, batch time: 0.11\n",
      "Epoch [1/5], Step [1733/1875], Loss: 2.3177, batch time: 0.12\n",
      "Epoch [1/5], Step [1734/1875], Loss: 2.2997, batch time: 0.10\n",
      "Epoch [1/5], Step [1735/1875], Loss: 2.2840, batch time: 0.10\n",
      "Epoch [1/5], Step [1736/1875], Loss: 2.3202, batch time: 0.10\n",
      "Epoch [1/5], Step [1737/1875], Loss: 2.3364, batch time: 0.27\n",
      "Epoch [1/5], Step [1738/1875], Loss: 2.3209, batch time: 0.10\n",
      "Epoch [1/5], Step [1739/1875], Loss: 2.2627, batch time: 0.10\n",
      "Epoch [1/5], Step [1740/1875], Loss: 2.2932, batch time: 0.11\n",
      "Epoch [1/5], Step [1741/1875], Loss: 2.3112, batch time: 0.11\n",
      "Epoch [1/5], Step [1742/1875], Loss: 2.2588, batch time: 0.13\n",
      "Epoch [1/5], Step [1743/1875], Loss: 2.2923, batch time: 0.10\n",
      "Epoch [1/5], Step [1744/1875], Loss: 2.2456, batch time: 0.10\n",
      "Epoch [1/5], Step [1745/1875], Loss: 2.2831, batch time: 0.20\n",
      "Epoch [1/5], Step [1746/1875], Loss: 2.2781, batch time: 0.10\n",
      "Epoch [1/5], Step [1747/1875], Loss: 2.3313, batch time: 0.10\n",
      "Epoch [1/5], Step [1748/1875], Loss: 2.3237, batch time: 0.10\n",
      "Epoch [1/5], Step [1749/1875], Loss: 2.3047, batch time: 0.11\n",
      "Epoch [1/5], Step [1750/1875], Loss: 2.3149, batch time: 0.10\n",
      "Epoch [1/5], Step [1751/1875], Loss: 2.2988, batch time: 0.10\n",
      "Epoch [1/5], Step [1752/1875], Loss: 2.2874, batch time: 0.10\n",
      "Epoch [1/5], Step [1753/1875], Loss: 2.2760, batch time: 0.10\n",
      "Epoch [1/5], Step [1754/1875], Loss: 2.3017, batch time: 0.10\n",
      "Epoch [1/5], Step [1755/1875], Loss: 2.3127, batch time: 0.10\n",
      "Epoch [1/5], Step [1756/1875], Loss: 2.3390, batch time: 0.10\n",
      "Epoch [1/5], Step [1757/1875], Loss: 2.2570, batch time: 0.10\n",
      "Epoch [1/5], Step [1758/1875], Loss: 2.2856, batch time: 0.10\n",
      "Epoch [1/5], Step [1759/1875], Loss: 2.2809, batch time: 0.10\n",
      "Epoch [1/5], Step [1760/1875], Loss: 2.3056, batch time: 0.18\n",
      "Epoch [1/5], Step [1761/1875], Loss: 2.3034, batch time: 0.10\n",
      "Epoch [1/5], Step [1762/1875], Loss: 2.2991, batch time: 0.11\n",
      "Epoch [1/5], Step [1763/1875], Loss: 2.3357, batch time: 0.10\n",
      "Epoch [1/5], Step [1764/1875], Loss: 2.3272, batch time: 0.10\n",
      "Epoch [1/5], Step [1765/1875], Loss: 2.2816, batch time: 0.10\n",
      "Epoch [1/5], Step [1766/1875], Loss: 2.2971, batch time: 0.10\n",
      "Epoch [1/5], Step [1767/1875], Loss: 2.2813, batch time: 0.10\n",
      "Epoch [1/5], Step [1768/1875], Loss: 2.3171, batch time: 0.10\n",
      "Epoch [1/5], Step [1769/1875], Loss: 2.3216, batch time: 0.10\n",
      "Epoch [1/5], Step [1770/1875], Loss: 2.3353, batch time: 0.10\n",
      "Epoch [1/5], Step [1771/1875], Loss: 2.3139, batch time: -2.83\n",
      "Epoch [1/5], Step [1772/1875], Loss: 2.3002, batch time: 0.10\n",
      "Epoch [1/5], Step [1773/1875], Loss: 2.2828, batch time: 0.10\n",
      "Epoch [1/5], Step [1774/1875], Loss: 2.2662, batch time: 0.10\n",
      "Epoch [1/5], Step [1775/1875], Loss: 2.3006, batch time: 0.10\n",
      "Epoch [1/5], Step [1776/1875], Loss: 2.2962, batch time: 0.10\n",
      "Epoch [1/5], Step [1777/1875], Loss: 2.3054, batch time: 0.10\n",
      "Epoch [1/5], Step [1778/1875], Loss: 2.2659, batch time: 0.10\n",
      "Epoch [1/5], Step [1779/1875], Loss: 2.2878, batch time: 0.10\n",
      "Epoch [1/5], Step [1780/1875], Loss: 2.3018, batch time: 0.12\n",
      "Epoch [1/5], Step [1781/1875], Loss: 2.3047, batch time: 0.10\n",
      "Epoch [1/5], Step [1782/1875], Loss: 2.2971, batch time: 0.16\n",
      "Epoch [1/5], Step [1783/1875], Loss: 2.2965, batch time: 0.10\n",
      "Epoch [1/5], Step [1784/1875], Loss: 2.3008, batch time: 0.10\n",
      "Epoch [1/5], Step [1785/1875], Loss: 2.2964, batch time: 0.10\n",
      "Epoch [1/5], Step [1786/1875], Loss: 2.3163, batch time: 0.11\n",
      "Epoch [1/5], Step [1787/1875], Loss: 2.3123, batch time: 0.10\n",
      "Epoch [1/5], Step [1788/1875], Loss: 2.2782, batch time: 0.10\n",
      "Epoch [1/5], Step [1789/1875], Loss: 2.2832, batch time: 0.10\n",
      "Epoch [1/5], Step [1790/1875], Loss: 2.3402, batch time: 0.15\n",
      "Epoch [1/5], Step [1791/1875], Loss: 2.3235, batch time: 0.11\n",
      "Epoch [1/5], Step [1792/1875], Loss: 2.3142, batch time: 0.10\n",
      "Epoch [1/5], Step [1793/1875], Loss: 2.2766, batch time: 0.11\n",
      "Epoch [1/5], Step [1794/1875], Loss: 2.2986, batch time: 0.10\n",
      "Epoch [1/5], Step [1795/1875], Loss: 2.2775, batch time: 0.12\n",
      "Epoch [1/5], Step [1796/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [1/5], Step [1797/1875], Loss: 2.3182, batch time: 0.11\n",
      "Epoch [1/5], Step [1798/1875], Loss: 2.3010, batch time: 0.10\n",
      "Epoch [1/5], Step [1799/1875], Loss: 2.2988, batch time: 0.19\n",
      "Epoch [1/5], Step [1800/1875], Loss: 2.3068, batch time: 0.10\n",
      "Epoch [1/5], Step [1801/1875], Loss: 2.3001, batch time: 0.11\n",
      "Epoch [1/5], Step [1802/1875], Loss: 2.2849, batch time: 0.20\n",
      "Epoch [1/5], Step [1803/1875], Loss: 2.2788, batch time: 0.10\n",
      "Epoch [1/5], Step [1804/1875], Loss: 2.2900, batch time: 0.15\n",
      "Epoch [1/5], Step [1805/1875], Loss: 2.2753, batch time: 0.10\n",
      "Epoch [1/5], Step [1806/1875], Loss: 2.3188, batch time: 0.10\n",
      "Epoch [1/5], Step [1807/1875], Loss: 2.2864, batch time: 0.10\n",
      "Epoch [1/5], Step [1808/1875], Loss: 2.2920, batch time: 0.10\n",
      "Epoch [1/5], Step [1809/1875], Loss: 2.2865, batch time: 0.10\n",
      "Epoch [1/5], Step [1810/1875], Loss: 2.2350, batch time: 0.10\n",
      "Epoch [1/5], Step [1811/1875], Loss: 2.2982, batch time: 0.10\n",
      "Epoch [1/5], Step [1812/1875], Loss: 2.2637, batch time: 0.10\n",
      "Epoch [1/5], Step [1813/1875], Loss: 2.2929, batch time: 0.10\n",
      "Epoch [1/5], Step [1814/1875], Loss: 2.3055, batch time: 0.13\n",
      "Epoch [1/5], Step [1815/1875], Loss: 2.3028, batch time: 0.10\n",
      "Epoch [1/5], Step [1816/1875], Loss: 2.3399, batch time: 0.10\n",
      "Epoch [1/5], Step [1817/1875], Loss: 2.2711, batch time: 0.10\n",
      "Epoch [1/5], Step [1818/1875], Loss: 2.3074, batch time: 0.12\n",
      "Epoch [1/5], Step [1819/1875], Loss: 2.2516, batch time: 0.17\n",
      "Epoch [1/5], Step [1820/1875], Loss: 2.3202, batch time: 0.10\n",
      "Epoch [1/5], Step [1821/1875], Loss: 2.2843, batch time: 0.13\n",
      "Epoch [1/5], Step [1822/1875], Loss: 2.3078, batch time: 0.10\n",
      "Epoch [1/5], Step [1823/1875], Loss: 2.2858, batch time: 0.10\n",
      "Epoch [1/5], Step [1824/1875], Loss: 2.2771, batch time: 0.10\n",
      "Epoch [1/5], Step [1825/1875], Loss: 2.2988, batch time: 0.11\n",
      "Epoch [1/5], Step [1826/1875], Loss: 2.2999, batch time: 0.14\n",
      "Epoch [1/5], Step [1827/1875], Loss: 2.3001, batch time: 0.13\n",
      "Epoch [1/5], Step [1828/1875], Loss: 2.3246, batch time: 0.12\n",
      "Epoch [1/5], Step [1829/1875], Loss: 2.2692, batch time: 0.12\n",
      "Epoch [1/5], Step [1830/1875], Loss: 2.2661, batch time: 0.10\n",
      "Epoch [1/5], Step [1831/1875], Loss: 2.2695, batch time: 0.24\n",
      "Epoch [1/5], Step [1832/1875], Loss: 2.2603, batch time: 0.11\n",
      "Epoch [1/5], Step [1833/1875], Loss: 2.2840, batch time: 0.13\n",
      "Epoch [1/5], Step [1834/1875], Loss: 2.3548, batch time: 0.12\n",
      "Epoch [1/5], Step [1835/1875], Loss: 2.3353, batch time: 0.14\n",
      "Epoch [1/5], Step [1836/1875], Loss: 2.2972, batch time: 0.12\n",
      "Epoch [1/5], Step [1837/1875], Loss: 2.2885, batch time: 0.12\n",
      "Epoch [1/5], Step [1838/1875], Loss: 2.2612, batch time: 0.14\n",
      "Epoch [1/5], Step [1839/1875], Loss: 2.3109, batch time: 0.13\n",
      "Epoch [1/5], Step [1840/1875], Loss: 2.2595, batch time: 0.18\n",
      "Epoch [1/5], Step [1841/1875], Loss: 2.2842, batch time: 0.17\n",
      "Epoch [1/5], Step [1842/1875], Loss: 2.2881, batch time: 0.23\n",
      "Epoch [1/5], Step [1843/1875], Loss: 2.3094, batch time: 0.14\n",
      "Epoch [1/5], Step [1844/1875], Loss: 2.3219, batch time: 0.14\n",
      "Epoch [1/5], Step [1845/1875], Loss: 2.3216, batch time: 0.13\n",
      "Epoch [1/5], Step [1846/1875], Loss: 2.3187, batch time: 0.11\n",
      "Epoch [1/5], Step [1847/1875], Loss: 2.2922, batch time: 0.10\n",
      "Epoch [1/5], Step [1848/1875], Loss: 2.3188, batch time: 0.10\n",
      "Epoch [1/5], Step [1849/1875], Loss: 2.2165, batch time: 0.10\n",
      "Epoch [1/5], Step [1850/1875], Loss: 2.3005, batch time: 0.12\n",
      "Epoch [1/5], Step [1851/1875], Loss: 2.3161, batch time: 0.13\n",
      "Epoch [1/5], Step [1852/1875], Loss: 2.2848, batch time: 0.10\n",
      "Epoch [1/5], Step [1853/1875], Loss: 2.2796, batch time: 0.22\n",
      "Epoch [1/5], Step [1854/1875], Loss: 2.2673, batch time: 0.13\n",
      "Epoch [1/5], Step [1855/1875], Loss: 2.2932, batch time: 0.14\n",
      "Epoch [1/5], Step [1856/1875], Loss: 2.2906, batch time: 0.13\n",
      "Epoch [1/5], Step [1857/1875], Loss: 2.2862, batch time: 0.14\n",
      "Epoch [1/5], Step [1858/1875], Loss: 2.2828, batch time: 0.14\n",
      "Epoch [1/5], Step [1859/1875], Loss: 2.3027, batch time: 0.10\n",
      "Epoch [1/5], Step [1860/1875], Loss: 2.2790, batch time: 0.14\n",
      "Epoch [1/5], Step [1861/1875], Loss: 2.3091, batch time: 0.13\n",
      "Epoch [1/5], Step [1862/1875], Loss: 2.2701, batch time: 0.10\n",
      "Epoch [1/5], Step [1863/1875], Loss: 2.3108, batch time: 0.11\n",
      "Epoch [1/5], Step [1864/1875], Loss: 2.3239, batch time: 0.11\n",
      "Epoch [1/5], Step [1865/1875], Loss: 2.2727, batch time: 0.11\n",
      "Epoch [1/5], Step [1866/1875], Loss: 2.2895, batch time: 0.12\n",
      "Epoch [1/5], Step [1867/1875], Loss: 2.2867, batch time: 0.10\n",
      "Epoch [1/5], Step [1868/1875], Loss: 2.2786, batch time: 0.11\n",
      "Epoch [1/5], Step [1869/1875], Loss: 2.3392, batch time: 0.10\n",
      "Epoch [1/5], Step [1870/1875], Loss: 2.3234, batch time: 0.10\n",
      "Epoch [1/5], Step [1871/1875], Loss: 2.3150, batch time: 0.10\n",
      "Epoch [1/5], Step [1872/1875], Loss: 2.3048, batch time: 0.10\n",
      "Epoch [1/5], Step [1873/1875], Loss: 2.2991, batch time: 0.10\n",
      "Epoch [1/5], Step [1874/1875], Loss: 2.2760, batch time: 0.14\n",
      "Epoch [1/5], Step [1875/1875], Loss: 2.2566, batch time: 0.10\n",
      "Epoch [1/5] Accuracy: 11.15%\n",
      "Epoch [2/5], Step [1/1875], Loss: 2.2981, batch time: 0.10\n",
      "Epoch [2/5], Step [2/1875], Loss: 2.2969, batch time: 0.19\n",
      "Epoch [2/5], Step [3/1875], Loss: 2.2944, batch time: 0.14\n",
      "Epoch [2/5], Step [4/1875], Loss: 2.3086, batch time: 0.10\n",
      "Epoch [2/5], Step [5/1875], Loss: 2.2676, batch time: 0.10\n",
      "Epoch [2/5], Step [6/1875], Loss: 2.3324, batch time: 0.10\n",
      "Epoch [2/5], Step [7/1875], Loss: 2.3224, batch time: 0.10\n",
      "Epoch [2/5], Step [8/1875], Loss: 2.2919, batch time: 0.11\n",
      "Epoch [2/5], Step [9/1875], Loss: 2.2852, batch time: 0.17\n",
      "Epoch [2/5], Step [10/1875], Loss: 2.3279, batch time: 0.12\n",
      "Epoch [2/5], Step [11/1875], Loss: 2.2747, batch time: 0.10\n",
      "Epoch [2/5], Step [12/1875], Loss: 2.2708, batch time: 0.12\n",
      "Epoch [2/5], Step [13/1875], Loss: 2.2848, batch time: 0.10\n",
      "Epoch [2/5], Step [14/1875], Loss: 2.2629, batch time: 0.15\n",
      "Epoch [2/5], Step [15/1875], Loss: 2.2749, batch time: 0.12\n",
      "Epoch [2/5], Step [16/1875], Loss: 2.3115, batch time: 0.20\n",
      "Epoch [2/5], Step [17/1875], Loss: 2.2759, batch time: 0.11\n",
      "Epoch [2/5], Step [18/1875], Loss: 2.2939, batch time: 0.10\n",
      "Epoch [2/5], Step [19/1875], Loss: 2.2879, batch time: 0.10\n",
      "Epoch [2/5], Step [20/1875], Loss: 2.2822, batch time: 0.22\n",
      "Epoch [2/5], Step [21/1875], Loss: 2.3400, batch time: 0.10\n",
      "Epoch [2/5], Step [22/1875], Loss: 2.2661, batch time: 0.10\n",
      "Epoch [2/5], Step [23/1875], Loss: 2.3022, batch time: 0.10\n",
      "Epoch [2/5], Step [24/1875], Loss: 2.2748, batch time: 0.10\n",
      "Epoch [2/5], Step [25/1875], Loss: 2.2946, batch time: 0.18\n",
      "Epoch [2/5], Step [26/1875], Loss: 2.3033, batch time: 0.10\n",
      "Epoch [2/5], Step [27/1875], Loss: 2.2950, batch time: 0.10\n",
      "Epoch [2/5], Step [28/1875], Loss: 2.2738, batch time: 0.10\n",
      "Epoch [2/5], Step [29/1875], Loss: 2.2784, batch time: 0.10\n",
      "Epoch [2/5], Step [30/1875], Loss: 2.2338, batch time: 0.17\n",
      "Epoch [2/5], Step [31/1875], Loss: 2.2767, batch time: 0.10\n",
      "Epoch [2/5], Step [32/1875], Loss: 2.3067, batch time: 0.10\n",
      "Epoch [2/5], Step [33/1875], Loss: 2.3730, batch time: 0.13\n",
      "Epoch [2/5], Step [34/1875], Loss: 2.2300, batch time: 0.10\n",
      "Epoch [2/5], Step [35/1875], Loss: 2.3062, batch time: 0.14\n",
      "Epoch [2/5], Step [36/1875], Loss: 2.2985, batch time: 0.13\n",
      "Epoch [2/5], Step [37/1875], Loss: 2.2980, batch time: 0.12\n",
      "Epoch [2/5], Step [38/1875], Loss: 2.3231, batch time: 0.10\n",
      "Epoch [2/5], Step [39/1875], Loss: 2.3159, batch time: 0.10\n",
      "Epoch [2/5], Step [40/1875], Loss: 2.2714, batch time: 0.10\n",
      "Epoch [2/5], Step [41/1875], Loss: 2.3036, batch time: 0.10\n",
      "Epoch [2/5], Step [42/1875], Loss: 2.2968, batch time: 0.10\n",
      "Epoch [2/5], Step [43/1875], Loss: 2.2740, batch time: 0.11\n",
      "Epoch [2/5], Step [44/1875], Loss: 2.3308, batch time: 0.10\n",
      "Epoch [2/5], Step [45/1875], Loss: 2.2556, batch time: 0.13\n",
      "Epoch [2/5], Step [46/1875], Loss: 2.3100, batch time: 0.12\n",
      "Epoch [2/5], Step [47/1875], Loss: 2.3151, batch time: 0.13\n",
      "Epoch [2/5], Step [48/1875], Loss: 2.3221, batch time: 0.10\n",
      "Epoch [2/5], Step [49/1875], Loss: 2.3075, batch time: 0.14\n",
      "Epoch [2/5], Step [50/1875], Loss: 2.2376, batch time: 0.10\n",
      "Epoch [2/5], Step [51/1875], Loss: 2.2487, batch time: 0.10\n",
      "Epoch [2/5], Step [52/1875], Loss: 2.2947, batch time: 0.13\n",
      "Epoch [2/5], Step [53/1875], Loss: 2.2940, batch time: 0.10\n",
      "Epoch [2/5], Step [54/1875], Loss: 2.3467, batch time: 0.11\n",
      "Epoch [2/5], Step [55/1875], Loss: 2.3467, batch time: 0.10\n",
      "Epoch [2/5], Step [56/1875], Loss: 2.2338, batch time: 0.12\n",
      "Epoch [2/5], Step [57/1875], Loss: 2.2849, batch time: 0.13\n",
      "Epoch [2/5], Step [58/1875], Loss: 2.3269, batch time: 0.13\n",
      "Epoch [2/5], Step [59/1875], Loss: 2.3252, batch time: 0.17\n",
      "Epoch [2/5], Step [60/1875], Loss: 2.2730, batch time: 0.10\n",
      "Epoch [2/5], Step [61/1875], Loss: 2.2853, batch time: 0.13\n",
      "Epoch [2/5], Step [62/1875], Loss: 2.3138, batch time: 0.11\n",
      "Epoch [2/5], Step [63/1875], Loss: 2.2929, batch time: 0.11\n",
      "Epoch [2/5], Step [64/1875], Loss: 2.3168, batch time: 0.11\n",
      "Epoch [2/5], Step [65/1875], Loss: 2.2738, batch time: 0.10\n",
      "Epoch [2/5], Step [66/1875], Loss: 2.2883, batch time: 0.10\n",
      "Epoch [2/5], Step [67/1875], Loss: 2.3240, batch time: 0.10\n",
      "Epoch [2/5], Step [68/1875], Loss: 2.3100, batch time: 0.14\n",
      "Epoch [2/5], Step [69/1875], Loss: 2.3247, batch time: 0.11\n",
      "Epoch [2/5], Step [70/1875], Loss: 2.3237, batch time: 0.13\n",
      "Epoch [2/5], Step [71/1875], Loss: 2.2730, batch time: 0.10\n",
      "Epoch [2/5], Step [72/1875], Loss: 2.2736, batch time: 0.13\n",
      "Epoch [2/5], Step [73/1875], Loss: 2.2858, batch time: 0.11\n",
      "Epoch [2/5], Step [74/1875], Loss: 2.2837, batch time: 0.15\n",
      "Epoch [2/5], Step [75/1875], Loss: 2.2807, batch time: 0.10\n",
      "Epoch [2/5], Step [76/1875], Loss: 2.2562, batch time: 0.10\n",
      "Epoch [2/5], Step [77/1875], Loss: 2.3074, batch time: 0.12\n",
      "Epoch [2/5], Step [78/1875], Loss: 2.3381, batch time: 0.10\n",
      "Epoch [2/5], Step [79/1875], Loss: 2.3128, batch time: 0.10\n",
      "Epoch [2/5], Step [80/1875], Loss: 2.2768, batch time: 0.13\n",
      "Epoch [2/5], Step [81/1875], Loss: 2.3282, batch time: 0.13\n",
      "Epoch [2/5], Step [82/1875], Loss: 2.3119, batch time: 0.10\n",
      "Epoch [2/5], Step [83/1875], Loss: 2.2994, batch time: 0.13\n",
      "Epoch [2/5], Step [84/1875], Loss: 2.2554, batch time: 0.14\n",
      "Epoch [2/5], Step [85/1875], Loss: 2.2984, batch time: 0.10\n",
      "Epoch [2/5], Step [86/1875], Loss: 2.2695, batch time: 0.12\n",
      "Epoch [2/5], Step [87/1875], Loss: 2.2962, batch time: 0.10\n",
      "Epoch [2/5], Step [88/1875], Loss: 2.2921, batch time: 0.10\n",
      "Epoch [2/5], Step [89/1875], Loss: 2.2995, batch time: 0.10\n",
      "Epoch [2/5], Step [90/1875], Loss: 2.2608, batch time: 0.12\n",
      "Epoch [2/5], Step [91/1875], Loss: 2.3012, batch time: 0.11\n",
      "Epoch [2/5], Step [92/1875], Loss: 2.2960, batch time: 0.12\n",
      "Epoch [2/5], Step [93/1875], Loss: 2.2793, batch time: 0.12\n",
      "Epoch [2/5], Step [94/1875], Loss: 2.2935, batch time: 0.11\n",
      "Epoch [2/5], Step [95/1875], Loss: 2.3360, batch time: 0.13\n",
      "Epoch [2/5], Step [96/1875], Loss: 2.2708, batch time: 0.10\n",
      "Epoch [2/5], Step [97/1875], Loss: 2.3144, batch time: 0.10\n",
      "Epoch [2/5], Step [98/1875], Loss: 2.2931, batch time: 0.13\n",
      "Epoch [2/5], Step [99/1875], Loss: 2.2767, batch time: 0.13\n",
      "Epoch [2/5], Step [100/1875], Loss: 2.2938, batch time: 0.10\n",
      "Epoch [2/5], Step [101/1875], Loss: 2.3039, batch time: 0.10\n",
      "Epoch [2/5], Step [102/1875], Loss: 2.2832, batch time: 0.10\n",
      "Epoch [2/5], Step [103/1875], Loss: 2.2837, batch time: 0.12\n",
      "Epoch [2/5], Step [104/1875], Loss: 2.2912, batch time: 0.10\n",
      "Epoch [2/5], Step [105/1875], Loss: 2.2883, batch time: 0.13\n",
      "Epoch [2/5], Step [106/1875], Loss: 2.2822, batch time: 0.11\n",
      "Epoch [2/5], Step [107/1875], Loss: 2.3011, batch time: 0.12\n",
      "Epoch [2/5], Step [108/1875], Loss: 2.2992, batch time: 0.13\n",
      "Epoch [2/5], Step [109/1875], Loss: 2.2757, batch time: 0.10\n",
      "Epoch [2/5], Step [110/1875], Loss: 2.2911, batch time: 0.10\n",
      "Epoch [2/5], Step [111/1875], Loss: 2.3088, batch time: 0.10\n",
      "Epoch [2/5], Step [112/1875], Loss: 2.3074, batch time: 0.10\n",
      "Epoch [2/5], Step [113/1875], Loss: 2.3198, batch time: 0.13\n",
      "Epoch [2/5], Step [114/1875], Loss: 2.2914, batch time: 0.10\n",
      "Epoch [2/5], Step [115/1875], Loss: 2.2844, batch time: 0.10\n",
      "Epoch [2/5], Step [116/1875], Loss: 2.2725, batch time: 0.10\n",
      "Epoch [2/5], Step [117/1875], Loss: 2.2687, batch time: 0.10\n",
      "Epoch [2/5], Step [118/1875], Loss: 2.2915, batch time: 0.13\n",
      "Epoch [2/5], Step [119/1875], Loss: 2.2390, batch time: 0.13\n",
      "Epoch [2/5], Step [120/1875], Loss: 2.2714, batch time: 0.14\n",
      "Epoch [2/5], Step [121/1875], Loss: 2.2893, batch time: 0.10\n",
      "Epoch [2/5], Step [122/1875], Loss: 2.2883, batch time: 0.10\n",
      "Epoch [2/5], Step [123/1875], Loss: 2.2673, batch time: 0.12\n",
      "Epoch [2/5], Step [124/1875], Loss: 2.3113, batch time: 0.10\n",
      "Epoch [2/5], Step [125/1875], Loss: 2.2954, batch time: 0.10\n",
      "Epoch [2/5], Step [126/1875], Loss: 2.3025, batch time: 0.11\n",
      "Epoch [2/5], Step [127/1875], Loss: 2.2392, batch time: 0.10\n",
      "Epoch [2/5], Step [128/1875], Loss: 2.3157, batch time: 0.13\n",
      "Epoch [2/5], Step [129/1875], Loss: 2.2835, batch time: 0.10\n",
      "Epoch [2/5], Step [130/1875], Loss: 2.2720, batch time: 0.10\n",
      "Epoch [2/5], Step [131/1875], Loss: 2.3644, batch time: 0.13\n",
      "Epoch [2/5], Step [132/1875], Loss: 2.2877, batch time: 0.11\n",
      "Epoch [2/5], Step [133/1875], Loss: 2.2414, batch time: 0.16\n",
      "Epoch [2/5], Step [134/1875], Loss: 2.3370, batch time: 0.14\n",
      "Epoch [2/5], Step [135/1875], Loss: 2.2955, batch time: 0.14\n",
      "Epoch [2/5], Step [136/1875], Loss: 2.3212, batch time: 0.17\n",
      "Epoch [2/5], Step [137/1875], Loss: 2.3243, batch time: 0.15\n",
      "Epoch [2/5], Step [138/1875], Loss: 2.3081, batch time: 0.11\n",
      "Epoch [2/5], Step [139/1875], Loss: 2.2906, batch time: 0.11\n",
      "Epoch [2/5], Step [140/1875], Loss: 2.3303, batch time: 0.12\n",
      "Epoch [2/5], Step [141/1875], Loss: 2.2842, batch time: 0.12\n",
      "Epoch [2/5], Step [142/1875], Loss: 2.2730, batch time: 0.10\n",
      "Epoch [2/5], Step [143/1875], Loss: 2.3145, batch time: 0.10\n",
      "Epoch [2/5], Step [144/1875], Loss: 2.3019, batch time: 0.10\n",
      "Epoch [2/5], Step [145/1875], Loss: 2.2999, batch time: 0.11\n",
      "Epoch [2/5], Step [146/1875], Loss: 2.3072, batch time: 0.10\n",
      "Epoch [2/5], Step [147/1875], Loss: 2.2865, batch time: 0.12\n",
      "Epoch [2/5], Step [148/1875], Loss: 2.2969, batch time: 0.10\n",
      "Epoch [2/5], Step [149/1875], Loss: 2.2787, batch time: 0.10\n",
      "Epoch [2/5], Step [150/1875], Loss: 2.2576, batch time: 0.10\n",
      "Epoch [2/5], Step [151/1875], Loss: 2.3181, batch time: 0.16\n",
      "Epoch [2/5], Step [152/1875], Loss: 2.2926, batch time: 0.11\n",
      "Epoch [2/5], Step [153/1875], Loss: 2.2660, batch time: 0.12\n",
      "Epoch [2/5], Step [154/1875], Loss: 2.2889, batch time: 0.11\n",
      "Epoch [2/5], Step [155/1875], Loss: 2.2793, batch time: 0.15\n",
      "Epoch [2/5], Step [156/1875], Loss: 2.3195, batch time: 0.10\n",
      "Epoch [2/5], Step [157/1875], Loss: 2.3083, batch time: 0.10\n",
      "Epoch [2/5], Step [158/1875], Loss: 2.3334, batch time: 0.13\n",
      "Epoch [2/5], Step [159/1875], Loss: 2.3068, batch time: 0.14\n",
      "Epoch [2/5], Step [160/1875], Loss: 2.2992, batch time: 0.15\n",
      "Epoch [2/5], Step [161/1875], Loss: 2.2677, batch time: 0.11\n",
      "Epoch [2/5], Step [162/1875], Loss: 2.3001, batch time: 0.10\n",
      "Epoch [2/5], Step [163/1875], Loss: 2.3043, batch time: 0.13\n",
      "Epoch [2/5], Step [164/1875], Loss: 2.2985, batch time: 0.10\n",
      "Epoch [2/5], Step [165/1875], Loss: 2.2683, batch time: 0.10\n",
      "Epoch [2/5], Step [166/1875], Loss: 2.2839, batch time: 0.10\n",
      "Epoch [2/5], Step [167/1875], Loss: 2.2625, batch time: -2.81\n",
      "Epoch [2/5], Step [168/1875], Loss: 2.2637, batch time: 0.16\n",
      "Epoch [2/5], Step [169/1875], Loss: 2.3125, batch time: 0.10\n",
      "Epoch [2/5], Step [170/1875], Loss: 2.2812, batch time: 0.10\n",
      "Epoch [2/5], Step [171/1875], Loss: 2.3263, batch time: 0.10\n",
      "Epoch [2/5], Step [172/1875], Loss: 2.2709, batch time: 0.12\n",
      "Epoch [2/5], Step [173/1875], Loss: 2.2909, batch time: 0.10\n",
      "Epoch [2/5], Step [174/1875], Loss: 2.2559, batch time: 0.10\n",
      "Epoch [2/5], Step [175/1875], Loss: 2.2955, batch time: 0.13\n",
      "Epoch [2/5], Step [176/1875], Loss: 2.2860, batch time: 0.10\n",
      "Epoch [2/5], Step [177/1875], Loss: 2.2751, batch time: 0.10\n",
      "Epoch [2/5], Step [178/1875], Loss: 2.2834, batch time: 0.10\n",
      "Epoch [2/5], Step [179/1875], Loss: 2.2299, batch time: 0.18\n",
      "Epoch [2/5], Step [180/1875], Loss: 2.2856, batch time: 0.14\n",
      "Epoch [2/5], Step [181/1875], Loss: 2.2737, batch time: 0.10\n",
      "Epoch [2/5], Step [182/1875], Loss: 2.2695, batch time: 0.13\n",
      "Epoch [2/5], Step [183/1875], Loss: 2.2872, batch time: 0.12\n",
      "Epoch [2/5], Step [184/1875], Loss: 2.2830, batch time: 0.10\n",
      "Epoch [2/5], Step [185/1875], Loss: 2.2745, batch time: 0.10\n",
      "Epoch [2/5], Step [186/1875], Loss: 2.2906, batch time: 0.10\n",
      "Epoch [2/5], Step [187/1875], Loss: 2.3364, batch time: 0.10\n",
      "Epoch [2/5], Step [188/1875], Loss: 2.2917, batch time: 0.11\n",
      "Epoch [2/5], Step [189/1875], Loss: 2.3111, batch time: 0.10\n",
      "Epoch [2/5], Step [190/1875], Loss: 2.2942, batch time: 0.10\n",
      "Epoch [2/5], Step [191/1875], Loss: 2.2722, batch time: 0.10\n",
      "Epoch [2/5], Step [192/1875], Loss: 2.2996, batch time: 0.10\n",
      "Epoch [2/5], Step [193/1875], Loss: 2.2755, batch time: 0.09\n",
      "Epoch [2/5], Step [194/1875], Loss: 2.2954, batch time: 0.10\n",
      "Epoch [2/5], Step [195/1875], Loss: 2.2747, batch time: 0.10\n",
      "Epoch [2/5], Step [196/1875], Loss: 2.3091, batch time: 0.22\n",
      "Epoch [2/5], Step [197/1875], Loss: 2.2710, batch time: 0.10\n",
      "Epoch [2/5], Step [198/1875], Loss: 2.3107, batch time: 0.12\n",
      "Epoch [2/5], Step [199/1875], Loss: 2.3107, batch time: 0.10\n",
      "Epoch [2/5], Step [200/1875], Loss: 2.2337, batch time: 0.12\n",
      "Epoch [2/5], Step [201/1875], Loss: 2.3008, batch time: 0.10\n",
      "Epoch [2/5], Step [202/1875], Loss: 2.2911, batch time: 0.10\n",
      "Epoch [2/5], Step [203/1875], Loss: 2.3170, batch time: 0.12\n",
      "Epoch [2/5], Step [204/1875], Loss: 2.3189, batch time: 0.10\n",
      "Epoch [2/5], Step [205/1875], Loss: 2.2876, batch time: 0.10\n",
      "Epoch [2/5], Step [206/1875], Loss: 2.2666, batch time: 0.10\n",
      "Epoch [2/5], Step [207/1875], Loss: 2.2799, batch time: 0.13\n",
      "Epoch [2/5], Step [208/1875], Loss: 2.3043, batch time: 0.14\n",
      "Epoch [2/5], Step [209/1875], Loss: 2.3099, batch time: 0.22\n",
      "Epoch [2/5], Step [210/1875], Loss: 2.2952, batch time: 0.10\n",
      "Epoch [2/5], Step [211/1875], Loss: 2.3392, batch time: 0.12\n",
      "Epoch [2/5], Step [212/1875], Loss: 2.3307, batch time: 0.10\n",
      "Epoch [2/5], Step [213/1875], Loss: 2.3099, batch time: 0.11\n",
      "Epoch [2/5], Step [214/1875], Loss: 2.2837, batch time: 0.11\n",
      "Epoch [2/5], Step [215/1875], Loss: 2.2699, batch time: 0.12\n",
      "Epoch [2/5], Step [216/1875], Loss: 2.2531, batch time: 0.19\n",
      "Epoch [2/5], Step [217/1875], Loss: 2.2977, batch time: 0.10\n",
      "Epoch [2/5], Step [218/1875], Loss: 2.2821, batch time: 0.13\n",
      "Epoch [2/5], Step [219/1875], Loss: 2.2923, batch time: 0.11\n",
      "Epoch [2/5], Step [220/1875], Loss: 2.2970, batch time: 0.11\n",
      "Epoch [2/5], Step [221/1875], Loss: 2.2896, batch time: 0.10\n",
      "Epoch [2/5], Step [222/1875], Loss: 2.3201, batch time: 0.21\n",
      "Epoch [2/5], Step [223/1875], Loss: 2.3099, batch time: 0.13\n",
      "Epoch [2/5], Step [224/1875], Loss: 2.3191, batch time: 0.13\n",
      "Epoch [2/5], Step [225/1875], Loss: 2.3062, batch time: 0.10\n",
      "Epoch [2/5], Step [226/1875], Loss: 2.3294, batch time: 0.12\n",
      "Epoch [2/5], Step [227/1875], Loss: 2.3340, batch time: 0.10\n",
      "Epoch [2/5], Step [228/1875], Loss: 2.3016, batch time: 0.11\n",
      "Epoch [2/5], Step [229/1875], Loss: 2.2784, batch time: 0.10\n",
      "Epoch [2/5], Step [230/1875], Loss: 2.2952, batch time: 0.10\n",
      "Epoch [2/5], Step [231/1875], Loss: 2.2467, batch time: 0.14\n",
      "Epoch [2/5], Step [232/1875], Loss: 2.2902, batch time: 0.10\n",
      "Epoch [2/5], Step [233/1875], Loss: 2.3074, batch time: 0.10\n",
      "Epoch [2/5], Step [234/1875], Loss: 2.3129, batch time: 0.10\n",
      "Epoch [2/5], Step [235/1875], Loss: 2.2982, batch time: 0.23\n",
      "Epoch [2/5], Step [236/1875], Loss: 2.2791, batch time: 0.13\n",
      "Epoch [2/5], Step [237/1875], Loss: 2.3013, batch time: 0.10\n",
      "Epoch [2/5], Step [238/1875], Loss: 2.2868, batch time: 0.12\n",
      "Epoch [2/5], Step [239/1875], Loss: 2.3153, batch time: 0.11\n",
      "Epoch [2/5], Step [240/1875], Loss: 2.2684, batch time: 0.10\n",
      "Epoch [2/5], Step [241/1875], Loss: 2.2660, batch time: 0.13\n",
      "Epoch [2/5], Step [242/1875], Loss: 2.2886, batch time: 0.12\n",
      "Epoch [2/5], Step [243/1875], Loss: 2.2608, batch time: 0.14\n",
      "Epoch [2/5], Step [244/1875], Loss: 2.2613, batch time: 0.11\n",
      "Epoch [2/5], Step [245/1875], Loss: 2.2703, batch time: 0.10\n",
      "Epoch [2/5], Step [246/1875], Loss: 2.3136, batch time: 0.12\n",
      "Epoch [2/5], Step [247/1875], Loss: 2.2948, batch time: 0.10\n",
      "Epoch [2/5], Step [248/1875], Loss: 2.3038, batch time: 0.10\n",
      "Epoch [2/5], Step [249/1875], Loss: 2.2753, batch time: 0.10\n",
      "Epoch [2/5], Step [250/1875], Loss: 2.3129, batch time: 0.10\n",
      "Epoch [2/5], Step [251/1875], Loss: 2.2920, batch time: 0.10\n",
      "Epoch [2/5], Step [252/1875], Loss: 2.3103, batch time: 0.10\n",
      "Epoch [2/5], Step [253/1875], Loss: 2.3141, batch time: 0.13\n",
      "Epoch [2/5], Step [254/1875], Loss: 2.2787, batch time: 0.11\n",
      "Epoch [2/5], Step [255/1875], Loss: 2.2808, batch time: 0.11\n",
      "Epoch [2/5], Step [256/1875], Loss: 2.3026, batch time: 0.10\n",
      "Epoch [2/5], Step [257/1875], Loss: 2.2998, batch time: 0.10\n",
      "Epoch [2/5], Step [258/1875], Loss: 2.3006, batch time: 0.10\n",
      "Epoch [2/5], Step [259/1875], Loss: 2.2714, batch time: 0.27\n",
      "Epoch [2/5], Step [260/1875], Loss: 2.3194, batch time: 0.10\n",
      "Epoch [2/5], Step [261/1875], Loss: 2.3184, batch time: 0.10\n",
      "Epoch [2/5], Step [262/1875], Loss: 2.3053, batch time: 0.11\n",
      "Epoch [2/5], Step [263/1875], Loss: 2.2848, batch time: 0.11\n",
      "Epoch [2/5], Step [264/1875], Loss: 2.3086, batch time: 0.10\n",
      "Epoch [2/5], Step [265/1875], Loss: 2.2504, batch time: 0.10\n",
      "Epoch [2/5], Step [266/1875], Loss: 2.2647, batch time: 0.10\n",
      "Epoch [2/5], Step [267/1875], Loss: 2.3030, batch time: 0.10\n",
      "Epoch [2/5], Step [268/1875], Loss: 2.2942, batch time: 0.10\n",
      "Epoch [2/5], Step [269/1875], Loss: 2.2924, batch time: 0.10\n",
      "Epoch [2/5], Step [270/1875], Loss: 2.2957, batch time: 0.15\n",
      "Epoch [2/5], Step [271/1875], Loss: 2.3131, batch time: 0.11\n",
      "Epoch [2/5], Step [272/1875], Loss: 2.2796, batch time: 0.12\n",
      "Epoch [2/5], Step [273/1875], Loss: 2.3091, batch time: 0.10\n",
      "Epoch [2/5], Step [274/1875], Loss: 2.2728, batch time: 0.09\n",
      "Epoch [2/5], Step [275/1875], Loss: 2.2939, batch time: 0.10\n",
      "Epoch [2/5], Step [276/1875], Loss: 2.2401, batch time: 0.14\n",
      "Epoch [2/5], Step [277/1875], Loss: 2.2804, batch time: 0.14\n",
      "Epoch [2/5], Step [278/1875], Loss: 2.3454, batch time: 0.10\n",
      "Epoch [2/5], Step [279/1875], Loss: 2.2941, batch time: 0.10\n",
      "Epoch [2/5], Step [280/1875], Loss: 2.3072, batch time: 0.10\n",
      "Epoch [2/5], Step [281/1875], Loss: 2.2899, batch time: 0.10\n",
      "Epoch [2/5], Step [282/1875], Loss: 2.2759, batch time: 0.10\n",
      "Epoch [2/5], Step [283/1875], Loss: 2.2594, batch time: 0.10\n",
      "Epoch [2/5], Step [284/1875], Loss: 2.2967, batch time: 0.10\n",
      "Epoch [2/5], Step [285/1875], Loss: 2.2539, batch time: 0.10\n",
      "Epoch [2/5], Step [286/1875], Loss: 2.2917, batch time: 0.10\n",
      "Epoch [2/5], Step [287/1875], Loss: 2.3122, batch time: 0.33\n",
      "Epoch [2/5], Step [288/1875], Loss: 2.3120, batch time: 0.10\n",
      "Epoch [2/5], Step [289/1875], Loss: 2.3102, batch time: 0.10\n",
      "Epoch [2/5], Step [290/1875], Loss: 2.2876, batch time: 0.10\n",
      "Epoch [2/5], Step [291/1875], Loss: 2.2920, batch time: 0.10\n",
      "Epoch [2/5], Step [292/1875], Loss: 2.2675, batch time: 0.10\n",
      "Epoch [2/5], Step [293/1875], Loss: 2.2762, batch time: 0.10\n",
      "Epoch [2/5], Step [294/1875], Loss: 2.2520, batch time: 0.10\n",
      "Epoch [2/5], Step [295/1875], Loss: 2.2958, batch time: 0.10\n",
      "Epoch [2/5], Step [296/1875], Loss: 2.3197, batch time: 0.10\n",
      "Epoch [2/5], Step [297/1875], Loss: 2.2859, batch time: 0.10\n",
      "Epoch [2/5], Step [298/1875], Loss: 2.2869, batch time: 0.09\n",
      "Epoch [2/5], Step [299/1875], Loss: 2.2763, batch time: 0.10\n",
      "Epoch [2/5], Step [300/1875], Loss: 2.3064, batch time: 0.10\n",
      "Epoch [2/5], Step [301/1875], Loss: 2.2695, batch time: 0.10\n",
      "Epoch [2/5], Step [302/1875], Loss: 2.2628, batch time: 0.10\n",
      "Epoch [2/5], Step [303/1875], Loss: 2.2979, batch time: 0.10\n",
      "Epoch [2/5], Step [304/1875], Loss: 2.2790, batch time: 0.10\n",
      "Epoch [2/5], Step [305/1875], Loss: 2.3162, batch time: 0.10\n",
      "Epoch [2/5], Step [306/1875], Loss: 2.2826, batch time: 0.10\n",
      "Epoch [2/5], Step [307/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [2/5], Step [308/1875], Loss: 2.2905, batch time: 0.21\n",
      "Epoch [2/5], Step [309/1875], Loss: 2.3057, batch time: 0.23\n",
      "Epoch [2/5], Step [310/1875], Loss: 2.3054, batch time: 0.10\n",
      "Epoch [2/5], Step [311/1875], Loss: 2.2857, batch time: 0.10\n",
      "Epoch [2/5], Step [312/1875], Loss: 2.3373, batch time: 0.15\n",
      "Epoch [2/5], Step [313/1875], Loss: 2.2948, batch time: 0.10\n",
      "Epoch [2/5], Step [314/1875], Loss: 2.3434, batch time: 0.10\n",
      "Epoch [2/5], Step [315/1875], Loss: 2.3040, batch time: 0.10\n",
      "Epoch [2/5], Step [316/1875], Loss: 2.3016, batch time: 0.17\n",
      "Epoch [2/5], Step [317/1875], Loss: 2.2978, batch time: 0.10\n",
      "Epoch [2/5], Step [318/1875], Loss: 2.2982, batch time: 0.10\n",
      "Epoch [2/5], Step [319/1875], Loss: 2.3012, batch time: 0.10\n",
      "Epoch [2/5], Step [320/1875], Loss: 2.2886, batch time: 0.13\n",
      "Epoch [2/5], Step [321/1875], Loss: 2.2742, batch time: 0.10\n",
      "Epoch [2/5], Step [322/1875], Loss: 2.3311, batch time: 0.12\n",
      "Epoch [2/5], Step [323/1875], Loss: 2.2643, batch time: 0.13\n",
      "Epoch [2/5], Step [324/1875], Loss: 2.2706, batch time: 0.10\n",
      "Epoch [2/5], Step [325/1875], Loss: 2.3081, batch time: 0.10\n",
      "Epoch [2/5], Step [326/1875], Loss: 2.2668, batch time: 0.10\n",
      "Epoch [2/5], Step [327/1875], Loss: 2.2842, batch time: 0.13\n",
      "Epoch [2/5], Step [328/1875], Loss: 2.2719, batch time: 0.11\n",
      "Epoch [2/5], Step [329/1875], Loss: 2.2617, batch time: 0.14\n",
      "Epoch [2/5], Step [330/1875], Loss: 2.2823, batch time: 0.10\n",
      "Epoch [2/5], Step [331/1875], Loss: 2.3140, batch time: 0.10\n",
      "Epoch [2/5], Step [332/1875], Loss: 2.3016, batch time: 0.10\n",
      "Epoch [2/5], Step [333/1875], Loss: 2.2588, batch time: 0.10\n",
      "Epoch [2/5], Step [334/1875], Loss: 2.2456, batch time: 0.10\n",
      "Epoch [2/5], Step [335/1875], Loss: 2.2855, batch time: 0.10\n",
      "Epoch [2/5], Step [336/1875], Loss: 2.2796, batch time: 0.10\n",
      "Epoch [2/5], Step [337/1875], Loss: 2.3098, batch time: 0.10\n",
      "Epoch [2/5], Step [338/1875], Loss: 2.2997, batch time: 0.10\n",
      "Epoch [2/5], Step [339/1875], Loss: 2.2658, batch time: 0.10\n",
      "Epoch [2/5], Step [340/1875], Loss: 2.2862, batch time: 0.10\n",
      "Epoch [2/5], Step [341/1875], Loss: 2.2741, batch time: 0.10\n",
      "Epoch [2/5], Step [342/1875], Loss: 2.2828, batch time: 0.10\n",
      "Epoch [2/5], Step [343/1875], Loss: 2.2894, batch time: 0.10\n",
      "Epoch [2/5], Step [344/1875], Loss: 2.2827, batch time: 0.17\n",
      "Epoch [2/5], Step [345/1875], Loss: 2.2729, batch time: 0.10\n",
      "Epoch [2/5], Step [346/1875], Loss: 2.2693, batch time: 0.12\n",
      "Epoch [2/5], Step [347/1875], Loss: 2.3152, batch time: 0.13\n",
      "Epoch [2/5], Step [348/1875], Loss: 2.2685, batch time: 0.14\n",
      "Epoch [2/5], Step [349/1875], Loss: 2.3149, batch time: 0.10\n",
      "Epoch [2/5], Step [350/1875], Loss: 2.2697, batch time: 0.16\n",
      "Epoch [2/5], Step [351/1875], Loss: 2.2480, batch time: 0.13\n",
      "Epoch [2/5], Step [352/1875], Loss: 2.3170, batch time: 0.12\n",
      "Epoch [2/5], Step [353/1875], Loss: 2.3251, batch time: 0.14\n",
      "Epoch [2/5], Step [354/1875], Loss: 2.3150, batch time: 0.10\n",
      "Epoch [2/5], Step [355/1875], Loss: 2.2898, batch time: 0.10\n",
      "Epoch [2/5], Step [356/1875], Loss: 2.3000, batch time: 0.13\n",
      "Epoch [2/5], Step [357/1875], Loss: 2.3124, batch time: 0.12\n",
      "Epoch [2/5], Step [358/1875], Loss: 2.2290, batch time: 0.10\n",
      "Epoch [2/5], Step [359/1875], Loss: 2.2535, batch time: 0.12\n",
      "Epoch [2/5], Step [360/1875], Loss: 2.2377, batch time: 0.19\n",
      "Epoch [2/5], Step [361/1875], Loss: 2.3053, batch time: 0.10\n",
      "Epoch [2/5], Step [362/1875], Loss: 2.3092, batch time: 0.10\n",
      "Epoch [2/5], Step [363/1875], Loss: 2.2959, batch time: 0.10\n",
      "Epoch [2/5], Step [364/1875], Loss: 2.2659, batch time: 0.10\n",
      "Epoch [2/5], Step [365/1875], Loss: 2.3223, batch time: 0.16\n",
      "Epoch [2/5], Step [366/1875], Loss: 2.3093, batch time: 0.14\n",
      "Epoch [2/5], Step [367/1875], Loss: 2.2688, batch time: 0.10\n",
      "Epoch [2/5], Step [368/1875], Loss: 2.3100, batch time: 0.10\n",
      "Epoch [2/5], Step [369/1875], Loss: 2.3388, batch time: 0.10\n",
      "Epoch [2/5], Step [370/1875], Loss: 2.3141, batch time: 0.10\n",
      "Epoch [2/5], Step [371/1875], Loss: 2.2712, batch time: 0.13\n",
      "Epoch [2/5], Step [372/1875], Loss: 2.2937, batch time: 0.10\n",
      "Epoch [2/5], Step [373/1875], Loss: 2.2938, batch time: 0.13\n",
      "Epoch [2/5], Step [374/1875], Loss: 2.3207, batch time: 0.10\n",
      "Epoch [2/5], Step [375/1875], Loss: 2.2436, batch time: 0.10\n",
      "Epoch [2/5], Step [376/1875], Loss: 2.2793, batch time: 0.10\n",
      "Epoch [2/5], Step [377/1875], Loss: 2.3018, batch time: 0.14\n",
      "Epoch [2/5], Step [378/1875], Loss: 2.3149, batch time: 0.16\n",
      "Epoch [2/5], Step [379/1875], Loss: 2.3206, batch time: 0.12\n",
      "Epoch [2/5], Step [380/1875], Loss: 2.2908, batch time: 0.13\n",
      "Epoch [2/5], Step [381/1875], Loss: 2.2720, batch time: 0.10\n",
      "Epoch [2/5], Step [382/1875], Loss: 2.2626, batch time: 0.10\n",
      "Epoch [2/5], Step [383/1875], Loss: 2.2724, batch time: 0.10\n",
      "Epoch [2/5], Step [384/1875], Loss: 2.2902, batch time: 0.10\n",
      "Epoch [2/5], Step [385/1875], Loss: 2.2568, batch time: 0.10\n",
      "Epoch [2/5], Step [386/1875], Loss: 2.2822, batch time: 0.13\n",
      "Epoch [2/5], Step [387/1875], Loss: 2.2943, batch time: 0.10\n",
      "Epoch [2/5], Step [388/1875], Loss: 2.2975, batch time: 0.13\n",
      "Epoch [2/5], Step [389/1875], Loss: 2.2417, batch time: 0.14\n",
      "Epoch [2/5], Step [390/1875], Loss: 2.2902, batch time: 0.10\n",
      "Epoch [2/5], Step [391/1875], Loss: 2.3049, batch time: 0.10\n",
      "Epoch [2/5], Step [392/1875], Loss: 2.2863, batch time: 0.10\n",
      "Epoch [2/5], Step [393/1875], Loss: 2.3213, batch time: 0.11\n",
      "Epoch [2/5], Step [394/1875], Loss: 2.2812, batch time: 0.13\n",
      "Epoch [2/5], Step [395/1875], Loss: 2.3071, batch time: 0.10\n",
      "Epoch [2/5], Step [396/1875], Loss: 2.2883, batch time: 0.13\n",
      "Epoch [2/5], Step [397/1875], Loss: 2.3100, batch time: 0.10\n",
      "Epoch [2/5], Step [398/1875], Loss: 2.2960, batch time: 0.10\n",
      "Epoch [2/5], Step [399/1875], Loss: 2.2989, batch time: 0.10\n",
      "Epoch [2/5], Step [400/1875], Loss: 2.3263, batch time: 0.10\n",
      "Epoch [2/5], Step [401/1875], Loss: 2.2545, batch time: 0.10\n",
      "Epoch [2/5], Step [402/1875], Loss: 2.2862, batch time: 0.10\n",
      "Epoch [2/5], Step [403/1875], Loss: 2.2611, batch time: 0.16\n",
      "Epoch [2/5], Step [404/1875], Loss: 2.2938, batch time: 0.10\n",
      "Epoch [2/5], Step [405/1875], Loss: 2.3082, batch time: 0.10\n",
      "Epoch [2/5], Step [406/1875], Loss: 2.3020, batch time: 0.10\n",
      "Epoch [2/5], Step [407/1875], Loss: 2.2548, batch time: 0.10\n",
      "Epoch [2/5], Step [408/1875], Loss: 2.2486, batch time: 0.10\n",
      "Epoch [2/5], Step [409/1875], Loss: 2.2708, batch time: 0.10\n",
      "Epoch [2/5], Step [410/1875], Loss: 2.2830, batch time: 0.10\n",
      "Epoch [2/5], Step [411/1875], Loss: 2.2597, batch time: 0.17\n",
      "Epoch [2/5], Step [412/1875], Loss: 2.3067, batch time: 0.10\n",
      "Epoch [2/5], Step [413/1875], Loss: 2.2724, batch time: 0.10\n",
      "Epoch [2/5], Step [414/1875], Loss: 2.2794, batch time: 0.11\n",
      "Epoch [2/5], Step [415/1875], Loss: 2.2737, batch time: 0.20\n",
      "Epoch [2/5], Step [416/1875], Loss: 2.2947, batch time: 0.11\n",
      "Epoch [2/5], Step [417/1875], Loss: 2.2728, batch time: 0.10\n",
      "Epoch [2/5], Step [418/1875], Loss: 2.3152, batch time: 0.10\n",
      "Epoch [2/5], Step [419/1875], Loss: 2.3144, batch time: 0.13\n",
      "Epoch [2/5], Step [420/1875], Loss: 2.3130, batch time: 0.12\n",
      "Epoch [2/5], Step [421/1875], Loss: 2.3141, batch time: 0.13\n",
      "Epoch [2/5], Step [422/1875], Loss: 2.2600, batch time: 0.10\n",
      "Epoch [2/5], Step [423/1875], Loss: 2.2957, batch time: 0.13\n",
      "Epoch [2/5], Step [424/1875], Loss: 2.2505, batch time: 0.20\n",
      "Epoch [2/5], Step [425/1875], Loss: 2.2688, batch time: 0.10\n",
      "Epoch [2/5], Step [426/1875], Loss: 2.2615, batch time: 0.13\n",
      "Epoch [2/5], Step [427/1875], Loss: 2.2822, batch time: 0.10\n",
      "Epoch [2/5], Step [428/1875], Loss: 2.2913, batch time: 0.10\n",
      "Epoch [2/5], Step [429/1875], Loss: 2.2925, batch time: 0.10\n",
      "Epoch [2/5], Step [430/1875], Loss: 2.2996, batch time: 0.13\n",
      "Epoch [2/5], Step [431/1875], Loss: 2.2561, batch time: 0.10\n",
      "Epoch [2/5], Step [432/1875], Loss: 2.3012, batch time: 0.10\n",
      "Epoch [2/5], Step [433/1875], Loss: 2.3175, batch time: 0.11\n",
      "Epoch [2/5], Step [434/1875], Loss: 2.2943, batch time: 0.10\n",
      "Epoch [2/5], Step [435/1875], Loss: 2.2988, batch time: 0.10\n",
      "Epoch [2/5], Step [436/1875], Loss: 2.2941, batch time: 0.10\n",
      "Epoch [2/5], Step [437/1875], Loss: 2.2804, batch time: 0.10\n",
      "Epoch [2/5], Step [438/1875], Loss: 2.2715, batch time: 0.12\n",
      "Epoch [2/5], Step [439/1875], Loss: 2.3105, batch time: 0.10\n",
      "Epoch [2/5], Step [440/1875], Loss: 2.3420, batch time: 0.10\n",
      "Epoch [2/5], Step [441/1875], Loss: 2.3099, batch time: 0.10\n",
      "Epoch [2/5], Step [442/1875], Loss: 2.3024, batch time: 0.10\n",
      "Epoch [2/5], Step [443/1875], Loss: 2.2862, batch time: 0.13\n",
      "Epoch [2/5], Step [444/1875], Loss: 2.2746, batch time: 0.10\n",
      "Epoch [2/5], Step [445/1875], Loss: 2.2637, batch time: 0.11\n",
      "Epoch [2/5], Step [446/1875], Loss: 2.2663, batch time: -2.83\n",
      "Epoch [2/5], Step [447/1875], Loss: 2.2967, batch time: 0.09\n",
      "Epoch [2/5], Step [448/1875], Loss: 2.2342, batch time: 0.10\n",
      "Epoch [2/5], Step [449/1875], Loss: 2.2910, batch time: 0.10\n",
      "Epoch [2/5], Step [450/1875], Loss: 2.2405, batch time: 0.10\n",
      "Epoch [2/5], Step [451/1875], Loss: 2.2188, batch time: 0.10\n",
      "Epoch [2/5], Step [452/1875], Loss: 2.3201, batch time: 0.13\n",
      "Epoch [2/5], Step [453/1875], Loss: 2.3080, batch time: 0.10\n",
      "Epoch [2/5], Step [454/1875], Loss: 2.2820, batch time: 0.10\n",
      "Epoch [2/5], Step [455/1875], Loss: 2.3044, batch time: 0.10\n",
      "Epoch [2/5], Step [456/1875], Loss: 2.2921, batch time: 0.10\n",
      "Epoch [2/5], Step [457/1875], Loss: 2.3178, batch time: 0.10\n",
      "Epoch [2/5], Step [458/1875], Loss: 2.2694, batch time: 0.10\n",
      "Epoch [2/5], Step [459/1875], Loss: 2.2954, batch time: 0.10\n",
      "Epoch [2/5], Step [460/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [2/5], Step [461/1875], Loss: 2.2357, batch time: 0.10\n",
      "Epoch [2/5], Step [462/1875], Loss: 2.2424, batch time: 0.10\n",
      "Epoch [2/5], Step [463/1875], Loss: 2.2944, batch time: 0.12\n",
      "Epoch [2/5], Step [464/1875], Loss: 2.2453, batch time: 0.13\n",
      "Epoch [2/5], Step [465/1875], Loss: 2.2934, batch time: 0.12\n",
      "Epoch [2/5], Step [466/1875], Loss: 2.2517, batch time: 0.10\n",
      "Epoch [2/5], Step [467/1875], Loss: 2.2994, batch time: 0.10\n",
      "Epoch [2/5], Step [468/1875], Loss: 2.3318, batch time: 0.10\n",
      "Epoch [2/5], Step [469/1875], Loss: 2.2726, batch time: 0.12\n",
      "Epoch [2/5], Step [470/1875], Loss: 2.3339, batch time: 0.10\n",
      "Epoch [2/5], Step [471/1875], Loss: 2.3253, batch time: 0.10\n",
      "Epoch [2/5], Step [472/1875], Loss: 2.2946, batch time: 0.11\n",
      "Epoch [2/5], Step [473/1875], Loss: 2.2708, batch time: 0.10\n",
      "Epoch [2/5], Step [474/1875], Loss: 2.3241, batch time: 0.10\n",
      "Epoch [2/5], Step [475/1875], Loss: 2.3113, batch time: 0.10\n",
      "Epoch [2/5], Step [476/1875], Loss: 2.2804, batch time: 0.10\n",
      "Epoch [2/5], Step [477/1875], Loss: 2.3196, batch time: 0.10\n",
      "Epoch [2/5], Step [478/1875], Loss: 2.2855, batch time: 0.14\n",
      "Epoch [2/5], Step [479/1875], Loss: 2.2639, batch time: 0.12\n",
      "Epoch [2/5], Step [480/1875], Loss: 2.2893, batch time: 0.12\n",
      "Epoch [2/5], Step [481/1875], Loss: 2.2854, batch time: 0.12\n",
      "Epoch [2/5], Step [482/1875], Loss: 2.2831, batch time: 0.11\n",
      "Epoch [2/5], Step [483/1875], Loss: 2.2299, batch time: 0.10\n",
      "Epoch [2/5], Step [484/1875], Loss: 2.2749, batch time: 0.11\n",
      "Epoch [2/5], Step [485/1875], Loss: 2.2729, batch time: 0.10\n",
      "Epoch [2/5], Step [486/1875], Loss: 2.2843, batch time: 0.10\n",
      "Epoch [2/5], Step [487/1875], Loss: 2.2809, batch time: 0.10\n",
      "Epoch [2/5], Step [488/1875], Loss: 2.2653, batch time: 0.10\n",
      "Epoch [2/5], Step [489/1875], Loss: 2.3123, batch time: 0.10\n",
      "Epoch [2/5], Step [490/1875], Loss: 2.2681, batch time: 0.10\n",
      "Epoch [2/5], Step [491/1875], Loss: 2.2293, batch time: 0.10\n",
      "Epoch [2/5], Step [492/1875], Loss: 2.2642, batch time: 0.10\n",
      "Epoch [2/5], Step [493/1875], Loss: 2.2691, batch time: 0.13\n",
      "Epoch [2/5], Step [494/1875], Loss: 2.3090, batch time: 0.10\n",
      "Epoch [2/5], Step [495/1875], Loss: 2.2918, batch time: 0.10\n",
      "Epoch [2/5], Step [496/1875], Loss: 2.2886, batch time: 0.10\n",
      "Epoch [2/5], Step [497/1875], Loss: 2.2612, batch time: 0.10\n",
      "Epoch [2/5], Step [498/1875], Loss: 2.2692, batch time: 0.10\n",
      "Epoch [2/5], Step [499/1875], Loss: 2.3288, batch time: 0.11\n",
      "Epoch [2/5], Step [500/1875], Loss: 2.2990, batch time: 0.10\n",
      "Epoch [2/5], Step [501/1875], Loss: 2.2725, batch time: 0.14\n",
      "Epoch [2/5], Step [502/1875], Loss: 2.2811, batch time: 0.10\n",
      "Epoch [2/5], Step [503/1875], Loss: 2.3395, batch time: 0.11\n",
      "Epoch [2/5], Step [504/1875], Loss: 2.2803, batch time: 0.20\n",
      "Epoch [2/5], Step [505/1875], Loss: 2.2741, batch time: 0.10\n",
      "Epoch [2/5], Step [506/1875], Loss: 2.2849, batch time: 0.10\n",
      "Epoch [2/5], Step [507/1875], Loss: 2.2824, batch time: 0.14\n",
      "Epoch [2/5], Step [508/1875], Loss: 2.2514, batch time: 0.10\n",
      "Epoch [2/5], Step [509/1875], Loss: 2.2581, batch time: 0.10\n",
      "Epoch [2/5], Step [510/1875], Loss: 2.2713, batch time: 0.10\n",
      "Epoch [2/5], Step [511/1875], Loss: 2.2470, batch time: 0.10\n",
      "Epoch [2/5], Step [512/1875], Loss: 2.3144, batch time: 0.10\n",
      "Epoch [2/5], Step [513/1875], Loss: 2.2660, batch time: 0.12\n",
      "Epoch [2/5], Step [514/1875], Loss: 2.2956, batch time: 0.10\n",
      "Epoch [2/5], Step [515/1875], Loss: 2.2844, batch time: 0.11\n",
      "Epoch [2/5], Step [516/1875], Loss: 2.2651, batch time: 0.10\n",
      "Epoch [2/5], Step [517/1875], Loss: 2.3268, batch time: 0.10\n",
      "Epoch [2/5], Step [518/1875], Loss: 2.2997, batch time: 0.10\n",
      "Epoch [2/5], Step [519/1875], Loss: 2.2490, batch time: 0.12\n",
      "Epoch [2/5], Step [520/1875], Loss: 2.2883, batch time: 0.12\n",
      "Epoch [2/5], Step [521/1875], Loss: 2.2976, batch time: 0.11\n",
      "Epoch [2/5], Step [522/1875], Loss: 2.2658, batch time: 0.10\n",
      "Epoch [2/5], Step [523/1875], Loss: 2.2983, batch time: 0.10\n",
      "Epoch [2/5], Step [524/1875], Loss: 2.2483, batch time: 0.10\n",
      "Epoch [2/5], Step [525/1875], Loss: 2.2483, batch time: 0.14\n",
      "Epoch [2/5], Step [526/1875], Loss: 2.2597, batch time: 0.13\n",
      "Epoch [2/5], Step [527/1875], Loss: 2.3489, batch time: 0.12\n",
      "Epoch [2/5], Step [528/1875], Loss: 2.2734, batch time: 0.14\n",
      "Epoch [2/5], Step [529/1875], Loss: 2.2902, batch time: 0.12\n",
      "Epoch [2/5], Step [530/1875], Loss: 2.2491, batch time: 0.12\n",
      "Epoch [2/5], Step [531/1875], Loss: 2.2978, batch time: 0.10\n",
      "Epoch [2/5], Step [532/1875], Loss: 2.3039, batch time: 0.14\n",
      "Epoch [2/5], Step [533/1875], Loss: 2.2995, batch time: 0.10\n",
      "Epoch [2/5], Step [534/1875], Loss: 2.3036, batch time: 0.15\n",
      "Epoch [2/5], Step [535/1875], Loss: 2.2945, batch time: 0.10\n",
      "Epoch [2/5], Step [536/1875], Loss: 2.3083, batch time: 0.10\n",
      "Epoch [2/5], Step [537/1875], Loss: 2.2705, batch time: 0.13\n",
      "Epoch [2/5], Step [538/1875], Loss: 2.3187, batch time: 0.12\n",
      "Epoch [2/5], Step [539/1875], Loss: 2.2818, batch time: 0.10\n",
      "Epoch [2/5], Step [540/1875], Loss: 2.3109, batch time: 0.09\n",
      "Epoch [2/5], Step [541/1875], Loss: 2.2887, batch time: 0.09\n",
      "Epoch [2/5], Step [542/1875], Loss: 2.2837, batch time: 0.13\n",
      "Epoch [2/5], Step [543/1875], Loss: 2.2853, batch time: 0.10\n",
      "Epoch [2/5], Step [544/1875], Loss: 2.2758, batch time: 0.12\n",
      "Epoch [2/5], Step [545/1875], Loss: 2.2790, batch time: 0.10\n",
      "Epoch [2/5], Step [546/1875], Loss: 2.2706, batch time: 0.11\n",
      "Epoch [2/5], Step [547/1875], Loss: 2.2562, batch time: 0.13\n",
      "Epoch [2/5], Step [548/1875], Loss: 2.2833, batch time: 0.13\n",
      "Epoch [2/5], Step [549/1875], Loss: 2.2409, batch time: 0.10\n",
      "Epoch [2/5], Step [550/1875], Loss: 2.3265, batch time: 0.10\n",
      "Epoch [2/5], Step [551/1875], Loss: 2.2715, batch time: 0.10\n",
      "Epoch [2/5], Step [552/1875], Loss: 2.3050, batch time: 0.12\n",
      "Epoch [2/5], Step [553/1875], Loss: 2.2728, batch time: 0.12\n",
      "Epoch [2/5], Step [554/1875], Loss: 2.2809, batch time: 0.13\n",
      "Epoch [2/5], Step [555/1875], Loss: 2.3013, batch time: 0.11\n",
      "Epoch [2/5], Step [556/1875], Loss: 2.3009, batch time: 0.13\n",
      "Epoch [2/5], Step [557/1875], Loss: 2.2553, batch time: 0.10\n",
      "Epoch [2/5], Step [558/1875], Loss: 2.2488, batch time: 0.10\n",
      "Epoch [2/5], Step [559/1875], Loss: 2.2733, batch time: 0.13\n",
      "Epoch [2/5], Step [560/1875], Loss: 2.3140, batch time: 0.10\n",
      "Epoch [2/5], Step [561/1875], Loss: 2.2982, batch time: 0.10\n",
      "Epoch [2/5], Step [562/1875], Loss: 2.3110, batch time: 0.14\n",
      "Epoch [2/5], Step [563/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [2/5], Step [564/1875], Loss: 2.2779, batch time: 0.10\n",
      "Epoch [2/5], Step [565/1875], Loss: 2.3129, batch time: 0.12\n",
      "Epoch [2/5], Step [566/1875], Loss: 2.3163, batch time: 0.10\n",
      "Epoch [2/5], Step [567/1875], Loss: 2.3080, batch time: 0.14\n",
      "Epoch [2/5], Step [568/1875], Loss: 2.2678, batch time: 0.13\n",
      "Epoch [2/5], Step [569/1875], Loss: 2.2467, batch time: 0.13\n",
      "Epoch [2/5], Step [570/1875], Loss: 2.2787, batch time: 0.12\n",
      "Epoch [2/5], Step [571/1875], Loss: 2.2697, batch time: 0.15\n",
      "Epoch [2/5], Step [572/1875], Loss: 2.2919, batch time: 0.12\n",
      "Epoch [2/5], Step [573/1875], Loss: 2.2655, batch time: 0.10\n",
      "Epoch [2/5], Step [574/1875], Loss: 2.2966, batch time: 0.14\n",
      "Epoch [2/5], Step [575/1875], Loss: 2.2914, batch time: 0.13\n",
      "Epoch [2/5], Step [576/1875], Loss: 2.3048, batch time: 0.10\n",
      "Epoch [2/5], Step [577/1875], Loss: 2.3066, batch time: 0.14\n",
      "Epoch [2/5], Step [578/1875], Loss: 2.2894, batch time: 0.11\n",
      "Epoch [2/5], Step [579/1875], Loss: 2.2932, batch time: 0.14\n",
      "Epoch [2/5], Step [580/1875], Loss: 2.3406, batch time: 0.10\n",
      "Epoch [2/5], Step [581/1875], Loss: 2.3291, batch time: 0.16\n",
      "Epoch [2/5], Step [582/1875], Loss: 2.2621, batch time: 0.13\n",
      "Epoch [2/5], Step [583/1875], Loss: 2.3251, batch time: 0.11\n",
      "Epoch [2/5], Step [584/1875], Loss: 2.2972, batch time: 0.10\n",
      "Epoch [2/5], Step [585/1875], Loss: 2.2958, batch time: 0.11\n",
      "Epoch [2/5], Step [586/1875], Loss: 2.2894, batch time: 0.10\n",
      "Epoch [2/5], Step [587/1875], Loss: 2.2859, batch time: 0.10\n",
      "Epoch [2/5], Step [588/1875], Loss: 2.2903, batch time: 0.10\n",
      "Epoch [2/5], Step [589/1875], Loss: 2.2869, batch time: 0.10\n",
      "Epoch [2/5], Step [590/1875], Loss: 2.2573, batch time: 0.11\n",
      "Epoch [2/5], Step [591/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [2/5], Step [592/1875], Loss: 2.2666, batch time: 0.10\n",
      "Epoch [2/5], Step [593/1875], Loss: 2.2797, batch time: 0.11\n",
      "Epoch [2/5], Step [594/1875], Loss: 2.3234, batch time: 0.10\n",
      "Epoch [2/5], Step [595/1875], Loss: 2.2663, batch time: 0.13\n",
      "Epoch [2/5], Step [596/1875], Loss: 2.2973, batch time: 0.14\n",
      "Epoch [2/5], Step [597/1875], Loss: 2.2677, batch time: 0.10\n",
      "Epoch [2/5], Step [598/1875], Loss: 2.3008, batch time: 0.20\n",
      "Epoch [2/5], Step [599/1875], Loss: 2.2550, batch time: 0.10\n",
      "Epoch [2/5], Step [600/1875], Loss: 2.2564, batch time: 0.10\n",
      "Epoch [2/5], Step [601/1875], Loss: 2.2613, batch time: 0.10\n",
      "Epoch [2/5], Step [602/1875], Loss: 2.2703, batch time: 0.11\n",
      "Epoch [2/5], Step [603/1875], Loss: 2.2952, batch time: 0.10\n",
      "Epoch [2/5], Step [604/1875], Loss: 2.3089, batch time: 0.10\n",
      "Epoch [2/5], Step [605/1875], Loss: 2.3093, batch time: 0.10\n",
      "Epoch [2/5], Step [606/1875], Loss: 2.2724, batch time: 0.10\n",
      "Epoch [2/5], Step [607/1875], Loss: 2.2786, batch time: 0.15\n",
      "Epoch [2/5], Step [608/1875], Loss: 2.2555, batch time: 0.10\n",
      "Epoch [2/5], Step [609/1875], Loss: 2.3551, batch time: 0.10\n",
      "Epoch [2/5], Step [610/1875], Loss: 2.2604, batch time: 0.23\n",
      "Epoch [2/5], Step [611/1875], Loss: 2.2666, batch time: 0.10\n",
      "Epoch [2/5], Step [612/1875], Loss: 2.2522, batch time: 0.10\n",
      "Epoch [2/5], Step [613/1875], Loss: 2.2985, batch time: 0.12\n",
      "Epoch [2/5], Step [614/1875], Loss: 2.2848, batch time: 0.10\n",
      "Epoch [2/5], Step [615/1875], Loss: 2.3151, batch time: 0.18\n",
      "Epoch [2/5], Step [616/1875], Loss: 2.2613, batch time: 0.13\n",
      "Epoch [2/5], Step [617/1875], Loss: 2.3354, batch time: 0.14\n",
      "Epoch [2/5], Step [618/1875], Loss: 2.2740, batch time: 0.10\n",
      "Epoch [2/5], Step [619/1875], Loss: 2.2944, batch time: 0.10\n",
      "Epoch [2/5], Step [620/1875], Loss: 2.2321, batch time: 0.10\n",
      "Epoch [2/5], Step [621/1875], Loss: 2.3321, batch time: 0.12\n",
      "Epoch [2/5], Step [622/1875], Loss: 2.2665, batch time: 0.13\n",
      "Epoch [2/5], Step [623/1875], Loss: 2.2948, batch time: 0.17\n",
      "Epoch [2/5], Step [624/1875], Loss: 2.3210, batch time: 0.10\n",
      "Epoch [2/5], Step [625/1875], Loss: 2.2789, batch time: 0.13\n",
      "Epoch [2/5], Step [626/1875], Loss: 2.2796, batch time: 0.19\n",
      "Epoch [2/5], Step [627/1875], Loss: 2.2932, batch time: 0.14\n",
      "Epoch [2/5], Step [628/1875], Loss: 2.2862, batch time: 0.10\n",
      "Epoch [2/5], Step [629/1875], Loss: 2.2797, batch time: 0.11\n",
      "Epoch [2/5], Step [630/1875], Loss: 2.2390, batch time: 0.10\n",
      "Epoch [2/5], Step [631/1875], Loss: 2.2456, batch time: 0.11\n",
      "Epoch [2/5], Step [632/1875], Loss: 2.2559, batch time: 0.12\n",
      "Epoch [2/5], Step [633/1875], Loss: 2.2771, batch time: 0.10\n",
      "Epoch [2/5], Step [634/1875], Loss: 2.3063, batch time: 0.10\n",
      "Epoch [2/5], Step [635/1875], Loss: 2.2510, batch time: 0.10\n",
      "Epoch [2/5], Step [636/1875], Loss: 2.2743, batch time: 0.10\n",
      "Epoch [2/5], Step [637/1875], Loss: 2.2705, batch time: 0.10\n",
      "Epoch [2/5], Step [638/1875], Loss: 2.2464, batch time: 0.10\n",
      "Epoch [2/5], Step [639/1875], Loss: 2.3231, batch time: 0.10\n",
      "Epoch [2/5], Step [640/1875], Loss: 2.2856, batch time: 0.10\n",
      "Epoch [2/5], Step [641/1875], Loss: 2.3232, batch time: 0.10\n",
      "Epoch [2/5], Step [642/1875], Loss: 2.3299, batch time: 0.10\n",
      "Epoch [2/5], Step [643/1875], Loss: 2.2519, batch time: 0.10\n",
      "Epoch [2/5], Step [644/1875], Loss: 2.2232, batch time: 0.10\n",
      "Epoch [2/5], Step [645/1875], Loss: 2.2828, batch time: 0.10\n",
      "Epoch [2/5], Step [646/1875], Loss: 2.2683, batch time: 0.10\n",
      "Epoch [2/5], Step [647/1875], Loss: 2.2876, batch time: 0.10\n",
      "Epoch [2/5], Step [648/1875], Loss: 2.2689, batch time: 0.10\n",
      "Epoch [2/5], Step [649/1875], Loss: 2.2689, batch time: 0.10\n",
      "Epoch [2/5], Step [650/1875], Loss: 2.2663, batch time: 0.10\n",
      "Epoch [2/5], Step [651/1875], Loss: 2.2734, batch time: 0.10\n",
      "Epoch [2/5], Step [652/1875], Loss: 2.2474, batch time: 0.10\n",
      "Epoch [2/5], Step [653/1875], Loss: 2.2667, batch time: 0.14\n",
      "Epoch [2/5], Step [654/1875], Loss: 2.2982, batch time: 0.10\n",
      "Epoch [2/5], Step [655/1875], Loss: 2.2686, batch time: 0.10\n",
      "Epoch [2/5], Step [656/1875], Loss: 2.2823, batch time: 0.10\n",
      "Epoch [2/5], Step [657/1875], Loss: 2.2829, batch time: 0.10\n",
      "Epoch [2/5], Step [658/1875], Loss: 2.2809, batch time: 0.11\n",
      "Epoch [2/5], Step [659/1875], Loss: 2.2417, batch time: 0.10\n",
      "Epoch [2/5], Step [660/1875], Loss: 2.2447, batch time: 0.10\n",
      "Epoch [2/5], Step [661/1875], Loss: 2.2688, batch time: 0.10\n",
      "Epoch [2/5], Step [662/1875], Loss: 2.2880, batch time: 0.10\n",
      "Epoch [2/5], Step [663/1875], Loss: 2.3081, batch time: 0.13\n",
      "Epoch [2/5], Step [664/1875], Loss: 2.2577, batch time: 0.12\n",
      "Epoch [2/5], Step [665/1875], Loss: 2.2699, batch time: 0.12\n",
      "Epoch [2/5], Step [666/1875], Loss: 2.2744, batch time: 0.13\n",
      "Epoch [2/5], Step [667/1875], Loss: 2.3218, batch time: 0.11\n",
      "Epoch [2/5], Step [668/1875], Loss: 2.2943, batch time: 0.15\n",
      "Epoch [2/5], Step [669/1875], Loss: 2.2787, batch time: 0.14\n",
      "Epoch [2/5], Step [670/1875], Loss: 2.3156, batch time: 0.10\n",
      "Epoch [2/5], Step [671/1875], Loss: 2.3195, batch time: 0.20\n",
      "Epoch [2/5], Step [672/1875], Loss: 2.2909, batch time: 0.12\n",
      "Epoch [2/5], Step [673/1875], Loss: 2.2533, batch time: 0.19\n",
      "Epoch [2/5], Step [674/1875], Loss: 2.2650, batch time: 0.10\n",
      "Epoch [2/5], Step [675/1875], Loss: 2.2578, batch time: 0.16\n",
      "Epoch [2/5], Step [676/1875], Loss: 2.2863, batch time: 0.13\n",
      "Epoch [2/5], Step [677/1875], Loss: 2.2414, batch time: 0.11\n",
      "Epoch [2/5], Step [678/1875], Loss: 2.2760, batch time: 0.10\n",
      "Epoch [2/5], Step [679/1875], Loss: 2.2570, batch time: 0.20\n",
      "Epoch [2/5], Step [680/1875], Loss: 2.2440, batch time: 0.10\n",
      "Epoch [2/5], Step [681/1875], Loss: 2.2626, batch time: 0.10\n",
      "Epoch [2/5], Step [682/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [2/5], Step [683/1875], Loss: 2.2699, batch time: 0.10\n",
      "Epoch [2/5], Step [684/1875], Loss: 2.2295, batch time: 0.10\n",
      "Epoch [2/5], Step [685/1875], Loss: 2.3272, batch time: 0.10\n",
      "Epoch [2/5], Step [686/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [2/5], Step [687/1875], Loss: 2.2840, batch time: 0.17\n",
      "Epoch [2/5], Step [688/1875], Loss: 2.2823, batch time: 0.10\n",
      "Epoch [2/5], Step [689/1875], Loss: 2.3413, batch time: 0.10\n",
      "Epoch [2/5], Step [690/1875], Loss: 2.2814, batch time: 0.10\n",
      "Epoch [2/5], Step [691/1875], Loss: 2.3355, batch time: 0.11\n",
      "Epoch [2/5], Step [692/1875], Loss: 2.2636, batch time: 0.10\n",
      "Epoch [2/5], Step [693/1875], Loss: 2.2920, batch time: 0.21\n",
      "Epoch [2/5], Step [694/1875], Loss: 2.3188, batch time: 0.10\n",
      "Epoch [2/5], Step [695/1875], Loss: 2.3126, batch time: 0.20\n",
      "Epoch [2/5], Step [696/1875], Loss: 2.2421, batch time: 0.10\n",
      "Epoch [2/5], Step [697/1875], Loss: 2.3181, batch time: 0.10\n",
      "Epoch [2/5], Step [698/1875], Loss: 2.2832, batch time: 0.13\n",
      "Epoch [2/5], Step [699/1875], Loss: 2.2911, batch time: 0.10\n",
      "Epoch [2/5], Step [700/1875], Loss: 2.2506, batch time: 0.10\n",
      "Epoch [2/5], Step [701/1875], Loss: 2.2615, batch time: 0.13\n",
      "Epoch [2/5], Step [702/1875], Loss: 2.2531, batch time: 0.10\n",
      "Epoch [2/5], Step [703/1875], Loss: 2.3016, batch time: 0.17\n",
      "Epoch [2/5], Step [704/1875], Loss: 2.2675, batch time: 0.10\n",
      "Epoch [2/5], Step [705/1875], Loss: 2.3026, batch time: 0.12\n",
      "Epoch [2/5], Step [706/1875], Loss: 2.3271, batch time: 0.10\n",
      "Epoch [2/5], Step [707/1875], Loss: 2.2720, batch time: 0.13\n",
      "Epoch [2/5], Step [708/1875], Loss: 2.3238, batch time: 0.10\n",
      "Epoch [2/5], Step [709/1875], Loss: 2.2661, batch time: 0.11\n",
      "Epoch [2/5], Step [710/1875], Loss: 2.2977, batch time: 0.15\n",
      "Epoch [2/5], Step [711/1875], Loss: 2.2769, batch time: 0.10\n",
      "Epoch [2/5], Step [712/1875], Loss: 2.3186, batch time: 0.10\n",
      "Epoch [2/5], Step [713/1875], Loss: 2.2864, batch time: 0.10\n",
      "Epoch [2/5], Step [714/1875], Loss: 2.3191, batch time: 0.10\n",
      "Epoch [2/5], Step [715/1875], Loss: 2.2992, batch time: 0.10\n",
      "Epoch [2/5], Step [716/1875], Loss: 2.2736, batch time: 0.13\n",
      "Epoch [2/5], Step [717/1875], Loss: 2.2481, batch time: 0.10\n",
      "Epoch [2/5], Step [718/1875], Loss: 2.3051, batch time: 0.11\n",
      "Epoch [2/5], Step [719/1875], Loss: 2.3037, batch time: 0.10\n",
      "Epoch [2/5], Step [720/1875], Loss: 2.3035, batch time: 0.09\n",
      "Epoch [2/5], Step [721/1875], Loss: 2.3132, batch time: 0.10\n",
      "Epoch [2/5], Step [722/1875], Loss: 2.3003, batch time: 0.10\n",
      "Epoch [2/5], Step [723/1875], Loss: 2.3020, batch time: 0.10\n",
      "Epoch [2/5], Step [724/1875], Loss: 2.2535, batch time: 0.10\n",
      "Epoch [2/5], Step [725/1875], Loss: 2.2708, batch time: 0.10\n",
      "Epoch [2/5], Step [726/1875], Loss: 2.2580, batch time: 0.10\n",
      "Epoch [2/5], Step [727/1875], Loss: 2.3142, batch time: 0.10\n",
      "Epoch [2/5], Step [728/1875], Loss: 2.2605, batch time: -2.84\n",
      "Epoch [2/5], Step [729/1875], Loss: 2.2967, batch time: 0.10\n",
      "Epoch [2/5], Step [730/1875], Loss: 2.2673, batch time: 0.10\n",
      "Epoch [2/5], Step [731/1875], Loss: 2.2788, batch time: 0.16\n",
      "Epoch [2/5], Step [732/1875], Loss: 2.2456, batch time: 0.10\n",
      "Epoch [2/5], Step [733/1875], Loss: 2.2687, batch time: 0.22\n",
      "Epoch [2/5], Step [734/1875], Loss: 2.2692, batch time: 0.10\n",
      "Epoch [2/5], Step [735/1875], Loss: 2.3153, batch time: 0.10\n",
      "Epoch [2/5], Step [736/1875], Loss: 2.2580, batch time: 0.10\n",
      "Epoch [2/5], Step [737/1875], Loss: 2.2622, batch time: 0.10\n",
      "Epoch [2/5], Step [738/1875], Loss: 2.2780, batch time: 0.14\n",
      "Epoch [2/5], Step [739/1875], Loss: 2.2682, batch time: 0.11\n",
      "Epoch [2/5], Step [740/1875], Loss: 2.3047, batch time: 0.10\n",
      "Epoch [2/5], Step [741/1875], Loss: 2.2762, batch time: 0.10\n",
      "Epoch [2/5], Step [742/1875], Loss: 2.2676, batch time: 0.10\n",
      "Epoch [2/5], Step [743/1875], Loss: 2.2626, batch time: 0.10\n",
      "Epoch [2/5], Step [744/1875], Loss: 2.3062, batch time: 0.10\n",
      "Epoch [2/5], Step [745/1875], Loss: 2.2985, batch time: 0.10\n",
      "Epoch [2/5], Step [746/1875], Loss: 2.2863, batch time: 0.12\n",
      "Epoch [2/5], Step [747/1875], Loss: 2.3154, batch time: 0.10\n",
      "Epoch [2/5], Step [748/1875], Loss: 2.2393, batch time: 0.10\n",
      "Epoch [2/5], Step [749/1875], Loss: 2.3041, batch time: 0.10\n",
      "Epoch [2/5], Step [750/1875], Loss: 2.3196, batch time: 0.14\n",
      "Epoch [2/5], Step [751/1875], Loss: 2.2519, batch time: 0.10\n",
      "Epoch [2/5], Step [752/1875], Loss: 2.2801, batch time: 0.09\n",
      "Epoch [2/5], Step [753/1875], Loss: 2.2709, batch time: 0.10\n",
      "Epoch [2/5], Step [754/1875], Loss: 2.2741, batch time: 0.10\n",
      "Epoch [2/5], Step [755/1875], Loss: 2.3032, batch time: 0.12\n",
      "Epoch [2/5], Step [756/1875], Loss: 2.2808, batch time: 0.10\n",
      "Epoch [2/5], Step [757/1875], Loss: 2.2965, batch time: 0.10\n",
      "Epoch [2/5], Step [758/1875], Loss: 2.2990, batch time: 0.10\n",
      "Epoch [2/5], Step [759/1875], Loss: 2.2725, batch time: 0.13\n",
      "Epoch [2/5], Step [760/1875], Loss: 2.2666, batch time: 0.10\n",
      "Epoch [2/5], Step [761/1875], Loss: 2.3037, batch time: 0.10\n",
      "Epoch [2/5], Step [762/1875], Loss: 2.2959, batch time: 0.10\n",
      "Epoch [2/5], Step [763/1875], Loss: 2.2749, batch time: 0.10\n",
      "Epoch [2/5], Step [764/1875], Loss: 2.2932, batch time: 0.10\n",
      "Epoch [2/5], Step [765/1875], Loss: 2.2865, batch time: 0.13\n",
      "Epoch [2/5], Step [766/1875], Loss: 2.3157, batch time: 0.10\n",
      "Epoch [2/5], Step [767/1875], Loss: 2.3031, batch time: 0.10\n",
      "Epoch [2/5], Step [768/1875], Loss: 2.2669, batch time: 0.10\n",
      "Epoch [2/5], Step [769/1875], Loss: 2.2357, batch time: 0.10\n",
      "Epoch [2/5], Step [770/1875], Loss: 2.2646, batch time: 0.10\n",
      "Epoch [2/5], Step [771/1875], Loss: 2.2527, batch time: 0.10\n",
      "Epoch [2/5], Step [772/1875], Loss: 2.2941, batch time: 0.12\n",
      "Epoch [2/5], Step [773/1875], Loss: 2.2277, batch time: 0.10\n",
      "Epoch [2/5], Step [774/1875], Loss: 2.2866, batch time: 0.11\n",
      "Epoch [2/5], Step [775/1875], Loss: 2.2436, batch time: 0.13\n",
      "Epoch [2/5], Step [776/1875], Loss: 2.3054, batch time: 0.10\n",
      "Epoch [2/5], Step [777/1875], Loss: 2.2861, batch time: 0.10\n",
      "Epoch [2/5], Step [778/1875], Loss: 2.2621, batch time: 0.10\n",
      "Epoch [2/5], Step [779/1875], Loss: 2.2897, batch time: 0.10\n",
      "Epoch [2/5], Step [780/1875], Loss: 2.2946, batch time: 0.10\n",
      "Epoch [2/5], Step [781/1875], Loss: 2.2219, batch time: 0.11\n",
      "Epoch [2/5], Step [782/1875], Loss: 2.2885, batch time: 0.10\n",
      "Epoch [2/5], Step [783/1875], Loss: 2.2827, batch time: 0.10\n",
      "Epoch [2/5], Step [784/1875], Loss: 2.2820, batch time: 0.10\n",
      "Epoch [2/5], Step [785/1875], Loss: 2.3278, batch time: 0.10\n",
      "Epoch [2/5], Step [786/1875], Loss: 2.2485, batch time: 0.10\n",
      "Epoch [2/5], Step [787/1875], Loss: 2.2930, batch time: 0.10\n",
      "Epoch [2/5], Step [788/1875], Loss: 2.2587, batch time: 0.10\n",
      "Epoch [2/5], Step [789/1875], Loss: 2.2867, batch time: 0.12\n",
      "Epoch [2/5], Step [790/1875], Loss: 2.3045, batch time: 0.11\n",
      "Epoch [2/5], Step [791/1875], Loss: 2.3267, batch time: 0.10\n",
      "Epoch [2/5], Step [792/1875], Loss: 2.2653, batch time: 0.12\n",
      "Epoch [2/5], Step [793/1875], Loss: 2.2925, batch time: 0.13\n",
      "Epoch [2/5], Step [794/1875], Loss: 2.2346, batch time: 0.10\n",
      "Epoch [2/5], Step [795/1875], Loss: 2.2508, batch time: 0.10\n",
      "Epoch [2/5], Step [796/1875], Loss: 2.3154, batch time: 0.10\n",
      "Epoch [2/5], Step [797/1875], Loss: 2.2558, batch time: 0.10\n",
      "Epoch [2/5], Step [798/1875], Loss: 2.2332, batch time: 0.10\n",
      "Epoch [2/5], Step [799/1875], Loss: 2.2409, batch time: 0.10\n",
      "Epoch [2/5], Step [800/1875], Loss: 2.2802, batch time: 0.10\n",
      "Epoch [2/5], Step [801/1875], Loss: 2.3167, batch time: 0.13\n",
      "Epoch [2/5], Step [802/1875], Loss: 2.2758, batch time: 0.10\n",
      "Epoch [2/5], Step [803/1875], Loss: 2.3064, batch time: 0.10\n",
      "Epoch [2/5], Step [804/1875], Loss: 2.2361, batch time: 0.13\n",
      "Epoch [2/5], Step [805/1875], Loss: 2.3110, batch time: 0.10\n",
      "Epoch [2/5], Step [806/1875], Loss: 2.2495, batch time: 0.10\n",
      "Epoch [2/5], Step [807/1875], Loss: 2.2699, batch time: 0.13\n",
      "Epoch [2/5], Step [808/1875], Loss: 2.2125, batch time: 0.10\n",
      "Epoch [2/5], Step [809/1875], Loss: 2.2765, batch time: 0.10\n",
      "Epoch [2/5], Step [810/1875], Loss: 2.2703, batch time: 0.10\n",
      "Epoch [2/5], Step [811/1875], Loss: 2.2803, batch time: 0.10\n",
      "Epoch [2/5], Step [812/1875], Loss: 2.2227, batch time: 0.10\n",
      "Epoch [2/5], Step [813/1875], Loss: 2.3111, batch time: 0.10\n",
      "Epoch [2/5], Step [814/1875], Loss: 2.2572, batch time: 0.10\n",
      "Epoch [2/5], Step [815/1875], Loss: 2.2580, batch time: 0.12\n",
      "Epoch [2/5], Step [816/1875], Loss: 2.2551, batch time: 0.14\n",
      "Epoch [2/5], Step [817/1875], Loss: 2.2985, batch time: 0.18\n",
      "Epoch [2/5], Step [818/1875], Loss: 2.2706, batch time: 0.13\n",
      "Epoch [2/5], Step [819/1875], Loss: 2.2293, batch time: 0.11\n",
      "Epoch [2/5], Step [820/1875], Loss: 2.2785, batch time: 0.10\n",
      "Epoch [2/5], Step [821/1875], Loss: 2.3038, batch time: 0.14\n",
      "Epoch [2/5], Step [822/1875], Loss: 2.3139, batch time: 0.10\n",
      "Epoch [2/5], Step [823/1875], Loss: 2.3040, batch time: 0.14\n",
      "Epoch [2/5], Step [824/1875], Loss: 2.2476, batch time: 0.10\n",
      "Epoch [2/5], Step [825/1875], Loss: 2.2743, batch time: 0.10\n",
      "Epoch [2/5], Step [826/1875], Loss: 2.2705, batch time: 0.10\n",
      "Epoch [2/5], Step [827/1875], Loss: 2.3017, batch time: 0.10\n",
      "Epoch [2/5], Step [828/1875], Loss: 2.2933, batch time: 0.18\n",
      "Epoch [2/5], Step [829/1875], Loss: 2.2489, batch time: 0.10\n",
      "Epoch [2/5], Step [830/1875], Loss: 2.2901, batch time: 0.10\n",
      "Epoch [2/5], Step [831/1875], Loss: 2.3377, batch time: 0.14\n",
      "Epoch [2/5], Step [832/1875], Loss: 2.2542, batch time: 0.11\n",
      "Epoch [2/5], Step [833/1875], Loss: 2.2517, batch time: 0.10\n",
      "Epoch [2/5], Step [834/1875], Loss: 2.3114, batch time: 0.10\n",
      "Epoch [2/5], Step [835/1875], Loss: 2.2665, batch time: 0.10\n",
      "Epoch [2/5], Step [836/1875], Loss: 2.2911, batch time: 0.11\n",
      "Epoch [2/5], Step [837/1875], Loss: 2.3151, batch time: 0.10\n",
      "Epoch [2/5], Step [838/1875], Loss: 2.2706, batch time: 0.10\n",
      "Epoch [2/5], Step [839/1875], Loss: 2.2624, batch time: 0.10\n",
      "Epoch [2/5], Step [840/1875], Loss: 2.2626, batch time: 0.10\n",
      "Epoch [2/5], Step [841/1875], Loss: 2.2601, batch time: 0.10\n",
      "Epoch [2/5], Step [842/1875], Loss: 2.2895, batch time: 0.10\n",
      "Epoch [2/5], Step [843/1875], Loss: 2.2891, batch time: 0.10\n",
      "Epoch [2/5], Step [844/1875], Loss: 2.3011, batch time: 0.10\n",
      "Epoch [2/5], Step [845/1875], Loss: 2.3311, batch time: 0.17\n",
      "Epoch [2/5], Step [846/1875], Loss: 2.2705, batch time: 0.10\n",
      "Epoch [2/5], Step [847/1875], Loss: 2.2842, batch time: 0.10\n",
      "Epoch [2/5], Step [848/1875], Loss: 2.2843, batch time: 0.10\n",
      "Epoch [2/5], Step [849/1875], Loss: 2.2560, batch time: 0.10\n",
      "Epoch [2/5], Step [850/1875], Loss: 2.2815, batch time: 0.10\n",
      "Epoch [2/5], Step [851/1875], Loss: 2.2904, batch time: 0.10\n",
      "Epoch [2/5], Step [852/1875], Loss: 2.2714, batch time: 0.10\n",
      "Epoch [2/5], Step [853/1875], Loss: 2.2322, batch time: 0.15\n",
      "Epoch [2/5], Step [854/1875], Loss: 2.2506, batch time: 0.10\n",
      "Epoch [2/5], Step [855/1875], Loss: 2.2685, batch time: 0.10\n",
      "Epoch [2/5], Step [856/1875], Loss: 2.2966, batch time: 0.10\n",
      "Epoch [2/5], Step [857/1875], Loss: 2.2520, batch time: 0.10\n",
      "Epoch [2/5], Step [858/1875], Loss: 2.2631, batch time: 0.10\n",
      "Epoch [2/5], Step [859/1875], Loss: 2.2849, batch time: 0.10\n",
      "Epoch [2/5], Step [860/1875], Loss: 2.3101, batch time: 0.10\n",
      "Epoch [2/5], Step [861/1875], Loss: 2.2783, batch time: 0.10\n",
      "Epoch [2/5], Step [862/1875], Loss: 2.2454, batch time: 0.10\n",
      "Epoch [2/5], Step [863/1875], Loss: 2.2595, batch time: 0.10\n",
      "Epoch [2/5], Step [864/1875], Loss: 2.2882, batch time: 0.10\n",
      "Epoch [2/5], Step [865/1875], Loss: 2.2886, batch time: 0.10\n",
      "Epoch [2/5], Step [866/1875], Loss: 2.2193, batch time: 0.10\n",
      "Epoch [2/5], Step [867/1875], Loss: 2.2985, batch time: 0.10\n",
      "Epoch [2/5], Step [868/1875], Loss: 2.2779, batch time: 0.18\n",
      "Epoch [2/5], Step [869/1875], Loss: 2.2962, batch time: 0.09\n",
      "Epoch [2/5], Step [870/1875], Loss: 2.2541, batch time: 0.10\n",
      "Epoch [2/5], Step [871/1875], Loss: 2.2564, batch time: 0.15\n",
      "Epoch [2/5], Step [872/1875], Loss: 2.2706, batch time: 0.10\n",
      "Epoch [2/5], Step [873/1875], Loss: 2.2804, batch time: 0.13\n",
      "Epoch [2/5], Step [874/1875], Loss: 2.2418, batch time: 0.10\n",
      "Epoch [2/5], Step [875/1875], Loss: 2.3079, batch time: 0.10\n",
      "Epoch [2/5], Step [876/1875], Loss: 2.2468, batch time: 0.14\n",
      "Epoch [2/5], Step [877/1875], Loss: 2.2532, batch time: 0.13\n",
      "Epoch [2/5], Step [878/1875], Loss: 2.2751, batch time: 0.10\n",
      "Epoch [2/5], Step [879/1875], Loss: 2.2442, batch time: 0.10\n",
      "Epoch [2/5], Step [880/1875], Loss: 2.3102, batch time: 0.10\n",
      "Epoch [2/5], Step [881/1875], Loss: 2.2901, batch time: 0.13\n",
      "Epoch [2/5], Step [882/1875], Loss: 2.2110, batch time: 0.10\n",
      "Epoch [2/5], Step [883/1875], Loss: 2.1956, batch time: 0.10\n",
      "Epoch [2/5], Step [884/1875], Loss: 2.2930, batch time: 0.13\n",
      "Epoch [2/5], Step [885/1875], Loss: 2.2607, batch time: 0.10\n",
      "Epoch [2/5], Step [886/1875], Loss: 2.2388, batch time: 0.12\n",
      "Epoch [2/5], Step [887/1875], Loss: 2.2843, batch time: 0.10\n",
      "Epoch [2/5], Step [888/1875], Loss: 2.2748, batch time: 0.11\n",
      "Epoch [2/5], Step [889/1875], Loss: 2.2679, batch time: 0.10\n",
      "Epoch [2/5], Step [890/1875], Loss: 2.2534, batch time: 0.11\n",
      "Epoch [2/5], Step [891/1875], Loss: 2.2852, batch time: 0.10\n",
      "Epoch [2/5], Step [892/1875], Loss: 2.2235, batch time: 0.10\n",
      "Epoch [2/5], Step [893/1875], Loss: 2.2150, batch time: 0.19\n",
      "Epoch [2/5], Step [894/1875], Loss: 2.2817, batch time: 0.10\n",
      "Epoch [2/5], Step [895/1875], Loss: 2.3026, batch time: 0.18\n",
      "Epoch [2/5], Step [896/1875], Loss: 2.2924, batch time: 0.15\n",
      "Epoch [2/5], Step [897/1875], Loss: 2.2123, batch time: 0.10\n",
      "Epoch [2/5], Step [898/1875], Loss: 2.2678, batch time: 0.09\n",
      "Epoch [2/5], Step [899/1875], Loss: 2.3439, batch time: 0.13\n",
      "Epoch [2/5], Step [900/1875], Loss: 2.2557, batch time: 0.10\n",
      "Epoch [2/5], Step [901/1875], Loss: 2.2812, batch time: 0.10\n",
      "Epoch [2/5], Step [902/1875], Loss: 2.3181, batch time: 0.10\n",
      "Epoch [2/5], Step [903/1875], Loss: 2.3245, batch time: 0.10\n",
      "Epoch [2/5], Step [904/1875], Loss: 2.3122, batch time: 0.10\n",
      "Epoch [2/5], Step [905/1875], Loss: 2.2986, batch time: 0.12\n",
      "Epoch [2/5], Step [906/1875], Loss: 2.2814, batch time: 0.10\n",
      "Epoch [2/5], Step [907/1875], Loss: 2.2678, batch time: 0.10\n",
      "Epoch [2/5], Step [908/1875], Loss: 2.2863, batch time: 0.15\n",
      "Epoch [2/5], Step [909/1875], Loss: 2.2191, batch time: 0.10\n",
      "Epoch [2/5], Step [910/1875], Loss: 2.2648, batch time: 0.10\n",
      "Epoch [2/5], Step [911/1875], Loss: 2.2420, batch time: 0.14\n",
      "Epoch [2/5], Step [912/1875], Loss: 2.2766, batch time: 0.10\n",
      "Epoch [2/5], Step [913/1875], Loss: 2.2057, batch time: 0.10\n",
      "Epoch [2/5], Step [914/1875], Loss: 2.2706, batch time: 0.12\n",
      "Epoch [2/5], Step [915/1875], Loss: 2.2550, batch time: 0.10\n",
      "Epoch [2/5], Step [916/1875], Loss: 2.2689, batch time: 0.10\n",
      "Epoch [2/5], Step [917/1875], Loss: 2.2941, batch time: 0.10\n",
      "Epoch [2/5], Step [918/1875], Loss: 2.2965, batch time: 0.10\n",
      "Epoch [2/5], Step [919/1875], Loss: 2.2990, batch time: 0.10\n",
      "Epoch [2/5], Step [920/1875], Loss: 2.2723, batch time: 0.10\n",
      "Epoch [2/5], Step [921/1875], Loss: 2.3158, batch time: 0.13\n",
      "Epoch [2/5], Step [922/1875], Loss: 2.2748, batch time: 0.15\n",
      "Epoch [2/5], Step [923/1875], Loss: 2.2283, batch time: 0.14\n",
      "Epoch [2/5], Step [924/1875], Loss: 2.2661, batch time: 0.10\n",
      "Epoch [2/5], Step [925/1875], Loss: 2.2911, batch time: 0.13\n",
      "Epoch [2/5], Step [926/1875], Loss: 2.2942, batch time: 0.10\n",
      "Epoch [2/5], Step [927/1875], Loss: 2.3135, batch time: 0.13\n",
      "Epoch [2/5], Step [928/1875], Loss: 2.2760, batch time: 0.12\n",
      "Epoch [2/5], Step [929/1875], Loss: 2.3164, batch time: 0.17\n",
      "Epoch [2/5], Step [930/1875], Loss: 2.2418, batch time: 0.12\n",
      "Epoch [2/5], Step [931/1875], Loss: 2.1914, batch time: 0.13\n",
      "Epoch [2/5], Step [932/1875], Loss: 2.2219, batch time: 0.10\n",
      "Epoch [2/5], Step [933/1875], Loss: 2.2492, batch time: 0.10\n",
      "Epoch [2/5], Step [934/1875], Loss: 2.2611, batch time: 0.12\n",
      "Epoch [2/5], Step [935/1875], Loss: 2.2649, batch time: 0.13\n",
      "Epoch [2/5], Step [936/1875], Loss: 2.2193, batch time: 0.12\n",
      "Epoch [2/5], Step [937/1875], Loss: 2.3010, batch time: 0.10\n",
      "Epoch [2/5], Step [938/1875], Loss: 2.2941, batch time: 0.12\n",
      "Epoch [2/5], Step [939/1875], Loss: 2.3366, batch time: 0.13\n",
      "Epoch [2/5], Step [940/1875], Loss: 2.2921, batch time: 0.10\n",
      "Epoch [2/5], Step [941/1875], Loss: 2.2263, batch time: 0.10\n",
      "Epoch [2/5], Step [942/1875], Loss: 2.2642, batch time: 0.10\n",
      "Epoch [2/5], Step [943/1875], Loss: 2.3334, batch time: 0.11\n",
      "Epoch [2/5], Step [944/1875], Loss: 2.2995, batch time: 0.10\n",
      "Epoch [2/5], Step [945/1875], Loss: 2.2442, batch time: 0.13\n",
      "Epoch [2/5], Step [946/1875], Loss: 2.2506, batch time: 0.10\n",
      "Epoch [2/5], Step [947/1875], Loss: 2.2513, batch time: 0.10\n",
      "Epoch [2/5], Step [948/1875], Loss: 2.2970, batch time: 0.10\n",
      "Epoch [2/5], Step [949/1875], Loss: 2.3213, batch time: 0.10\n",
      "Epoch [2/5], Step [950/1875], Loss: 2.3423, batch time: 0.16\n",
      "Epoch [2/5], Step [951/1875], Loss: 2.2781, batch time: 0.10\n",
      "Epoch [2/5], Step [952/1875], Loss: 2.2785, batch time: 0.11\n",
      "Epoch [2/5], Step [953/1875], Loss: 2.2848, batch time: 0.12\n",
      "Epoch [2/5], Step [954/1875], Loss: 2.2784, batch time: 0.10\n",
      "Epoch [2/5], Step [955/1875], Loss: 2.2757, batch time: 0.21\n",
      "Epoch [2/5], Step [956/1875], Loss: 2.2917, batch time: 0.19\n",
      "Epoch [2/5], Step [957/1875], Loss: 2.2789, batch time: 0.10\n",
      "Epoch [2/5], Step [958/1875], Loss: 2.2459, batch time: 0.12\n",
      "Epoch [2/5], Step [959/1875], Loss: 2.2217, batch time: 0.14\n",
      "Epoch [2/5], Step [960/1875], Loss: 2.2932, batch time: 0.10\n",
      "Epoch [2/5], Step [961/1875], Loss: 2.3266, batch time: 0.10\n",
      "Epoch [2/5], Step [962/1875], Loss: 2.2433, batch time: 0.12\n",
      "Epoch [2/5], Step [963/1875], Loss: 2.2824, batch time: 0.11\n",
      "Epoch [2/5], Step [964/1875], Loss: 2.2908, batch time: 0.12\n",
      "Epoch [2/5], Step [965/1875], Loss: 2.3051, batch time: 0.10\n",
      "Epoch [2/5], Step [966/1875], Loss: 2.3030, batch time: 0.12\n",
      "Epoch [2/5], Step [967/1875], Loss: 2.2651, batch time: 0.10\n",
      "Epoch [2/5], Step [968/1875], Loss: 2.2954, batch time: 0.12\n",
      "Epoch [2/5], Step [969/1875], Loss: 2.2534, batch time: 0.10\n",
      "Epoch [2/5], Step [970/1875], Loss: 2.2934, batch time: 0.10\n",
      "Epoch [2/5], Step [971/1875], Loss: 2.2487, batch time: 0.11\n",
      "Epoch [2/5], Step [972/1875], Loss: 2.2892, batch time: 0.11\n",
      "Epoch [2/5], Step [973/1875], Loss: 2.2124, batch time: 0.13\n",
      "Epoch [2/5], Step [974/1875], Loss: 2.2091, batch time: 0.10\n",
      "Epoch [2/5], Step [975/1875], Loss: 2.2790, batch time: 0.10\n",
      "Epoch [2/5], Step [976/1875], Loss: 2.2690, batch time: 0.13\n",
      "Epoch [2/5], Step [977/1875], Loss: 2.2831, batch time: 0.14\n",
      "Epoch [2/5], Step [978/1875], Loss: 2.2027, batch time: 0.10\n",
      "Epoch [2/5], Step [979/1875], Loss: 2.2810, batch time: 0.10\n",
      "Epoch [2/5], Step [980/1875], Loss: 2.2188, batch time: 0.10\n",
      "Epoch [2/5], Step [981/1875], Loss: 2.2642, batch time: 0.11\n",
      "Epoch [2/5], Step [982/1875], Loss: 2.2885, batch time: 0.26\n",
      "Epoch [2/5], Step [983/1875], Loss: 2.3026, batch time: 0.10\n",
      "Epoch [2/5], Step [984/1875], Loss: 2.3334, batch time: 0.12\n",
      "Epoch [2/5], Step [985/1875], Loss: 2.2115, batch time: 0.14\n",
      "Epoch [2/5], Step [986/1875], Loss: 2.2770, batch time: 0.12\n",
      "Epoch [2/5], Step [987/1875], Loss: 2.3029, batch time: 0.17\n",
      "Epoch [2/5], Step [988/1875], Loss: 2.2684, batch time: 0.10\n",
      "Epoch [2/5], Step [989/1875], Loss: 2.3172, batch time: 0.15\n",
      "Epoch [2/5], Step [990/1875], Loss: 2.3001, batch time: 0.14\n",
      "Epoch [2/5], Step [991/1875], Loss: 2.2894, batch time: 0.11\n",
      "Epoch [2/5], Step [992/1875], Loss: 2.2726, batch time: 0.11\n",
      "Epoch [2/5], Step [993/1875], Loss: 2.2832, batch time: 0.13\n",
      "Epoch [2/5], Step [994/1875], Loss: 2.2341, batch time: 0.10\n",
      "Epoch [2/5], Step [995/1875], Loss: 2.2588, batch time: 0.10\n",
      "Epoch [2/5], Step [996/1875], Loss: 2.2660, batch time: 0.10\n",
      "Epoch [2/5], Step [997/1875], Loss: 2.3025, batch time: 0.17\n",
      "Epoch [2/5], Step [998/1875], Loss: 2.2674, batch time: 0.10\n",
      "Epoch [2/5], Step [999/1875], Loss: 2.2985, batch time: 0.16\n",
      "Epoch [2/5], Step [1000/1875], Loss: 2.2590, batch time: 0.09\n",
      "Epoch [2/5], Step [1001/1875], Loss: 2.3366, batch time: 0.10\n",
      "Epoch [2/5], Step [1002/1875], Loss: 2.2686, batch time: 0.10\n",
      "Epoch [2/5], Step [1003/1875], Loss: 2.2587, batch time: 0.12\n",
      "Epoch [2/5], Step [1004/1875], Loss: 2.2494, batch time: 0.10\n",
      "Epoch [2/5], Step [1005/1875], Loss: 2.2416, batch time: 0.09\n",
      "Epoch [2/5], Step [1006/1875], Loss: 2.3035, batch time: 0.10\n",
      "Epoch [2/5], Step [1007/1875], Loss: 2.3036, batch time: 0.10\n",
      "Epoch [2/5], Step [1008/1875], Loss: 2.3170, batch time: 0.10\n",
      "Epoch [2/5], Step [1009/1875], Loss: 2.2498, batch time: 0.21\n",
      "Epoch [2/5], Step [1010/1875], Loss: 2.2734, batch time: 0.10\n",
      "Epoch [2/5], Step [1011/1875], Loss: 2.2510, batch time: 0.10\n",
      "Epoch [2/5], Step [1012/1875], Loss: 2.2464, batch time: -2.84\n",
      "Epoch [2/5], Step [1013/1875], Loss: 2.2566, batch time: 0.10\n",
      "Epoch [2/5], Step [1014/1875], Loss: 2.2420, batch time: 0.10\n",
      "Epoch [2/5], Step [1015/1875], Loss: 2.2747, batch time: 0.10\n",
      "Epoch [2/5], Step [1016/1875], Loss: 2.2357, batch time: 0.13\n",
      "Epoch [2/5], Step [1017/1875], Loss: 2.2203, batch time: 0.10\n",
      "Epoch [2/5], Step [1018/1875], Loss: 2.2246, batch time: 0.12\n",
      "Epoch [2/5], Step [1019/1875], Loss: 2.2850, batch time: 0.12\n",
      "Epoch [2/5], Step [1020/1875], Loss: 2.2796, batch time: 0.10\n",
      "Epoch [2/5], Step [1021/1875], Loss: 2.2763, batch time: 0.09\n",
      "Epoch [2/5], Step [1022/1875], Loss: 2.2596, batch time: 0.13\n",
      "Epoch [2/5], Step [1023/1875], Loss: 2.2426, batch time: 0.12\n",
      "Epoch [2/5], Step [1024/1875], Loss: 2.2841, batch time: 0.10\n",
      "Epoch [2/5], Step [1025/1875], Loss: 2.2927, batch time: 0.11\n",
      "Epoch [2/5], Step [1026/1875], Loss: 2.3021, batch time: 0.10\n",
      "Epoch [2/5], Step [1027/1875], Loss: 2.3118, batch time: 0.10\n",
      "Epoch [2/5], Step [1028/1875], Loss: 2.2938, batch time: 0.14\n",
      "Epoch [2/5], Step [1029/1875], Loss: 2.2899, batch time: 0.12\n",
      "Epoch [2/5], Step [1030/1875], Loss: 2.2533, batch time: 0.10\n",
      "Epoch [2/5], Step [1031/1875], Loss: 2.2465, batch time: 0.15\n",
      "Epoch [2/5], Step [1032/1875], Loss: 2.2609, batch time: 0.12\n",
      "Epoch [2/5], Step [1033/1875], Loss: 2.2818, batch time: 0.13\n",
      "Epoch [2/5], Step [1034/1875], Loss: 2.3192, batch time: 0.10\n",
      "Epoch [2/5], Step [1035/1875], Loss: 2.2428, batch time: 0.13\n",
      "Epoch [2/5], Step [1036/1875], Loss: 2.2056, batch time: 0.10\n",
      "Epoch [2/5], Step [1037/1875], Loss: 2.2676, batch time: 0.10\n",
      "Epoch [2/5], Step [1038/1875], Loss: 2.2641, batch time: 0.13\n",
      "Epoch [2/5], Step [1039/1875], Loss: 2.2747, batch time: 0.10\n",
      "Epoch [2/5], Step [1040/1875], Loss: 2.3016, batch time: 0.10\n",
      "Epoch [2/5], Step [1041/1875], Loss: 2.2912, batch time: 0.10\n",
      "Epoch [2/5], Step [1042/1875], Loss: 2.2723, batch time: 0.12\n",
      "Epoch [2/5], Step [1043/1875], Loss: 2.2390, batch time: 0.10\n",
      "Epoch [2/5], Step [1044/1875], Loss: 2.2910, batch time: 0.10\n",
      "Epoch [2/5], Step [1045/1875], Loss: 2.1753, batch time: 0.10\n",
      "Epoch [2/5], Step [1046/1875], Loss: 2.3450, batch time: 0.14\n",
      "Epoch [2/5], Step [1047/1875], Loss: 2.2752, batch time: 0.11\n",
      "Epoch [2/5], Step [1048/1875], Loss: 2.2989, batch time: 0.10\n",
      "Epoch [2/5], Step [1049/1875], Loss: 2.2537, batch time: 0.15\n",
      "Epoch [2/5], Step [1050/1875], Loss: 2.1923, batch time: 0.10\n",
      "Epoch [2/5], Step [1051/1875], Loss: 2.2602, batch time: 0.12\n",
      "Epoch [2/5], Step [1052/1875], Loss: 2.1945, batch time: 0.10\n",
      "Epoch [2/5], Step [1053/1875], Loss: 2.2950, batch time: 0.13\n",
      "Epoch [2/5], Step [1054/1875], Loss: 2.2427, batch time: 0.10\n",
      "Epoch [2/5], Step [1055/1875], Loss: 2.2089, batch time: 0.13\n",
      "Epoch [2/5], Step [1056/1875], Loss: 2.2792, batch time: 0.22\n",
      "Epoch [2/5], Step [1057/1875], Loss: 2.2349, batch time: 0.10\n",
      "Epoch [2/5], Step [1058/1875], Loss: 2.2861, batch time: 0.10\n",
      "Epoch [2/5], Step [1059/1875], Loss: 2.2592, batch time: 0.12\n",
      "Epoch [2/5], Step [1060/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [2/5], Step [1061/1875], Loss: 2.2820, batch time: 0.11\n",
      "Epoch [2/5], Step [1062/1875], Loss: 2.2823, batch time: 0.10\n",
      "Epoch [2/5], Step [1063/1875], Loss: 2.2431, batch time: 0.10\n",
      "Epoch [2/5], Step [1064/1875], Loss: 2.2565, batch time: 0.10\n",
      "Epoch [2/5], Step [1065/1875], Loss: 2.2380, batch time: 0.10\n",
      "Epoch [2/5], Step [1066/1875], Loss: 2.2711, batch time: 0.15\n",
      "Epoch [2/5], Step [1067/1875], Loss: 2.2827, batch time: 0.14\n",
      "Epoch [2/5], Step [1068/1875], Loss: 2.2828, batch time: 0.10\n",
      "Epoch [2/5], Step [1069/1875], Loss: 2.2965, batch time: 0.12\n",
      "Epoch [2/5], Step [1070/1875], Loss: 2.2544, batch time: 0.10\n",
      "Epoch [2/5], Step [1071/1875], Loss: 2.2801, batch time: 0.11\n",
      "Epoch [2/5], Step [1072/1875], Loss: 2.2676, batch time: 0.10\n",
      "Epoch [2/5], Step [1073/1875], Loss: 2.2738, batch time: 0.12\n",
      "Epoch [2/5], Step [1074/1875], Loss: 2.1762, batch time: 0.17\n",
      "Epoch [2/5], Step [1075/1875], Loss: 2.2531, batch time: 0.11\n",
      "Epoch [2/5], Step [1076/1875], Loss: 2.2937, batch time: 0.10\n",
      "Epoch [2/5], Step [1077/1875], Loss: 2.3076, batch time: 0.10\n",
      "Epoch [2/5], Step [1078/1875], Loss: 2.2856, batch time: 0.11\n",
      "Epoch [2/5], Step [1079/1875], Loss: 2.2770, batch time: 0.14\n",
      "Epoch [2/5], Step [1080/1875], Loss: 2.2584, batch time: 0.10\n",
      "Epoch [2/5], Step [1081/1875], Loss: 2.2862, batch time: 0.16\n",
      "Epoch [2/5], Step [1082/1875], Loss: 2.3246, batch time: 0.11\n",
      "Epoch [2/5], Step [1083/1875], Loss: 2.3454, batch time: 0.10\n",
      "Epoch [2/5], Step [1084/1875], Loss: 2.2417, batch time: 0.10\n",
      "Epoch [2/5], Step [1085/1875], Loss: 2.2676, batch time: 0.10\n",
      "Epoch [2/5], Step [1086/1875], Loss: 2.2527, batch time: 0.10\n",
      "Epoch [2/5], Step [1087/1875], Loss: 2.3059, batch time: 0.11\n",
      "Epoch [2/5], Step [1088/1875], Loss: 2.3315, batch time: 0.10\n",
      "Epoch [2/5], Step [1089/1875], Loss: 2.3131, batch time: 0.10\n",
      "Epoch [2/5], Step [1090/1875], Loss: 2.2501, batch time: 0.13\n",
      "Epoch [2/5], Step [1091/1875], Loss: 2.2311, batch time: 0.10\n",
      "Epoch [2/5], Step [1092/1875], Loss: 2.2992, batch time: 0.11\n",
      "Epoch [2/5], Step [1093/1875], Loss: 2.2659, batch time: 0.10\n",
      "Epoch [2/5], Step [1094/1875], Loss: 2.2114, batch time: 0.10\n",
      "Epoch [2/5], Step [1095/1875], Loss: 2.2684, batch time: 0.10\n",
      "Epoch [2/5], Step [1096/1875], Loss: 2.2342, batch time: 0.10\n",
      "Epoch [2/5], Step [1097/1875], Loss: 2.2696, batch time: 0.10\n",
      "Epoch [2/5], Step [1098/1875], Loss: 2.2384, batch time: 0.10\n",
      "Epoch [2/5], Step [1099/1875], Loss: 2.2695, batch time: 0.10\n",
      "Epoch [2/5], Step [1100/1875], Loss: 2.2780, batch time: 0.09\n",
      "Epoch [2/5], Step [1101/1875], Loss: 2.2700, batch time: 0.10\n",
      "Epoch [2/5], Step [1102/1875], Loss: 2.2161, batch time: 0.10\n",
      "Epoch [2/5], Step [1103/1875], Loss: 2.2239, batch time: 0.10\n",
      "Epoch [2/5], Step [1104/1875], Loss: 2.2752, batch time: 0.14\n",
      "Epoch [2/5], Step [1105/1875], Loss: 2.2775, batch time: 0.10\n",
      "Epoch [2/5], Step [1106/1875], Loss: 2.2709, batch time: 0.13\n",
      "Epoch [2/5], Step [1107/1875], Loss: 2.2692, batch time: 0.13\n",
      "Epoch [2/5], Step [1108/1875], Loss: 2.3709, batch time: 0.14\n",
      "Epoch [2/5], Step [1109/1875], Loss: 2.2891, batch time: 0.17\n",
      "Epoch [2/5], Step [1110/1875], Loss: 2.3227, batch time: 0.11\n",
      "Epoch [2/5], Step [1111/1875], Loss: 2.2633, batch time: 0.10\n",
      "Epoch [2/5], Step [1112/1875], Loss: 2.2682, batch time: 0.10\n",
      "Epoch [2/5], Step [1113/1875], Loss: 2.2701, batch time: 0.16\n",
      "Epoch [2/5], Step [1114/1875], Loss: 2.2954, batch time: 0.13\n",
      "Epoch [2/5], Step [1115/1875], Loss: 2.2487, batch time: 0.10\n",
      "Epoch [2/5], Step [1116/1875], Loss: 2.2928, batch time: 0.10\n",
      "Epoch [2/5], Step [1117/1875], Loss: 2.2571, batch time: 0.17\n",
      "Epoch [2/5], Step [1118/1875], Loss: 2.2757, batch time: 0.10\n",
      "Epoch [2/5], Step [1119/1875], Loss: 2.2808, batch time: 0.20\n",
      "Epoch [2/5], Step [1120/1875], Loss: 2.2940, batch time: 0.10\n",
      "Epoch [2/5], Step [1121/1875], Loss: 2.3615, batch time: 0.10\n",
      "Epoch [2/5], Step [1122/1875], Loss: 2.2799, batch time: 0.10\n",
      "Epoch [2/5], Step [1123/1875], Loss: 2.3701, batch time: 0.10\n",
      "Epoch [2/5], Step [1124/1875], Loss: 2.2323, batch time: 0.18\n",
      "Epoch [2/5], Step [1125/1875], Loss: 2.2069, batch time: 0.10\n",
      "Epoch [2/5], Step [1126/1875], Loss: 2.3059, batch time: 0.10\n",
      "Epoch [2/5], Step [1127/1875], Loss: 2.2412, batch time: 0.10\n",
      "Epoch [2/5], Step [1128/1875], Loss: 2.2867, batch time: 0.10\n",
      "Epoch [2/5], Step [1129/1875], Loss: 2.2805, batch time: 0.10\n",
      "Epoch [2/5], Step [1130/1875], Loss: 2.2590, batch time: 0.11\n",
      "Epoch [2/5], Step [1131/1875], Loss: 2.2759, batch time: 0.10\n",
      "Epoch [2/5], Step [1132/1875], Loss: 2.3541, batch time: 0.11\n",
      "Epoch [2/5], Step [1133/1875], Loss: 2.2436, batch time: 0.11\n",
      "Epoch [2/5], Step [1134/1875], Loss: 2.3261, batch time: 0.12\n",
      "Epoch [2/5], Step [1135/1875], Loss: 2.2394, batch time: 0.14\n",
      "Epoch [2/5], Step [1136/1875], Loss: 2.2850, batch time: 0.13\n",
      "Epoch [2/5], Step [1137/1875], Loss: 2.2899, batch time: 0.14\n",
      "Epoch [2/5], Step [1138/1875], Loss: 2.2371, batch time: 0.10\n",
      "Epoch [2/5], Step [1139/1875], Loss: 2.2796, batch time: 0.12\n",
      "Epoch [2/5], Step [1140/1875], Loss: 2.2804, batch time: 0.11\n",
      "Epoch [2/5], Step [1141/1875], Loss: 2.1944, batch time: 0.12\n",
      "Epoch [2/5], Step [1142/1875], Loss: 2.2584, batch time: 0.13\n",
      "Epoch [2/5], Step [1143/1875], Loss: 2.2611, batch time: 0.10\n",
      "Epoch [2/5], Step [1144/1875], Loss: 2.2565, batch time: 0.12\n",
      "Epoch [2/5], Step [1145/1875], Loss: 2.2744, batch time: 0.10\n",
      "Epoch [2/5], Step [1146/1875], Loss: 2.2278, batch time: 0.10\n",
      "Epoch [2/5], Step [1147/1875], Loss: 2.2891, batch time: 0.13\n",
      "Epoch [2/5], Step [1148/1875], Loss: 2.3103, batch time: 0.10\n",
      "Epoch [2/5], Step [1149/1875], Loss: 2.2930, batch time: 0.10\n",
      "Epoch [2/5], Step [1150/1875], Loss: 2.2111, batch time: 0.11\n",
      "Epoch [2/5], Step [1151/1875], Loss: 2.2438, batch time: 0.10\n",
      "Epoch [2/5], Step [1152/1875], Loss: 2.2525, batch time: 0.14\n",
      "Epoch [2/5], Step [1153/1875], Loss: 2.2962, batch time: 0.10\n",
      "Epoch [2/5], Step [1154/1875], Loss: 2.2328, batch time: 0.10\n",
      "Epoch [2/5], Step [1155/1875], Loss: 2.2797, batch time: 0.11\n",
      "Epoch [2/5], Step [1156/1875], Loss: 2.2662, batch time: 0.10\n",
      "Epoch [2/5], Step [1157/1875], Loss: 2.2930, batch time: 0.15\n",
      "Epoch [2/5], Step [1158/1875], Loss: 2.3238, batch time: 0.10\n",
      "Epoch [2/5], Step [1159/1875], Loss: 2.2236, batch time: 0.10\n",
      "Epoch [2/5], Step [1160/1875], Loss: 2.2741, batch time: 0.10\n",
      "Epoch [2/5], Step [1161/1875], Loss: 2.2539, batch time: 0.10\n",
      "Epoch [2/5], Step [1162/1875], Loss: 2.2571, batch time: 0.10\n",
      "Epoch [2/5], Step [1163/1875], Loss: 2.2492, batch time: 0.10\n",
      "Epoch [2/5], Step [1164/1875], Loss: 2.2764, batch time: 0.13\n",
      "Epoch [2/5], Step [1165/1875], Loss: 2.2580, batch time: 0.10\n",
      "Epoch [2/5], Step [1166/1875], Loss: 2.3134, batch time: 0.10\n",
      "Epoch [2/5], Step [1167/1875], Loss: 2.2485, batch time: 0.11\n",
      "Epoch [2/5], Step [1168/1875], Loss: 2.2233, batch time: 0.10\n",
      "Epoch [2/5], Step [1169/1875], Loss: 2.3193, batch time: 0.13\n",
      "Epoch [2/5], Step [1170/1875], Loss: 2.3326, batch time: 0.10\n",
      "Epoch [2/5], Step [1171/1875], Loss: 2.2423, batch time: 0.14\n",
      "Epoch [2/5], Step [1172/1875], Loss: 2.3351, batch time: 0.17\n",
      "Epoch [2/5], Step [1173/1875], Loss: 2.2407, batch time: 0.10\n",
      "Epoch [2/5], Step [1174/1875], Loss: 2.2588, batch time: 0.10\n",
      "Epoch [2/5], Step [1175/1875], Loss: 2.2296, batch time: 0.10\n",
      "Epoch [2/5], Step [1176/1875], Loss: 2.2849, batch time: 0.10\n",
      "Epoch [2/5], Step [1177/1875], Loss: 2.2924, batch time: 0.14\n",
      "Epoch [2/5], Step [1178/1875], Loss: 2.2901, batch time: 0.12\n",
      "Epoch [2/5], Step [1179/1875], Loss: 2.3113, batch time: 0.10\n",
      "Epoch [2/5], Step [1180/1875], Loss: 2.2893, batch time: 0.10\n",
      "Epoch [2/5], Step [1181/1875], Loss: 2.3046, batch time: 0.14\n",
      "Epoch [2/5], Step [1182/1875], Loss: 2.2881, batch time: 0.10\n",
      "Epoch [2/5], Step [1183/1875], Loss: 2.2190, batch time: 0.10\n",
      "Epoch [2/5], Step [1184/1875], Loss: 2.2959, batch time: 0.19\n",
      "Epoch [2/5], Step [1185/1875], Loss: 2.2480, batch time: 0.10\n",
      "Epoch [2/5], Step [1186/1875], Loss: 2.2558, batch time: 0.10\n",
      "Epoch [2/5], Step [1187/1875], Loss: 2.2845, batch time: 0.10\n",
      "Epoch [2/5], Step [1188/1875], Loss: 2.3227, batch time: 0.10\n",
      "Epoch [2/5], Step [1189/1875], Loss: 2.3115, batch time: 0.10\n",
      "Epoch [2/5], Step [1190/1875], Loss: 2.2823, batch time: 0.10\n",
      "Epoch [2/5], Step [1191/1875], Loss: 2.2198, batch time: 0.15\n",
      "Epoch [2/5], Step [1192/1875], Loss: 2.3560, batch time: 0.17\n",
      "Epoch [2/5], Step [1193/1875], Loss: 2.2913, batch time: 0.10\n",
      "Epoch [2/5], Step [1194/1875], Loss: 2.2122, batch time: 0.10\n",
      "Epoch [2/5], Step [1195/1875], Loss: 2.2049, batch time: 0.11\n",
      "Epoch [2/5], Step [1196/1875], Loss: 2.2572, batch time: 0.10\n",
      "Epoch [2/5], Step [1197/1875], Loss: 2.2436, batch time: 0.10\n",
      "Epoch [2/5], Step [1198/1875], Loss: 2.1921, batch time: 0.10\n",
      "Epoch [2/5], Step [1199/1875], Loss: 2.3185, batch time: 0.10\n",
      "Epoch [2/5], Step [1200/1875], Loss: 2.2803, batch time: 0.10\n",
      "Epoch [2/5], Step [1201/1875], Loss: 2.2655, batch time: 0.14\n",
      "Epoch [2/5], Step [1202/1875], Loss: 2.2798, batch time: 0.10\n",
      "Epoch [2/5], Step [1203/1875], Loss: 2.2462, batch time: 0.10\n",
      "Epoch [2/5], Step [1204/1875], Loss: 2.3100, batch time: 0.10\n",
      "Epoch [2/5], Step [1205/1875], Loss: 2.1911, batch time: 0.10\n",
      "Epoch [2/5], Step [1206/1875], Loss: 2.2789, batch time: 0.10\n",
      "Epoch [2/5], Step [1207/1875], Loss: 2.2545, batch time: 0.10\n",
      "Epoch [2/5], Step [1208/1875], Loss: 2.2363, batch time: 0.10\n",
      "Epoch [2/5], Step [1209/1875], Loss: 2.2411, batch time: 0.10\n",
      "Epoch [2/5], Step [1210/1875], Loss: 2.2889, batch time: 0.12\n",
      "Epoch [2/5], Step [1211/1875], Loss: 2.2714, batch time: 0.18\n",
      "Epoch [2/5], Step [1212/1875], Loss: 2.2576, batch time: 0.10\n",
      "Epoch [2/5], Step [1213/1875], Loss: 2.2697, batch time: 0.10\n",
      "Epoch [2/5], Step [1214/1875], Loss: 2.2477, batch time: 0.15\n",
      "Epoch [2/5], Step [1215/1875], Loss: 2.2761, batch time: 0.10\n",
      "Epoch [2/5], Step [1216/1875], Loss: 2.2904, batch time: 0.10\n",
      "Epoch [2/5], Step [1217/1875], Loss: 2.2350, batch time: 0.10\n",
      "Epoch [2/5], Step [1218/1875], Loss: 2.2142, batch time: 0.15\n",
      "Epoch [2/5], Step [1219/1875], Loss: 2.2942, batch time: 0.15\n",
      "Epoch [2/5], Step [1220/1875], Loss: 2.1825, batch time: 0.10\n",
      "Epoch [2/5], Step [1221/1875], Loss: 2.2244, batch time: 0.14\n",
      "Epoch [2/5], Step [1222/1875], Loss: 2.2692, batch time: 0.10\n",
      "Epoch [2/5], Step [1223/1875], Loss: 2.3179, batch time: 0.10\n",
      "Epoch [2/5], Step [1224/1875], Loss: 2.2315, batch time: 0.10\n",
      "Epoch [2/5], Step [1225/1875], Loss: 2.2726, batch time: 0.10\n",
      "Epoch [2/5], Step [1226/1875], Loss: 2.2058, batch time: 0.10\n",
      "Epoch [2/5], Step [1227/1875], Loss: 2.3043, batch time: 0.14\n",
      "Epoch [2/5], Step [1228/1875], Loss: 2.2367, batch time: 0.10\n",
      "Epoch [2/5], Step [1229/1875], Loss: 2.2820, batch time: 0.10\n",
      "Epoch [2/5], Step [1230/1875], Loss: 2.2561, batch time: 0.11\n",
      "Epoch [2/5], Step [1231/1875], Loss: 2.2055, batch time: 0.12\n",
      "Epoch [2/5], Step [1232/1875], Loss: 2.2582, batch time: 0.10\n",
      "Epoch [2/5], Step [1233/1875], Loss: 2.2908, batch time: 0.10\n",
      "Epoch [2/5], Step [1234/1875], Loss: 2.2245, batch time: 0.10\n",
      "Epoch [2/5], Step [1235/1875], Loss: 2.2208, batch time: 0.16\n",
      "Epoch [2/5], Step [1236/1875], Loss: 2.2705, batch time: 0.10\n",
      "Epoch [2/5], Step [1237/1875], Loss: 2.2622, batch time: 0.15\n",
      "Epoch [2/5], Step [1238/1875], Loss: 2.2060, batch time: 0.10\n",
      "Epoch [2/5], Step [1239/1875], Loss: 2.2496, batch time: 0.10\n",
      "Epoch [2/5], Step [1240/1875], Loss: 2.2465, batch time: 0.13\n",
      "Epoch [2/5], Step [1241/1875], Loss: 2.2585, batch time: 0.10\n",
      "Epoch [2/5], Step [1242/1875], Loss: 2.2479, batch time: 0.15\n",
      "Epoch [2/5], Step [1243/1875], Loss: 2.2659, batch time: 0.10\n",
      "Epoch [2/5], Step [1244/1875], Loss: 2.2368, batch time: 0.17\n",
      "Epoch [2/5], Step [1245/1875], Loss: 2.2865, batch time: 0.10\n",
      "Epoch [2/5], Step [1246/1875], Loss: 2.2896, batch time: 0.11\n",
      "Epoch [2/5], Step [1247/1875], Loss: 2.2807, batch time: 0.10\n",
      "Epoch [2/5], Step [1248/1875], Loss: 2.2792, batch time: 0.10\n",
      "Epoch [2/5], Step [1249/1875], Loss: 2.2999, batch time: 0.13\n",
      "Epoch [2/5], Step [1250/1875], Loss: 2.2519, batch time: 0.10\n",
      "Epoch [2/5], Step [1251/1875], Loss: 2.3088, batch time: 0.10\n",
      "Epoch [2/5], Step [1252/1875], Loss: 2.2767, batch time: 0.10\n",
      "Epoch [2/5], Step [1253/1875], Loss: 2.2227, batch time: 0.10\n",
      "Epoch [2/5], Step [1254/1875], Loss: 2.2513, batch time: 0.19\n",
      "Epoch [2/5], Step [1255/1875], Loss: 2.2223, batch time: 0.10\n",
      "Epoch [2/5], Step [1256/1875], Loss: 2.2247, batch time: 0.10\n",
      "Epoch [2/5], Step [1257/1875], Loss: 2.2845, batch time: 0.14\n",
      "Epoch [2/5], Step [1258/1875], Loss: 2.2012, batch time: 0.10\n",
      "Epoch [2/5], Step [1259/1875], Loss: 2.2418, batch time: 0.15\n",
      "Epoch [2/5], Step [1260/1875], Loss: 2.2229, batch time: 0.10\n",
      "Epoch [2/5], Step [1261/1875], Loss: 2.2221, batch time: 0.10\n",
      "Epoch [2/5], Step [1262/1875], Loss: 2.2764, batch time: 0.10\n",
      "Epoch [2/5], Step [1263/1875], Loss: 2.1965, batch time: 0.14\n",
      "Epoch [2/5], Step [1264/1875], Loss: 2.2915, batch time: 0.10\n",
      "Epoch [2/5], Step [1265/1875], Loss: 2.3041, batch time: 0.10\n",
      "Epoch [2/5], Step [1266/1875], Loss: 2.2305, batch time: 0.10\n",
      "Epoch [2/5], Step [1267/1875], Loss: 2.2806, batch time: 0.11\n",
      "Epoch [2/5], Step [1268/1875], Loss: 2.2475, batch time: 0.13\n",
      "Epoch [2/5], Step [1269/1875], Loss: 2.2891, batch time: 0.10\n",
      "Epoch [2/5], Step [1270/1875], Loss: 2.2743, batch time: 0.10\n",
      "Epoch [2/5], Step [1271/1875], Loss: 2.3183, batch time: 0.10\n",
      "Epoch [2/5], Step [1272/1875], Loss: 2.2894, batch time: 0.13\n",
      "Epoch [2/5], Step [1273/1875], Loss: 2.2611, batch time: 0.10\n",
      "Epoch [2/5], Step [1274/1875], Loss: 2.2458, batch time: 0.10\n",
      "Epoch [2/5], Step [1275/1875], Loss: 2.2593, batch time: 0.12\n",
      "Epoch [2/5], Step [1276/1875], Loss: 2.2892, batch time: 0.10\n",
      "Epoch [2/5], Step [1277/1875], Loss: 2.2900, batch time: 0.10\n",
      "Epoch [2/5], Step [1278/1875], Loss: 2.2325, batch time: 0.14\n",
      "Epoch [2/5], Step [1279/1875], Loss: 2.2316, batch time: 0.10\n",
      "Epoch [2/5], Step [1280/1875], Loss: 2.2384, batch time: 0.13\n",
      "Epoch [2/5], Step [1281/1875], Loss: 2.2934, batch time: 0.10\n",
      "Epoch [2/5], Step [1282/1875], Loss: 2.3132, batch time: 0.10\n",
      "Epoch [2/5], Step [1283/1875], Loss: 2.3192, batch time: 0.12\n",
      "Epoch [2/5], Step [1284/1875], Loss: 2.2125, batch time: 0.11\n",
      "Epoch [2/5], Step [1285/1875], Loss: 2.2856, batch time: 0.18\n",
      "Epoch [2/5], Step [1286/1875], Loss: 2.2789, batch time: 0.10\n",
      "Epoch [2/5], Step [1287/1875], Loss: 2.2454, batch time: 0.10\n",
      "Epoch [2/5], Step [1288/1875], Loss: 2.2710, batch time: 0.15\n",
      "Epoch [2/5], Step [1289/1875], Loss: 2.2314, batch time: 0.09\n",
      "Epoch [2/5], Step [1290/1875], Loss: 2.2728, batch time: 0.13\n",
      "Epoch [2/5], Step [1291/1875], Loss: 2.3155, batch time: 0.17\n",
      "Epoch [2/5], Step [1292/1875], Loss: 2.2770, batch time: 0.10\n",
      "Epoch [2/5], Step [1293/1875], Loss: 2.2306, batch time: 0.10\n",
      "Epoch [2/5], Step [1294/1875], Loss: 2.2978, batch time: 0.13\n",
      "Epoch [2/5], Step [1295/1875], Loss: 2.2562, batch time: 0.10\n",
      "Epoch [2/5], Step [1296/1875], Loss: 2.2014, batch time: 0.10\n",
      "Epoch [2/5], Step [1297/1875], Loss: 2.2472, batch time: 0.10\n",
      "Epoch [2/5], Step [1298/1875], Loss: 2.2563, batch time: 0.10\n",
      "Epoch [2/5], Step [1299/1875], Loss: 2.3766, batch time: 0.10\n",
      "Epoch [2/5], Step [1300/1875], Loss: 2.2334, batch time: 0.11\n",
      "Epoch [2/5], Step [1301/1875], Loss: 2.2162, batch time: 0.10\n",
      "Epoch [2/5], Step [1302/1875], Loss: 2.2548, batch time: 0.10\n",
      "Epoch [2/5], Step [1303/1875], Loss: 2.2646, batch time: 0.10\n",
      "Epoch [2/5], Step [1304/1875], Loss: 2.2417, batch time: 0.14\n",
      "Epoch [2/5], Step [1305/1875], Loss: 2.3489, batch time: 0.10\n",
      "Epoch [2/5], Step [1306/1875], Loss: 2.3282, batch time: 0.09\n",
      "Epoch [2/5], Step [1307/1875], Loss: 2.2695, batch time: 0.12\n",
      "Epoch [2/5], Step [1308/1875], Loss: 2.2478, batch time: 0.10\n",
      "Epoch [2/5], Step [1309/1875], Loss: 2.2776, batch time: 0.11\n",
      "Epoch [2/5], Step [1310/1875], Loss: 2.3060, batch time: 0.14\n",
      "Epoch [2/5], Step [1311/1875], Loss: 2.2808, batch time: 0.10\n",
      "Epoch [2/5], Step [1312/1875], Loss: 2.2048, batch time: 0.10\n",
      "Epoch [2/5], Step [1313/1875], Loss: 2.2789, batch time: 0.10\n",
      "Epoch [2/5], Step [1314/1875], Loss: 2.3032, batch time: 0.10\n",
      "Epoch [2/5], Step [1315/1875], Loss: 2.2370, batch time: 0.10\n",
      "Epoch [2/5], Step [1316/1875], Loss: 2.2372, batch time: 0.10\n",
      "Epoch [2/5], Step [1317/1875], Loss: 2.2564, batch time: 0.10\n",
      "Epoch [2/5], Step [1318/1875], Loss: 2.2843, batch time: 0.12\n",
      "Epoch [2/5], Step [1319/1875], Loss: 2.2651, batch time: 0.10\n",
      "Epoch [2/5], Step [1320/1875], Loss: 2.2929, batch time: 0.10\n",
      "Epoch [2/5], Step [1321/1875], Loss: 2.2920, batch time: 0.10\n",
      "Epoch [2/5], Step [1322/1875], Loss: 2.2717, batch time: 0.10\n",
      "Epoch [2/5], Step [1323/1875], Loss: 2.2733, batch time: 0.11\n",
      "Epoch [2/5], Step [1324/1875], Loss: 2.2444, batch time: 0.10\n",
      "Epoch [2/5], Step [1325/1875], Loss: 2.2354, batch time: 0.10\n",
      "Epoch [2/5], Step [1326/1875], Loss: 2.3137, batch time: 0.12\n",
      "Epoch [2/5], Step [1327/1875], Loss: 2.1957, batch time: 0.12\n",
      "Epoch [2/5], Step [1328/1875], Loss: 2.2645, batch time: 0.12\n",
      "Epoch [2/5], Step [1329/1875], Loss: 2.1976, batch time: 0.10\n",
      "Epoch [2/5], Step [1330/1875], Loss: 2.2828, batch time: 0.15\n",
      "Epoch [2/5], Step [1331/1875], Loss: 2.2488, batch time: 0.13\n",
      "Epoch [2/5], Step [1332/1875], Loss: 2.2990, batch time: 0.13\n",
      "Epoch [2/5], Step [1333/1875], Loss: 2.2380, batch time: 0.18\n",
      "Epoch [2/5], Step [1334/1875], Loss: 2.3107, batch time: 0.10\n",
      "Epoch [2/5], Step [1335/1875], Loss: 2.1625, batch time: 0.10\n",
      "Epoch [2/5], Step [1336/1875], Loss: 2.2225, batch time: 0.10\n",
      "Epoch [2/5], Step [1337/1875], Loss: 2.3355, batch time: 0.13\n",
      "Epoch [2/5], Step [1338/1875], Loss: 2.2643, batch time: 0.10\n",
      "Epoch [2/5], Step [1339/1875], Loss: 2.2863, batch time: 0.13\n",
      "Epoch [2/5], Step [1340/1875], Loss: 2.2382, batch time: 0.12\n",
      "Epoch [2/5], Step [1341/1875], Loss: 2.2875, batch time: 0.10\n",
      "Epoch [2/5], Step [1342/1875], Loss: 2.2047, batch time: 0.11\n",
      "Epoch [2/5], Step [1343/1875], Loss: 2.2713, batch time: 0.14\n",
      "Epoch [2/5], Step [1344/1875], Loss: 2.2786, batch time: 0.12\n",
      "Epoch [2/5], Step [1345/1875], Loss: 2.2235, batch time: 0.10\n",
      "Epoch [2/5], Step [1346/1875], Loss: 2.2659, batch time: 0.26\n",
      "Epoch [2/5], Step [1347/1875], Loss: 2.2464, batch time: 0.10\n",
      "Epoch [2/5], Step [1348/1875], Loss: 2.2739, batch time: 0.10\n",
      "Epoch [2/5], Step [1349/1875], Loss: 2.2023, batch time: 0.13\n",
      "Epoch [2/5], Step [1350/1875], Loss: 2.3277, batch time: 0.10\n",
      "Epoch [2/5], Step [1351/1875], Loss: 2.3407, batch time: 0.10\n",
      "Epoch [2/5], Step [1352/1875], Loss: 2.2234, batch time: 0.10\n",
      "Epoch [2/5], Step [1353/1875], Loss: 2.1525, batch time: 0.10\n",
      "Epoch [2/5], Step [1354/1875], Loss: 2.3017, batch time: 0.10\n",
      "Epoch [2/5], Step [1355/1875], Loss: 2.2451, batch time: 0.14\n",
      "Epoch [2/5], Step [1356/1875], Loss: 2.2850, batch time: 0.11\n",
      "Epoch [2/5], Step [1357/1875], Loss: 2.2546, batch time: 0.10\n",
      "Epoch [2/5], Step [1358/1875], Loss: 2.3044, batch time: 0.10\n",
      "Epoch [2/5], Step [1359/1875], Loss: 2.2592, batch time: 0.10\n",
      "Epoch [2/5], Step [1360/1875], Loss: 2.2426, batch time: 0.10\n",
      "Epoch [2/5], Step [1361/1875], Loss: 2.2824, batch time: 0.10\n",
      "Epoch [2/5], Step [1362/1875], Loss: 2.2184, batch time: 0.10\n",
      "Epoch [2/5], Step [1363/1875], Loss: 2.2648, batch time: 0.14\n",
      "Epoch [2/5], Step [1364/1875], Loss: 2.2371, batch time: 0.12\n",
      "Epoch [2/5], Step [1365/1875], Loss: 2.2683, batch time: 0.11\n",
      "Epoch [2/5], Step [1366/1875], Loss: 2.2636, batch time: 0.19\n",
      "Epoch [2/5], Step [1367/1875], Loss: 2.3090, batch time: 0.25\n",
      "Epoch [2/5], Step [1368/1875], Loss: 2.2308, batch time: 0.10\n",
      "Epoch [2/5], Step [1369/1875], Loss: 2.3035, batch time: 0.10\n",
      "Epoch [2/5], Step [1370/1875], Loss: 2.2244, batch time: 0.10\n",
      "Epoch [2/5], Step [1371/1875], Loss: 2.2914, batch time: 0.14\n",
      "Epoch [2/5], Step [1372/1875], Loss: 2.2646, batch time: 0.13\n",
      "Epoch [2/5], Step [1373/1875], Loss: 2.3772, batch time: 0.10\n",
      "Epoch [2/5], Step [1374/1875], Loss: 2.2736, batch time: 0.13\n",
      "Epoch [2/5], Step [1375/1875], Loss: 2.2515, batch time: 0.10\n",
      "Epoch [2/5], Step [1376/1875], Loss: 2.2831, batch time: 0.13\n",
      "Epoch [2/5], Step [1377/1875], Loss: 2.2674, batch time: 0.10\n",
      "Epoch [2/5], Step [1378/1875], Loss: 2.2555, batch time: 0.11\n",
      "Epoch [2/5], Step [1379/1875], Loss: 2.2716, batch time: 0.12\n",
      "Epoch [2/5], Step [1380/1875], Loss: 2.3104, batch time: 0.16\n",
      "Epoch [2/5], Step [1381/1875], Loss: 2.2771, batch time: 0.11\n",
      "Epoch [2/5], Step [1382/1875], Loss: 2.1553, batch time: 0.14\n",
      "Epoch [2/5], Step [1383/1875], Loss: 2.2894, batch time: 0.10\n",
      "Epoch [2/5], Step [1384/1875], Loss: 2.2905, batch time: 0.10\n",
      "Epoch [2/5], Step [1385/1875], Loss: 2.2196, batch time: 0.10\n",
      "Epoch [2/5], Step [1386/1875], Loss: 2.3049, batch time: 0.10\n",
      "Epoch [2/5], Step [1387/1875], Loss: 2.2469, batch time: 0.13\n",
      "Epoch [2/5], Step [1388/1875], Loss: 2.2325, batch time: 0.10\n",
      "Epoch [2/5], Step [1389/1875], Loss: 2.2903, batch time: 0.11\n",
      "Epoch [2/5], Step [1390/1875], Loss: 2.1887, batch time: 0.10\n",
      "Epoch [2/5], Step [1391/1875], Loss: 2.2498, batch time: 0.14\n",
      "Epoch [2/5], Step [1392/1875], Loss: 2.2220, batch time: 0.13\n",
      "Epoch [2/5], Step [1393/1875], Loss: 2.2535, batch time: 0.10\n",
      "Epoch [2/5], Step [1394/1875], Loss: 2.3214, batch time: 0.10\n",
      "Epoch [2/5], Step [1395/1875], Loss: 2.2533, batch time: 0.14\n",
      "Epoch [2/5], Step [1396/1875], Loss: 2.2890, batch time: 0.11\n",
      "Epoch [2/5], Step [1397/1875], Loss: 2.2541, batch time: 0.10\n",
      "Epoch [2/5], Step [1398/1875], Loss: 2.2244, batch time: 0.12\n",
      "Epoch [2/5], Step [1399/1875], Loss: 2.2210, batch time: 0.13\n",
      "Epoch [2/5], Step [1400/1875], Loss: 2.2768, batch time: 0.10\n",
      "Epoch [2/5], Step [1401/1875], Loss: 2.2613, batch time: 0.10\n",
      "Epoch [2/5], Step [1402/1875], Loss: 2.3014, batch time: 0.14\n",
      "Epoch [2/5], Step [1403/1875], Loss: 2.2428, batch time: 0.14\n",
      "Epoch [2/5], Step [1404/1875], Loss: 2.2866, batch time: 0.10\n",
      "Epoch [2/5], Step [1405/1875], Loss: 2.2652, batch time: 0.13\n",
      "Epoch [2/5], Step [1406/1875], Loss: 2.3130, batch time: 0.13\n",
      "Epoch [2/5], Step [1407/1875], Loss: 2.2373, batch time: 0.10\n",
      "Epoch [2/5], Step [1408/1875], Loss: 2.2664, batch time: 0.09\n",
      "Epoch [2/5], Step [1409/1875], Loss: 2.2452, batch time: 0.25\n",
      "Epoch [2/5], Step [1410/1875], Loss: 2.2433, batch time: 0.16\n",
      "Epoch [2/5], Step [1411/1875], Loss: 2.2544, batch time: 0.14\n",
      "Epoch [2/5], Step [1412/1875], Loss: 2.1982, batch time: 0.10\n",
      "Epoch [2/5], Step [1413/1875], Loss: 2.2325, batch time: 0.10\n",
      "Epoch [2/5], Step [1414/1875], Loss: 2.2448, batch time: 0.14\n",
      "Epoch [2/5], Step [1415/1875], Loss: 2.2852, batch time: 0.10\n",
      "Epoch [2/5], Step [1416/1875], Loss: 2.2359, batch time: 0.12\n",
      "Epoch [2/5], Step [1417/1875], Loss: 2.2904, batch time: 0.11\n",
      "Epoch [2/5], Step [1418/1875], Loss: 2.3436, batch time: 0.14\n",
      "Epoch [2/5], Step [1419/1875], Loss: 2.1865, batch time: 0.14\n",
      "Epoch [2/5], Step [1420/1875], Loss: 2.3317, batch time: 0.13\n",
      "Epoch [2/5], Step [1421/1875], Loss: 2.2721, batch time: 0.10\n",
      "Epoch [2/5], Step [1422/1875], Loss: 2.2138, batch time: -4.22\n",
      "Epoch [2/5], Step [1423/1875], Loss: 2.2595, batch time: 0.13\n",
      "Epoch [2/5], Step [1424/1875], Loss: 2.2587, batch time: 0.11\n",
      "Epoch [2/5], Step [1425/1875], Loss: 2.2687, batch time: 0.10\n",
      "Epoch [2/5], Step [1426/1875], Loss: 2.2075, batch time: 0.10\n",
      "Epoch [2/5], Step [1427/1875], Loss: 2.1875, batch time: 0.13\n",
      "Epoch [2/5], Step [1428/1875], Loss: 2.2527, batch time: 0.14\n",
      "Epoch [2/5], Step [1429/1875], Loss: 2.2677, batch time: 0.13\n",
      "Epoch [2/5], Step [1430/1875], Loss: 2.2583, batch time: 0.13\n",
      "Epoch [2/5], Step [1431/1875], Loss: 2.3254, batch time: 0.10\n",
      "Epoch [2/5], Step [1432/1875], Loss: 2.2961, batch time: 0.12\n",
      "Epoch [2/5], Step [1433/1875], Loss: 2.2628, batch time: 0.13\n",
      "Epoch [2/5], Step [1434/1875], Loss: 2.2745, batch time: 0.14\n",
      "Epoch [2/5], Step [1435/1875], Loss: 2.1673, batch time: 0.10\n",
      "Epoch [2/5], Step [1436/1875], Loss: 2.2552, batch time: 0.11\n",
      "Epoch [2/5], Step [1437/1875], Loss: 2.3300, batch time: 0.14\n",
      "Epoch [2/5], Step [1438/1875], Loss: 2.2593, batch time: 0.10\n",
      "Epoch [2/5], Step [1439/1875], Loss: 2.2348, batch time: 0.10\n",
      "Epoch [2/5], Step [1440/1875], Loss: 2.2545, batch time: 0.10\n",
      "Epoch [2/5], Step [1441/1875], Loss: 2.2678, batch time: 0.10\n",
      "Epoch [2/5], Step [1442/1875], Loss: 2.2895, batch time: 0.16\n",
      "Epoch [2/5], Step [1443/1875], Loss: 2.3115, batch time: 0.15\n",
      "Epoch [2/5], Step [1444/1875], Loss: 2.3149, batch time: 0.13\n",
      "Epoch [2/5], Step [1445/1875], Loss: 2.2422, batch time: 0.10\n",
      "Epoch [2/5], Step [1446/1875], Loss: 2.3075, batch time: 0.10\n",
      "Epoch [2/5], Step [1447/1875], Loss: 2.2596, batch time: 0.11\n",
      "Epoch [2/5], Step [1448/1875], Loss: 2.2066, batch time: 0.11\n",
      "Epoch [2/5], Step [1449/1875], Loss: 2.3409, batch time: 0.10\n",
      "Epoch [2/5], Step [1450/1875], Loss: 2.2363, batch time: 0.13\n",
      "Epoch [2/5], Step [1451/1875], Loss: 2.2324, batch time: 0.20\n",
      "Epoch [2/5], Step [1452/1875], Loss: 2.2383, batch time: 0.13\n",
      "Epoch [2/5], Step [1453/1875], Loss: 2.2784, batch time: 0.11\n",
      "Epoch [2/5], Step [1454/1875], Loss: 2.2633, batch time: 0.10\n",
      "Epoch [2/5], Step [1455/1875], Loss: 2.2361, batch time: 0.10\n",
      "Epoch [2/5], Step [1456/1875], Loss: 2.2542, batch time: 0.13\n",
      "Epoch [2/5], Step [1457/1875], Loss: 2.3003, batch time: 0.11\n",
      "Epoch [2/5], Step [1458/1875], Loss: 2.2687, batch time: 0.10\n",
      "Epoch [2/5], Step [1459/1875], Loss: 2.2068, batch time: 0.12\n",
      "Epoch [2/5], Step [1460/1875], Loss: 2.2670, batch time: 0.21\n",
      "Epoch [2/5], Step [1461/1875], Loss: 2.2475, batch time: 0.11\n",
      "Epoch [2/5], Step [1462/1875], Loss: 2.3096, batch time: 0.10\n",
      "Epoch [2/5], Step [1463/1875], Loss: 2.2290, batch time: 0.11\n",
      "Epoch [2/5], Step [1464/1875], Loss: 2.3312, batch time: 0.14\n",
      "Epoch [2/5], Step [1465/1875], Loss: 2.2213, batch time: 0.10\n",
      "Epoch [2/5], Step [1466/1875], Loss: 2.2848, batch time: 0.10\n",
      "Epoch [2/5], Step [1467/1875], Loss: 2.2930, batch time: 0.10\n",
      "Epoch [2/5], Step [1468/1875], Loss: 2.2335, batch time: 0.10\n",
      "Epoch [2/5], Step [1469/1875], Loss: 2.2093, batch time: 0.10\n",
      "Epoch [2/5], Step [1470/1875], Loss: 2.2359, batch time: 0.14\n",
      "Epoch [2/5], Step [1471/1875], Loss: 2.2508, batch time: 0.12\n",
      "Epoch [2/5], Step [1472/1875], Loss: 2.2365, batch time: 0.14\n",
      "Epoch [2/5], Step [1473/1875], Loss: 2.3227, batch time: 0.10\n",
      "Epoch [2/5], Step [1474/1875], Loss: 2.2976, batch time: 0.10\n",
      "Epoch [2/5], Step [1475/1875], Loss: 2.2460, batch time: 0.14\n",
      "Epoch [2/5], Step [1476/1875], Loss: 2.3066, batch time: 0.10\n",
      "Epoch [2/5], Step [1477/1875], Loss: 2.2469, batch time: 0.11\n",
      "Epoch [2/5], Step [1478/1875], Loss: 2.2758, batch time: 0.15\n",
      "Epoch [2/5], Step [1479/1875], Loss: 2.2366, batch time: 0.11\n",
      "Epoch [2/5], Step [1480/1875], Loss: 2.3149, batch time: 0.13\n",
      "Epoch [2/5], Step [1481/1875], Loss: 2.1973, batch time: 0.10\n",
      "Epoch [2/5], Step [1482/1875], Loss: 2.2437, batch time: 0.14\n",
      "Epoch [2/5], Step [1483/1875], Loss: 2.1980, batch time: 0.10\n",
      "Epoch [2/5], Step [1484/1875], Loss: 2.1821, batch time: 0.13\n",
      "Epoch [2/5], Step [1485/1875], Loss: 2.2267, batch time: 0.10\n",
      "Epoch [2/5], Step [1486/1875], Loss: 2.2144, batch time: 0.10\n",
      "Epoch [2/5], Step [1487/1875], Loss: 2.2430, batch time: 0.13\n",
      "Epoch [2/5], Step [1488/1875], Loss: 2.2771, batch time: 0.14\n",
      "Epoch [2/5], Step [1489/1875], Loss: 2.1669, batch time: 0.11\n",
      "Epoch [2/5], Step [1490/1875], Loss: 2.3161, batch time: 0.14\n",
      "Epoch [2/5], Step [1491/1875], Loss: 2.2266, batch time: 0.10\n",
      "Epoch [2/5], Step [1492/1875], Loss: 2.2050, batch time: 0.10\n",
      "Epoch [2/5], Step [1493/1875], Loss: 2.3547, batch time: 0.12\n",
      "Epoch [2/5], Step [1494/1875], Loss: 2.2793, batch time: 0.11\n",
      "Epoch [2/5], Step [1495/1875], Loss: 2.2877, batch time: 0.10\n",
      "Epoch [2/5], Step [1496/1875], Loss: 2.2428, batch time: 0.12\n",
      "Epoch [2/5], Step [1497/1875], Loss: 2.2486, batch time: 0.14\n",
      "Epoch [2/5], Step [1498/1875], Loss: 2.2328, batch time: 0.10\n",
      "Epoch [2/5], Step [1499/1875], Loss: 2.2412, batch time: 0.12\n",
      "Epoch [2/5], Step [1500/1875], Loss: 2.2253, batch time: 0.10\n",
      "Epoch [2/5], Step [1501/1875], Loss: 2.3169, batch time: 0.10\n",
      "Epoch [2/5], Step [1502/1875], Loss: 2.2766, batch time: 0.10\n",
      "Epoch [2/5], Step [1503/1875], Loss: 2.3451, batch time: 0.10\n",
      "Epoch [2/5], Step [1504/1875], Loss: 2.1919, batch time: 0.10\n",
      "Epoch [2/5], Step [1505/1875], Loss: 2.2848, batch time: 0.14\n",
      "Epoch [2/5], Step [1506/1875], Loss: 2.2638, batch time: 0.14\n",
      "Epoch [2/5], Step [1507/1875], Loss: 2.1514, batch time: 0.10\n",
      "Epoch [2/5], Step [1508/1875], Loss: 2.2899, batch time: 0.10\n",
      "Epoch [2/5], Step [1509/1875], Loss: 2.3077, batch time: 0.19\n",
      "Epoch [2/5], Step [1510/1875], Loss: 2.2707, batch time: 0.10\n",
      "Epoch [2/5], Step [1511/1875], Loss: 2.2584, batch time: 0.10\n",
      "Epoch [2/5], Step [1512/1875], Loss: 2.1519, batch time: 0.10\n",
      "Epoch [2/5], Step [1513/1875], Loss: 2.3156, batch time: 0.25\n",
      "Epoch [2/5], Step [1514/1875], Loss: 2.2630, batch time: 0.10\n",
      "Epoch [2/5], Step [1515/1875], Loss: 2.2033, batch time: 0.10\n",
      "Epoch [2/5], Step [1516/1875], Loss: 2.2707, batch time: 0.13\n",
      "Epoch [2/5], Step [1517/1875], Loss: 2.3202, batch time: 0.21\n",
      "Epoch [2/5], Step [1518/1875], Loss: 2.3060, batch time: 0.10\n",
      "Epoch [2/5], Step [1519/1875], Loss: 2.2205, batch time: 0.14\n",
      "Epoch [2/5], Step [1520/1875], Loss: 2.2340, batch time: 0.10\n",
      "Epoch [2/5], Step [1521/1875], Loss: 2.1936, batch time: 0.14\n",
      "Epoch [2/5], Step [1522/1875], Loss: 2.2332, batch time: 0.14\n",
      "Epoch [2/5], Step [1523/1875], Loss: 2.2061, batch time: 0.10\n",
      "Epoch [2/5], Step [1524/1875], Loss: 2.2606, batch time: 0.13\n",
      "Epoch [2/5], Step [1525/1875], Loss: 2.2924, batch time: 0.10\n",
      "Epoch [2/5], Step [1526/1875], Loss: 2.3039, batch time: 0.15\n",
      "Epoch [2/5], Step [1527/1875], Loss: 2.2681, batch time: 0.11\n",
      "Epoch [2/5], Step [1528/1875], Loss: 2.2831, batch time: 0.12\n",
      "Epoch [2/5], Step [1529/1875], Loss: 2.2256, batch time: 0.11\n",
      "Epoch [2/5], Step [1530/1875], Loss: 2.3015, batch time: 0.17\n",
      "Epoch [2/5], Step [1531/1875], Loss: 2.2556, batch time: 0.16\n",
      "Epoch [2/5], Step [1532/1875], Loss: 2.2641, batch time: 0.14\n",
      "Epoch [2/5], Step [1533/1875], Loss: 2.2819, batch time: 0.15\n",
      "Epoch [2/5], Step [1534/1875], Loss: 2.2374, batch time: 0.13\n",
      "Epoch [2/5], Step [1535/1875], Loss: 2.2753, batch time: 0.13\n",
      "Epoch [2/5], Step [1536/1875], Loss: 2.2647, batch time: 0.17\n",
      "Epoch [2/5], Step [1537/1875], Loss: 2.2533, batch time: 0.14\n",
      "Epoch [2/5], Step [1538/1875], Loss: 2.2505, batch time: 0.12\n",
      "Epoch [2/5], Step [1539/1875], Loss: 2.3356, batch time: 0.10\n",
      "Epoch [2/5], Step [1540/1875], Loss: 2.2322, batch time: 0.13\n",
      "Epoch [2/5], Step [1541/1875], Loss: 2.2404, batch time: 0.10\n",
      "Epoch [2/5], Step [1542/1875], Loss: 2.1923, batch time: 0.12\n",
      "Epoch [2/5], Step [1543/1875], Loss: 2.2163, batch time: 0.10\n",
      "Epoch [2/5], Step [1544/1875], Loss: 2.2672, batch time: 0.14\n",
      "Epoch [2/5], Step [1545/1875], Loss: 2.2440, batch time: 0.10\n",
      "Epoch [2/5], Step [1546/1875], Loss: 2.3240, batch time: 0.13\n",
      "Epoch [2/5], Step [1547/1875], Loss: 2.2523, batch time: 0.12\n",
      "Epoch [2/5], Step [1548/1875], Loss: 2.2827, batch time: 0.11\n",
      "Epoch [2/5], Step [1549/1875], Loss: 2.2549, batch time: 0.10\n",
      "Epoch [2/5], Step [1550/1875], Loss: 2.0958, batch time: 0.11\n",
      "Epoch [2/5], Step [1551/1875], Loss: 2.1947, batch time: 0.13\n",
      "Epoch [2/5], Step [1552/1875], Loss: 2.2594, batch time: 0.10\n",
      "Epoch [2/5], Step [1553/1875], Loss: 2.3094, batch time: 0.10\n",
      "Epoch [2/5], Step [1554/1875], Loss: 2.2308, batch time: 0.12\n",
      "Epoch [2/5], Step [1555/1875], Loss: 2.2823, batch time: 0.13\n",
      "Epoch [2/5], Step [1556/1875], Loss: 2.2860, batch time: 0.12\n",
      "Epoch [2/5], Step [1557/1875], Loss: 2.1739, batch time: 0.11\n",
      "Epoch [2/5], Step [1558/1875], Loss: 2.2561, batch time: 0.12\n",
      "Epoch [2/5], Step [1559/1875], Loss: 2.2622, batch time: 0.14\n",
      "Epoch [2/5], Step [1560/1875], Loss: 2.2131, batch time: 0.10\n",
      "Epoch [2/5], Step [1561/1875], Loss: 2.2780, batch time: 0.10\n",
      "Epoch [2/5], Step [1562/1875], Loss: 2.2278, batch time: 0.13\n",
      "Epoch [2/5], Step [1563/1875], Loss: 2.2322, batch time: 0.13\n",
      "Epoch [2/5], Step [1564/1875], Loss: 2.2939, batch time: 0.10\n",
      "Epoch [2/5], Step [1565/1875], Loss: 2.2753, batch time: 0.10\n",
      "Epoch [2/5], Step [1566/1875], Loss: 2.2761, batch time: 0.11\n",
      "Epoch [2/5], Step [1567/1875], Loss: 2.1806, batch time: 0.10\n",
      "Epoch [2/5], Step [1568/1875], Loss: 2.2181, batch time: 0.10\n",
      "Epoch [2/5], Step [1569/1875], Loss: 2.2205, batch time: 0.15\n",
      "Epoch [2/5], Step [1570/1875], Loss: 2.3157, batch time: 0.10\n",
      "Epoch [2/5], Step [1571/1875], Loss: 2.2678, batch time: 0.10\n",
      "Epoch [2/5], Step [1572/1875], Loss: 2.2960, batch time: 0.15\n",
      "Epoch [2/5], Step [1573/1875], Loss: 2.2116, batch time: 0.13\n",
      "Epoch [2/5], Step [1574/1875], Loss: 2.2452, batch time: 0.10\n",
      "Epoch [2/5], Step [1575/1875], Loss: 2.3455, batch time: 0.10\n",
      "Epoch [2/5], Step [1576/1875], Loss: 2.1942, batch time: 0.13\n",
      "Epoch [2/5], Step [1577/1875], Loss: 2.2147, batch time: 0.13\n",
      "Epoch [2/5], Step [1578/1875], Loss: 2.2224, batch time: 0.10\n",
      "Epoch [2/5], Step [1579/1875], Loss: 2.1958, batch time: 0.10\n",
      "Epoch [2/5], Step [1580/1875], Loss: 2.2000, batch time: 0.10\n",
      "Epoch [2/5], Step [1581/1875], Loss: 2.1757, batch time: 0.10\n",
      "Epoch [2/5], Step [1582/1875], Loss: 2.1128, batch time: 0.11\n",
      "Epoch [2/5], Step [1583/1875], Loss: 2.3151, batch time: 0.10\n",
      "Epoch [2/5], Step [1584/1875], Loss: 2.2643, batch time: 0.10\n",
      "Epoch [2/5], Step [1585/1875], Loss: 2.2897, batch time: 0.10\n",
      "Epoch [2/5], Step [1586/1875], Loss: 2.1737, batch time: 0.14\n",
      "Epoch [2/5], Step [1587/1875], Loss: 2.2231, batch time: 0.10\n",
      "Epoch [2/5], Step [1588/1875], Loss: 2.1944, batch time: 0.10\n",
      "Epoch [2/5], Step [1589/1875], Loss: 2.2052, batch time: 0.12\n",
      "Epoch [2/5], Step [1590/1875], Loss: 2.2316, batch time: 0.10\n",
      "Epoch [2/5], Step [1591/1875], Loss: 2.1338, batch time: 0.10\n",
      "Epoch [2/5], Step [1592/1875], Loss: 2.2957, batch time: 0.10\n",
      "Epoch [2/5], Step [1593/1875], Loss: 2.2264, batch time: 0.10\n",
      "Epoch [2/5], Step [1594/1875], Loss: 2.2051, batch time: 0.14\n",
      "Epoch [2/5], Step [1595/1875], Loss: 2.2745, batch time: 0.16\n",
      "Epoch [2/5], Step [1596/1875], Loss: 2.1534, batch time: 0.13\n",
      "Epoch [2/5], Step [1597/1875], Loss: 2.2469, batch time: 0.10\n",
      "Epoch [2/5], Step [1598/1875], Loss: 2.2701, batch time: 0.10\n",
      "Epoch [2/5], Step [1599/1875], Loss: 2.2373, batch time: 0.14\n",
      "Epoch [2/5], Step [1600/1875], Loss: 2.2734, batch time: 0.12\n",
      "Epoch [2/5], Step [1601/1875], Loss: 2.3383, batch time: 0.10\n",
      "Epoch [2/5], Step [1602/1875], Loss: 2.1730, batch time: 0.10\n",
      "Epoch [2/5], Step [1603/1875], Loss: 2.2409, batch time: 0.17\n",
      "Epoch [2/5], Step [1604/1875], Loss: 2.2388, batch time: 0.10\n",
      "Epoch [2/5], Step [1605/1875], Loss: 2.2787, batch time: 0.10\n",
      "Epoch [2/5], Step [1606/1875], Loss: 2.2854, batch time: 0.26\n",
      "Epoch [2/5], Step [1607/1875], Loss: 2.2302, batch time: 0.10\n",
      "Epoch [2/5], Step [1608/1875], Loss: 2.3118, batch time: 0.10\n",
      "Epoch [2/5], Step [1609/1875], Loss: 2.2359, batch time: 0.11\n",
      "Epoch [2/5], Step [1610/1875], Loss: 2.2745, batch time: 0.13\n",
      "Epoch [2/5], Step [1611/1875], Loss: 2.2343, batch time: 0.15\n",
      "Epoch [2/5], Step [1612/1875], Loss: 2.2611, batch time: 0.11\n",
      "Epoch [2/5], Step [1613/1875], Loss: 2.2576, batch time: 0.14\n",
      "Epoch [2/5], Step [1614/1875], Loss: 2.1836, batch time: 0.10\n",
      "Epoch [2/5], Step [1615/1875], Loss: 2.1381, batch time: 0.10\n",
      "Epoch [2/5], Step [1616/1875], Loss: 2.2717, batch time: 0.11\n",
      "Epoch [2/5], Step [1617/1875], Loss: 2.2334, batch time: 0.11\n",
      "Epoch [2/5], Step [1618/1875], Loss: 2.2669, batch time: 0.10\n",
      "Epoch [2/5], Step [1619/1875], Loss: 2.1550, batch time: 0.13\n",
      "Epoch [2/5], Step [1620/1875], Loss: 2.2401, batch time: 0.14\n",
      "Epoch [2/5], Step [1621/1875], Loss: 2.2635, batch time: 0.10\n",
      "Epoch [2/5], Step [1622/1875], Loss: 2.2514, batch time: 0.13\n",
      "Epoch [2/5], Step [1623/1875], Loss: 2.2590, batch time: 0.12\n",
      "Epoch [2/5], Step [1624/1875], Loss: 2.2111, batch time: 0.11\n",
      "Epoch [2/5], Step [1625/1875], Loss: 2.2878, batch time: 0.10\n",
      "Epoch [2/5], Step [1626/1875], Loss: 2.2237, batch time: 0.12\n",
      "Epoch [2/5], Step [1627/1875], Loss: 2.3440, batch time: 0.11\n",
      "Epoch [2/5], Step [1628/1875], Loss: 2.2644, batch time: 0.11\n",
      "Epoch [2/5], Step [1629/1875], Loss: 2.1506, batch time: 0.11\n",
      "Epoch [2/5], Step [1630/1875], Loss: 2.2487, batch time: 0.10\n",
      "Epoch [2/5], Step [1631/1875], Loss: 2.2749, batch time: 0.10\n",
      "Epoch [2/5], Step [1632/1875], Loss: 2.2661, batch time: 0.10\n",
      "Epoch [2/5], Step [1633/1875], Loss: 2.2043, batch time: 0.10\n",
      "Epoch [2/5], Step [1634/1875], Loss: 2.1708, batch time: 0.10\n",
      "Epoch [2/5], Step [1635/1875], Loss: 2.2714, batch time: 0.10\n",
      "Epoch [2/5], Step [1636/1875], Loss: 2.3068, batch time: 0.15\n",
      "Epoch [2/5], Step [1637/1875], Loss: 2.2376, batch time: 0.11\n",
      "Epoch [2/5], Step [1638/1875], Loss: 2.2713, batch time: 0.11\n",
      "Epoch [2/5], Step [1639/1875], Loss: 2.1757, batch time: 0.10\n",
      "Epoch [2/5], Step [1640/1875], Loss: 2.2170, batch time: 0.12\n",
      "Epoch [2/5], Step [1641/1875], Loss: 2.1759, batch time: 0.10\n",
      "Epoch [2/5], Step [1642/1875], Loss: 2.2975, batch time: 0.24\n",
      "Epoch [2/5], Step [1643/1875], Loss: 2.2396, batch time: 0.12\n",
      "Epoch [2/5], Step [1644/1875], Loss: 2.2352, batch time: 0.10\n",
      "Epoch [2/5], Step [1645/1875], Loss: 2.1836, batch time: 0.10\n",
      "Epoch [2/5], Step [1646/1875], Loss: 2.2930, batch time: 0.10\n",
      "Epoch [2/5], Step [1647/1875], Loss: 2.2046, batch time: 0.10\n",
      "Epoch [2/5], Step [1648/1875], Loss: 2.2675, batch time: 0.14\n",
      "Epoch [2/5], Step [1649/1875], Loss: 2.2486, batch time: 0.10\n",
      "Epoch [2/5], Step [1650/1875], Loss: 2.3915, batch time: 0.12\n",
      "Epoch [2/5], Step [1651/1875], Loss: 2.2214, batch time: 0.13\n",
      "Epoch [2/5], Step [1652/1875], Loss: 2.3082, batch time: 0.10\n",
      "Epoch [2/5], Step [1653/1875], Loss: 2.4138, batch time: 0.10\n",
      "Epoch [2/5], Step [1654/1875], Loss: 2.1712, batch time: 0.10\n",
      "Epoch [2/5], Step [1655/1875], Loss: 2.1733, batch time: 0.10\n",
      "Epoch [2/5], Step [1656/1875], Loss: 2.1071, batch time: 0.11\n",
      "Epoch [2/5], Step [1657/1875], Loss: 2.2094, batch time: 0.10\n",
      "Epoch [2/5], Step [1658/1875], Loss: 2.1779, batch time: 0.09\n",
      "Epoch [2/5], Step [1659/1875], Loss: 2.2867, batch time: 0.10\n",
      "Epoch [2/5], Step [1660/1875], Loss: 2.2718, batch time: 0.10\n",
      "Epoch [2/5], Step [1661/1875], Loss: 2.2160, batch time: 0.10\n",
      "Epoch [2/5], Step [1662/1875], Loss: 2.2534, batch time: 0.10\n",
      "Epoch [2/5], Step [1663/1875], Loss: 2.2566, batch time: 0.16\n",
      "Epoch [2/5], Step [1664/1875], Loss: 2.2889, batch time: 0.10\n",
      "Epoch [2/5], Step [1665/1875], Loss: 2.2151, batch time: 0.10\n",
      "Epoch [2/5], Step [1666/1875], Loss: 2.2491, batch time: 0.11\n",
      "Epoch [2/5], Step [1667/1875], Loss: 2.2484, batch time: 0.13\n",
      "Epoch [2/5], Step [1668/1875], Loss: 2.1816, batch time: 0.13\n",
      "Epoch [2/5], Step [1669/1875], Loss: 2.2887, batch time: 0.13\n",
      "Epoch [2/5], Step [1670/1875], Loss: 2.2958, batch time: 0.10\n",
      "Epoch [2/5], Step [1671/1875], Loss: 2.1968, batch time: 0.10\n",
      "Epoch [2/5], Step [1672/1875], Loss: 2.2452, batch time: 0.10\n",
      "Epoch [2/5], Step [1673/1875], Loss: 2.2533, batch time: 0.11\n",
      "Epoch [2/5], Step [1674/1875], Loss: 2.2131, batch time: 0.12\n",
      "Epoch [2/5], Step [1675/1875], Loss: 2.2348, batch time: 0.13\n",
      "Epoch [2/5], Step [1676/1875], Loss: 2.2811, batch time: 0.12\n",
      "Epoch [2/5], Step [1677/1875], Loss: 2.2224, batch time: 0.23\n",
      "Epoch [2/5], Step [1678/1875], Loss: 2.2615, batch time: 0.10\n",
      "Epoch [2/5], Step [1679/1875], Loss: 2.2906, batch time: 0.10\n",
      "Epoch [2/5], Step [1680/1875], Loss: 2.2077, batch time: 0.12\n",
      "Epoch [2/5], Step [1681/1875], Loss: 2.1390, batch time: 0.10\n",
      "Epoch [2/5], Step [1682/1875], Loss: 2.2827, batch time: 0.11\n",
      "Epoch [2/5], Step [1683/1875], Loss: 2.2177, batch time: 0.13\n",
      "Epoch [2/5], Step [1684/1875], Loss: 2.3180, batch time: 0.10\n",
      "Epoch [2/5], Step [1685/1875], Loss: 2.3333, batch time: 0.10\n",
      "Epoch [2/5], Step [1686/1875], Loss: 2.2626, batch time: 0.10\n",
      "Epoch [2/5], Step [1687/1875], Loss: 2.2036, batch time: 0.10\n",
      "Epoch [2/5], Step [1688/1875], Loss: 2.2800, batch time: 0.15\n",
      "Epoch [2/5], Step [1689/1875], Loss: 2.2726, batch time: 0.10\n",
      "Epoch [2/5], Step [1690/1875], Loss: 2.2963, batch time: 0.10\n",
      "Epoch [2/5], Step [1691/1875], Loss: 2.3050, batch time: 0.10\n",
      "Epoch [2/5], Step [1692/1875], Loss: 2.1569, batch time: -2.75\n",
      "Epoch [2/5], Step [1693/1875], Loss: 2.2316, batch time: 0.10\n",
      "Epoch [2/5], Step [1694/1875], Loss: 2.3088, batch time: 0.12\n",
      "Epoch [2/5], Step [1695/1875], Loss: 2.2438, batch time: 0.13\n",
      "Epoch [2/5], Step [1696/1875], Loss: 2.1750, batch time: 0.10\n",
      "Epoch [2/5], Step [1697/1875], Loss: 2.2738, batch time: 0.10\n",
      "Epoch [2/5], Step [1698/1875], Loss: 2.3137, batch time: 0.11\n",
      "Epoch [2/5], Step [1699/1875], Loss: 2.2217, batch time: 0.15\n",
      "Epoch [2/5], Step [1700/1875], Loss: 2.2212, batch time: 0.13\n",
      "Epoch [2/5], Step [1701/1875], Loss: 2.1912, batch time: 0.13\n",
      "Epoch [2/5], Step [1702/1875], Loss: 2.2716, batch time: 0.13\n",
      "Epoch [2/5], Step [1703/1875], Loss: 2.1473, batch time: 0.10\n",
      "Epoch [2/5], Step [1704/1875], Loss: 2.3517, batch time: 0.11\n",
      "Epoch [2/5], Step [1705/1875], Loss: 2.1262, batch time: 0.12\n",
      "Epoch [2/5], Step [1706/1875], Loss: 2.2983, batch time: 0.13\n",
      "Epoch [2/5], Step [1707/1875], Loss: 2.2052, batch time: 0.10\n",
      "Epoch [2/5], Step [1708/1875], Loss: 2.3143, batch time: 0.13\n",
      "Epoch [2/5], Step [1709/1875], Loss: 2.2539, batch time: 0.19\n",
      "Epoch [2/5], Step [1710/1875], Loss: 2.2076, batch time: 0.10\n",
      "Epoch [2/5], Step [1711/1875], Loss: 2.2405, batch time: 0.10\n",
      "Epoch [2/5], Step [1712/1875], Loss: 2.2442, batch time: 0.13\n",
      "Epoch [2/5], Step [1713/1875], Loss: 2.2687, batch time: 0.10\n",
      "Epoch [2/5], Step [1714/1875], Loss: 2.2299, batch time: 0.13\n",
      "Epoch [2/5], Step [1715/1875], Loss: 2.2091, batch time: 0.13\n",
      "Epoch [2/5], Step [1716/1875], Loss: 2.2883, batch time: 0.14\n",
      "Epoch [2/5], Step [1717/1875], Loss: 2.2904, batch time: 0.13\n",
      "Epoch [2/5], Step [1718/1875], Loss: 2.2084, batch time: 0.10\n",
      "Epoch [2/5], Step [1719/1875], Loss: 2.2492, batch time: 0.11\n",
      "Epoch [2/5], Step [1720/1875], Loss: 2.1902, batch time: 0.13\n",
      "Epoch [2/5], Step [1721/1875], Loss: 2.2898, batch time: 0.18\n",
      "Epoch [2/5], Step [1722/1875], Loss: 2.1964, batch time: 0.10\n",
      "Epoch [2/5], Step [1723/1875], Loss: 2.1754, batch time: 0.10\n",
      "Epoch [2/5], Step [1724/1875], Loss: 2.3443, batch time: 0.10\n",
      "Epoch [2/5], Step [1725/1875], Loss: 2.1876, batch time: 0.19\n",
      "Epoch [2/5], Step [1726/1875], Loss: 2.2730, batch time: 0.10\n",
      "Epoch [2/5], Step [1727/1875], Loss: 2.1761, batch time: 0.10\n",
      "Epoch [2/5], Step [1728/1875], Loss: 2.2335, batch time: 0.10\n",
      "Epoch [2/5], Step [1729/1875], Loss: 2.2694, batch time: 0.12\n",
      "Epoch [2/5], Step [1730/1875], Loss: 2.2302, batch time: 0.16\n",
      "Epoch [2/5], Step [1731/1875], Loss: 2.2597, batch time: 0.13\n",
      "Epoch [2/5], Step [1732/1875], Loss: 2.2345, batch time: 0.12\n",
      "Epoch [2/5], Step [1733/1875], Loss: 2.2673, batch time: 0.15\n",
      "Epoch [2/5], Step [1734/1875], Loss: 2.2071, batch time: 0.10\n",
      "Epoch [2/5], Step [1735/1875], Loss: 2.2662, batch time: 0.10\n",
      "Epoch [2/5], Step [1736/1875], Loss: 2.2381, batch time: 0.10\n",
      "Epoch [2/5], Step [1737/1875], Loss: 2.2461, batch time: 0.11\n",
      "Epoch [2/5], Step [1738/1875], Loss: 2.2950, batch time: 0.10\n",
      "Epoch [2/5], Step [1739/1875], Loss: 2.1414, batch time: 0.10\n",
      "Epoch [2/5], Step [1740/1875], Loss: 2.2264, batch time: 0.12\n",
      "Epoch [2/5], Step [1741/1875], Loss: 2.3577, batch time: 0.13\n",
      "Epoch [2/5], Step [1742/1875], Loss: 2.2533, batch time: 0.12\n",
      "Epoch [2/5], Step [1743/1875], Loss: 2.2008, batch time: 0.11\n",
      "Epoch [2/5], Step [1744/1875], Loss: 2.2769, batch time: 0.12\n",
      "Epoch [2/5], Step [1745/1875], Loss: 2.2465, batch time: 0.13\n",
      "Epoch [2/5], Step [1746/1875], Loss: 2.2242, batch time: 0.11\n",
      "Epoch [2/5], Step [1747/1875], Loss: 2.2673, batch time: 0.10\n",
      "Epoch [2/5], Step [1748/1875], Loss: 2.2872, batch time: 0.11\n",
      "Epoch [2/5], Step [1749/1875], Loss: 2.1538, batch time: 0.13\n",
      "Epoch [2/5], Step [1750/1875], Loss: 2.1667, batch time: 0.11\n",
      "Epoch [2/5], Step [1751/1875], Loss: 2.2845, batch time: 0.13\n",
      "Epoch [2/5], Step [1752/1875], Loss: 2.2482, batch time: 0.11\n",
      "Epoch [2/5], Step [1753/1875], Loss: 2.2105, batch time: 0.15\n",
      "Epoch [2/5], Step [1754/1875], Loss: 2.2400, batch time: 0.12\n",
      "Epoch [2/5], Step [1755/1875], Loss: 2.2266, batch time: 0.10\n",
      "Epoch [2/5], Step [1756/1875], Loss: 2.1517, batch time: 0.10\n",
      "Epoch [2/5], Step [1757/1875], Loss: 2.3346, batch time: 0.15\n",
      "Epoch [2/5], Step [1758/1875], Loss: 2.2829, batch time: 0.10\n",
      "Epoch [2/5], Step [1759/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [2/5], Step [1760/1875], Loss: 2.2284, batch time: 0.13\n",
      "Epoch [2/5], Step [1761/1875], Loss: 2.3092, batch time: 0.13\n",
      "Epoch [2/5], Step [1762/1875], Loss: 2.2650, batch time: 0.10\n",
      "Epoch [2/5], Step [1763/1875], Loss: 2.2530, batch time: 0.16\n",
      "Epoch [2/5], Step [1764/1875], Loss: 2.2494, batch time: 0.10\n",
      "Epoch [2/5], Step [1765/1875], Loss: 2.2860, batch time: 0.10\n",
      "Epoch [2/5], Step [1766/1875], Loss: 2.1808, batch time: 0.11\n",
      "Epoch [2/5], Step [1767/1875], Loss: 2.1952, batch time: 0.14\n",
      "Epoch [2/5], Step [1768/1875], Loss: 2.2797, batch time: 0.13\n",
      "Epoch [2/5], Step [1769/1875], Loss: 2.1883, batch time: 0.17\n",
      "Epoch [2/5], Step [1770/1875], Loss: 2.2131, batch time: 0.15\n",
      "Epoch [2/5], Step [1771/1875], Loss: 2.2517, batch time: 0.10\n",
      "Epoch [2/5], Step [1772/1875], Loss: 2.2099, batch time: 0.12\n",
      "Epoch [2/5], Step [1773/1875], Loss: 2.2083, batch time: 0.10\n",
      "Epoch [2/5], Step [1774/1875], Loss: 2.1973, batch time: 0.10\n",
      "Epoch [2/5], Step [1775/1875], Loss: 2.2808, batch time: 0.10\n",
      "Epoch [2/5], Step [1776/1875], Loss: 2.2312, batch time: 0.13\n",
      "Epoch [2/5], Step [1777/1875], Loss: 2.1770, batch time: 0.10\n",
      "Epoch [2/5], Step [1778/1875], Loss: 2.1716, batch time: 0.10\n",
      "Epoch [2/5], Step [1779/1875], Loss: 2.3397, batch time: 0.20\n",
      "Epoch [2/5], Step [1780/1875], Loss: 2.2350, batch time: 0.11\n",
      "Epoch [2/5], Step [1781/1875], Loss: 2.2778, batch time: 0.10\n",
      "Epoch [2/5], Step [1782/1875], Loss: 2.2210, batch time: 0.10\n",
      "Epoch [2/5], Step [1783/1875], Loss: 2.3188, batch time: 0.10\n",
      "Epoch [2/5], Step [1784/1875], Loss: 2.2340, batch time: 0.10\n",
      "Epoch [2/5], Step [1785/1875], Loss: 2.2887, batch time: 0.13\n",
      "Epoch [2/5], Step [1786/1875], Loss: 2.3139, batch time: 0.10\n",
      "Epoch [2/5], Step [1787/1875], Loss: 2.2231, batch time: 0.10\n",
      "Epoch [2/5], Step [1788/1875], Loss: 2.3217, batch time: 0.11\n",
      "Epoch [2/5], Step [1789/1875], Loss: 2.2602, batch time: 0.10\n",
      "Epoch [2/5], Step [1790/1875], Loss: 2.2601, batch time: 0.14\n",
      "Epoch [2/5], Step [1791/1875], Loss: 2.3269, batch time: 0.09\n",
      "Epoch [2/5], Step [1792/1875], Loss: 2.2105, batch time: 0.12\n",
      "Epoch [2/5], Step [1793/1875], Loss: 2.1986, batch time: 0.10\n",
      "Epoch [2/5], Step [1794/1875], Loss: 2.1093, batch time: 0.10\n",
      "Epoch [2/5], Step [1795/1875], Loss: 2.3338, batch time: 0.12\n",
      "Epoch [2/5], Step [1796/1875], Loss: 2.2342, batch time: 0.21\n",
      "Epoch [2/5], Step [1797/1875], Loss: 2.3156, batch time: 0.10\n",
      "Epoch [2/5], Step [1798/1875], Loss: 2.2370, batch time: 0.13\n",
      "Epoch [2/5], Step [1799/1875], Loss: 2.1271, batch time: 0.10\n",
      "Epoch [2/5], Step [1800/1875], Loss: 2.2398, batch time: 0.12\n",
      "Epoch [2/5], Step [1801/1875], Loss: 2.1234, batch time: 0.10\n",
      "Epoch [2/5], Step [1802/1875], Loss: 2.2627, batch time: 0.20\n",
      "Epoch [2/5], Step [1803/1875], Loss: 2.2865, batch time: 0.10\n",
      "Epoch [2/5], Step [1804/1875], Loss: 2.3522, batch time: 0.10\n",
      "Epoch [2/5], Step [1805/1875], Loss: 2.2971, batch time: 0.10\n",
      "Epoch [2/5], Step [1806/1875], Loss: 2.2136, batch time: 0.09\n",
      "Epoch [2/5], Step [1807/1875], Loss: 2.2236, batch time: 0.10\n",
      "Epoch [2/5], Step [1808/1875], Loss: 2.2858, batch time: 0.10\n",
      "Epoch [2/5], Step [1809/1875], Loss: 2.2486, batch time: 0.10\n",
      "Epoch [2/5], Step [1810/1875], Loss: 2.1933, batch time: 0.11\n",
      "Epoch [2/5], Step [1811/1875], Loss: 2.2533, batch time: 0.11\n",
      "Epoch [2/5], Step [1812/1875], Loss: 2.2583, batch time: 0.11\n",
      "Epoch [2/5], Step [1813/1875], Loss: 2.2733, batch time: 0.10\n",
      "Epoch [2/5], Step [1814/1875], Loss: 2.2766, batch time: 0.18\n",
      "Epoch [2/5], Step [1815/1875], Loss: 2.1153, batch time: 0.14\n",
      "Epoch [2/5], Step [1816/1875], Loss: 2.1102, batch time: 0.15\n",
      "Epoch [2/5], Step [1817/1875], Loss: 2.1929, batch time: 0.10\n",
      "Epoch [2/5], Step [1818/1875], Loss: 2.2375, batch time: 0.10\n",
      "Epoch [2/5], Step [1819/1875], Loss: 2.1933, batch time: 0.10\n",
      "Epoch [2/5], Step [1820/1875], Loss: 2.1884, batch time: 0.13\n",
      "Epoch [2/5], Step [1821/1875], Loss: 2.2308, batch time: 0.10\n",
      "Epoch [2/5], Step [1822/1875], Loss: 2.1745, batch time: 0.10\n",
      "Epoch [2/5], Step [1823/1875], Loss: 2.2451, batch time: 0.09\n",
      "Epoch [2/5], Step [1824/1875], Loss: 2.2643, batch time: 0.10\n",
      "Epoch [2/5], Step [1825/1875], Loss: 2.2722, batch time: 0.10\n",
      "Epoch [2/5], Step [1826/1875], Loss: 2.3049, batch time: 0.17\n",
      "Epoch [2/5], Step [1827/1875], Loss: 2.1790, batch time: 0.10\n",
      "Epoch [2/5], Step [1828/1875], Loss: 2.3400, batch time: 0.12\n",
      "Epoch [2/5], Step [1829/1875], Loss: 2.3011, batch time: 0.10\n",
      "Epoch [2/5], Step [1830/1875], Loss: 2.3058, batch time: 0.16\n",
      "Epoch [2/5], Step [1831/1875], Loss: 2.2553, batch time: 0.10\n",
      "Epoch [2/5], Step [1832/1875], Loss: 2.2226, batch time: 0.10\n",
      "Epoch [2/5], Step [1833/1875], Loss: 2.1979, batch time: 0.10\n",
      "Epoch [2/5], Step [1834/1875], Loss: 2.3040, batch time: 0.12\n",
      "Epoch [2/5], Step [1835/1875], Loss: 2.1730, batch time: 0.10\n",
      "Epoch [2/5], Step [1836/1875], Loss: 2.1968, batch time: 0.10\n",
      "Epoch [2/5], Step [1837/1875], Loss: 2.2819, batch time: 0.10\n",
      "Epoch [2/5], Step [1838/1875], Loss: 2.2372, batch time: 0.10\n",
      "Epoch [2/5], Step [1839/1875], Loss: 2.1993, batch time: 0.10\n",
      "Epoch [2/5], Step [1840/1875], Loss: 2.3399, batch time: 0.10\n",
      "Epoch [2/5], Step [1841/1875], Loss: 2.2170, batch time: 0.10\n",
      "Epoch [2/5], Step [1842/1875], Loss: 2.1679, batch time: 0.12\n",
      "Epoch [2/5], Step [1843/1875], Loss: 2.2284, batch time: 0.10\n",
      "Epoch [2/5], Step [1844/1875], Loss: 2.2335, batch time: 0.11\n",
      "Epoch [2/5], Step [1845/1875], Loss: 2.2427, batch time: 0.15\n",
      "Epoch [2/5], Step [1846/1875], Loss: 2.2906, batch time: 0.10\n",
      "Epoch [2/5], Step [1847/1875], Loss: 2.2513, batch time: 0.10\n",
      "Epoch [2/5], Step [1848/1875], Loss: 2.2340, batch time: 0.10\n",
      "Epoch [2/5], Step [1849/1875], Loss: 2.2462, batch time: 0.10\n",
      "Epoch [2/5], Step [1850/1875], Loss: 2.2676, batch time: 0.10\n",
      "Epoch [2/5], Step [1851/1875], Loss: 2.2294, batch time: 0.10\n",
      "Epoch [2/5], Step [1852/1875], Loss: 2.1864, batch time: 0.10\n",
      "Epoch [2/5], Step [1853/1875], Loss: 2.2084, batch time: 0.16\n",
      "Epoch [2/5], Step [1854/1875], Loss: 2.1488, batch time: 0.10\n",
      "Epoch [2/5], Step [1855/1875], Loss: 2.2717, batch time: 0.17\n",
      "Epoch [2/5], Step [1856/1875], Loss: 2.1819, batch time: 0.15\n",
      "Epoch [2/5], Step [1857/1875], Loss: 2.1881, batch time: 0.11\n",
      "Epoch [2/5], Step [1858/1875], Loss: 2.2113, batch time: 0.10\n",
      "Epoch [2/5], Step [1859/1875], Loss: 2.3623, batch time: 0.10\n",
      "Epoch [2/5], Step [1860/1875], Loss: 2.2527, batch time: 0.09\n",
      "Epoch [2/5], Step [1861/1875], Loss: 2.2369, batch time: 0.11\n",
      "Epoch [2/5], Step [1862/1875], Loss: 2.1931, batch time: 0.10\n",
      "Epoch [2/5], Step [1863/1875], Loss: 2.1442, batch time: 0.09\n",
      "Epoch [2/5], Step [1864/1875], Loss: 2.2670, batch time: 0.10\n",
      "Epoch [2/5], Step [1865/1875], Loss: 2.3222, batch time: 0.10\n",
      "Epoch [2/5], Step [1866/1875], Loss: 2.1519, batch time: 0.11\n",
      "Epoch [2/5], Step [1867/1875], Loss: 2.2242, batch time: 0.10\n",
      "Epoch [2/5], Step [1868/1875], Loss: 2.3599, batch time: 0.10\n",
      "Epoch [2/5], Step [1869/1875], Loss: 2.1293, batch time: 0.10\n",
      "Epoch [2/5], Step [1870/1875], Loss: 2.2838, batch time: 0.10\n",
      "Epoch [2/5], Step [1871/1875], Loss: 2.2155, batch time: 0.10\n",
      "Epoch [2/5], Step [1872/1875], Loss: 2.2524, batch time: 0.10\n",
      "Epoch [2/5], Step [1873/1875], Loss: 2.3309, batch time: 0.11\n",
      "Epoch [2/5], Step [1874/1875], Loss: 2.3206, batch time: 0.10\n",
      "Epoch [2/5], Step [1875/1875], Loss: 2.2615, batch time: 0.10\n",
      "Epoch [2/5] Accuracy: 17.29%\n",
      "Epoch [3/5], Step [1/1875], Loss: 2.3753, batch time: 0.12\n",
      "Epoch [3/5], Step [2/1875], Loss: 2.2140, batch time: 0.12\n",
      "Epoch [3/5], Step [3/1875], Loss: 2.2283, batch time: 0.10\n",
      "Epoch [3/5], Step [4/1875], Loss: 2.2719, batch time: 0.13\n",
      "Epoch [3/5], Step [5/1875], Loss: 2.1878, batch time: 0.09\n",
      "Epoch [3/5], Step [6/1875], Loss: 2.4286, batch time: 0.10\n",
      "Epoch [3/5], Step [7/1875], Loss: 2.2797, batch time: 0.10\n",
      "Epoch [3/5], Step [8/1875], Loss: 2.1648, batch time: 0.25\n",
      "Epoch [3/5], Step [9/1875], Loss: 2.2247, batch time: 0.11\n",
      "Epoch [3/5], Step [10/1875], Loss: 2.2230, batch time: 0.09\n",
      "Epoch [3/5], Step [11/1875], Loss: 2.2098, batch time: 0.20\n",
      "Epoch [3/5], Step [12/1875], Loss: 2.1831, batch time: 0.10\n",
      "Epoch [3/5], Step [13/1875], Loss: 2.2384, batch time: 0.12\n",
      "Epoch [3/5], Step [14/1875], Loss: 2.2465, batch time: 0.10\n",
      "Epoch [3/5], Step [15/1875], Loss: 2.1440, batch time: 0.12\n",
      "Epoch [3/5], Step [16/1875], Loss: 2.3132, batch time: 0.10\n",
      "Epoch [3/5], Step [17/1875], Loss: 2.1960, batch time: 0.10\n",
      "Epoch [3/5], Step [18/1875], Loss: 2.2774, batch time: 0.12\n",
      "Epoch [3/5], Step [19/1875], Loss: 2.2958, batch time: 0.10\n",
      "Epoch [3/5], Step [20/1875], Loss: 2.2130, batch time: 0.10\n",
      "Epoch [3/5], Step [21/1875], Loss: 2.2390, batch time: 0.25\n",
      "Epoch [3/5], Step [22/1875], Loss: 2.1672, batch time: 0.10\n",
      "Epoch [3/5], Step [23/1875], Loss: 2.2299, batch time: 0.10\n",
      "Epoch [3/5], Step [24/1875], Loss: 2.1439, batch time: 0.10\n",
      "Epoch [3/5], Step [25/1875], Loss: 2.2708, batch time: 0.13\n",
      "Epoch [3/5], Step [26/1875], Loss: 2.2321, batch time: 0.10\n",
      "Epoch [3/5], Step [27/1875], Loss: 2.1339, batch time: 0.12\n",
      "Epoch [3/5], Step [28/1875], Loss: 2.2578, batch time: 0.10\n",
      "Epoch [3/5], Step [29/1875], Loss: 2.2847, batch time: 0.10\n",
      "Epoch [3/5], Step [30/1875], Loss: 2.2397, batch time: 0.14\n",
      "Epoch [3/5], Step [31/1875], Loss: 2.1578, batch time: 0.10\n",
      "Epoch [3/5], Step [32/1875], Loss: 2.4287, batch time: 0.10\n",
      "Epoch [3/5], Step [33/1875], Loss: 2.2392, batch time: 0.10\n",
      "Epoch [3/5], Step [34/1875], Loss: 2.2217, batch time: 0.11\n",
      "Epoch [3/5], Step [35/1875], Loss: 2.2381, batch time: 0.10\n",
      "Epoch [3/5], Step [36/1875], Loss: 2.1195, batch time: 0.15\n",
      "Epoch [3/5], Step [37/1875], Loss: 2.3173, batch time: 0.13\n",
      "Epoch [3/5], Step [38/1875], Loss: 2.1812, batch time: 0.17\n",
      "Epoch [3/5], Step [39/1875], Loss: 2.2606, batch time: 0.10\n",
      "Epoch [3/5], Step [40/1875], Loss: 2.2617, batch time: 0.10\n",
      "Epoch [3/5], Step [41/1875], Loss: 2.1436, batch time: 0.14\n",
      "Epoch [3/5], Step [42/1875], Loss: 2.2196, batch time: 0.10\n",
      "Epoch [3/5], Step [43/1875], Loss: 2.3041, batch time: 0.11\n",
      "Epoch [3/5], Step [44/1875], Loss: 2.3021, batch time: 0.10\n",
      "Epoch [3/5], Step [45/1875], Loss: 2.2958, batch time: 0.10\n",
      "Epoch [3/5], Step [46/1875], Loss: 2.2760, batch time: 0.12\n",
      "Epoch [3/5], Step [47/1875], Loss: 2.1977, batch time: 0.13\n",
      "Epoch [3/5], Step [48/1875], Loss: 2.2576, batch time: 0.11\n",
      "Epoch [3/5], Step [49/1875], Loss: 2.2395, batch time: 0.14\n",
      "Epoch [3/5], Step [50/1875], Loss: 2.2596, batch time: 0.11\n",
      "Epoch [3/5], Step [51/1875], Loss: 2.3836, batch time: 0.13\n",
      "Epoch [3/5], Step [52/1875], Loss: 2.1676, batch time: 0.12\n",
      "Epoch [3/5], Step [53/1875], Loss: 2.1824, batch time: 0.10\n",
      "Epoch [3/5], Step [54/1875], Loss: 2.2668, batch time: 0.10\n",
      "Epoch [3/5], Step [55/1875], Loss: 2.1747, batch time: 0.10\n",
      "Epoch [3/5], Step [56/1875], Loss: 2.3182, batch time: 0.12\n",
      "Epoch [3/5], Step [57/1875], Loss: 2.1712, batch time: 0.10\n",
      "Epoch [3/5], Step [58/1875], Loss: 2.3030, batch time: 0.10\n",
      "Epoch [3/5], Step [59/1875], Loss: 2.1249, batch time: 0.10\n",
      "Epoch [3/5], Step [60/1875], Loss: 2.1197, batch time: 0.10\n",
      "Epoch [3/5], Step [61/1875], Loss: 2.2746, batch time: 0.10\n",
      "Epoch [3/5], Step [62/1875], Loss: 2.3093, batch time: 0.10\n",
      "Epoch [3/5], Step [63/1875], Loss: 2.2148, batch time: 0.16\n",
      "Epoch [3/5], Step [64/1875], Loss: 2.2929, batch time: 0.12\n",
      "Epoch [3/5], Step [65/1875], Loss: 2.2756, batch time: 0.10\n",
      "Epoch [3/5], Step [66/1875], Loss: 2.2369, batch time: 0.13\n",
      "Epoch [3/5], Step [67/1875], Loss: 2.2312, batch time: 0.10\n",
      "Epoch [3/5], Step [68/1875], Loss: 2.2616, batch time: 0.10\n",
      "Epoch [3/5], Step [69/1875], Loss: 2.2572, batch time: 0.11\n",
      "Epoch [3/5], Step [70/1875], Loss: 2.2476, batch time: 0.10\n",
      "Epoch [3/5], Step [71/1875], Loss: 2.3322, batch time: 0.10\n",
      "Epoch [3/5], Step [72/1875], Loss: 2.2080, batch time: 0.10\n",
      "Epoch [3/5], Step [73/1875], Loss: 2.2883, batch time: 0.11\n",
      "Epoch [3/5], Step [74/1875], Loss: 2.3343, batch time: 0.10\n",
      "Epoch [3/5], Step [75/1875], Loss: 2.2440, batch time: 0.10\n",
      "Epoch [3/5], Step [76/1875], Loss: 2.2100, batch time: 0.20\n",
      "Epoch [3/5], Step [77/1875], Loss: 2.1684, batch time: 0.10\n",
      "Epoch [3/5], Step [78/1875], Loss: 2.1654, batch time: 0.11\n",
      "Epoch [3/5], Step [79/1875], Loss: 2.2312, batch time: 0.10\n",
      "Epoch [3/5], Step [80/1875], Loss: 2.1075, batch time: 0.11\n",
      "Epoch [3/5], Step [81/1875], Loss: 2.2268, batch time: 0.10\n",
      "Epoch [3/5], Step [82/1875], Loss: 2.2480, batch time: 0.13\n",
      "Epoch [3/5], Step [83/1875], Loss: 2.1810, batch time: 0.18\n",
      "Epoch [3/5], Step [84/1875], Loss: 2.2068, batch time: 0.13\n",
      "Epoch [3/5], Step [85/1875], Loss: 2.2508, batch time: 0.13\n",
      "Epoch [3/5], Step [86/1875], Loss: 2.2086, batch time: 0.12\n",
      "Epoch [3/5], Step [87/1875], Loss: 2.3040, batch time: 0.10\n",
      "Epoch [3/5], Step [88/1875], Loss: 2.2671, batch time: 0.10\n",
      "Epoch [3/5], Step [89/1875], Loss: 2.2273, batch time: 0.11\n",
      "Epoch [3/5], Step [90/1875], Loss: 2.2673, batch time: 0.10\n",
      "Epoch [3/5], Step [91/1875], Loss: 2.2459, batch time: 0.10\n",
      "Epoch [3/5], Step [92/1875], Loss: 2.2520, batch time: 0.13\n",
      "Epoch [3/5], Step [93/1875], Loss: 2.2435, batch time: -2.83\n",
      "Epoch [3/5], Step [94/1875], Loss: 2.2242, batch time: 0.13\n",
      "Epoch [3/5], Step [95/1875], Loss: 2.2670, batch time: 0.12\n",
      "Epoch [3/5], Step [96/1875], Loss: 2.2868, batch time: 0.10\n",
      "Epoch [3/5], Step [97/1875], Loss: 2.2294, batch time: 0.12\n",
      "Epoch [3/5], Step [98/1875], Loss: 2.2671, batch time: 0.10\n",
      "Epoch [3/5], Step [99/1875], Loss: 2.2560, batch time: 0.13\n",
      "Epoch [3/5], Step [100/1875], Loss: 2.2416, batch time: 0.10\n",
      "Epoch [3/5], Step [101/1875], Loss: 2.2062, batch time: 0.17\n",
      "Epoch [3/5], Step [102/1875], Loss: 2.1747, batch time: 0.17\n",
      "Epoch [3/5], Step [103/1875], Loss: 2.2020, batch time: 0.10\n",
      "Epoch [3/5], Step [104/1875], Loss: 2.1987, batch time: 0.10\n",
      "Epoch [3/5], Step [105/1875], Loss: 2.2147, batch time: 0.10\n",
      "Epoch [3/5], Step [106/1875], Loss: 2.1760, batch time: 0.20\n",
      "Epoch [3/5], Step [107/1875], Loss: 2.2282, batch time: 0.13\n",
      "Epoch [3/5], Step [108/1875], Loss: 2.1976, batch time: 0.10\n",
      "Epoch [3/5], Step [109/1875], Loss: 2.2056, batch time: 0.10\n",
      "Epoch [3/5], Step [110/1875], Loss: 2.2959, batch time: 0.11\n",
      "Epoch [3/5], Step [111/1875], Loss: 2.1863, batch time: 0.13\n",
      "Epoch [3/5], Step [112/1875], Loss: 2.2519, batch time: 0.10\n",
      "Epoch [3/5], Step [113/1875], Loss: 2.1737, batch time: 0.10\n",
      "Epoch [3/5], Step [114/1875], Loss: 2.2701, batch time: 0.10\n",
      "Epoch [3/5], Step [115/1875], Loss: 2.2780, batch time: 0.10\n",
      "Epoch [3/5], Step [116/1875], Loss: 2.2271, batch time: 0.10\n",
      "Epoch [3/5], Step [117/1875], Loss: 2.1849, batch time: 0.10\n",
      "Epoch [3/5], Step [118/1875], Loss: 2.2818, batch time: 0.10\n",
      "Epoch [3/5], Step [119/1875], Loss: 2.2162, batch time: 0.09\n",
      "Epoch [3/5], Step [120/1875], Loss: 2.1857, batch time: 0.10\n",
      "Epoch [3/5], Step [121/1875], Loss: 2.2375, batch time: 0.19\n",
      "Epoch [3/5], Step [122/1875], Loss: 2.2171, batch time: 0.10\n",
      "Epoch [3/5], Step [123/1875], Loss: 2.2238, batch time: 0.10\n",
      "Epoch [3/5], Step [124/1875], Loss: 2.2682, batch time: 0.10\n",
      "Epoch [3/5], Step [125/1875], Loss: 2.2257, batch time: 0.10\n",
      "Epoch [3/5], Step [126/1875], Loss: 2.2988, batch time: 0.12\n",
      "Epoch [3/5], Step [127/1875], Loss: 2.2782, batch time: 0.12\n",
      "Epoch [3/5], Step [128/1875], Loss: 2.2924, batch time: 0.10\n",
      "Epoch [3/5], Step [129/1875], Loss: 2.1975, batch time: 0.15\n",
      "Epoch [3/5], Step [130/1875], Loss: 2.2007, batch time: 0.13\n",
      "Epoch [3/5], Step [131/1875], Loss: 2.1470, batch time: 0.14\n",
      "Epoch [3/5], Step [132/1875], Loss: 2.2534, batch time: 0.10\n",
      "Epoch [3/5], Step [133/1875], Loss: 2.2891, batch time: 0.11\n",
      "Epoch [3/5], Step [134/1875], Loss: 2.2185, batch time: 0.16\n",
      "Epoch [3/5], Step [135/1875], Loss: 2.1475, batch time: 0.10\n",
      "Epoch [3/5], Step [136/1875], Loss: 2.1962, batch time: 0.09\n",
      "Epoch [3/5], Step [137/1875], Loss: 2.2639, batch time: 0.10\n",
      "Epoch [3/5], Step [138/1875], Loss: 2.3177, batch time: 0.10\n",
      "Epoch [3/5], Step [139/1875], Loss: 2.2476, batch time: 0.10\n",
      "Epoch [3/5], Step [140/1875], Loss: 2.1637, batch time: 0.20\n",
      "Epoch [3/5], Step [141/1875], Loss: 2.2456, batch time: 0.10\n",
      "Epoch [3/5], Step [142/1875], Loss: 2.1906, batch time: 0.10\n",
      "Epoch [3/5], Step [143/1875], Loss: 2.1860, batch time: 0.13\n",
      "Epoch [3/5], Step [144/1875], Loss: 2.1611, batch time: 0.10\n",
      "Epoch [3/5], Step [145/1875], Loss: 2.2239, batch time: 0.13\n",
      "Epoch [3/5], Step [146/1875], Loss: 2.1881, batch time: 0.10\n",
      "Epoch [3/5], Step [147/1875], Loss: 2.3145, batch time: 0.10\n",
      "Epoch [3/5], Step [148/1875], Loss: 2.3146, batch time: 0.13\n",
      "Epoch [3/5], Step [149/1875], Loss: 2.2646, batch time: 0.10\n",
      "Epoch [3/5], Step [150/1875], Loss: 2.2887, batch time: 0.10\n",
      "Epoch [3/5], Step [151/1875], Loss: 2.2677, batch time: 0.15\n",
      "Epoch [3/5], Step [152/1875], Loss: 2.1909, batch time: 0.11\n",
      "Epoch [3/5], Step [153/1875], Loss: 2.1590, batch time: 0.11\n",
      "Epoch [3/5], Step [154/1875], Loss: 2.2416, batch time: 0.15\n",
      "Epoch [3/5], Step [155/1875], Loss: 2.2929, batch time: 0.11\n",
      "Epoch [3/5], Step [156/1875], Loss: 2.2075, batch time: 0.13\n",
      "Epoch [3/5], Step [157/1875], Loss: 2.2709, batch time: 0.14\n",
      "Epoch [3/5], Step [158/1875], Loss: 2.2647, batch time: 0.15\n",
      "Epoch [3/5], Step [159/1875], Loss: 2.2886, batch time: 0.14\n",
      "Epoch [3/5], Step [160/1875], Loss: 2.1226, batch time: 0.14\n",
      "Epoch [3/5], Step [161/1875], Loss: 2.2410, batch time: 0.14\n",
      "Epoch [3/5], Step [162/1875], Loss: 2.3546, batch time: 0.12\n",
      "Epoch [3/5], Step [163/1875], Loss: 2.2355, batch time: 0.10\n",
      "Epoch [3/5], Step [164/1875], Loss: 2.1635, batch time: 0.10\n",
      "Epoch [3/5], Step [165/1875], Loss: 2.2508, batch time: 0.10\n",
      "Epoch [3/5], Step [166/1875], Loss: 2.2441, batch time: 0.10\n",
      "Epoch [3/5], Step [167/1875], Loss: 2.1799, batch time: 0.11\n",
      "Epoch [3/5], Step [168/1875], Loss: 2.2862, batch time: 0.10\n",
      "Epoch [3/5], Step [169/1875], Loss: 2.2366, batch time: 0.11\n",
      "Epoch [3/5], Step [170/1875], Loss: 2.2689, batch time: 0.11\n",
      "Epoch [3/5], Step [171/1875], Loss: 2.2020, batch time: 0.12\n",
      "Epoch [3/5], Step [172/1875], Loss: 2.2546, batch time: 0.23\n",
      "Epoch [3/5], Step [173/1875], Loss: 2.1119, batch time: 0.11\n",
      "Epoch [3/5], Step [174/1875], Loss: 2.2632, batch time: 0.13\n",
      "Epoch [3/5], Step [175/1875], Loss: 2.1510, batch time: 0.11\n",
      "Epoch [3/5], Step [176/1875], Loss: 2.1342, batch time: 0.10\n",
      "Epoch [3/5], Step [177/1875], Loss: 2.2419, batch time: 0.10\n",
      "Epoch [3/5], Step [178/1875], Loss: 2.1695, batch time: 0.10\n",
      "Epoch [3/5], Step [179/1875], Loss: 2.1659, batch time: 0.16\n",
      "Epoch [3/5], Step [180/1875], Loss: 2.2805, batch time: 0.10\n",
      "Epoch [3/5], Step [181/1875], Loss: 2.2263, batch time: 0.10\n",
      "Epoch [3/5], Step [182/1875], Loss: 2.1751, batch time: 0.10\n",
      "Epoch [3/5], Step [183/1875], Loss: 2.2261, batch time: 0.10\n",
      "Epoch [3/5], Step [184/1875], Loss: 2.1875, batch time: 0.13\n",
      "Epoch [3/5], Step [185/1875], Loss: 2.2015, batch time: 0.10\n",
      "Epoch [3/5], Step [186/1875], Loss: 2.2175, batch time: 0.10\n",
      "Epoch [3/5], Step [187/1875], Loss: 2.3637, batch time: 0.10\n",
      "Epoch [3/5], Step [188/1875], Loss: 2.3125, batch time: 0.10\n",
      "Epoch [3/5], Step [189/1875], Loss: 2.2372, batch time: 0.14\n",
      "Epoch [3/5], Step [190/1875], Loss: 2.3448, batch time: 0.10\n",
      "Epoch [3/5], Step [191/1875], Loss: 2.2445, batch time: 0.10\n",
      "Epoch [3/5], Step [192/1875], Loss: 2.2864, batch time: 0.12\n",
      "Epoch [3/5], Step [193/1875], Loss: 2.1648, batch time: 0.10\n",
      "Epoch [3/5], Step [194/1875], Loss: 2.2761, batch time: 0.12\n",
      "Epoch [3/5], Step [195/1875], Loss: 2.3299, batch time: 0.10\n",
      "Epoch [3/5], Step [196/1875], Loss: 2.2910, batch time: 0.10\n",
      "Epoch [3/5], Step [197/1875], Loss: 2.2218, batch time: 0.10\n",
      "Epoch [3/5], Step [198/1875], Loss: 2.1754, batch time: 0.10\n",
      "Epoch [3/5], Step [199/1875], Loss: 2.1548, batch time: 0.10\n",
      "Epoch [3/5], Step [200/1875], Loss: 2.2421, batch time: 0.10\n",
      "Epoch [3/5], Step [201/1875], Loss: 2.2891, batch time: 0.10\n",
      "Epoch [3/5], Step [202/1875], Loss: 2.2113, batch time: 0.14\n",
      "Epoch [3/5], Step [203/1875], Loss: 2.3131, batch time: 0.10\n",
      "Epoch [3/5], Step [204/1875], Loss: 2.1020, batch time: 0.10\n",
      "Epoch [3/5], Step [205/1875], Loss: 2.3187, batch time: 0.18\n",
      "Epoch [3/5], Step [206/1875], Loss: 2.1486, batch time: 0.10\n",
      "Epoch [3/5], Step [207/1875], Loss: 2.3495, batch time: 0.12\n",
      "Epoch [3/5], Step [208/1875], Loss: 2.1319, batch time: 0.10\n",
      "Epoch [3/5], Step [209/1875], Loss: 2.2575, batch time: 0.13\n",
      "Epoch [3/5], Step [210/1875], Loss: 2.2021, batch time: 0.10\n",
      "Epoch [3/5], Step [211/1875], Loss: 2.2384, batch time: 0.16\n",
      "Epoch [3/5], Step [212/1875], Loss: 2.2240, batch time: 0.10\n",
      "Epoch [3/5], Step [213/1875], Loss: 2.2255, batch time: 0.13\n",
      "Epoch [3/5], Step [214/1875], Loss: 2.2534, batch time: 0.10\n",
      "Epoch [3/5], Step [215/1875], Loss: 2.1925, batch time: 0.10\n",
      "Epoch [3/5], Step [216/1875], Loss: 2.1951, batch time: 0.12\n",
      "Epoch [3/5], Step [217/1875], Loss: 2.3372, batch time: 0.11\n",
      "Epoch [3/5], Step [218/1875], Loss: 2.2555, batch time: 0.15\n",
      "Epoch [3/5], Step [219/1875], Loss: 2.2489, batch time: 0.10\n",
      "Epoch [3/5], Step [220/1875], Loss: 2.2957, batch time: 0.10\n",
      "Epoch [3/5], Step [221/1875], Loss: 2.1981, batch time: 0.10\n",
      "Epoch [3/5], Step [222/1875], Loss: 2.3867, batch time: 0.10\n",
      "Epoch [3/5], Step [223/1875], Loss: 2.1927, batch time: 0.10\n",
      "Epoch [3/5], Step [224/1875], Loss: 2.2299, batch time: 0.12\n",
      "Epoch [3/5], Step [225/1875], Loss: 2.1860, batch time: 0.10\n",
      "Epoch [3/5], Step [226/1875], Loss: 2.3213, batch time: 0.10\n",
      "Epoch [3/5], Step [227/1875], Loss: 2.1986, batch time: 0.10\n",
      "Epoch [3/5], Step [228/1875], Loss: 2.1370, batch time: 0.10\n",
      "Epoch [3/5], Step [229/1875], Loss: 2.2890, batch time: 0.10\n",
      "Epoch [3/5], Step [230/1875], Loss: 2.1620, batch time: 0.10\n",
      "Epoch [3/5], Step [231/1875], Loss: 2.1717, batch time: 0.10\n",
      "Epoch [3/5], Step [232/1875], Loss: 2.1569, batch time: 0.10\n",
      "Epoch [3/5], Step [233/1875], Loss: 2.3338, batch time: 0.10\n",
      "Epoch [3/5], Step [234/1875], Loss: 2.3273, batch time: 0.10\n",
      "Epoch [3/5], Step [235/1875], Loss: 2.2856, batch time: 0.15\n",
      "Epoch [3/5], Step [236/1875], Loss: 2.3015, batch time: 0.10\n",
      "Epoch [3/5], Step [237/1875], Loss: 2.1693, batch time: 0.11\n",
      "Epoch [3/5], Step [238/1875], Loss: 2.2408, batch time: 0.34\n",
      "Epoch [3/5], Step [239/1875], Loss: 2.2098, batch time: 0.14\n",
      "Epoch [3/5], Step [240/1875], Loss: 2.2342, batch time: 0.12\n",
      "Epoch [3/5], Step [241/1875], Loss: 2.0920, batch time: 0.10\n",
      "Epoch [3/5], Step [242/1875], Loss: 2.2153, batch time: 0.10\n",
      "Epoch [3/5], Step [243/1875], Loss: 2.1321, batch time: 0.10\n",
      "Epoch [3/5], Step [244/1875], Loss: 2.2286, batch time: 0.10\n",
      "Epoch [3/5], Step [245/1875], Loss: 2.3101, batch time: 0.10\n",
      "Epoch [3/5], Step [246/1875], Loss: 2.2314, batch time: 0.13\n",
      "Epoch [3/5], Step [247/1875], Loss: 2.1397, batch time: 0.18\n",
      "Epoch [3/5], Step [248/1875], Loss: 2.2143, batch time: 0.13\n",
      "Epoch [3/5], Step [249/1875], Loss: 2.2232, batch time: 0.10\n",
      "Epoch [3/5], Step [250/1875], Loss: 2.1309, batch time: 0.10\n",
      "Epoch [3/5], Step [251/1875], Loss: 2.2307, batch time: 0.10\n",
      "Epoch [3/5], Step [252/1875], Loss: 2.2852, batch time: 0.10\n",
      "Epoch [3/5], Step [253/1875], Loss: 2.2968, batch time: 0.11\n",
      "Epoch [3/5], Step [254/1875], Loss: 2.2633, batch time: 0.10\n",
      "Epoch [3/5], Step [255/1875], Loss: 2.2899, batch time: 0.10\n",
      "Epoch [3/5], Step [256/1875], Loss: 2.1844, batch time: 0.10\n",
      "Epoch [3/5], Step [257/1875], Loss: 2.2282, batch time: 0.10\n",
      "Epoch [3/5], Step [258/1875], Loss: 2.1980, batch time: 0.10\n",
      "Epoch [3/5], Step [259/1875], Loss: 2.2424, batch time: 0.10\n",
      "Epoch [3/5], Step [260/1875], Loss: 2.2835, batch time: 0.10\n",
      "Epoch [3/5], Step [261/1875], Loss: 2.2786, batch time: 0.10\n",
      "Epoch [3/5], Step [262/1875], Loss: 2.1707, batch time: 0.27\n",
      "Epoch [3/5], Step [263/1875], Loss: 2.2312, batch time: 0.10\n",
      "Epoch [3/5], Step [264/1875], Loss: 2.2734, batch time: 0.10\n",
      "Epoch [3/5], Step [265/1875], Loss: 2.2332, batch time: 0.10\n",
      "Epoch [3/5], Step [266/1875], Loss: 2.1818, batch time: 0.10\n",
      "Epoch [3/5], Step [267/1875], Loss: 2.3236, batch time: 0.10\n",
      "Epoch [3/5], Step [268/1875], Loss: 2.1912, batch time: 0.10\n",
      "Epoch [3/5], Step [269/1875], Loss: 2.1689, batch time: 0.11\n",
      "Epoch [3/5], Step [270/1875], Loss: 2.2420, batch time: 0.10\n",
      "Epoch [3/5], Step [271/1875], Loss: 2.1870, batch time: 0.10\n",
      "Epoch [3/5], Step [272/1875], Loss: 2.3018, batch time: 0.09\n",
      "Epoch [3/5], Step [273/1875], Loss: 2.2511, batch time: 0.10\n",
      "Epoch [3/5], Step [274/1875], Loss: 2.2648, batch time: 0.10\n",
      "Epoch [3/5], Step [275/1875], Loss: 2.2096, batch time: 0.10\n",
      "Epoch [3/5], Step [276/1875], Loss: 2.2894, batch time: 0.10\n",
      "Epoch [3/5], Step [277/1875], Loss: 2.2012, batch time: 0.10\n",
      "Epoch [3/5], Step [278/1875], Loss: 2.2848, batch time: 0.10\n",
      "Epoch [3/5], Step [279/1875], Loss: 2.2307, batch time: 0.10\n",
      "Epoch [3/5], Step [280/1875], Loss: 2.2437, batch time: 0.10\n",
      "Epoch [3/5], Step [281/1875], Loss: 2.2279, batch time: 0.10\n",
      "Epoch [3/5], Step [282/1875], Loss: 2.1592, batch time: 0.14\n",
      "Epoch [3/5], Step [283/1875], Loss: 2.1580, batch time: 0.10\n",
      "Epoch [3/5], Step [284/1875], Loss: 2.2729, batch time: 0.12\n",
      "Epoch [3/5], Step [285/1875], Loss: 2.2420, batch time: 0.10\n",
      "Epoch [3/5], Step [286/1875], Loss: 2.3229, batch time: 0.11\n",
      "Epoch [3/5], Step [287/1875], Loss: 2.2006, batch time: 0.12\n",
      "Epoch [3/5], Step [288/1875], Loss: 2.2983, batch time: 0.10\n",
      "Epoch [3/5], Step [289/1875], Loss: 2.2432, batch time: 0.10\n",
      "Epoch [3/5], Step [290/1875], Loss: 2.1781, batch time: 0.10\n",
      "Epoch [3/5], Step [291/1875], Loss: 2.1824, batch time: 0.11\n",
      "Epoch [3/5], Step [292/1875], Loss: 2.2267, batch time: 0.12\n",
      "Epoch [3/5], Step [293/1875], Loss: 2.2118, batch time: 0.10\n",
      "Epoch [3/5], Step [294/1875], Loss: 2.2288, batch time: 0.14\n",
      "Epoch [3/5], Step [295/1875], Loss: 2.1486, batch time: 0.09\n",
      "Epoch [3/5], Step [296/1875], Loss: 2.2087, batch time: 0.10\n",
      "Epoch [3/5], Step [297/1875], Loss: 2.2401, batch time: 0.10\n",
      "Epoch [3/5], Step [298/1875], Loss: 2.3436, batch time: 0.10\n",
      "Epoch [3/5], Step [299/1875], Loss: 2.1666, batch time: 0.10\n",
      "Epoch [3/5], Step [300/1875], Loss: 2.3707, batch time: 0.10\n",
      "Epoch [3/5], Step [301/1875], Loss: 2.2624, batch time: 0.10\n",
      "Epoch [3/5], Step [302/1875], Loss: 2.1318, batch time: 0.12\n",
      "Epoch [3/5], Step [303/1875], Loss: 2.2614, batch time: 0.14\n",
      "Epoch [3/5], Step [304/1875], Loss: 2.2042, batch time: 0.18\n",
      "Epoch [3/5], Step [305/1875], Loss: 2.2017, batch time: 0.10\n",
      "Epoch [3/5], Step [306/1875], Loss: 2.1475, batch time: 0.10\n",
      "Epoch [3/5], Step [307/1875], Loss: 2.2407, batch time: 0.10\n",
      "Epoch [3/5], Step [308/1875], Loss: 2.3115, batch time: 0.10\n",
      "Epoch [3/5], Step [309/1875], Loss: 2.3262, batch time: 0.10\n",
      "Epoch [3/5], Step [310/1875], Loss: 2.2122, batch time: 0.10\n",
      "Epoch [3/5], Step [311/1875], Loss: 2.2863, batch time: 0.10\n",
      "Epoch [3/5], Step [312/1875], Loss: 2.0891, batch time: 0.10\n",
      "Epoch [3/5], Step [313/1875], Loss: 2.3241, batch time: 0.10\n",
      "Epoch [3/5], Step [314/1875], Loss: 2.2458, batch time: 0.10\n",
      "Epoch [3/5], Step [315/1875], Loss: 2.2762, batch time: 0.10\n",
      "Epoch [3/5], Step [316/1875], Loss: 2.1591, batch time: 0.10\n",
      "Epoch [3/5], Step [317/1875], Loss: 2.2116, batch time: 0.12\n",
      "Epoch [3/5], Step [318/1875], Loss: 2.1361, batch time: 0.10\n",
      "Epoch [3/5], Step [319/1875], Loss: 2.2920, batch time: 0.10\n",
      "Epoch [3/5], Step [320/1875], Loss: 2.1369, batch time: 0.13\n",
      "Epoch [3/5], Step [321/1875], Loss: 2.1431, batch time: 0.10\n",
      "Epoch [3/5], Step [322/1875], Loss: 2.1237, batch time: 0.10\n",
      "Epoch [3/5], Step [323/1875], Loss: 2.2222, batch time: 0.10\n",
      "Epoch [3/5], Step [324/1875], Loss: 2.1800, batch time: 0.10\n",
      "Epoch [3/5], Step [325/1875], Loss: 2.1963, batch time: 0.15\n",
      "Epoch [3/5], Step [326/1875], Loss: 2.1906, batch time: 0.13\n",
      "Epoch [3/5], Step [327/1875], Loss: 2.3108, batch time: 0.11\n",
      "Epoch [3/5], Step [328/1875], Loss: 2.1787, batch time: 0.15\n",
      "Epoch [3/5], Step [329/1875], Loss: 2.2510, batch time: 0.11\n",
      "Epoch [3/5], Step [330/1875], Loss: 2.2140, batch time: 0.11\n",
      "Epoch [3/5], Step [331/1875], Loss: 2.1775, batch time: 0.13\n",
      "Epoch [3/5], Step [332/1875], Loss: 2.1008, batch time: 0.11\n",
      "Epoch [3/5], Step [333/1875], Loss: 2.1578, batch time: 0.12\n",
      "Epoch [3/5], Step [334/1875], Loss: 2.3073, batch time: 0.10\n",
      "Epoch [3/5], Step [335/1875], Loss: 2.3155, batch time: 0.10\n",
      "Epoch [3/5], Step [336/1875], Loss: 2.2864, batch time: 0.14\n",
      "Epoch [3/5], Step [337/1875], Loss: 2.1513, batch time: 0.11\n",
      "Epoch [3/5], Step [338/1875], Loss: 2.0971, batch time: 0.12\n",
      "Epoch [3/5], Step [339/1875], Loss: 2.2171, batch time: 0.10\n",
      "Epoch [3/5], Step [340/1875], Loss: 2.2910, batch time: 0.10\n",
      "Epoch [3/5], Step [341/1875], Loss: 2.1039, batch time: 0.10\n",
      "Epoch [3/5], Step [342/1875], Loss: 2.2294, batch time: 0.12\n",
      "Epoch [3/5], Step [343/1875], Loss: 2.2031, batch time: 0.10\n",
      "Epoch [3/5], Step [344/1875], Loss: 2.2145, batch time: 0.11\n",
      "Epoch [3/5], Step [345/1875], Loss: 2.2514, batch time: 0.10\n",
      "Epoch [3/5], Step [346/1875], Loss: 2.0893, batch time: 0.12\n",
      "Epoch [3/5], Step [347/1875], Loss: 2.3658, batch time: 0.10\n",
      "Epoch [3/5], Step [348/1875], Loss: 2.2843, batch time: 0.14\n",
      "Epoch [3/5], Step [349/1875], Loss: 2.3296, batch time: 0.10\n",
      "Epoch [3/5], Step [350/1875], Loss: 2.2426, batch time: 0.10\n",
      "Epoch [3/5], Step [351/1875], Loss: 2.2338, batch time: 0.10\n",
      "Epoch [3/5], Step [352/1875], Loss: 2.0686, batch time: 0.12\n",
      "Epoch [3/5], Step [353/1875], Loss: 2.2994, batch time: 0.13\n",
      "Epoch [3/5], Step [354/1875], Loss: 2.2217, batch time: 0.10\n",
      "Epoch [3/5], Step [355/1875], Loss: 2.2174, batch time: 0.10\n",
      "Epoch [3/5], Step [356/1875], Loss: 2.1279, batch time: 0.11\n",
      "Epoch [3/5], Step [357/1875], Loss: 2.3607, batch time: 0.10\n",
      "Epoch [3/5], Step [358/1875], Loss: 2.2028, batch time: 0.12\n",
      "Epoch [3/5], Step [359/1875], Loss: 2.3500, batch time: 0.13\n",
      "Epoch [3/5], Step [360/1875], Loss: 2.2396, batch time: 0.11\n",
      "Epoch [3/5], Step [361/1875], Loss: 2.2385, batch time: 0.10\n",
      "Epoch [3/5], Step [362/1875], Loss: 2.1988, batch time: 0.11\n",
      "Epoch [3/5], Step [363/1875], Loss: 2.2868, batch time: 0.10\n",
      "Epoch [3/5], Step [364/1875], Loss: 2.2707, batch time: 0.10\n",
      "Epoch [3/5], Step [365/1875], Loss: 2.2506, batch time: 0.10\n",
      "Epoch [3/5], Step [366/1875], Loss: 2.1965, batch time: 0.10\n",
      "Epoch [3/5], Step [367/1875], Loss: 2.1545, batch time: 0.13\n",
      "Epoch [3/5], Step [368/1875], Loss: 2.2752, batch time: 0.11\n",
      "Epoch [3/5], Step [369/1875], Loss: 2.2511, batch time: 0.10\n",
      "Epoch [3/5], Step [370/1875], Loss: 2.2710, batch time: 0.10\n",
      "Epoch [3/5], Step [371/1875], Loss: 2.2755, batch time: 0.10\n",
      "Epoch [3/5], Step [372/1875], Loss: 2.1740, batch time: 0.10\n",
      "Epoch [3/5], Step [373/1875], Loss: 2.3341, batch time: 0.13\n",
      "Epoch [3/5], Step [374/1875], Loss: 2.2712, batch time: 0.15\n",
      "Epoch [3/5], Step [375/1875], Loss: 2.1827, batch time: 0.13\n",
      "Epoch [3/5], Step [376/1875], Loss: 2.2296, batch time: -2.84\n",
      "Epoch [3/5], Step [377/1875], Loss: 2.2671, batch time: 0.13\n",
      "Epoch [3/5], Step [378/1875], Loss: 2.2443, batch time: 0.14\n",
      "Epoch [3/5], Step [379/1875], Loss: 2.3411, batch time: 0.11\n",
      "Epoch [3/5], Step [380/1875], Loss: 2.2095, batch time: 0.12\n",
      "Epoch [3/5], Step [381/1875], Loss: 2.2561, batch time: 0.10\n",
      "Epoch [3/5], Step [382/1875], Loss: 2.1182, batch time: 0.19\n",
      "Epoch [3/5], Step [383/1875], Loss: 2.1690, batch time: 0.11\n",
      "Epoch [3/5], Step [384/1875], Loss: 2.3261, batch time: 0.13\n",
      "Epoch [3/5], Step [385/1875], Loss: 2.1810, batch time: 0.10\n",
      "Epoch [3/5], Step [386/1875], Loss: 2.3028, batch time: 0.15\n",
      "Epoch [3/5], Step [387/1875], Loss: 2.2321, batch time: 0.10\n",
      "Epoch [3/5], Step [388/1875], Loss: 2.2116, batch time: 0.10\n",
      "Epoch [3/5], Step [389/1875], Loss: 2.3729, batch time: 0.10\n",
      "Epoch [3/5], Step [390/1875], Loss: 2.2108, batch time: 0.12\n",
      "Epoch [3/5], Step [391/1875], Loss: 2.2083, batch time: 0.11\n",
      "Epoch [3/5], Step [392/1875], Loss: 2.2920, batch time: 0.11\n",
      "Epoch [3/5], Step [393/1875], Loss: 2.2761, batch time: 0.10\n",
      "Epoch [3/5], Step [394/1875], Loss: 2.1980, batch time: 0.12\n",
      "Epoch [3/5], Step [395/1875], Loss: 2.2122, batch time: 0.10\n",
      "Epoch [3/5], Step [396/1875], Loss: 2.2801, batch time: 0.10\n",
      "Epoch [3/5], Step [397/1875], Loss: 2.3192, batch time: 0.11\n",
      "Epoch [3/5], Step [398/1875], Loss: 2.2156, batch time: 0.10\n",
      "Epoch [3/5], Step [399/1875], Loss: 2.2929, batch time: 0.10\n",
      "Epoch [3/5], Step [400/1875], Loss: 2.2155, batch time: 0.11\n",
      "Epoch [3/5], Step [401/1875], Loss: 2.2594, batch time: 0.09\n",
      "Epoch [3/5], Step [402/1875], Loss: 2.2682, batch time: 0.12\n",
      "Epoch [3/5], Step [403/1875], Loss: 2.3213, batch time: 0.10\n",
      "Epoch [3/5], Step [404/1875], Loss: 2.2426, batch time: 0.15\n",
      "Epoch [3/5], Step [405/1875], Loss: 2.1104, batch time: 0.10\n",
      "Epoch [3/5], Step [406/1875], Loss: 2.2585, batch time: 0.09\n",
      "Epoch [3/5], Step [407/1875], Loss: 2.2205, batch time: 0.10\n",
      "Epoch [3/5], Step [408/1875], Loss: 2.2033, batch time: 0.10\n",
      "Epoch [3/5], Step [409/1875], Loss: 2.3155, batch time: 0.10\n",
      "Epoch [3/5], Step [410/1875], Loss: 2.3712, batch time: 0.15\n",
      "Epoch [3/5], Step [411/1875], Loss: 2.2428, batch time: 0.10\n",
      "Epoch [3/5], Step [412/1875], Loss: 2.2837, batch time: 0.13\n",
      "Epoch [3/5], Step [413/1875], Loss: 2.2063, batch time: 0.10\n",
      "Epoch [3/5], Step [414/1875], Loss: 2.2142, batch time: 0.10\n",
      "Epoch [3/5], Step [415/1875], Loss: 2.2233, batch time: 0.13\n",
      "Epoch [3/5], Step [416/1875], Loss: 2.2783, batch time: 0.10\n",
      "Epoch [3/5], Step [417/1875], Loss: 2.2331, batch time: 0.15\n",
      "Epoch [3/5], Step [418/1875], Loss: 2.2837, batch time: 0.19\n",
      "Epoch [3/5], Step [419/1875], Loss: 2.2512, batch time: 0.10\n",
      "Epoch [3/5], Step [420/1875], Loss: 2.1949, batch time: 0.11\n",
      "Epoch [3/5], Step [421/1875], Loss: 2.2939, batch time: 0.15\n",
      "Epoch [3/5], Step [422/1875], Loss: 2.2522, batch time: 0.14\n",
      "Epoch [3/5], Step [423/1875], Loss: 2.1552, batch time: 0.17\n",
      "Epoch [3/5], Step [424/1875], Loss: 2.1823, batch time: 0.10\n",
      "Epoch [3/5], Step [425/1875], Loss: 2.1910, batch time: 0.10\n",
      "Epoch [3/5], Step [426/1875], Loss: 2.2232, batch time: 0.10\n",
      "Epoch [3/5], Step [427/1875], Loss: 2.2929, batch time: 0.10\n",
      "Epoch [3/5], Step [428/1875], Loss: 2.1686, batch time: 0.13\n",
      "Epoch [3/5], Step [429/1875], Loss: 2.1872, batch time: 0.10\n",
      "Epoch [3/5], Step [430/1875], Loss: 2.2251, batch time: 0.10\n",
      "Epoch [3/5], Step [431/1875], Loss: 2.1970, batch time: 0.13\n",
      "Epoch [3/5], Step [432/1875], Loss: 2.3030, batch time: 0.10\n",
      "Epoch [3/5], Step [433/1875], Loss: 2.0597, batch time: 0.10\n",
      "Epoch [3/5], Step [434/1875], Loss: 2.2945, batch time: 0.11\n",
      "Epoch [3/5], Step [435/1875], Loss: 2.3577, batch time: 0.09\n",
      "Epoch [3/5], Step [436/1875], Loss: 2.2354, batch time: 0.14\n",
      "Epoch [3/5], Step [437/1875], Loss: 2.2423, batch time: 0.10\n",
      "Epoch [3/5], Step [438/1875], Loss: 2.1991, batch time: 0.10\n",
      "Epoch [3/5], Step [439/1875], Loss: 2.1827, batch time: 0.10\n",
      "Epoch [3/5], Step [440/1875], Loss: 2.1715, batch time: 0.10\n",
      "Epoch [3/5], Step [441/1875], Loss: 2.2236, batch time: 0.10\n",
      "Epoch [3/5], Step [442/1875], Loss: 2.2624, batch time: 0.11\n",
      "Epoch [3/5], Step [443/1875], Loss: 2.1429, batch time: 0.10\n",
      "Epoch [3/5], Step [444/1875], Loss: 2.1891, batch time: 0.10\n",
      "Epoch [3/5], Step [445/1875], Loss: 2.2665, batch time: 0.10\n",
      "Epoch [3/5], Step [446/1875], Loss: 2.2981, batch time: 0.16\n",
      "Epoch [3/5], Step [447/1875], Loss: 2.2631, batch time: 0.10\n",
      "Epoch [3/5], Step [448/1875], Loss: 2.0864, batch time: 0.10\n",
      "Epoch [3/5], Step [449/1875], Loss: 2.1760, batch time: 0.10\n",
      "Epoch [3/5], Step [450/1875], Loss: 2.3163, batch time: 0.10\n",
      "Epoch [3/5], Step [451/1875], Loss: 2.2407, batch time: 0.10\n",
      "Epoch [3/5], Step [452/1875], Loss: 2.3170, batch time: 0.10\n",
      "Epoch [3/5], Step [453/1875], Loss: 2.2101, batch time: 0.10\n",
      "Epoch [3/5], Step [454/1875], Loss: 2.3395, batch time: 0.10\n",
      "Epoch [3/5], Step [455/1875], Loss: 2.2196, batch time: 0.12\n",
      "Epoch [3/5], Step [456/1875], Loss: 2.3002, batch time: 0.13\n",
      "Epoch [3/5], Step [457/1875], Loss: 2.2324, batch time: 0.10\n",
      "Epoch [3/5], Step [458/1875], Loss: 2.1679, batch time: 0.10\n",
      "Epoch [3/5], Step [459/1875], Loss: 2.2514, batch time: 0.12\n",
      "Epoch [3/5], Step [460/1875], Loss: 2.2966, batch time: 0.10\n",
      "Epoch [3/5], Step [461/1875], Loss: 2.2117, batch time: 0.10\n",
      "Epoch [3/5], Step [462/1875], Loss: 2.1544, batch time: 0.12\n",
      "Epoch [3/5], Step [463/1875], Loss: 2.1939, batch time: 0.10\n",
      "Epoch [3/5], Step [464/1875], Loss: 2.2207, batch time: 0.13\n",
      "Epoch [3/5], Step [465/1875], Loss: 2.2948, batch time: 0.10\n",
      "Epoch [3/5], Step [466/1875], Loss: 2.1542, batch time: 0.13\n",
      "Epoch [3/5], Step [467/1875], Loss: 2.2557, batch time: 0.13\n",
      "Epoch [3/5], Step [468/1875], Loss: 2.1448, batch time: 0.14\n",
      "Epoch [3/5], Step [469/1875], Loss: 2.2468, batch time: 0.10\n",
      "Epoch [3/5], Step [470/1875], Loss: 2.3285, batch time: 0.11\n",
      "Epoch [3/5], Step [471/1875], Loss: 2.2680, batch time: 0.14\n",
      "Epoch [3/5], Step [472/1875], Loss: 2.3241, batch time: 0.10\n",
      "Epoch [3/5], Step [473/1875], Loss: 2.2955, batch time: 0.14\n",
      "Epoch [3/5], Step [474/1875], Loss: 2.2747, batch time: 0.14\n",
      "Epoch [3/5], Step [475/1875], Loss: 2.1591, batch time: 0.14\n",
      "Epoch [3/5], Step [476/1875], Loss: 2.2868, batch time: 0.12\n",
      "Epoch [3/5], Step [477/1875], Loss: 2.3516, batch time: 0.11\n",
      "Epoch [3/5], Step [478/1875], Loss: 2.2198, batch time: 0.20\n",
      "Epoch [3/5], Step [479/1875], Loss: 2.2371, batch time: 0.14\n",
      "Epoch [3/5], Step [480/1875], Loss: 2.2059, batch time: 0.16\n",
      "Epoch [3/5], Step [481/1875], Loss: 2.2504, batch time: 0.13\n",
      "Epoch [3/5], Step [482/1875], Loss: 2.2356, batch time: 0.14\n",
      "Epoch [3/5], Step [483/1875], Loss: 2.1610, batch time: 0.13\n",
      "Epoch [3/5], Step [484/1875], Loss: 2.2467, batch time: 0.10\n",
      "Epoch [3/5], Step [485/1875], Loss: 2.3052, batch time: 0.10\n",
      "Epoch [3/5], Step [486/1875], Loss: 2.2901, batch time: 0.10\n",
      "Epoch [3/5], Step [487/1875], Loss: 2.2104, batch time: 0.32\n",
      "Epoch [3/5], Step [488/1875], Loss: 2.1322, batch time: 0.10\n",
      "Epoch [3/5], Step [489/1875], Loss: 2.1152, batch time: 0.10\n",
      "Epoch [3/5], Step [490/1875], Loss: 2.1339, batch time: 0.11\n",
      "Epoch [3/5], Step [491/1875], Loss: 2.1788, batch time: 0.11\n",
      "Epoch [3/5], Step [492/1875], Loss: 2.3325, batch time: 0.10\n",
      "Epoch [3/5], Step [493/1875], Loss: 2.2441, batch time: 0.13\n",
      "Epoch [3/5], Step [494/1875], Loss: 2.2509, batch time: 0.14\n",
      "Epoch [3/5], Step [495/1875], Loss: 2.1786, batch time: 0.11\n",
      "Epoch [3/5], Step [496/1875], Loss: 2.1493, batch time: 0.14\n",
      "Epoch [3/5], Step [497/1875], Loss: 2.2902, batch time: 0.14\n",
      "Epoch [3/5], Step [498/1875], Loss: 2.2252, batch time: 0.12\n",
      "Epoch [3/5], Step [499/1875], Loss: 2.2815, batch time: 0.11\n",
      "Epoch [3/5], Step [500/1875], Loss: 2.1768, batch time: 0.14\n",
      "Epoch [3/5], Step [501/1875], Loss: 2.1131, batch time: 0.13\n",
      "Epoch [3/5], Step [502/1875], Loss: 2.2375, batch time: 0.12\n",
      "Epoch [3/5], Step [503/1875], Loss: 2.3101, batch time: 0.10\n",
      "Epoch [3/5], Step [504/1875], Loss: 2.2395, batch time: 0.10\n",
      "Epoch [3/5], Step [505/1875], Loss: 2.2362, batch time: 0.10\n",
      "Epoch [3/5], Step [506/1875], Loss: 2.2406, batch time: 0.14\n",
      "Epoch [3/5], Step [507/1875], Loss: 2.0993, batch time: 0.13\n",
      "Epoch [3/5], Step [508/1875], Loss: 2.2253, batch time: 0.10\n",
      "Epoch [3/5], Step [509/1875], Loss: 2.0588, batch time: 0.10\n",
      "Epoch [3/5], Step [510/1875], Loss: 2.3693, batch time: 0.10\n",
      "Epoch [3/5], Step [511/1875], Loss: 2.0975, batch time: 0.10\n",
      "Epoch [3/5], Step [512/1875], Loss: 2.1508, batch time: 0.13\n",
      "Epoch [3/5], Step [513/1875], Loss: 2.1832, batch time: 0.10\n",
      "Epoch [3/5], Step [514/1875], Loss: 2.3295, batch time: 0.12\n",
      "Epoch [3/5], Step [515/1875], Loss: 2.1626, batch time: 0.10\n",
      "Epoch [3/5], Step [516/1875], Loss: 2.2070, batch time: 0.10\n",
      "Epoch [3/5], Step [517/1875], Loss: 2.2721, batch time: 0.10\n",
      "Epoch [3/5], Step [518/1875], Loss: 2.1020, batch time: 0.10\n",
      "Epoch [3/5], Step [519/1875], Loss: 2.1910, batch time: 0.10\n",
      "Epoch [3/5], Step [520/1875], Loss: 2.1918, batch time: 0.13\n",
      "Epoch [3/5], Step [521/1875], Loss: 2.2658, batch time: 0.16\n",
      "Epoch [3/5], Step [522/1875], Loss: 2.2308, batch time: 0.10\n",
      "Epoch [3/5], Step [523/1875], Loss: 2.2533, batch time: 0.11\n",
      "Epoch [3/5], Step [524/1875], Loss: 2.1262, batch time: 0.11\n",
      "Epoch [3/5], Step [525/1875], Loss: 2.1658, batch time: 0.10\n",
      "Epoch [3/5], Step [526/1875], Loss: 2.2349, batch time: 0.10\n",
      "Epoch [3/5], Step [527/1875], Loss: 2.2899, batch time: 0.14\n",
      "Epoch [3/5], Step [528/1875], Loss: 2.2135, batch time: 0.11\n",
      "Epoch [3/5], Step [529/1875], Loss: 2.1600, batch time: 0.13\n",
      "Epoch [3/5], Step [530/1875], Loss: 2.1626, batch time: 0.14\n",
      "Epoch [3/5], Step [531/1875], Loss: 2.2126, batch time: 0.16\n",
      "Epoch [3/5], Step [532/1875], Loss: 2.2679, batch time: 0.10\n",
      "Epoch [3/5], Step [533/1875], Loss: 2.2842, batch time: 0.11\n",
      "Epoch [3/5], Step [534/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [3/5], Step [535/1875], Loss: 2.2844, batch time: 0.10\n",
      "Epoch [3/5], Step [536/1875], Loss: 2.3119, batch time: 0.10\n",
      "Epoch [3/5], Step [537/1875], Loss: 2.1030, batch time: 0.10\n",
      "Epoch [3/5], Step [538/1875], Loss: 2.2180, batch time: 0.13\n",
      "Epoch [3/5], Step [539/1875], Loss: 2.0987, batch time: 0.12\n",
      "Epoch [3/5], Step [540/1875], Loss: 2.3234, batch time: 0.10\n",
      "Epoch [3/5], Step [541/1875], Loss: 2.2711, batch time: 0.13\n",
      "Epoch [3/5], Step [542/1875], Loss: 2.2116, batch time: 0.13\n",
      "Epoch [3/5], Step [543/1875], Loss: 2.2470, batch time: 0.13\n",
      "Epoch [3/5], Step [544/1875], Loss: 2.2730, batch time: 0.10\n",
      "Epoch [3/5], Step [545/1875], Loss: 2.2521, batch time: 0.10\n",
      "Epoch [3/5], Step [546/1875], Loss: 2.2595, batch time: 0.11\n",
      "Epoch [3/5], Step [547/1875], Loss: 2.2884, batch time: 0.10\n",
      "Epoch [3/5], Step [548/1875], Loss: 2.2593, batch time: 0.10\n",
      "Epoch [3/5], Step [549/1875], Loss: 2.2125, batch time: 0.10\n",
      "Epoch [3/5], Step [550/1875], Loss: 2.2106, batch time: 0.10\n",
      "Epoch [3/5], Step [551/1875], Loss: 2.3370, batch time: 0.13\n",
      "Epoch [3/5], Step [552/1875], Loss: 2.1733, batch time: 0.19\n",
      "Epoch [3/5], Step [553/1875], Loss: 2.3081, batch time: 0.10\n",
      "Epoch [3/5], Step [554/1875], Loss: 2.3149, batch time: 0.12\n",
      "Epoch [3/5], Step [555/1875], Loss: 2.2714, batch time: 0.11\n",
      "Epoch [3/5], Step [556/1875], Loss: 2.3307, batch time: 0.13\n",
      "Epoch [3/5], Step [557/1875], Loss: 2.1124, batch time: 0.10\n",
      "Epoch [3/5], Step [558/1875], Loss: 2.2505, batch time: 0.10\n",
      "Epoch [3/5], Step [559/1875], Loss: 2.2230, batch time: 0.10\n",
      "Epoch [3/5], Step [560/1875], Loss: 2.2577, batch time: 0.10\n",
      "Epoch [3/5], Step [561/1875], Loss: 2.1845, batch time: 0.19\n",
      "Epoch [3/5], Step [562/1875], Loss: 2.2659, batch time: 0.14\n",
      "Epoch [3/5], Step [563/1875], Loss: 2.3023, batch time: 0.10\n",
      "Epoch [3/5], Step [564/1875], Loss: 2.2802, batch time: 0.12\n",
      "Epoch [3/5], Step [565/1875], Loss: 2.1675, batch time: 0.10\n",
      "Epoch [3/5], Step [566/1875], Loss: 2.2069, batch time: 0.10\n",
      "Epoch [3/5], Step [567/1875], Loss: 2.2593, batch time: 0.10\n",
      "Epoch [3/5], Step [568/1875], Loss: 2.2319, batch time: 0.10\n",
      "Epoch [3/5], Step [569/1875], Loss: 2.3483, batch time: 0.10\n",
      "Epoch [3/5], Step [570/1875], Loss: 2.1801, batch time: 0.10\n",
      "Epoch [3/5], Step [571/1875], Loss: 2.2099, batch time: 0.10\n",
      "Epoch [3/5], Step [572/1875], Loss: 2.2417, batch time: 0.13\n",
      "Epoch [3/5], Step [573/1875], Loss: 2.3196, batch time: 0.10\n",
      "Epoch [3/5], Step [574/1875], Loss: 2.2516, batch time: 0.14\n",
      "Epoch [3/5], Step [575/1875], Loss: 2.2362, batch time: 0.11\n",
      "Epoch [3/5], Step [576/1875], Loss: 2.2633, batch time: 0.10\n",
      "Epoch [3/5], Step [577/1875], Loss: 2.1853, batch time: 0.11\n",
      "Epoch [3/5], Step [578/1875], Loss: 2.1975, batch time: 0.10\n",
      "Epoch [3/5], Step [579/1875], Loss: 2.2413, batch time: 0.13\n",
      "Epoch [3/5], Step [580/1875], Loss: 2.3489, batch time: 0.13\n",
      "Epoch [3/5], Step [581/1875], Loss: 2.1169, batch time: 0.16\n",
      "Epoch [3/5], Step [582/1875], Loss: 2.1346, batch time: 0.10\n",
      "Epoch [3/5], Step [583/1875], Loss: 2.3029, batch time: 0.14\n",
      "Epoch [3/5], Step [584/1875], Loss: 2.3205, batch time: 0.10\n",
      "Epoch [3/5], Step [585/1875], Loss: 2.2236, batch time: 0.11\n",
      "Epoch [3/5], Step [586/1875], Loss: 2.2692, batch time: 0.10\n",
      "Epoch [3/5], Step [587/1875], Loss: 2.2708, batch time: 0.10\n",
      "Epoch [3/5], Step [588/1875], Loss: 2.1637, batch time: 0.13\n",
      "Epoch [3/5], Step [589/1875], Loss: 2.1900, batch time: 0.10\n",
      "Epoch [3/5], Step [590/1875], Loss: 2.2022, batch time: 0.13\n",
      "Epoch [3/5], Step [591/1875], Loss: 2.1954, batch time: 0.15\n",
      "Epoch [3/5], Step [592/1875], Loss: 2.2511, batch time: 0.12\n",
      "Epoch [3/5], Step [593/1875], Loss: 2.3218, batch time: 0.13\n",
      "Epoch [3/5], Step [594/1875], Loss: 2.1345, batch time: 0.12\n",
      "Epoch [3/5], Step [595/1875], Loss: 2.1541, batch time: 0.13\n",
      "Epoch [3/5], Step [596/1875], Loss: 2.1465, batch time: 0.10\n",
      "Epoch [3/5], Step [597/1875], Loss: 2.2779, batch time: 0.13\n",
      "Epoch [3/5], Step [598/1875], Loss: 2.2464, batch time: 0.14\n",
      "Epoch [3/5], Step [599/1875], Loss: 2.3230, batch time: 0.11\n",
      "Epoch [3/5], Step [600/1875], Loss: 2.1762, batch time: 0.10\n",
      "Epoch [3/5], Step [601/1875], Loss: 2.3382, batch time: 0.10\n",
      "Epoch [3/5], Step [602/1875], Loss: 2.3206, batch time: 0.12\n",
      "Epoch [3/5], Step [603/1875], Loss: 2.2611, batch time: 0.10\n",
      "Epoch [3/5], Step [604/1875], Loss: 2.2322, batch time: 0.11\n",
      "Epoch [3/5], Step [605/1875], Loss: 2.1881, batch time: 0.10\n",
      "Epoch [3/5], Step [606/1875], Loss: 2.0701, batch time: 0.14\n",
      "Epoch [3/5], Step [607/1875], Loss: 2.2206, batch time: 0.09\n",
      "Epoch [3/5], Step [608/1875], Loss: 2.2963, batch time: 0.12\n",
      "Epoch [3/5], Step [609/1875], Loss: 2.2449, batch time: 0.13\n",
      "Epoch [3/5], Step [610/1875], Loss: 2.3328, batch time: 0.10\n",
      "Epoch [3/5], Step [611/1875], Loss: 2.2224, batch time: 0.11\n",
      "Epoch [3/5], Step [612/1875], Loss: 2.2220, batch time: 0.11\n",
      "Epoch [3/5], Step [613/1875], Loss: 2.3246, batch time: 0.13\n",
      "Epoch [3/5], Step [614/1875], Loss: 2.1661, batch time: 0.10\n",
      "Epoch [3/5], Step [615/1875], Loss: 2.2129, batch time: 0.09\n",
      "Epoch [3/5], Step [616/1875], Loss: 2.2928, batch time: 0.10\n",
      "Epoch [3/5], Step [617/1875], Loss: 2.2127, batch time: 0.10\n",
      "Epoch [3/5], Step [618/1875], Loss: 2.1815, batch time: 0.10\n",
      "Epoch [3/5], Step [619/1875], Loss: 2.2083, batch time: 0.10\n",
      "Epoch [3/5], Step [620/1875], Loss: 2.2557, batch time: 0.10\n",
      "Epoch [3/5], Step [621/1875], Loss: 2.1348, batch time: 0.09\n",
      "Epoch [3/5], Step [622/1875], Loss: 2.2119, batch time: 0.12\n",
      "Epoch [3/5], Step [623/1875], Loss: 2.2618, batch time: 0.11\n",
      "Epoch [3/5], Step [624/1875], Loss: 2.1743, batch time: 0.10\n",
      "Epoch [3/5], Step [625/1875], Loss: 2.2118, batch time: 0.16\n",
      "Epoch [3/5], Step [626/1875], Loss: 2.2338, batch time: 0.12\n",
      "Epoch [3/5], Step [627/1875], Loss: 2.2275, batch time: 0.11\n",
      "Epoch [3/5], Step [628/1875], Loss: 2.2365, batch time: 0.12\n",
      "Epoch [3/5], Step [629/1875], Loss: 2.1340, batch time: 0.13\n",
      "Epoch [3/5], Step [630/1875], Loss: 2.2365, batch time: 0.10\n",
      "Epoch [3/5], Step [631/1875], Loss: 2.2627, batch time: 0.10\n",
      "Epoch [3/5], Step [632/1875], Loss: 2.2325, batch time: 0.12\n",
      "Epoch [3/5], Step [633/1875], Loss: 2.3156, batch time: 0.10\n",
      "Epoch [3/5], Step [634/1875], Loss: 2.2146, batch time: 0.13\n",
      "Epoch [3/5], Step [635/1875], Loss: 2.1868, batch time: 0.10\n",
      "Epoch [3/5], Step [636/1875], Loss: 2.2022, batch time: 0.13\n",
      "Epoch [3/5], Step [637/1875], Loss: 2.1311, batch time: 0.10\n",
      "Epoch [3/5], Step [638/1875], Loss: 2.2881, batch time: 0.13\n",
      "Epoch [3/5], Step [639/1875], Loss: 2.1742, batch time: 0.10\n",
      "Epoch [3/5], Step [640/1875], Loss: 2.2841, batch time: 0.13\n",
      "Epoch [3/5], Step [641/1875], Loss: 2.1840, batch time: 0.14\n",
      "Epoch [3/5], Step [642/1875], Loss: 2.2507, batch time: 0.13\n",
      "Epoch [3/5], Step [643/1875], Loss: 2.1434, batch time: 0.10\n",
      "Epoch [3/5], Step [644/1875], Loss: 2.2060, batch time: 0.15\n",
      "Epoch [3/5], Step [645/1875], Loss: 2.2462, batch time: 0.10\n",
      "Epoch [3/5], Step [646/1875], Loss: 2.2641, batch time: 0.14\n",
      "Epoch [3/5], Step [647/1875], Loss: 2.2072, batch time: 0.13\n",
      "Epoch [3/5], Step [648/1875], Loss: 2.1383, batch time: 0.13\n",
      "Epoch [3/5], Step [649/1875], Loss: 2.1897, batch time: 0.10\n",
      "Epoch [3/5], Step [650/1875], Loss: 2.2375, batch time: -2.79\n",
      "Epoch [3/5], Step [651/1875], Loss: 2.1363, batch time: 0.12\n",
      "Epoch [3/5], Step [652/1875], Loss: 2.3536, batch time: 0.11\n",
      "Epoch [3/5], Step [653/1875], Loss: 2.3813, batch time: 0.15\n",
      "Epoch [3/5], Step [654/1875], Loss: 2.2393, batch time: 0.10\n",
      "Epoch [3/5], Step [655/1875], Loss: 2.2509, batch time: 0.10\n",
      "Epoch [3/5], Step [656/1875], Loss: 2.1902, batch time: 0.13\n",
      "Epoch [3/5], Step [657/1875], Loss: 2.1817, batch time: 0.14\n",
      "Epoch [3/5], Step [658/1875], Loss: 2.1376, batch time: 0.10\n",
      "Epoch [3/5], Step [659/1875], Loss: 2.2173, batch time: 0.11\n",
      "Epoch [3/5], Step [660/1875], Loss: 2.3949, batch time: 0.09\n",
      "Epoch [3/5], Step [661/1875], Loss: 2.2529, batch time: 0.10\n",
      "Epoch [3/5], Step [662/1875], Loss: 2.2932, batch time: 0.10\n",
      "Epoch [3/5], Step [663/1875], Loss: 2.1344, batch time: 0.13\n",
      "Epoch [3/5], Step [664/1875], Loss: 2.2125, batch time: 0.13\n",
      "Epoch [3/5], Step [665/1875], Loss: 2.2494, batch time: 0.18\n",
      "Epoch [3/5], Step [666/1875], Loss: 2.2407, batch time: 0.10\n",
      "Epoch [3/5], Step [667/1875], Loss: 2.1970, batch time: 0.12\n",
      "Epoch [3/5], Step [668/1875], Loss: 2.1085, batch time: 0.10\n",
      "Epoch [3/5], Step [669/1875], Loss: 2.1402, batch time: 0.10\n",
      "Epoch [3/5], Step [670/1875], Loss: 2.1828, batch time: 0.10\n",
      "Epoch [3/5], Step [671/1875], Loss: 2.1652, batch time: 0.10\n",
      "Epoch [3/5], Step [672/1875], Loss: 2.2003, batch time: 0.14\n",
      "Epoch [3/5], Step [673/1875], Loss: 2.4125, batch time: 0.20\n",
      "Epoch [3/5], Step [674/1875], Loss: 2.3514, batch time: 0.12\n",
      "Epoch [3/5], Step [675/1875], Loss: 2.2756, batch time: 0.10\n",
      "Epoch [3/5], Step [676/1875], Loss: 2.1351, batch time: 0.12\n",
      "Epoch [3/5], Step [677/1875], Loss: 2.2605, batch time: 0.23\n",
      "Epoch [3/5], Step [678/1875], Loss: 2.3286, batch time: 0.12\n",
      "Epoch [3/5], Step [679/1875], Loss: 2.1843, batch time: 0.11\n",
      "Epoch [3/5], Step [680/1875], Loss: 2.1237, batch time: 0.10\n",
      "Epoch [3/5], Step [681/1875], Loss: 2.1840, batch time: 0.10\n",
      "Epoch [3/5], Step [682/1875], Loss: 2.1676, batch time: 0.13\n",
      "Epoch [3/5], Step [683/1875], Loss: 2.2356, batch time: 0.13\n",
      "Epoch [3/5], Step [684/1875], Loss: 2.2021, batch time: 0.14\n",
      "Epoch [3/5], Step [685/1875], Loss: 2.1873, batch time: 0.09\n",
      "Epoch [3/5], Step [686/1875], Loss: 2.1428, batch time: 0.14\n",
      "Epoch [3/5], Step [687/1875], Loss: 2.2024, batch time: 0.12\n",
      "Epoch [3/5], Step [688/1875], Loss: 2.3198, batch time: 0.10\n",
      "Epoch [3/5], Step [689/1875], Loss: 2.2074, batch time: 0.10\n",
      "Epoch [3/5], Step [690/1875], Loss: 2.2450, batch time: 0.12\n",
      "Epoch [3/5], Step [691/1875], Loss: 2.1036, batch time: 0.10\n",
      "Epoch [3/5], Step [692/1875], Loss: 2.3016, batch time: 0.14\n",
      "Epoch [3/5], Step [693/1875], Loss: 2.2841, batch time: 0.10\n",
      "Epoch [3/5], Step [694/1875], Loss: 2.2994, batch time: 0.10\n",
      "Epoch [3/5], Step [695/1875], Loss: 2.2228, batch time: 0.11\n",
      "Epoch [3/5], Step [696/1875], Loss: 2.1615, batch time: 0.10\n",
      "Epoch [3/5], Step [697/1875], Loss: 2.2092, batch time: 0.10\n",
      "Epoch [3/5], Step [698/1875], Loss: 2.1354, batch time: 0.10\n",
      "Epoch [3/5], Step [699/1875], Loss: 2.2528, batch time: 0.11\n",
      "Epoch [3/5], Step [700/1875], Loss: 2.2685, batch time: 0.12\n",
      "Epoch [3/5], Step [701/1875], Loss: 2.1985, batch time: 0.15\n",
      "Epoch [3/5], Step [702/1875], Loss: 2.3098, batch time: 0.12\n",
      "Epoch [3/5], Step [703/1875], Loss: 2.1054, batch time: 0.10\n",
      "Epoch [3/5], Step [704/1875], Loss: 2.3194, batch time: 0.10\n",
      "Epoch [3/5], Step [705/1875], Loss: 2.1984, batch time: 0.10\n",
      "Epoch [3/5], Step [706/1875], Loss: 2.2789, batch time: 0.14\n",
      "Epoch [3/5], Step [707/1875], Loss: 2.2102, batch time: 0.11\n",
      "Epoch [3/5], Step [708/1875], Loss: 2.2485, batch time: 0.10\n",
      "Epoch [3/5], Step [709/1875], Loss: 2.1396, batch time: 0.13\n",
      "Epoch [3/5], Step [710/1875], Loss: 2.1707, batch time: 0.10\n",
      "Epoch [3/5], Step [711/1875], Loss: 2.3001, batch time: 0.09\n",
      "Epoch [3/5], Step [712/1875], Loss: 2.3586, batch time: 0.10\n",
      "Epoch [3/5], Step [713/1875], Loss: 2.2588, batch time: 0.17\n",
      "Epoch [3/5], Step [714/1875], Loss: 2.1089, batch time: 0.13\n",
      "Epoch [3/5], Step [715/1875], Loss: 2.3372, batch time: 0.10\n",
      "Epoch [3/5], Step [716/1875], Loss: 2.2606, batch time: 0.12\n",
      "Epoch [3/5], Step [717/1875], Loss: 2.1815, batch time: 0.11\n",
      "Epoch [3/5], Step [718/1875], Loss: 2.2759, batch time: 0.12\n",
      "Epoch [3/5], Step [719/1875], Loss: 2.2959, batch time: 0.17\n",
      "Epoch [3/5], Step [720/1875], Loss: 2.2421, batch time: 0.13\n",
      "Epoch [3/5], Step [721/1875], Loss: 2.1954, batch time: 0.09\n",
      "Epoch [3/5], Step [722/1875], Loss: 2.2223, batch time: 0.10\n",
      "Epoch [3/5], Step [723/1875], Loss: 2.0442, batch time: 0.13\n",
      "Epoch [3/5], Step [724/1875], Loss: 2.1918, batch time: 0.13\n",
      "Epoch [3/5], Step [725/1875], Loss: 2.2693, batch time: 0.13\n",
      "Epoch [3/5], Step [726/1875], Loss: 2.1970, batch time: 0.10\n",
      "Epoch [3/5], Step [727/1875], Loss: 2.3335, batch time: 0.10\n",
      "Epoch [3/5], Step [728/1875], Loss: 2.4190, batch time: 0.14\n",
      "Epoch [3/5], Step [729/1875], Loss: 2.2356, batch time: 0.10\n",
      "Epoch [3/5], Step [730/1875], Loss: 2.1794, batch time: 0.14\n",
      "Epoch [3/5], Step [731/1875], Loss: 2.2013, batch time: 0.10\n",
      "Epoch [3/5], Step [732/1875], Loss: 2.1834, batch time: 0.10\n",
      "Epoch [3/5], Step [733/1875], Loss: 2.1456, batch time: 0.10\n",
      "Epoch [3/5], Step [734/1875], Loss: 2.1746, batch time: 0.10\n",
      "Epoch [3/5], Step [735/1875], Loss: 2.2004, batch time: 0.09\n",
      "Epoch [3/5], Step [736/1875], Loss: 2.2083, batch time: 0.10\n",
      "Epoch [3/5], Step [737/1875], Loss: 2.1479, batch time: 0.10\n",
      "Epoch [3/5], Step [738/1875], Loss: 2.1412, batch time: 0.16\n",
      "Epoch [3/5], Step [739/1875], Loss: 2.2085, batch time: 0.10\n",
      "Epoch [3/5], Step [740/1875], Loss: 2.1776, batch time: 0.10\n",
      "Epoch [3/5], Step [741/1875], Loss: 2.1198, batch time: 0.22\n",
      "Epoch [3/5], Step [742/1875], Loss: 2.2953, batch time: 0.10\n",
      "Epoch [3/5], Step [743/1875], Loss: 2.4445, batch time: 0.10\n",
      "Epoch [3/5], Step [744/1875], Loss: 2.2482, batch time: 0.10\n",
      "Epoch [3/5], Step [745/1875], Loss: 2.1763, batch time: 0.13\n",
      "Epoch [3/5], Step [746/1875], Loss: 2.1189, batch time: 0.10\n",
      "Epoch [3/5], Step [747/1875], Loss: 2.2065, batch time: 0.10\n",
      "Epoch [3/5], Step [748/1875], Loss: 2.2762, batch time: 0.10\n",
      "Epoch [3/5], Step [749/1875], Loss: 2.2088, batch time: 0.16\n",
      "Epoch [3/5], Step [750/1875], Loss: 2.2079, batch time: 0.09\n",
      "Epoch [3/5], Step [751/1875], Loss: 2.1330, batch time: 0.11\n",
      "Epoch [3/5], Step [752/1875], Loss: 2.1428, batch time: 0.10\n",
      "Epoch [3/5], Step [753/1875], Loss: 2.1849, batch time: 0.10\n",
      "Epoch [3/5], Step [754/1875], Loss: 2.2687, batch time: 0.09\n",
      "Epoch [3/5], Step [755/1875], Loss: 2.1564, batch time: 0.14\n",
      "Epoch [3/5], Step [756/1875], Loss: 2.1973, batch time: 0.10\n",
      "Epoch [3/5], Step [757/1875], Loss: 2.2305, batch time: 0.13\n",
      "Epoch [3/5], Step [758/1875], Loss: 2.2285, batch time: 0.13\n",
      "Epoch [3/5], Step [759/1875], Loss: 2.1877, batch time: 0.10\n",
      "Epoch [3/5], Step [760/1875], Loss: 2.2478, batch time: 0.12\n",
      "Epoch [3/5], Step [761/1875], Loss: 2.0957, batch time: 0.12\n",
      "Epoch [3/5], Step [762/1875], Loss: 2.3233, batch time: 0.14\n",
      "Epoch [3/5], Step [763/1875], Loss: 2.2446, batch time: 0.19\n",
      "Epoch [3/5], Step [764/1875], Loss: 2.1675, batch time: 0.13\n",
      "Epoch [3/5], Step [765/1875], Loss: 2.2559, batch time: 0.15\n",
      "Epoch [3/5], Step [766/1875], Loss: 2.3356, batch time: 0.20\n",
      "Epoch [3/5], Step [767/1875], Loss: 2.3037, batch time: 0.12\n",
      "Epoch [3/5], Step [768/1875], Loss: 2.1648, batch time: 0.14\n",
      "Epoch [3/5], Step [769/1875], Loss: 2.2095, batch time: 0.12\n",
      "Epoch [3/5], Step [770/1875], Loss: 2.1470, batch time: 0.13\n",
      "Epoch [3/5], Step [771/1875], Loss: 2.1253, batch time: 0.14\n",
      "Epoch [3/5], Step [772/1875], Loss: 2.2884, batch time: 0.10\n",
      "Epoch [3/5], Step [773/1875], Loss: 2.1851, batch time: 0.10\n",
      "Epoch [3/5], Step [774/1875], Loss: 2.3116, batch time: 0.14\n",
      "Epoch [3/5], Step [775/1875], Loss: 2.2342, batch time: 0.12\n",
      "Epoch [3/5], Step [776/1875], Loss: 2.2440, batch time: 0.13\n",
      "Epoch [3/5], Step [777/1875], Loss: 2.3681, batch time: 0.11\n",
      "Epoch [3/5], Step [778/1875], Loss: 2.2025, batch time: 0.13\n",
      "Epoch [3/5], Step [779/1875], Loss: 2.2511, batch time: 0.12\n",
      "Epoch [3/5], Step [780/1875], Loss: 2.2213, batch time: 0.10\n",
      "Epoch [3/5], Step [781/1875], Loss: 2.2242, batch time: 0.12\n",
      "Epoch [3/5], Step [782/1875], Loss: 2.1601, batch time: 0.10\n",
      "Epoch [3/5], Step [783/1875], Loss: 2.2491, batch time: 0.10\n",
      "Epoch [3/5], Step [784/1875], Loss: 2.2205, batch time: 0.11\n",
      "Epoch [3/5], Step [785/1875], Loss: 2.2281, batch time: 0.14\n",
      "Epoch [3/5], Step [786/1875], Loss: 2.2672, batch time: 0.13\n",
      "Epoch [3/5], Step [787/1875], Loss: 2.1473, batch time: 0.11\n",
      "Epoch [3/5], Step [788/1875], Loss: 2.2771, batch time: 0.09\n",
      "Epoch [3/5], Step [789/1875], Loss: 1.9941, batch time: 0.10\n",
      "Epoch [3/5], Step [790/1875], Loss: 2.0369, batch time: 0.11\n",
      "Epoch [3/5], Step [791/1875], Loss: 2.2325, batch time: 0.18\n",
      "Epoch [3/5], Step [792/1875], Loss: 2.2690, batch time: 0.09\n",
      "Epoch [3/5], Step [793/1875], Loss: 2.1487, batch time: 0.12\n",
      "Epoch [3/5], Step [794/1875], Loss: 2.2930, batch time: 0.13\n",
      "Epoch [3/5], Step [795/1875], Loss: 2.2146, batch time: 0.09\n",
      "Epoch [3/5], Step [796/1875], Loss: 2.1828, batch time: 0.10\n",
      "Epoch [3/5], Step [797/1875], Loss: 2.3451, batch time: 0.10\n",
      "Epoch [3/5], Step [798/1875], Loss: 2.1488, batch time: 0.10\n",
      "Epoch [3/5], Step [799/1875], Loss: 2.2298, batch time: 0.10\n",
      "Epoch [3/5], Step [800/1875], Loss: 2.2141, batch time: 0.10\n",
      "Epoch [3/5], Step [801/1875], Loss: 2.1961, batch time: 0.09\n",
      "Epoch [3/5], Step [802/1875], Loss: 2.2057, batch time: 0.10\n",
      "Epoch [3/5], Step [803/1875], Loss: 2.1915, batch time: 0.10\n",
      "Epoch [3/5], Step [804/1875], Loss: 2.2782, batch time: 0.16\n",
      "Epoch [3/5], Step [805/1875], Loss: 2.2428, batch time: 0.10\n",
      "Epoch [3/5], Step [806/1875], Loss: 2.1995, batch time: 0.11\n",
      "Epoch [3/5], Step [807/1875], Loss: 2.1573, batch time: 0.10\n",
      "Epoch [3/5], Step [808/1875], Loss: 2.2545, batch time: 0.10\n",
      "Epoch [3/5], Step [809/1875], Loss: 2.1379, batch time: 0.09\n",
      "Epoch [3/5], Step [810/1875], Loss: 2.2913, batch time: 0.09\n",
      "Epoch [3/5], Step [811/1875], Loss: 2.2210, batch time: 0.10\n",
      "Epoch [3/5], Step [812/1875], Loss: 2.3176, batch time: 0.10\n",
      "Epoch [3/5], Step [813/1875], Loss: 2.2194, batch time: 0.09\n",
      "Epoch [3/5], Step [814/1875], Loss: 2.2713, batch time: 0.10\n",
      "Epoch [3/5], Step [815/1875], Loss: 2.1624, batch time: 0.11\n",
      "Epoch [3/5], Step [816/1875], Loss: 2.2117, batch time: 0.16\n",
      "Epoch [3/5], Step [817/1875], Loss: 2.2262, batch time: 0.09\n",
      "Epoch [3/5], Step [818/1875], Loss: 2.2021, batch time: 0.10\n",
      "Epoch [3/5], Step [819/1875], Loss: 2.2372, batch time: 0.10\n",
      "Epoch [3/5], Step [820/1875], Loss: 2.1867, batch time: 0.13\n",
      "Epoch [3/5], Step [821/1875], Loss: 2.1898, batch time: 0.11\n",
      "Epoch [3/5], Step [822/1875], Loss: 2.2724, batch time: 0.10\n",
      "Epoch [3/5], Step [823/1875], Loss: 2.0982, batch time: 0.10\n",
      "Epoch [3/5], Step [824/1875], Loss: 2.1332, batch time: 0.10\n",
      "Epoch [3/5], Step [825/1875], Loss: 2.2938, batch time: 0.10\n",
      "Epoch [3/5], Step [826/1875], Loss: 2.2674, batch time: 0.10\n",
      "Epoch [3/5], Step [827/1875], Loss: 2.2134, batch time: 0.10\n",
      "Epoch [3/5], Step [828/1875], Loss: 2.2566, batch time: 0.09\n",
      "Epoch [3/5], Step [829/1875], Loss: 2.2968, batch time: 0.09\n",
      "Epoch [3/5], Step [830/1875], Loss: 2.2209, batch time: 0.13\n",
      "Epoch [3/5], Step [831/1875], Loss: 2.2784, batch time: 0.10\n",
      "Epoch [3/5], Step [832/1875], Loss: 2.1455, batch time: 0.12\n",
      "Epoch [3/5], Step [833/1875], Loss: 2.1074, batch time: 0.16\n",
      "Epoch [3/5], Step [834/1875], Loss: 2.1879, batch time: 0.11\n",
      "Epoch [3/5], Step [835/1875], Loss: 2.0851, batch time: 0.11\n",
      "Epoch [3/5], Step [836/1875], Loss: 2.2101, batch time: 0.10\n",
      "Epoch [3/5], Step [837/1875], Loss: 2.2140, batch time: 0.10\n",
      "Epoch [3/5], Step [838/1875], Loss: 2.1679, batch time: 0.12\n",
      "Epoch [3/5], Step [839/1875], Loss: 2.2309, batch time: 0.22\n",
      "Epoch [3/5], Step [840/1875], Loss: 2.1569, batch time: 0.10\n",
      "Epoch [3/5], Step [841/1875], Loss: 2.0956, batch time: 0.09\n",
      "Epoch [3/5], Step [842/1875], Loss: 2.0313, batch time: 0.10\n",
      "Epoch [3/5], Step [843/1875], Loss: 2.2124, batch time: 0.11\n",
      "Epoch [3/5], Step [844/1875], Loss: 2.2819, batch time: 0.10\n",
      "Epoch [3/5], Step [845/1875], Loss: 2.2463, batch time: 0.10\n",
      "Epoch [3/5], Step [846/1875], Loss: 2.2777, batch time: 0.10\n",
      "Epoch [3/5], Step [847/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [3/5], Step [848/1875], Loss: 2.2301, batch time: 0.10\n",
      "Epoch [3/5], Step [849/1875], Loss: 2.2742, batch time: 0.10\n",
      "Epoch [3/5], Step [850/1875], Loss: 2.1863, batch time: 0.10\n",
      "Epoch [3/5], Step [851/1875], Loss: 2.1886, batch time: 0.12\n",
      "Epoch [3/5], Step [852/1875], Loss: 2.1945, batch time: 0.11\n",
      "Epoch [3/5], Step [853/1875], Loss: 2.1575, batch time: 0.09\n",
      "Epoch [3/5], Step [854/1875], Loss: 2.1210, batch time: 0.10\n",
      "Epoch [3/5], Step [855/1875], Loss: 2.2666, batch time: 0.10\n",
      "Epoch [3/5], Step [856/1875], Loss: 2.2087, batch time: 0.10\n",
      "Epoch [3/5], Step [857/1875], Loss: 2.1648, batch time: 0.10\n",
      "Epoch [3/5], Step [858/1875], Loss: 2.3077, batch time: 0.09\n",
      "Epoch [3/5], Step [859/1875], Loss: 2.1019, batch time: 0.11\n",
      "Epoch [3/5], Step [860/1875], Loss: 2.0633, batch time: 0.09\n",
      "Epoch [3/5], Step [861/1875], Loss: 2.2688, batch time: 0.10\n",
      "Epoch [3/5], Step [862/1875], Loss: 2.3662, batch time: 0.10\n",
      "Epoch [3/5], Step [863/1875], Loss: 2.1239, batch time: 0.10\n",
      "Epoch [3/5], Step [864/1875], Loss: 2.1496, batch time: 0.09\n",
      "Epoch [3/5], Step [865/1875], Loss: 2.2277, batch time: 0.13\n",
      "Epoch [3/5], Step [866/1875], Loss: 2.2287, batch time: 0.09\n",
      "Epoch [3/5], Step [867/1875], Loss: 2.2499, batch time: 0.11\n",
      "Epoch [3/5], Step [868/1875], Loss: 2.1076, batch time: 0.12\n",
      "Epoch [3/5], Step [869/1875], Loss: 2.3199, batch time: 0.12\n",
      "Epoch [3/5], Step [870/1875], Loss: 2.1971, batch time: 0.17\n",
      "Epoch [3/5], Step [871/1875], Loss: 2.2090, batch time: 0.19\n",
      "Epoch [3/5], Step [872/1875], Loss: 2.2447, batch time: 0.10\n",
      "Epoch [3/5], Step [873/1875], Loss: 2.1427, batch time: 0.11\n",
      "Epoch [3/5], Step [874/1875], Loss: 2.3746, batch time: 0.12\n",
      "Epoch [3/5], Step [875/1875], Loss: 2.1956, batch time: 0.10\n",
      "Epoch [3/5], Step [876/1875], Loss: 2.2721, batch time: 0.10\n",
      "Epoch [3/5], Step [877/1875], Loss: 2.1904, batch time: 0.09\n",
      "Epoch [3/5], Step [878/1875], Loss: 2.2632, batch time: 0.10\n",
      "Epoch [3/5], Step [879/1875], Loss: 2.1787, batch time: 0.09\n",
      "Epoch [3/5], Step [880/1875], Loss: 2.2955, batch time: 0.11\n",
      "Epoch [3/5], Step [881/1875], Loss: 2.2058, batch time: 0.15\n",
      "Epoch [3/5], Step [882/1875], Loss: 2.1500, batch time: 0.10\n",
      "Epoch [3/5], Step [883/1875], Loss: 2.2723, batch time: 0.09\n",
      "Epoch [3/5], Step [884/1875], Loss: 2.2466, batch time: 0.10\n",
      "Epoch [3/5], Step [885/1875], Loss: 2.2212, batch time: 0.14\n",
      "Epoch [3/5], Step [886/1875], Loss: 2.2802, batch time: 0.15\n",
      "Epoch [3/5], Step [887/1875], Loss: 2.1668, batch time: 0.09\n",
      "Epoch [3/5], Step [888/1875], Loss: 2.1688, batch time: 0.09\n",
      "Epoch [3/5], Step [889/1875], Loss: 2.2571, batch time: 0.10\n",
      "Epoch [3/5], Step [890/1875], Loss: 2.1715, batch time: 0.09\n",
      "Epoch [3/5], Step [891/1875], Loss: 2.3580, batch time: 0.09\n",
      "Epoch [3/5], Step [892/1875], Loss: 2.2209, batch time: 0.10\n",
      "Epoch [3/5], Step [893/1875], Loss: 2.1218, batch time: 0.09\n",
      "Epoch [3/5], Step [894/1875], Loss: 2.2043, batch time: 0.09\n",
      "Epoch [3/5], Step [895/1875], Loss: 2.2343, batch time: 0.10\n",
      "Epoch [3/5], Step [896/1875], Loss: 2.2635, batch time: 0.09\n",
      "Epoch [3/5], Step [897/1875], Loss: 2.2562, batch time: 0.10\n",
      "Epoch [3/5], Step [898/1875], Loss: 2.1802, batch time: 0.12\n",
      "Epoch [3/5], Step [899/1875], Loss: 2.0946, batch time: 0.09\n",
      "Epoch [3/5], Step [900/1875], Loss: 2.0965, batch time: 0.09\n",
      "Epoch [3/5], Step [901/1875], Loss: 2.2310, batch time: 0.10\n",
      "Epoch [3/5], Step [902/1875], Loss: 2.2319, batch time: 0.12\n",
      "Epoch [3/5], Step [903/1875], Loss: 2.2429, batch time: 0.14\n",
      "Epoch [3/5], Step [904/1875], Loss: 2.3102, batch time: 0.10\n",
      "Epoch [3/5], Step [905/1875], Loss: 2.1921, batch time: 0.18\n",
      "Epoch [3/5], Step [906/1875], Loss: 2.2362, batch time: 0.20\n",
      "Epoch [3/5], Step [907/1875], Loss: 2.2047, batch time: 0.10\n",
      "Epoch [3/5], Step [908/1875], Loss: 2.1566, batch time: 0.09\n",
      "Epoch [3/5], Step [909/1875], Loss: 2.2362, batch time: 0.09\n",
      "Epoch [3/5], Step [910/1875], Loss: 2.1221, batch time: 0.10\n",
      "Epoch [3/5], Step [911/1875], Loss: 2.1787, batch time: 0.09\n",
      "Epoch [3/5], Step [912/1875], Loss: 2.2340, batch time: 0.09\n",
      "Epoch [3/5], Step [913/1875], Loss: 2.2567, batch time: 0.11\n",
      "Epoch [3/5], Step [914/1875], Loss: 2.0834, batch time: 0.10\n",
      "Epoch [3/5], Step [915/1875], Loss: 2.2555, batch time: 0.09\n",
      "Epoch [3/5], Step [916/1875], Loss: 2.1423, batch time: 0.10\n",
      "Epoch [3/5], Step [917/1875], Loss: 2.1318, batch time: 0.09\n",
      "Epoch [3/5], Step [918/1875], Loss: 2.2852, batch time: 0.13\n",
      "Epoch [3/5], Step [919/1875], Loss: 2.1200, batch time: 0.09\n",
      "Epoch [3/5], Step [920/1875], Loss: 2.2995, batch time: 0.09\n",
      "Epoch [3/5], Step [921/1875], Loss: 2.1807, batch time: 0.10\n",
      "Epoch [3/5], Step [922/1875], Loss: 2.1529, batch time: 0.13\n",
      "Epoch [3/5], Step [923/1875], Loss: 2.3011, batch time: 0.10\n",
      "Epoch [3/5], Step [924/1875], Loss: 2.2143, batch time: 0.10\n",
      "Epoch [3/5], Step [925/1875], Loss: 2.1002, batch time: 0.10\n",
      "Epoch [3/5], Step [926/1875], Loss: 2.1941, batch time: 0.13\n",
      "Epoch [3/5], Step [927/1875], Loss: 2.2317, batch time: 0.12\n",
      "Epoch [3/5], Step [928/1875], Loss: 2.2017, batch time: 0.10\n",
      "Epoch [3/5], Step [929/1875], Loss: 2.1704, batch time: 0.25\n",
      "Epoch [3/5], Step [930/1875], Loss: 2.2981, batch time: -2.83\n",
      "Epoch [3/5], Step [931/1875], Loss: 2.3253, batch time: 0.17\n",
      "Epoch [3/5], Step [932/1875], Loss: 2.1684, batch time: 0.10\n",
      "Epoch [3/5], Step [933/1875], Loss: 2.2437, batch time: 0.10\n",
      "Epoch [3/5], Step [934/1875], Loss: 2.2519, batch time: 0.10\n",
      "Epoch [3/5], Step [935/1875], Loss: 2.2570, batch time: 0.09\n",
      "Epoch [3/5], Step [936/1875], Loss: 2.2517, batch time: 0.09\n",
      "Epoch [3/5], Step [937/1875], Loss: 2.2277, batch time: 0.09\n",
      "Epoch [3/5], Step [938/1875], Loss: 2.2633, batch time: 0.09\n",
      "Epoch [3/5], Step [939/1875], Loss: 2.2422, batch time: 0.14\n",
      "Epoch [3/5], Step [940/1875], Loss: 2.3141, batch time: 0.09\n",
      "Epoch [3/5], Step [941/1875], Loss: 2.2998, batch time: 0.09\n",
      "Epoch [3/5], Step [942/1875], Loss: 2.3238, batch time: 0.10\n",
      "Epoch [3/5], Step [943/1875], Loss: 2.3511, batch time: 0.10\n",
      "Epoch [3/5], Step [944/1875], Loss: 2.2291, batch time: 0.10\n",
      "Epoch [3/5], Step [945/1875], Loss: 2.1770, batch time: 0.10\n",
      "Epoch [3/5], Step [946/1875], Loss: 2.1561, batch time: 0.10\n",
      "Epoch [3/5], Step [947/1875], Loss: 2.2694, batch time: 0.11\n",
      "Epoch [3/5], Step [948/1875], Loss: 2.1964, batch time: 0.14\n",
      "Epoch [3/5], Step [949/1875], Loss: 2.2446, batch time: 0.11\n",
      "Epoch [3/5], Step [950/1875], Loss: 2.1876, batch time: 0.16\n",
      "Epoch [3/5], Step [951/1875], Loss: 2.1300, batch time: 0.09\n",
      "Epoch [3/5], Step [952/1875], Loss: 2.2109, batch time: 0.10\n",
      "Epoch [3/5], Step [953/1875], Loss: 2.2017, batch time: 0.11\n",
      "Epoch [3/5], Step [954/1875], Loss: 2.1448, batch time: 0.10\n",
      "Epoch [3/5], Step [955/1875], Loss: 2.3266, batch time: 0.10\n",
      "Epoch [3/5], Step [956/1875], Loss: 2.0881, batch time: 0.10\n",
      "Epoch [3/5], Step [957/1875], Loss: 2.3919, batch time: 0.10\n",
      "Epoch [3/5], Step [958/1875], Loss: 2.2073, batch time: 0.13\n",
      "Epoch [3/5], Step [959/1875], Loss: 2.1042, batch time: 0.10\n",
      "Epoch [3/5], Step [960/1875], Loss: 2.2116, batch time: 0.09\n",
      "Epoch [3/5], Step [961/1875], Loss: 2.2885, batch time: 0.10\n",
      "Epoch [3/5], Step [962/1875], Loss: 2.1961, batch time: 0.09\n",
      "Epoch [3/5], Step [963/1875], Loss: 2.2018, batch time: 0.10\n",
      "Epoch [3/5], Step [964/1875], Loss: 2.1682, batch time: 0.11\n",
      "Epoch [3/5], Step [965/1875], Loss: 2.2645, batch time: 0.16\n",
      "Epoch [3/5], Step [966/1875], Loss: 2.2817, batch time: 0.13\n",
      "Epoch [3/5], Step [967/1875], Loss: 2.2584, batch time: 0.09\n",
      "Epoch [3/5], Step [968/1875], Loss: 2.1509, batch time: 0.10\n",
      "Epoch [3/5], Step [969/1875], Loss: 2.2879, batch time: 0.10\n",
      "Epoch [3/5], Step [970/1875], Loss: 2.1543, batch time: 0.09\n",
      "Epoch [3/5], Step [971/1875], Loss: 2.1884, batch time: 0.09\n",
      "Epoch [3/5], Step [972/1875], Loss: 2.1104, batch time: 0.14\n",
      "Epoch [3/5], Step [973/1875], Loss: 2.2605, batch time: 0.10\n",
      "Epoch [3/5], Step [974/1875], Loss: 2.2687, batch time: 0.11\n",
      "Epoch [3/5], Step [975/1875], Loss: 2.1057, batch time: 0.10\n",
      "Epoch [3/5], Step [976/1875], Loss: 2.1569, batch time: 0.10\n",
      "Epoch [3/5], Step [977/1875], Loss: 2.2792, batch time: 0.11\n",
      "Epoch [3/5], Step [978/1875], Loss: 2.2289, batch time: 0.09\n",
      "Epoch [3/5], Step [979/1875], Loss: 2.1455, batch time: 0.12\n",
      "Epoch [3/5], Step [980/1875], Loss: 2.3210, batch time: 0.10\n",
      "Epoch [3/5], Step [981/1875], Loss: 2.2312, batch time: 0.09\n",
      "Epoch [3/5], Step [982/1875], Loss: 2.1150, batch time: 0.10\n",
      "Epoch [3/5], Step [983/1875], Loss: 2.2643, batch time: 0.10\n",
      "Epoch [3/5], Step [984/1875], Loss: 2.1533, batch time: 0.11\n",
      "Epoch [3/5], Step [985/1875], Loss: 2.2684, batch time: 0.16\n",
      "Epoch [3/5], Step [986/1875], Loss: 2.1282, batch time: 0.09\n",
      "Epoch [3/5], Step [987/1875], Loss: 2.3162, batch time: 0.09\n",
      "Epoch [3/5], Step [988/1875], Loss: 2.2627, batch time: 0.18\n",
      "Epoch [3/5], Step [989/1875], Loss: 2.1943, batch time: 0.15\n",
      "Epoch [3/5], Step [990/1875], Loss: 2.0754, batch time: 0.12\n",
      "Epoch [3/5], Step [991/1875], Loss: 2.1501, batch time: 0.09\n",
      "Epoch [3/5], Step [992/1875], Loss: 2.1823, batch time: 0.09\n",
      "Epoch [3/5], Step [993/1875], Loss: 2.1997, batch time: 0.10\n",
      "Epoch [3/5], Step [994/1875], Loss: 2.2620, batch time: 0.10\n",
      "Epoch [3/5], Step [995/1875], Loss: 2.2493, batch time: 0.19\n",
      "Epoch [3/5], Step [996/1875], Loss: 2.1163, batch time: 0.10\n",
      "Epoch [3/5], Step [997/1875], Loss: 2.2640, batch time: 0.09\n",
      "Epoch [3/5], Step [998/1875], Loss: 2.2009, batch time: 0.14\n",
      "Epoch [3/5], Step [999/1875], Loss: 2.2320, batch time: 0.09\n",
      "Epoch [3/5], Step [1000/1875], Loss: 2.2121, batch time: 0.09\n",
      "Epoch [3/5], Step [1001/1875], Loss: 2.1794, batch time: 0.09\n",
      "Epoch [3/5], Step [1002/1875], Loss: 2.2148, batch time: 0.10\n",
      "Epoch [3/5], Step [1003/1875], Loss: 2.2836, batch time: 0.10\n",
      "Epoch [3/5], Step [1004/1875], Loss: 2.2562, batch time: 0.10\n",
      "Epoch [3/5], Step [1005/1875], Loss: 2.1553, batch time: 0.11\n",
      "Epoch [3/5], Step [1006/1875], Loss: 2.2552, batch time: 0.10\n",
      "Epoch [3/5], Step [1007/1875], Loss: 2.3102, batch time: 0.10\n",
      "Epoch [3/5], Step [1008/1875], Loss: 2.0377, batch time: 0.13\n",
      "Epoch [3/5], Step [1009/1875], Loss: 2.2101, batch time: 0.10\n",
      "Epoch [3/5], Step [1010/1875], Loss: 2.2551, batch time: 0.10\n",
      "Epoch [3/5], Step [1011/1875], Loss: 2.2439, batch time: 0.16\n",
      "Epoch [3/5], Step [1012/1875], Loss: 2.2226, batch time: 0.10\n",
      "Epoch [3/5], Step [1013/1875], Loss: 2.2274, batch time: 0.13\n",
      "Epoch [3/5], Step [1014/1875], Loss: 2.2321, batch time: 0.10\n",
      "Epoch [3/5], Step [1015/1875], Loss: 2.1277, batch time: 0.13\n",
      "Epoch [3/5], Step [1016/1875], Loss: 2.1197, batch time: 0.14\n",
      "Epoch [3/5], Step [1017/1875], Loss: 2.2438, batch time: 0.13\n",
      "Epoch [3/5], Step [1018/1875], Loss: 2.0883, batch time: 0.14\n",
      "Epoch [3/5], Step [1019/1875], Loss: 2.1019, batch time: 0.14\n",
      "Epoch [3/5], Step [1020/1875], Loss: 2.2325, batch time: 0.10\n",
      "Epoch [3/5], Step [1021/1875], Loss: 2.3375, batch time: 0.10\n",
      "Epoch [3/5], Step [1022/1875], Loss: 2.1823, batch time: 0.12\n",
      "Epoch [3/5], Step [1023/1875], Loss: 2.1181, batch time: 0.12\n",
      "Epoch [3/5], Step [1024/1875], Loss: 2.1562, batch time: 0.10\n",
      "Epoch [3/5], Step [1025/1875], Loss: 2.1326, batch time: 0.10\n",
      "Epoch [3/5], Step [1026/1875], Loss: 2.2460, batch time: 0.09\n",
      "Epoch [3/5], Step [1027/1875], Loss: 2.3151, batch time: 0.10\n",
      "Epoch [3/5], Step [1028/1875], Loss: 2.3867, batch time: 0.10\n",
      "Epoch [3/5], Step [1029/1875], Loss: 2.0977, batch time: 0.10\n",
      "Epoch [3/5], Step [1030/1875], Loss: 2.2370, batch time: 0.15\n",
      "Epoch [3/5], Step [1031/1875], Loss: 2.1393, batch time: 0.10\n",
      "Epoch [3/5], Step [1032/1875], Loss: 2.0948, batch time: 0.10\n",
      "Epoch [3/5], Step [1033/1875], Loss: 2.2040, batch time: 0.11\n",
      "Epoch [3/5], Step [1034/1875], Loss: 2.1811, batch time: 0.11\n",
      "Epoch [3/5], Step [1035/1875], Loss: 2.1680, batch time: 0.11\n",
      "Epoch [3/5], Step [1036/1875], Loss: 2.2068, batch time: 0.10\n",
      "Epoch [3/5], Step [1037/1875], Loss: 2.0768, batch time: 0.10\n",
      "Epoch [3/5], Step [1038/1875], Loss: 2.1553, batch time: 0.10\n",
      "Epoch [3/5], Step [1039/1875], Loss: 2.3440, batch time: 0.26\n",
      "Epoch [3/5], Step [1040/1875], Loss: 2.2350, batch time: 0.10\n",
      "Epoch [3/5], Step [1041/1875], Loss: 2.1609, batch time: 0.13\n",
      "Epoch [3/5], Step [1042/1875], Loss: 2.1879, batch time: 0.10\n",
      "Epoch [3/5], Step [1043/1875], Loss: 2.1464, batch time: 0.11\n",
      "Epoch [3/5], Step [1044/1875], Loss: 2.1786, batch time: 0.12\n",
      "Epoch [3/5], Step [1045/1875], Loss: 2.1742, batch time: 0.10\n",
      "Epoch [3/5], Step [1046/1875], Loss: 2.1633, batch time: 0.09\n",
      "Epoch [3/5], Step [1047/1875], Loss: 2.2683, batch time: 0.15\n",
      "Epoch [3/5], Step [1048/1875], Loss: 2.2791, batch time: 0.10\n",
      "Epoch [3/5], Step [1049/1875], Loss: 2.1423, batch time: 0.09\n",
      "Epoch [3/5], Step [1050/1875], Loss: 2.2436, batch time: 0.13\n",
      "Epoch [3/5], Step [1051/1875], Loss: 2.1855, batch time: 0.10\n",
      "Epoch [3/5], Step [1052/1875], Loss: 2.1797, batch time: 0.11\n",
      "Epoch [3/5], Step [1053/1875], Loss: 2.2875, batch time: 0.14\n",
      "Epoch [3/5], Step [1054/1875], Loss: 2.1829, batch time: 0.13\n",
      "Epoch [3/5], Step [1055/1875], Loss: 2.2412, batch time: 0.13\n",
      "Epoch [3/5], Step [1056/1875], Loss: 2.0446, batch time: 0.11\n",
      "Epoch [3/5], Step [1057/1875], Loss: 2.2063, batch time: 0.12\n",
      "Epoch [3/5], Step [1058/1875], Loss: 2.1091, batch time: 0.13\n",
      "Epoch [3/5], Step [1059/1875], Loss: 2.2761, batch time: 0.10\n",
      "Epoch [3/5], Step [1060/1875], Loss: 2.2273, batch time: 0.10\n",
      "Epoch [3/5], Step [1061/1875], Loss: 2.2485, batch time: 0.19\n",
      "Epoch [3/5], Step [1062/1875], Loss: 2.1987, batch time: 0.13\n",
      "Epoch [3/5], Step [1063/1875], Loss: 2.3196, batch time: 0.15\n",
      "Epoch [3/5], Step [1064/1875], Loss: 2.1333, batch time: 0.10\n",
      "Epoch [3/5], Step [1065/1875], Loss: 2.0584, batch time: 0.10\n",
      "Epoch [3/5], Step [1066/1875], Loss: 2.1859, batch time: 0.10\n",
      "Epoch [3/5], Step [1067/1875], Loss: 2.2417, batch time: 0.09\n",
      "Epoch [3/5], Step [1068/1875], Loss: 2.1761, batch time: 0.17\n",
      "Epoch [3/5], Step [1069/1875], Loss: 2.1960, batch time: 0.11\n",
      "Epoch [3/5], Step [1070/1875], Loss: 2.2770, batch time: 0.10\n",
      "Epoch [3/5], Step [1071/1875], Loss: 2.2496, batch time: 0.10\n",
      "Epoch [3/5], Step [1072/1875], Loss: 2.1476, batch time: 0.13\n",
      "Epoch [3/5], Step [1073/1875], Loss: 2.2647, batch time: 0.10\n",
      "Epoch [3/5], Step [1074/1875], Loss: 2.2868, batch time: 0.10\n",
      "Epoch [3/5], Step [1075/1875], Loss: 2.1607, batch time: 0.12\n",
      "Epoch [3/5], Step [1076/1875], Loss: 2.1902, batch time: 0.12\n",
      "Epoch [3/5], Step [1077/1875], Loss: 2.1512, batch time: 0.10\n",
      "Epoch [3/5], Step [1078/1875], Loss: 2.1280, batch time: 0.11\n",
      "Epoch [3/5], Step [1079/1875], Loss: 2.3061, batch time: 0.11\n",
      "Epoch [3/5], Step [1080/1875], Loss: 2.2565, batch time: 0.11\n",
      "Epoch [3/5], Step [1081/1875], Loss: 2.1352, batch time: 0.14\n",
      "Epoch [3/5], Step [1082/1875], Loss: 2.1344, batch time: 0.10\n",
      "Epoch [3/5], Step [1083/1875], Loss: 2.1856, batch time: 0.10\n",
      "Epoch [3/5], Step [1084/1875], Loss: 2.2045, batch time: 0.10\n",
      "Epoch [3/5], Step [1085/1875], Loss: 2.2660, batch time: 0.13\n",
      "Epoch [3/5], Step [1086/1875], Loss: 2.3284, batch time: 0.13\n",
      "Epoch [3/5], Step [1087/1875], Loss: 2.0434, batch time: 0.10\n",
      "Epoch [3/5], Step [1088/1875], Loss: 2.1833, batch time: 0.10\n",
      "Epoch [3/5], Step [1089/1875], Loss: 2.1534, batch time: 0.12\n",
      "Epoch [3/5], Step [1090/1875], Loss: 2.1240, batch time: 0.10\n",
      "Epoch [3/5], Step [1091/1875], Loss: 2.2532, batch time: 0.12\n",
      "Epoch [3/5], Step [1092/1875], Loss: 2.1822, batch time: 0.09\n",
      "Epoch [3/5], Step [1093/1875], Loss: 2.1354, batch time: 0.10\n",
      "Epoch [3/5], Step [1094/1875], Loss: 2.2670, batch time: 0.11\n",
      "Epoch [3/5], Step [1095/1875], Loss: 2.1992, batch time: 0.10\n",
      "Epoch [3/5], Step [1096/1875], Loss: 2.3056, batch time: 0.12\n",
      "Epoch [3/5], Step [1097/1875], Loss: 2.1499, batch time: 0.10\n",
      "Epoch [3/5], Step [1098/1875], Loss: 2.3026, batch time: 0.10\n",
      "Epoch [3/5], Step [1099/1875], Loss: 2.1837, batch time: 0.10\n",
      "Epoch [3/5], Step [1100/1875], Loss: 2.3074, batch time: 0.10\n",
      "Epoch [3/5], Step [1101/1875], Loss: 2.1895, batch time: 0.13\n",
      "Epoch [3/5], Step [1102/1875], Loss: 2.2698, batch time: 0.10\n",
      "Epoch [3/5], Step [1103/1875], Loss: 2.1965, batch time: 0.09\n",
      "Epoch [3/5], Step [1104/1875], Loss: 2.2882, batch time: 0.10\n",
      "Epoch [3/5], Step [1105/1875], Loss: 2.2268, batch time: 0.09\n",
      "Epoch [3/5], Step [1106/1875], Loss: 2.1363, batch time: 0.09\n",
      "Epoch [3/5], Step [1107/1875], Loss: 2.1688, batch time: 0.10\n",
      "Epoch [3/5], Step [1108/1875], Loss: 2.2550, batch time: 0.10\n",
      "Epoch [3/5], Step [1109/1875], Loss: 2.2978, batch time: 0.10\n",
      "Epoch [3/5], Step [1110/1875], Loss: 2.2042, batch time: 0.14\n",
      "Epoch [3/5], Step [1111/1875], Loss: 2.2068, batch time: 0.10\n",
      "Epoch [3/5], Step [1112/1875], Loss: 2.1806, batch time: 0.10\n",
      "Epoch [3/5], Step [1113/1875], Loss: 2.1567, batch time: 0.10\n",
      "Epoch [3/5], Step [1114/1875], Loss: 2.1818, batch time: 0.11\n",
      "Epoch [3/5], Step [1115/1875], Loss: 2.1262, batch time: 0.24\n",
      "Epoch [3/5], Step [1116/1875], Loss: 2.1506, batch time: 0.15\n",
      "Epoch [3/5], Step [1117/1875], Loss: 2.2794, batch time: 0.11\n",
      "Epoch [3/5], Step [1118/1875], Loss: 2.2872, batch time: 0.10\n",
      "Epoch [3/5], Step [1119/1875], Loss: 2.3139, batch time: 0.12\n",
      "Epoch [3/5], Step [1120/1875], Loss: 2.1987, batch time: 0.10\n",
      "Epoch [3/5], Step [1121/1875], Loss: 2.1285, batch time: 0.12\n",
      "Epoch [3/5], Step [1122/1875], Loss: 2.2269, batch time: 0.09\n",
      "Epoch [3/5], Step [1123/1875], Loss: 2.1473, batch time: 0.10\n",
      "Epoch [3/5], Step [1124/1875], Loss: 2.1400, batch time: 0.12\n",
      "Epoch [3/5], Step [1125/1875], Loss: 2.1750, batch time: 0.10\n",
      "Epoch [3/5], Step [1126/1875], Loss: 2.0940, batch time: 0.14\n",
      "Epoch [3/5], Step [1127/1875], Loss: 2.2978, batch time: 0.10\n",
      "Epoch [3/5], Step [1128/1875], Loss: 2.2812, batch time: 0.10\n",
      "Epoch [3/5], Step [1129/1875], Loss: 2.0588, batch time: 0.10\n",
      "Epoch [3/5], Step [1130/1875], Loss: 2.2743, batch time: 0.13\n",
      "Epoch [3/5], Step [1131/1875], Loss: 2.0939, batch time: 0.13\n",
      "Epoch [3/5], Step [1132/1875], Loss: 2.2015, batch time: 0.13\n",
      "Epoch [3/5], Step [1133/1875], Loss: 2.0723, batch time: 0.12\n",
      "Epoch [3/5], Step [1134/1875], Loss: 2.0963, batch time: 0.09\n",
      "Epoch [3/5], Step [1135/1875], Loss: 2.0445, batch time: 0.10\n",
      "Epoch [3/5], Step [1136/1875], Loss: 2.0191, batch time: 0.10\n",
      "Epoch [3/5], Step [1137/1875], Loss: 2.3083, batch time: 0.09\n",
      "Epoch [3/5], Step [1138/1875], Loss: 2.1203, batch time: 0.10\n",
      "Epoch [3/5], Step [1139/1875], Loss: 2.1234, batch time: 0.10\n",
      "Epoch [3/5], Step [1140/1875], Loss: 2.1435, batch time: 0.10\n",
      "Epoch [3/5], Step [1141/1875], Loss: 2.2803, batch time: 0.09\n",
      "Epoch [3/5], Step [1142/1875], Loss: 2.2346, batch time: 0.11\n",
      "Epoch [3/5], Step [1143/1875], Loss: 2.2482, batch time: 0.14\n",
      "Epoch [3/5], Step [1144/1875], Loss: 2.2267, batch time: 0.11\n",
      "Epoch [3/5], Step [1145/1875], Loss: 2.1681, batch time: 0.13\n",
      "Epoch [3/5], Step [1146/1875], Loss: 2.2317, batch time: 0.10\n",
      "Epoch [3/5], Step [1147/1875], Loss: 2.3165, batch time: 0.09\n",
      "Epoch [3/5], Step [1148/1875], Loss: 2.2038, batch time: 0.09\n",
      "Epoch [3/5], Step [1149/1875], Loss: 2.1212, batch time: 0.12\n",
      "Epoch [3/5], Step [1150/1875], Loss: 2.1062, batch time: 0.10\n",
      "Epoch [3/5], Step [1151/1875], Loss: 2.1279, batch time: 0.22\n",
      "Epoch [3/5], Step [1152/1875], Loss: 2.1491, batch time: 0.10\n",
      "Epoch [3/5], Step [1153/1875], Loss: 2.4133, batch time: 0.09\n",
      "Epoch [3/5], Step [1154/1875], Loss: 2.1728, batch time: 0.10\n",
      "Epoch [3/5], Step [1155/1875], Loss: 2.1487, batch time: 0.09\n",
      "Epoch [3/5], Step [1156/1875], Loss: 2.3749, batch time: 0.10\n",
      "Epoch [3/5], Step [1157/1875], Loss: 2.1995, batch time: 0.16\n",
      "Epoch [3/5], Step [1158/1875], Loss: 2.1616, batch time: 0.11\n",
      "Epoch [3/5], Step [1159/1875], Loss: 2.2662, batch time: 0.10\n",
      "Epoch [3/5], Step [1160/1875], Loss: 2.2147, batch time: 0.10\n",
      "Epoch [3/5], Step [1161/1875], Loss: 2.2892, batch time: 0.17\n",
      "Epoch [3/5], Step [1162/1875], Loss: 2.1468, batch time: 0.09\n",
      "Epoch [3/5], Step [1163/1875], Loss: 2.3610, batch time: 0.11\n",
      "Epoch [3/5], Step [1164/1875], Loss: 2.2004, batch time: 0.13\n",
      "Epoch [3/5], Step [1165/1875], Loss: 2.1529, batch time: 0.13\n",
      "Epoch [3/5], Step [1166/1875], Loss: 2.2060, batch time: 0.12\n",
      "Epoch [3/5], Step [1167/1875], Loss: 2.0611, batch time: 0.10\n",
      "Epoch [3/5], Step [1168/1875], Loss: 2.2687, batch time: 0.19\n",
      "Epoch [3/5], Step [1169/1875], Loss: 2.2748, batch time: 0.14\n",
      "Epoch [3/5], Step [1170/1875], Loss: 2.2513, batch time: 0.09\n",
      "Epoch [3/5], Step [1171/1875], Loss: 2.1072, batch time: 0.09\n",
      "Epoch [3/5], Step [1172/1875], Loss: 2.2588, batch time: 0.13\n",
      "Epoch [3/5], Step [1173/1875], Loss: 2.1427, batch time: 0.10\n",
      "Epoch [3/5], Step [1174/1875], Loss: 2.2306, batch time: 0.13\n",
      "Epoch [3/5], Step [1175/1875], Loss: 2.2109, batch time: 0.10\n",
      "Epoch [3/5], Step [1176/1875], Loss: 2.2527, batch time: 0.10\n",
      "Epoch [3/5], Step [1177/1875], Loss: 2.2291, batch time: 0.10\n",
      "Epoch [3/5], Step [1178/1875], Loss: 2.0674, batch time: 0.09\n",
      "Epoch [3/5], Step [1179/1875], Loss: 2.1834, batch time: 0.12\n",
      "Epoch [3/5], Step [1180/1875], Loss: 2.2281, batch time: 0.10\n",
      "Epoch [3/5], Step [1181/1875], Loss: 2.2141, batch time: 0.09\n",
      "Epoch [3/5], Step [1182/1875], Loss: 2.2579, batch time: 0.13\n",
      "Epoch [3/5], Step [1183/1875], Loss: 2.2580, batch time: 0.09\n",
      "Epoch [3/5], Step [1184/1875], Loss: 2.2158, batch time: 0.13\n",
      "Epoch [3/5], Step [1185/1875], Loss: 2.2386, batch time: 0.11\n",
      "Epoch [3/5], Step [1186/1875], Loss: 2.2922, batch time: 0.13\n",
      "Epoch [3/5], Step [1187/1875], Loss: 2.2956, batch time: 0.09\n",
      "Epoch [3/5], Step [1188/1875], Loss: 2.2728, batch time: 0.12\n",
      "Epoch [3/5], Step [1189/1875], Loss: 2.1730, batch time: 0.10\n",
      "Epoch [3/5], Step [1190/1875], Loss: 2.2253, batch time: 0.09\n",
      "Epoch [3/5], Step [1191/1875], Loss: 2.2185, batch time: 0.10\n",
      "Epoch [3/5], Step [1192/1875], Loss: 2.1288, batch time: 0.10\n",
      "Epoch [3/5], Step [1193/1875], Loss: 2.2407, batch time: 0.11\n",
      "Epoch [3/5], Step [1194/1875], Loss: 2.2745, batch time: 0.11\n",
      "Epoch [3/5], Step [1195/1875], Loss: 2.2333, batch time: 0.10\n",
      "Epoch [3/5], Step [1196/1875], Loss: 2.2316, batch time: 0.09\n",
      "Epoch [3/5], Step [1197/1875], Loss: 2.1209, batch time: 0.10\n",
      "Epoch [3/5], Step [1198/1875], Loss: 2.1815, batch time: 0.10\n",
      "Epoch [3/5], Step [1199/1875], Loss: 2.1761, batch time: 0.09\n",
      "Epoch [3/5], Step [1200/1875], Loss: 2.2044, batch time: 0.11\n",
      "Epoch [3/5], Step [1201/1875], Loss: 2.1560, batch time: 0.09\n",
      "Epoch [3/5], Step [1202/1875], Loss: 2.1700, batch time: 0.09\n",
      "Epoch [3/5], Step [1203/1875], Loss: 2.2616, batch time: 0.10\n",
      "Epoch [3/5], Step [1204/1875], Loss: 2.1570, batch time: 0.09\n",
      "Epoch [3/5], Step [1205/1875], Loss: 2.2260, batch time: 0.09\n",
      "Epoch [3/5], Step [1206/1875], Loss: 2.1351, batch time: 0.10\n",
      "Epoch [3/5], Step [1207/1875], Loss: 2.1564, batch time: 0.13\n",
      "Epoch [3/5], Step [1208/1875], Loss: 2.0957, batch time: 0.10\n",
      "Epoch [3/5], Step [1209/1875], Loss: 2.0771, batch time: 0.12\n",
      "Epoch [3/5], Step [1210/1875], Loss: 2.1056, batch time: 0.09\n",
      "Epoch [3/5], Step [1211/1875], Loss: 2.2911, batch time: 0.12\n",
      "Epoch [3/5], Step [1212/1875], Loss: 2.2068, batch time: 0.10\n",
      "Epoch [3/5], Step [1213/1875], Loss: 2.1370, batch time: 0.13\n",
      "Epoch [3/5], Step [1214/1875], Loss: 2.2144, batch time: 0.11\n",
      "Epoch [3/5], Step [1215/1875], Loss: 2.1132, batch time: 0.12\n",
      "Epoch [3/5], Step [1216/1875], Loss: 2.1681, batch time: 0.12\n",
      "Epoch [3/5], Step [1217/1875], Loss: 2.1175, batch time: -2.78\n",
      "Epoch [3/5], Step [1218/1875], Loss: 2.2977, batch time: 0.10\n",
      "Epoch [3/5], Step [1219/1875], Loss: 1.9794, batch time: 0.12\n",
      "Epoch [3/5], Step [1220/1875], Loss: 2.1877, batch time: 0.10\n",
      "Epoch [3/5], Step [1221/1875], Loss: 2.1928, batch time: 0.10\n",
      "Epoch [3/5], Step [1222/1875], Loss: 2.2364, batch time: 0.13\n",
      "Epoch [3/5], Step [1223/1875], Loss: 2.1954, batch time: 0.10\n",
      "Epoch [3/5], Step [1224/1875], Loss: 1.9961, batch time: 0.11\n",
      "Epoch [3/5], Step [1225/1875], Loss: 2.2439, batch time: 0.13\n",
      "Epoch [3/5], Step [1226/1875], Loss: 2.2083, batch time: 0.10\n",
      "Epoch [3/5], Step [1227/1875], Loss: 2.1418, batch time: 0.10\n",
      "Epoch [3/5], Step [1228/1875], Loss: 2.2242, batch time: 0.12\n",
      "Epoch [3/5], Step [1229/1875], Loss: 2.1817, batch time: 0.13\n",
      "Epoch [3/5], Step [1230/1875], Loss: 2.1138, batch time: 0.12\n",
      "Epoch [3/5], Step [1231/1875], Loss: 2.1454, batch time: 0.14\n",
      "Epoch [3/5], Step [1232/1875], Loss: 2.2574, batch time: 0.10\n",
      "Epoch [3/5], Step [1233/1875], Loss: 2.2366, batch time: 0.10\n",
      "Epoch [3/5], Step [1234/1875], Loss: 2.2204, batch time: 0.13\n",
      "Epoch [3/5], Step [1235/1875], Loss: 2.2048, batch time: 0.09\n",
      "Epoch [3/5], Step [1236/1875], Loss: 2.1997, batch time: 0.12\n",
      "Epoch [3/5], Step [1237/1875], Loss: 2.2013, batch time: 0.11\n",
      "Epoch [3/5], Step [1238/1875], Loss: 2.2285, batch time: 0.12\n",
      "Epoch [3/5], Step [1239/1875], Loss: 2.2985, batch time: 0.09\n",
      "Epoch [3/5], Step [1240/1875], Loss: 2.2194, batch time: 0.09\n",
      "Epoch [3/5], Step [1241/1875], Loss: 2.1859, batch time: 0.09\n",
      "Epoch [3/5], Step [1242/1875], Loss: 2.2394, batch time: 0.10\n",
      "Epoch [3/5], Step [1243/1875], Loss: 2.1809, batch time: 0.09\n",
      "Epoch [3/5], Step [1244/1875], Loss: 2.2352, batch time: 0.09\n",
      "Epoch [3/5], Step [1245/1875], Loss: 2.1164, batch time: 0.13\n",
      "Epoch [3/5], Step [1246/1875], Loss: 2.3363, batch time: 0.13\n",
      "Epoch [3/5], Step [1247/1875], Loss: 2.2892, batch time: 0.14\n",
      "Epoch [3/5], Step [1248/1875], Loss: 2.0525, batch time: 0.14\n",
      "Epoch [3/5], Step [1249/1875], Loss: 2.2120, batch time: 0.11\n",
      "Epoch [3/5], Step [1250/1875], Loss: 2.1123, batch time: 0.10\n",
      "Epoch [3/5], Step [1251/1875], Loss: 2.3319, batch time: 0.09\n",
      "Epoch [3/5], Step [1252/1875], Loss: 2.1460, batch time: 0.10\n",
      "Epoch [3/5], Step [1253/1875], Loss: 2.2256, batch time: 0.10\n",
      "Epoch [3/5], Step [1254/1875], Loss: 2.2889, batch time: 0.09\n",
      "Epoch [3/5], Step [1255/1875], Loss: 2.2440, batch time: 0.10\n",
      "Epoch [3/5], Step [1256/1875], Loss: 2.1693, batch time: 0.14\n",
      "Epoch [3/5], Step [1257/1875], Loss: 2.1155, batch time: 0.10\n",
      "Epoch [3/5], Step [1258/1875], Loss: 2.0792, batch time: 0.13\n",
      "Epoch [3/5], Step [1259/1875], Loss: 2.1775, batch time: 0.09\n",
      "Epoch [3/5], Step [1260/1875], Loss: 2.2109, batch time: 0.10\n",
      "Epoch [3/5], Step [1261/1875], Loss: 2.2316, batch time: 0.10\n",
      "Epoch [3/5], Step [1262/1875], Loss: 2.1465, batch time: 0.10\n",
      "Epoch [3/5], Step [1263/1875], Loss: 2.0842, batch time: 0.10\n",
      "Epoch [3/5], Step [1264/1875], Loss: 2.4483, batch time: 0.10\n",
      "Epoch [3/5], Step [1265/1875], Loss: 2.1843, batch time: 0.10\n",
      "Epoch [3/5], Step [1266/1875], Loss: 2.2766, batch time: 0.10\n",
      "Epoch [3/5], Step [1267/1875], Loss: 2.1634, batch time: 0.10\n",
      "Epoch [3/5], Step [1268/1875], Loss: 2.2454, batch time: 0.10\n",
      "Epoch [3/5], Step [1269/1875], Loss: 2.2043, batch time: 0.11\n",
      "Epoch [3/5], Step [1270/1875], Loss: 2.2109, batch time: 0.10\n",
      "Epoch [3/5], Step [1271/1875], Loss: 2.2891, batch time: 0.10\n",
      "Epoch [3/5], Step [1272/1875], Loss: 2.1588, batch time: 0.11\n",
      "Epoch [3/5], Step [1273/1875], Loss: 2.1968, batch time: 0.12\n",
      "Epoch [3/5], Step [1274/1875], Loss: 2.2097, batch time: 0.14\n",
      "Epoch [3/5], Step [1275/1875], Loss: 2.0811, batch time: 0.10\n",
      "Epoch [3/5], Step [1276/1875], Loss: 2.1864, batch time: 0.10\n",
      "Epoch [3/5], Step [1277/1875], Loss: 2.1862, batch time: 0.18\n",
      "Epoch [3/5], Step [1278/1875], Loss: 2.2879, batch time: 0.09\n",
      "Epoch [3/5], Step [1279/1875], Loss: 2.1141, batch time: 0.10\n",
      "Epoch [3/5], Step [1280/1875], Loss: 2.3384, batch time: 0.10\n",
      "Epoch [3/5], Step [1281/1875], Loss: 2.1736, batch time: 0.10\n",
      "Epoch [3/5], Step [1282/1875], Loss: 2.2744, batch time: 0.12\n",
      "Epoch [3/5], Step [1283/1875], Loss: 2.1768, batch time: 0.09\n",
      "Epoch [3/5], Step [1284/1875], Loss: 2.2178, batch time: 0.14\n",
      "Epoch [3/5], Step [1285/1875], Loss: 2.1356, batch time: 0.09\n",
      "Epoch [3/5], Step [1286/1875], Loss: 2.1404, batch time: 0.10\n",
      "Epoch [3/5], Step [1287/1875], Loss: 2.1886, batch time: 0.18\n",
      "Epoch [3/5], Step [1288/1875], Loss: 2.2497, batch time: 0.14\n",
      "Epoch [3/5], Step [1289/1875], Loss: 2.1474, batch time: 0.10\n",
      "Epoch [3/5], Step [1290/1875], Loss: 2.1141, batch time: 0.09\n",
      "Epoch [3/5], Step [1291/1875], Loss: 2.4124, batch time: 0.18\n",
      "Epoch [3/5], Step [1292/1875], Loss: 2.2152, batch time: 0.14\n",
      "Epoch [3/5], Step [1293/1875], Loss: 2.2196, batch time: 0.09\n",
      "Epoch [3/5], Step [1294/1875], Loss: 2.1252, batch time: 0.10\n",
      "Epoch [3/5], Step [1295/1875], Loss: 2.3416, batch time: 0.11\n",
      "Epoch [3/5], Step [1296/1875], Loss: 2.0422, batch time: 0.13\n",
      "Epoch [3/5], Step [1297/1875], Loss: 2.1936, batch time: 0.21\n",
      "Epoch [3/5], Step [1298/1875], Loss: 2.1745, batch time: 0.16\n",
      "Epoch [3/5], Step [1299/1875], Loss: 2.2293, batch time: 0.13\n",
      "Epoch [3/5], Step [1300/1875], Loss: 2.2120, batch time: 0.10\n",
      "Epoch [3/5], Step [1301/1875], Loss: 2.2142, batch time: 0.12\n",
      "Epoch [3/5], Step [1302/1875], Loss: 2.1481, batch time: 0.10\n",
      "Epoch [3/5], Step [1303/1875], Loss: 2.3105, batch time: 0.10\n",
      "Epoch [3/5], Step [1304/1875], Loss: 2.2634, batch time: 0.11\n",
      "Epoch [3/5], Step [1305/1875], Loss: 2.3230, batch time: 0.15\n",
      "Epoch [3/5], Step [1306/1875], Loss: 2.2590, batch time: 0.14\n",
      "Epoch [3/5], Step [1307/1875], Loss: 2.0696, batch time: 0.13\n",
      "Epoch [3/5], Step [1308/1875], Loss: 2.1553, batch time: 0.10\n",
      "Epoch [3/5], Step [1309/1875], Loss: 2.2885, batch time: 0.10\n",
      "Epoch [3/5], Step [1310/1875], Loss: 2.0156, batch time: 0.14\n",
      "Epoch [3/5], Step [1311/1875], Loss: 2.2106, batch time: 0.11\n",
      "Epoch [3/5], Step [1312/1875], Loss: 2.2539, batch time: 0.14\n",
      "Epoch [3/5], Step [1313/1875], Loss: 2.2191, batch time: 0.15\n",
      "Epoch [3/5], Step [1314/1875], Loss: 2.1521, batch time: 0.12\n",
      "Epoch [3/5], Step [1315/1875], Loss: 2.0774, batch time: 0.10\n",
      "Epoch [3/5], Step [1316/1875], Loss: 2.1789, batch time: 0.16\n",
      "Epoch [3/5], Step [1317/1875], Loss: 2.3314, batch time: 0.10\n",
      "Epoch [3/5], Step [1318/1875], Loss: 2.2180, batch time: 0.16\n",
      "Epoch [3/5], Step [1319/1875], Loss: 2.1553, batch time: 0.10\n",
      "Epoch [3/5], Step [1320/1875], Loss: 2.1813, batch time: 0.10\n",
      "Epoch [3/5], Step [1321/1875], Loss: 2.2162, batch time: 0.11\n",
      "Epoch [3/5], Step [1322/1875], Loss: 2.4039, batch time: 0.11\n",
      "Epoch [3/5], Step [1323/1875], Loss: 2.1214, batch time: 0.10\n",
      "Epoch [3/5], Step [1324/1875], Loss: 2.2847, batch time: 0.10\n",
      "Epoch [3/5], Step [1325/1875], Loss: 2.3104, batch time: 0.15\n",
      "Epoch [3/5], Step [1326/1875], Loss: 2.2969, batch time: 0.10\n",
      "Epoch [3/5], Step [1327/1875], Loss: 2.2768, batch time: 0.09\n",
      "Epoch [3/5], Step [1328/1875], Loss: 2.2409, batch time: 0.23\n",
      "Epoch [3/5], Step [1329/1875], Loss: 2.1261, batch time: 0.10\n",
      "Epoch [3/5], Step [1330/1875], Loss: 2.2417, batch time: 0.11\n",
      "Epoch [3/5], Step [1331/1875], Loss: 2.2395, batch time: 0.10\n",
      "Epoch [3/5], Step [1332/1875], Loss: 2.1952, batch time: 0.12\n",
      "Epoch [3/5], Step [1333/1875], Loss: 2.0816, batch time: 0.09\n",
      "Epoch [3/5], Step [1334/1875], Loss: 2.1439, batch time: 0.15\n",
      "Epoch [3/5], Step [1335/1875], Loss: 2.1068, batch time: 0.13\n",
      "Epoch [3/5], Step [1336/1875], Loss: 2.1294, batch time: 0.10\n",
      "Epoch [3/5], Step [1337/1875], Loss: 2.2719, batch time: 0.14\n",
      "Epoch [3/5], Step [1338/1875], Loss: 2.2237, batch time: 0.10\n",
      "Epoch [3/5], Step [1339/1875], Loss: 2.3432, batch time: 0.16\n",
      "Epoch [3/5], Step [1340/1875], Loss: 2.0354, batch time: 0.12\n",
      "Epoch [3/5], Step [1341/1875], Loss: 2.2224, batch time: 0.19\n",
      "Epoch [3/5], Step [1342/1875], Loss: 2.0813, batch time: 0.10\n",
      "Epoch [3/5], Step [1343/1875], Loss: 2.2011, batch time: 0.10\n",
      "Epoch [3/5], Step [1344/1875], Loss: 2.2705, batch time: 0.09\n",
      "Epoch [3/5], Step [1345/1875], Loss: 2.0799, batch time: 0.12\n",
      "Epoch [3/5], Step [1346/1875], Loss: 2.1863, batch time: 0.10\n",
      "Epoch [3/5], Step [1347/1875], Loss: 2.0486, batch time: 0.11\n",
      "Epoch [3/5], Step [1348/1875], Loss: 2.1986, batch time: 0.11\n",
      "Epoch [3/5], Step [1349/1875], Loss: 2.1840, batch time: 0.10\n",
      "Epoch [3/5], Step [1350/1875], Loss: 2.2255, batch time: 0.10\n",
      "Epoch [3/5], Step [1351/1875], Loss: 2.2085, batch time: 0.10\n",
      "Epoch [3/5], Step [1352/1875], Loss: 2.2067, batch time: 0.14\n",
      "Epoch [3/5], Step [1353/1875], Loss: 2.1077, batch time: 0.13\n",
      "Epoch [3/5], Step [1354/1875], Loss: 2.2446, batch time: 0.14\n",
      "Epoch [3/5], Step [1355/1875], Loss: 2.1393, batch time: 0.12\n",
      "Epoch [3/5], Step [1356/1875], Loss: 2.0305, batch time: 0.12\n",
      "Epoch [3/5], Step [1357/1875], Loss: 2.2792, batch time: 0.14\n",
      "Epoch [3/5], Step [1358/1875], Loss: 2.2169, batch time: 0.14\n",
      "Epoch [3/5], Step [1359/1875], Loss: 2.1632, batch time: 0.21\n",
      "Epoch [3/5], Step [1360/1875], Loss: 2.2806, batch time: 0.15\n",
      "Epoch [3/5], Step [1361/1875], Loss: 2.1540, batch time: 0.14\n",
      "Epoch [3/5], Step [1362/1875], Loss: 2.1639, batch time: 0.10\n",
      "Epoch [3/5], Step [1363/1875], Loss: 2.1787, batch time: 0.10\n",
      "Epoch [3/5], Step [1364/1875], Loss: 2.1809, batch time: 0.09\n",
      "Epoch [3/5], Step [1365/1875], Loss: 2.1980, batch time: 0.14\n",
      "Epoch [3/5], Step [1366/1875], Loss: 2.2030, batch time: 0.10\n",
      "Epoch [3/5], Step [1367/1875], Loss: 2.2464, batch time: 0.13\n",
      "Epoch [3/5], Step [1368/1875], Loss: 2.1624, batch time: 0.11\n",
      "Epoch [3/5], Step [1369/1875], Loss: 2.1953, batch time: 0.10\n",
      "Epoch [3/5], Step [1370/1875], Loss: 2.1296, batch time: 0.10\n",
      "Epoch [3/5], Step [1371/1875], Loss: 2.2306, batch time: 0.10\n",
      "Epoch [3/5], Step [1372/1875], Loss: 2.2356, batch time: 0.10\n",
      "Epoch [3/5], Step [1373/1875], Loss: 2.2915, batch time: 0.10\n",
      "Epoch [3/5], Step [1374/1875], Loss: 2.1958, batch time: 0.09\n",
      "Epoch [3/5], Step [1375/1875], Loss: 2.1628, batch time: 0.12\n",
      "Epoch [3/5], Step [1376/1875], Loss: 2.1280, batch time: 0.11\n",
      "Epoch [3/5], Step [1377/1875], Loss: 2.2098, batch time: 0.11\n",
      "Epoch [3/5], Step [1378/1875], Loss: 1.9820, batch time: 0.10\n",
      "Epoch [3/5], Step [1379/1875], Loss: 2.1769, batch time: 0.09\n",
      "Epoch [3/5], Step [1380/1875], Loss: 2.2026, batch time: 0.16\n",
      "Epoch [3/5], Step [1381/1875], Loss: 2.1221, batch time: 0.09\n",
      "Epoch [3/5], Step [1382/1875], Loss: 2.1312, batch time: 0.13\n",
      "Epoch [3/5], Step [1383/1875], Loss: 2.1710, batch time: 0.13\n",
      "Epoch [3/5], Step [1384/1875], Loss: 2.1259, batch time: 0.14\n",
      "Epoch [3/5], Step [1385/1875], Loss: 2.1762, batch time: 0.14\n",
      "Epoch [3/5], Step [1386/1875], Loss: 2.1770, batch time: 0.12\n",
      "Epoch [3/5], Step [1387/1875], Loss: 2.2186, batch time: 0.13\n",
      "Epoch [3/5], Step [1388/1875], Loss: 2.1543, batch time: 0.14\n",
      "Epoch [3/5], Step [1389/1875], Loss: 2.2152, batch time: 0.10\n",
      "Epoch [3/5], Step [1390/1875], Loss: 2.3651, batch time: 0.17\n",
      "Epoch [3/5], Step [1391/1875], Loss: 2.1712, batch time: 0.14\n",
      "Epoch [3/5], Step [1392/1875], Loss: 2.2710, batch time: 0.13\n",
      "Epoch [3/5], Step [1393/1875], Loss: 2.2412, batch time: 0.13\n",
      "Epoch [3/5], Step [1394/1875], Loss: 2.0886, batch time: 0.14\n",
      "Epoch [3/5], Step [1395/1875], Loss: 2.0791, batch time: 0.14\n",
      "Epoch [3/5], Step [1396/1875], Loss: 2.2539, batch time: 0.13\n",
      "Epoch [3/5], Step [1397/1875], Loss: 2.3401, batch time: 0.16\n",
      "Epoch [3/5], Step [1398/1875], Loss: 2.3349, batch time: 0.12\n",
      "Epoch [3/5], Step [1399/1875], Loss: 2.2744, batch time: 0.15\n",
      "Epoch [3/5], Step [1400/1875], Loss: 2.1431, batch time: 0.10\n",
      "Epoch [3/5], Step [1401/1875], Loss: 2.2577, batch time: 0.09\n",
      "Epoch [3/5], Step [1402/1875], Loss: 2.2679, batch time: 0.09\n",
      "Epoch [3/5], Step [1403/1875], Loss: 2.1298, batch time: 0.25\n",
      "Epoch [3/5], Step [1404/1875], Loss: 2.2207, batch time: 0.10\n",
      "Epoch [3/5], Step [1405/1875], Loss: 2.3119, batch time: 0.10\n",
      "Epoch [3/5], Step [1406/1875], Loss: 2.2792, batch time: 0.10\n",
      "Epoch [3/5], Step [1407/1875], Loss: 2.2777, batch time: 0.10\n",
      "Epoch [3/5], Step [1408/1875], Loss: 2.2367, batch time: 0.09\n",
      "Epoch [3/5], Step [1409/1875], Loss: 2.2689, batch time: 0.10\n",
      "Epoch [3/5], Step [1410/1875], Loss: 2.2704, batch time: 0.12\n",
      "Epoch [3/5], Step [1411/1875], Loss: 2.3686, batch time: 0.10\n",
      "Epoch [3/5], Step [1412/1875], Loss: 2.2876, batch time: 0.14\n",
      "Epoch [3/5], Step [1413/1875], Loss: 2.1874, batch time: 0.14\n",
      "Epoch [3/5], Step [1414/1875], Loss: 2.2337, batch time: 0.14\n",
      "Epoch [3/5], Step [1415/1875], Loss: 2.2039, batch time: 0.10\n",
      "Epoch [3/5], Step [1416/1875], Loss: 2.1232, batch time: 0.12\n",
      "Epoch [3/5], Step [1417/1875], Loss: 2.2090, batch time: 0.10\n",
      "Epoch [3/5], Step [1418/1875], Loss: 2.2075, batch time: 0.12\n",
      "Epoch [3/5], Step [1419/1875], Loss: 2.2124, batch time: 0.13\n",
      "Epoch [3/5], Step [1420/1875], Loss: 2.2700, batch time: 0.10\n",
      "Epoch [3/5], Step [1421/1875], Loss: 2.3049, batch time: 0.13\n",
      "Epoch [3/5], Step [1422/1875], Loss: 2.2545, batch time: 0.10\n",
      "Epoch [3/5], Step [1423/1875], Loss: 2.1503, batch time: 0.09\n",
      "Epoch [3/5], Step [1424/1875], Loss: 2.1455, batch time: 0.10\n",
      "Epoch [3/5], Step [1425/1875], Loss: 2.3139, batch time: 0.16\n",
      "Epoch [3/5], Step [1426/1875], Loss: 2.1601, batch time: 0.09\n",
      "Epoch [3/5], Step [1427/1875], Loss: 2.2116, batch time: 0.09\n",
      "Epoch [3/5], Step [1428/1875], Loss: 2.2540, batch time: 0.10\n",
      "Epoch [3/5], Step [1429/1875], Loss: 2.1846, batch time: 0.11\n",
      "Epoch [3/5], Step [1430/1875], Loss: 2.2094, batch time: 0.18\n",
      "Epoch [3/5], Step [1431/1875], Loss: 2.2468, batch time: 0.14\n",
      "Epoch [3/5], Step [1432/1875], Loss: 2.2866, batch time: 0.10\n",
      "Epoch [3/5], Step [1433/1875], Loss: 2.1400, batch time: 0.09\n",
      "Epoch [3/5], Step [1434/1875], Loss: 2.2112, batch time: 0.09\n",
      "Epoch [3/5], Step [1435/1875], Loss: 2.2959, batch time: 0.13\n",
      "Epoch [3/5], Step [1436/1875], Loss: 2.1794, batch time: 0.09\n",
      "Epoch [3/5], Step [1437/1875], Loss: 2.2392, batch time: 0.10\n",
      "Epoch [3/5], Step [1438/1875], Loss: 2.2074, batch time: 0.12\n",
      "Epoch [3/5], Step [1439/1875], Loss: 2.2816, batch time: 0.12\n",
      "Epoch [3/5], Step [1440/1875], Loss: 2.1586, batch time: 0.10\n",
      "Epoch [3/5], Step [1441/1875], Loss: 2.2789, batch time: 0.10\n",
      "Epoch [3/5], Step [1442/1875], Loss: 2.2361, batch time: 0.10\n",
      "Epoch [3/5], Step [1443/1875], Loss: 2.2654, batch time: 0.10\n",
      "Epoch [3/5], Step [1444/1875], Loss: 2.1852, batch time: 0.15\n",
      "Epoch [3/5], Step [1445/1875], Loss: 2.3225, batch time: 0.09\n",
      "Epoch [3/5], Step [1446/1875], Loss: 2.2330, batch time: 0.09\n",
      "Epoch [3/5], Step [1447/1875], Loss: 2.2099, batch time: 0.11\n",
      "Epoch [3/5], Step [1448/1875], Loss: 2.2873, batch time: 0.10\n",
      "Epoch [3/5], Step [1449/1875], Loss: 2.1464, batch time: 0.11\n",
      "Epoch [3/5], Step [1450/1875], Loss: 2.3226, batch time: 0.14\n",
      "Epoch [3/5], Step [1451/1875], Loss: 2.2089, batch time: 0.11\n",
      "Epoch [3/5], Step [1452/1875], Loss: 2.2124, batch time: 0.09\n",
      "Epoch [3/5], Step [1453/1875], Loss: 2.2105, batch time: 0.11\n",
      "Epoch [3/5], Step [1454/1875], Loss: 2.2542, batch time: 0.10\n",
      "Epoch [3/5], Step [1455/1875], Loss: 2.1534, batch time: 0.10\n",
      "Epoch [3/5], Step [1456/1875], Loss: 2.2165, batch time: 0.10\n",
      "Epoch [3/5], Step [1457/1875], Loss: 2.2415, batch time: 0.10\n",
      "Epoch [3/5], Step [1458/1875], Loss: 2.2107, batch time: 0.10\n",
      "Epoch [3/5], Step [1459/1875], Loss: 2.2047, batch time: 0.10\n",
      "Epoch [3/5], Step [1460/1875], Loss: 2.2150, batch time: 0.09\n",
      "Epoch [3/5], Step [1461/1875], Loss: 2.1655, batch time: 0.10\n",
      "Epoch [3/5], Step [1462/1875], Loss: 2.0280, batch time: 0.10\n",
      "Epoch [3/5], Step [1463/1875], Loss: 2.2094, batch time: 0.10\n",
      "Epoch [3/5], Step [1464/1875], Loss: 2.2179, batch time: 0.10\n",
      "Epoch [3/5], Step [1465/1875], Loss: 2.2806, batch time: 0.10\n",
      "Epoch [3/5], Step [1466/1875], Loss: 2.1330, batch time: 0.10\n",
      "Epoch [3/5], Step [1467/1875], Loss: 2.2774, batch time: 0.11\n",
      "Epoch [3/5], Step [1468/1875], Loss: 2.1758, batch time: 0.16\n",
      "Epoch [3/5], Step [1469/1875], Loss: 2.1837, batch time: 0.13\n",
      "Epoch [3/5], Step [1470/1875], Loss: 2.0997, batch time: 0.10\n",
      "Epoch [3/5], Step [1471/1875], Loss: 2.1445, batch time: 0.15\n",
      "Epoch [3/5], Step [1472/1875], Loss: 2.1211, batch time: 0.14\n",
      "Epoch [3/5], Step [1473/1875], Loss: 2.1895, batch time: 0.10\n",
      "Epoch [3/5], Step [1474/1875], Loss: 2.2174, batch time: 0.09\n",
      "Epoch [3/5], Step [1475/1875], Loss: 2.1709, batch time: 0.10\n",
      "Epoch [3/5], Step [1476/1875], Loss: 2.2148, batch time: 0.10\n",
      "Epoch [3/5], Step [1477/1875], Loss: 2.2971, batch time: 0.13\n",
      "Epoch [3/5], Step [1478/1875], Loss: 2.1570, batch time: 0.10\n",
      "Epoch [3/5], Step [1479/1875], Loss: 2.2749, batch time: 0.10\n",
      "Epoch [3/5], Step [1480/1875], Loss: 2.2312, batch time: 0.10\n",
      "Epoch [3/5], Step [1481/1875], Loss: 2.2611, batch time: 0.12\n",
      "Epoch [3/5], Step [1482/1875], Loss: 2.0922, batch time: 0.10\n",
      "Epoch [3/5], Step [1483/1875], Loss: 2.1731, batch time: 0.10\n",
      "Epoch [3/5], Step [1484/1875], Loss: 2.3443, batch time: 0.10\n",
      "Epoch [3/5], Step [1485/1875], Loss: 2.1270, batch time: 0.10\n",
      "Epoch [3/5], Step [1486/1875], Loss: 2.1745, batch time: 0.20\n",
      "Epoch [3/5], Step [1487/1875], Loss: 2.0894, batch time: 0.11\n",
      "Epoch [3/5], Step [1488/1875], Loss: 2.2943, batch time: 0.13\n",
      "Epoch [3/5], Step [1489/1875], Loss: 2.2069, batch time: 0.11\n",
      "Epoch [3/5], Step [1490/1875], Loss: 2.2531, batch time: 0.14\n",
      "Epoch [3/5], Step [1491/1875], Loss: 2.1794, batch time: -2.82\n",
      "Epoch [3/5], Step [1492/1875], Loss: 2.0955, batch time: 0.13\n",
      "Epoch [3/5], Step [1493/1875], Loss: 2.0322, batch time: 0.13\n",
      "Epoch [3/5], Step [1494/1875], Loss: 2.0835, batch time: 0.15\n",
      "Epoch [3/5], Step [1495/1875], Loss: 2.1051, batch time: 0.11\n",
      "Epoch [3/5], Step [1496/1875], Loss: 2.0531, batch time: 0.10\n",
      "Epoch [3/5], Step [1497/1875], Loss: 2.1451, batch time: 0.14\n",
      "Epoch [3/5], Step [1498/1875], Loss: 2.2903, batch time: 0.16\n",
      "Epoch [3/5], Step [1499/1875], Loss: 2.0711, batch time: 0.11\n",
      "Epoch [3/5], Step [1500/1875], Loss: 2.3352, batch time: 0.16\n",
      "Epoch [3/5], Step [1501/1875], Loss: 2.1761, batch time: 0.12\n",
      "Epoch [3/5], Step [1502/1875], Loss: 2.1485, batch time: 0.10\n",
      "Epoch [3/5], Step [1503/1875], Loss: 2.1419, batch time: 0.12\n",
      "Epoch [3/5], Step [1504/1875], Loss: 2.1180, batch time: 0.13\n",
      "Epoch [3/5], Step [1505/1875], Loss: 2.2092, batch time: 0.09\n",
      "Epoch [3/5], Step [1506/1875], Loss: 2.2445, batch time: 0.15\n",
      "Epoch [3/5], Step [1507/1875], Loss: 2.0987, batch time: 0.15\n",
      "Epoch [3/5], Step [1508/1875], Loss: 2.1861, batch time: 0.15\n",
      "Epoch [3/5], Step [1509/1875], Loss: 2.1253, batch time: 0.15\n",
      "Epoch [3/5], Step [1510/1875], Loss: 2.2006, batch time: 0.17\n",
      "Epoch [3/5], Step [1511/1875], Loss: 2.2694, batch time: 0.12\n",
      "Epoch [3/5], Step [1512/1875], Loss: 2.1985, batch time: 0.13\n",
      "Epoch [3/5], Step [1513/1875], Loss: 2.2520, batch time: 0.13\n",
      "Epoch [3/5], Step [1514/1875], Loss: 2.1787, batch time: 0.18\n",
      "Epoch [3/5], Step [1515/1875], Loss: 2.1278, batch time: 0.14\n",
      "Epoch [3/5], Step [1516/1875], Loss: 2.0884, batch time: 0.10\n",
      "Epoch [3/5], Step [1517/1875], Loss: 2.2526, batch time: 0.10\n",
      "Epoch [3/5], Step [1518/1875], Loss: 2.2237, batch time: 0.15\n",
      "Epoch [3/5], Step [1519/1875], Loss: 2.1185, batch time: 0.14\n",
      "Epoch [3/5], Step [1520/1875], Loss: 2.1426, batch time: 0.10\n",
      "Epoch [3/5], Step [1521/1875], Loss: 2.1373, batch time: 0.17\n",
      "Epoch [3/5], Step [1522/1875], Loss: 2.1599, batch time: 0.10\n",
      "Epoch [3/5], Step [1523/1875], Loss: 2.2209, batch time: 0.11\n",
      "Epoch [3/5], Step [1524/1875], Loss: 2.3461, batch time: 0.13\n",
      "Epoch [3/5], Step [1525/1875], Loss: 2.2153, batch time: 0.13\n",
      "Epoch [3/5], Step [1526/1875], Loss: 2.1003, batch time: 0.14\n",
      "Epoch [3/5], Step [1527/1875], Loss: 2.2988, batch time: 0.12\n",
      "Epoch [3/5], Step [1528/1875], Loss: 2.1268, batch time: 0.11\n",
      "Epoch [3/5], Step [1529/1875], Loss: 2.1647, batch time: 0.11\n",
      "Epoch [3/5], Step [1530/1875], Loss: 2.1054, batch time: 0.15\n",
      "Epoch [3/5], Step [1531/1875], Loss: 2.2663, batch time: 0.12\n",
      "Epoch [3/5], Step [1532/1875], Loss: 2.2732, batch time: 0.11\n",
      "Epoch [3/5], Step [1533/1875], Loss: 2.0601, batch time: 0.14\n",
      "Epoch [3/5], Step [1534/1875], Loss: 2.1483, batch time: 0.14\n",
      "Epoch [3/5], Step [1535/1875], Loss: 2.2509, batch time: 0.10\n",
      "Epoch [3/5], Step [1536/1875], Loss: 2.1531, batch time: 0.10\n",
      "Epoch [3/5], Step [1537/1875], Loss: 2.2728, batch time: 0.11\n",
      "Epoch [3/5], Step [1538/1875], Loss: 2.2707, batch time: 0.13\n",
      "Epoch [3/5], Step [1539/1875], Loss: 2.1127, batch time: 0.11\n",
      "Epoch [3/5], Step [1540/1875], Loss: 2.2626, batch time: 0.13\n",
      "Epoch [3/5], Step [1541/1875], Loss: 2.1552, batch time: 0.10\n",
      "Epoch [3/5], Step [1542/1875], Loss: 2.2751, batch time: 0.11\n",
      "Epoch [3/5], Step [1543/1875], Loss: 2.1186, batch time: 0.10\n",
      "Epoch [3/5], Step [1544/1875], Loss: 2.1307, batch time: 0.15\n",
      "Epoch [3/5], Step [1545/1875], Loss: 2.1273, batch time: 0.10\n",
      "Epoch [3/5], Step [1546/1875], Loss: 2.1792, batch time: 0.10\n",
      "Epoch [3/5], Step [1547/1875], Loss: 2.1769, batch time: 0.11\n",
      "Epoch [3/5], Step [1548/1875], Loss: 2.1565, batch time: 0.10\n",
      "Epoch [3/5], Step [1549/1875], Loss: 2.3192, batch time: 0.10\n",
      "Epoch [3/5], Step [1550/1875], Loss: 2.3839, batch time: 0.11\n",
      "Epoch [3/5], Step [1551/1875], Loss: 2.1664, batch time: 0.10\n",
      "Epoch [3/5], Step [1552/1875], Loss: 2.1397, batch time: 0.14\n",
      "Epoch [3/5], Step [1553/1875], Loss: 2.0750, batch time: 0.10\n",
      "Epoch [3/5], Step [1554/1875], Loss: 2.2369, batch time: 0.10\n",
      "Epoch [3/5], Step [1555/1875], Loss: 2.1380, batch time: 0.10\n",
      "Epoch [3/5], Step [1556/1875], Loss: 2.1120, batch time: 0.10\n",
      "Epoch [3/5], Step [1557/1875], Loss: 2.1553, batch time: 0.10\n",
      "Epoch [3/5], Step [1558/1875], Loss: 2.3198, batch time: 0.13\n",
      "Epoch [3/5], Step [1559/1875], Loss: 2.3069, batch time: 0.12\n",
      "Epoch [3/5], Step [1560/1875], Loss: 2.1812, batch time: 0.10\n",
      "Epoch [3/5], Step [1561/1875], Loss: 2.1727, batch time: 0.12\n",
      "Epoch [3/5], Step [1562/1875], Loss: 2.3152, batch time: 0.10\n",
      "Epoch [3/5], Step [1563/1875], Loss: 2.3710, batch time: 0.12\n",
      "Epoch [3/5], Step [1564/1875], Loss: 2.1975, batch time: 0.12\n",
      "Epoch [3/5], Step [1565/1875], Loss: 2.1310, batch time: 0.09\n",
      "Epoch [3/5], Step [1566/1875], Loss: 2.1749, batch time: 0.11\n",
      "Epoch [3/5], Step [1567/1875], Loss: 2.1432, batch time: 0.10\n",
      "Epoch [3/5], Step [1568/1875], Loss: 2.2978, batch time: 0.11\n",
      "Epoch [3/5], Step [1569/1875], Loss: 2.1992, batch time: 0.10\n",
      "Epoch [3/5], Step [1570/1875], Loss: 2.1261, batch time: 0.10\n",
      "Epoch [3/5], Step [1571/1875], Loss: 2.1121, batch time: 0.12\n",
      "Epoch [3/5], Step [1572/1875], Loss: 2.1342, batch time: 0.10\n",
      "Epoch [3/5], Step [1573/1875], Loss: 2.1637, batch time: 0.14\n",
      "Epoch [3/5], Step [1574/1875], Loss: 2.2214, batch time: 0.17\n",
      "Epoch [3/5], Step [1575/1875], Loss: 2.3149, batch time: 0.12\n",
      "Epoch [3/5], Step [1576/1875], Loss: 2.2700, batch time: 0.09\n",
      "Epoch [3/5], Step [1577/1875], Loss: 2.1811, batch time: 0.10\n",
      "Epoch [3/5], Step [1578/1875], Loss: 2.2200, batch time: 0.12\n",
      "Epoch [3/5], Step [1579/1875], Loss: 2.0454, batch time: 0.14\n",
      "Epoch [3/5], Step [1580/1875], Loss: 2.1315, batch time: 0.12\n",
      "Epoch [3/5], Step [1581/1875], Loss: 2.0351, batch time: 0.14\n",
      "Epoch [3/5], Step [1582/1875], Loss: 2.2384, batch time: 0.13\n",
      "Epoch [3/5], Step [1583/1875], Loss: 2.1691, batch time: 0.10\n",
      "Epoch [3/5], Step [1584/1875], Loss: 2.2634, batch time: 0.10\n",
      "Epoch [3/5], Step [1585/1875], Loss: 2.2850, batch time: 0.10\n",
      "Epoch [3/5], Step [1586/1875], Loss: 2.2257, batch time: 0.10\n",
      "Epoch [3/5], Step [1587/1875], Loss: 2.2437, batch time: 0.11\n",
      "Epoch [3/5], Step [1588/1875], Loss: 2.2824, batch time: 0.10\n",
      "Epoch [3/5], Step [1589/1875], Loss: 2.2957, batch time: 0.15\n",
      "Epoch [3/5], Step [1590/1875], Loss: 2.1110, batch time: 0.11\n",
      "Epoch [3/5], Step [1591/1875], Loss: 2.2177, batch time: 0.14\n",
      "Epoch [3/5], Step [1592/1875], Loss: 2.2723, batch time: 0.10\n",
      "Epoch [3/5], Step [1593/1875], Loss: 2.0523, batch time: 0.14\n",
      "Epoch [3/5], Step [1594/1875], Loss: 2.1190, batch time: 0.10\n",
      "Epoch [3/5], Step [1595/1875], Loss: 2.1744, batch time: 0.10\n",
      "Epoch [3/5], Step [1596/1875], Loss: 2.1948, batch time: 0.10\n",
      "Epoch [3/5], Step [1597/1875], Loss: 2.1314, batch time: 0.12\n",
      "Epoch [3/5], Step [1598/1875], Loss: 2.3004, batch time: 0.20\n",
      "Epoch [3/5], Step [1599/1875], Loss: 2.2336, batch time: 0.10\n",
      "Epoch [3/5], Step [1600/1875], Loss: 2.0059, batch time: 0.14\n",
      "Epoch [3/5], Step [1601/1875], Loss: 2.1610, batch time: 0.10\n",
      "Epoch [3/5], Step [1602/1875], Loss: 2.1683, batch time: 0.14\n",
      "Epoch [3/5], Step [1603/1875], Loss: 2.2203, batch time: 0.10\n",
      "Epoch [3/5], Step [1604/1875], Loss: 2.3228, batch time: 0.11\n",
      "Epoch [3/5], Step [1605/1875], Loss: 2.3380, batch time: 0.10\n",
      "Epoch [3/5], Step [1606/1875], Loss: 2.2640, batch time: 0.10\n",
      "Epoch [3/5], Step [1607/1875], Loss: 2.1942, batch time: 0.11\n",
      "Epoch [3/5], Step [1608/1875], Loss: 2.1349, batch time: 0.10\n",
      "Epoch [3/5], Step [1609/1875], Loss: 2.0879, batch time: 0.10\n",
      "Epoch [3/5], Step [1610/1875], Loss: 2.1690, batch time: 0.10\n",
      "Epoch [3/5], Step [1611/1875], Loss: 2.0943, batch time: 0.10\n",
      "Epoch [3/5], Step [1612/1875], Loss: 2.0283, batch time: 0.19\n",
      "Epoch [3/5], Step [1613/1875], Loss: 2.2048, batch time: 0.10\n",
      "Epoch [3/5], Step [1614/1875], Loss: 2.1893, batch time: 0.12\n",
      "Epoch [3/5], Step [1615/1875], Loss: 2.2078, batch time: 0.11\n",
      "Epoch [3/5], Step [1616/1875], Loss: 2.1636, batch time: 0.11\n",
      "Epoch [3/5], Step [1617/1875], Loss: 2.1329, batch time: 0.10\n",
      "Epoch [3/5], Step [1618/1875], Loss: 2.1397, batch time: 0.20\n",
      "Epoch [3/5], Step [1619/1875], Loss: 2.0708, batch time: 0.10\n",
      "Epoch [3/5], Step [1620/1875], Loss: 2.1673, batch time: 0.10\n",
      "Epoch [3/5], Step [1621/1875], Loss: 2.2735, batch time: 0.11\n",
      "Epoch [3/5], Step [1622/1875], Loss: 2.3185, batch time: 0.10\n",
      "Epoch [3/5], Step [1623/1875], Loss: 2.1204, batch time: 0.11\n",
      "Epoch [3/5], Step [1624/1875], Loss: 2.2668, batch time: 0.13\n",
      "Epoch [3/5], Step [1625/1875], Loss: 2.2034, batch time: 0.10\n",
      "Epoch [3/5], Step [1626/1875], Loss: 2.1433, batch time: 0.10\n",
      "Epoch [3/5], Step [1627/1875], Loss: 2.3519, batch time: 0.20\n",
      "Epoch [3/5], Step [1628/1875], Loss: 2.1521, batch time: 0.10\n",
      "Epoch [3/5], Step [1629/1875], Loss: 2.2662, batch time: 0.15\n",
      "Epoch [3/5], Step [1630/1875], Loss: 2.0201, batch time: 0.10\n",
      "Epoch [3/5], Step [1631/1875], Loss: 2.1612, batch time: 0.15\n",
      "Epoch [3/5], Step [1632/1875], Loss: 2.1703, batch time: 0.11\n",
      "Epoch [3/5], Step [1633/1875], Loss: 2.0531, batch time: 0.11\n",
      "Epoch [3/5], Step [1634/1875], Loss: 2.2823, batch time: 0.10\n",
      "Epoch [3/5], Step [1635/1875], Loss: 2.2768, batch time: 0.10\n",
      "Epoch [3/5], Step [1636/1875], Loss: 2.2075, batch time: 0.12\n",
      "Epoch [3/5], Step [1637/1875], Loss: 2.2048, batch time: 0.10\n",
      "Epoch [3/5], Step [1638/1875], Loss: 2.2085, batch time: 0.10\n",
      "Epoch [3/5], Step [1639/1875], Loss: 2.2072, batch time: 0.14\n",
      "Epoch [3/5], Step [1640/1875], Loss: 2.3379, batch time: 0.10\n",
      "Epoch [3/5], Step [1641/1875], Loss: 2.1489, batch time: 0.16\n",
      "Epoch [3/5], Step [1642/1875], Loss: 2.3015, batch time: 0.10\n",
      "Epoch [3/5], Step [1643/1875], Loss: 2.1106, batch time: 0.10\n",
      "Epoch [3/5], Step [1644/1875], Loss: 2.0594, batch time: 0.10\n",
      "Epoch [3/5], Step [1645/1875], Loss: 2.0262, batch time: 0.10\n",
      "Epoch [3/5], Step [1646/1875], Loss: 2.1694, batch time: 0.14\n",
      "Epoch [3/5], Step [1647/1875], Loss: 2.2900, batch time: 0.11\n",
      "Epoch [3/5], Step [1648/1875], Loss: 2.1973, batch time: 0.11\n",
      "Epoch [3/5], Step [1649/1875], Loss: 2.2464, batch time: 0.11\n",
      "Epoch [3/5], Step [1650/1875], Loss: 2.2992, batch time: 0.20\n",
      "Epoch [3/5], Step [1651/1875], Loss: 2.1692, batch time: 0.11\n",
      "Epoch [3/5], Step [1652/1875], Loss: 2.2199, batch time: 0.12\n",
      "Epoch [3/5], Step [1653/1875], Loss: 2.1493, batch time: 0.10\n",
      "Epoch [3/5], Step [1654/1875], Loss: 2.1805, batch time: 0.11\n",
      "Epoch [3/5], Step [1655/1875], Loss: 2.1870, batch time: 0.18\n",
      "Epoch [3/5], Step [1656/1875], Loss: 2.1480, batch time: 0.10\n",
      "Epoch [3/5], Step [1657/1875], Loss: 2.2834, batch time: 0.22\n",
      "Epoch [3/5], Step [1658/1875], Loss: 2.2218, batch time: 0.14\n",
      "Epoch [3/5], Step [1659/1875], Loss: 2.2125, batch time: 0.13\n",
      "Epoch [3/5], Step [1660/1875], Loss: 2.1714, batch time: 0.14\n",
      "Epoch [3/5], Step [1661/1875], Loss: 2.3673, batch time: 0.11\n",
      "Epoch [3/5], Step [1662/1875], Loss: 2.2012, batch time: 0.10\n",
      "Epoch [3/5], Step [1663/1875], Loss: 2.1579, batch time: 0.12\n",
      "Epoch [3/5], Step [1664/1875], Loss: 2.1539, batch time: 0.12\n",
      "Epoch [3/5], Step [1665/1875], Loss: 2.1388, batch time: 0.12\n",
      "Epoch [3/5], Step [1666/1875], Loss: 2.2549, batch time: 0.14\n",
      "Epoch [3/5], Step [1667/1875], Loss: 2.2501, batch time: 0.13\n",
      "Epoch [3/5], Step [1668/1875], Loss: 2.1644, batch time: 0.10\n",
      "Epoch [3/5], Step [1669/1875], Loss: 2.1332, batch time: 0.10\n",
      "Epoch [3/5], Step [1670/1875], Loss: 2.0855, batch time: 0.10\n",
      "Epoch [3/5], Step [1671/1875], Loss: 2.2462, batch time: 0.12\n",
      "Epoch [3/5], Step [1672/1875], Loss: 2.1402, batch time: 0.17\n",
      "Epoch [3/5], Step [1673/1875], Loss: 2.1811, batch time: 0.16\n",
      "Epoch [3/5], Step [1674/1875], Loss: 2.1815, batch time: 0.14\n",
      "Epoch [3/5], Step [1675/1875], Loss: 2.3313, batch time: 0.13\n",
      "Epoch [3/5], Step [1676/1875], Loss: 2.2454, batch time: 0.12\n",
      "Epoch [3/5], Step [1677/1875], Loss: 2.3593, batch time: 0.10\n",
      "Epoch [3/5], Step [1678/1875], Loss: 2.2335, batch time: 0.13\n",
      "Epoch [3/5], Step [1679/1875], Loss: 2.2632, batch time: 0.11\n",
      "Epoch [3/5], Step [1680/1875], Loss: 2.0690, batch time: 0.15\n",
      "Epoch [3/5], Step [1681/1875], Loss: 2.2419, batch time: 0.14\n",
      "Epoch [3/5], Step [1682/1875], Loss: 2.2079, batch time: 0.14\n",
      "Epoch [3/5], Step [1683/1875], Loss: 2.1468, batch time: 0.10\n",
      "Epoch [3/5], Step [1684/1875], Loss: 2.2258, batch time: 0.18\n",
      "Epoch [3/5], Step [1685/1875], Loss: 2.1677, batch time: 0.14\n",
      "Epoch [3/5], Step [1686/1875], Loss: 2.2994, batch time: 0.11\n",
      "Epoch [3/5], Step [1687/1875], Loss: 2.2280, batch time: 0.13\n",
      "Epoch [3/5], Step [1688/1875], Loss: 2.1584, batch time: 0.11\n",
      "Epoch [3/5], Step [1689/1875], Loss: 2.1676, batch time: 0.12\n",
      "Epoch [3/5], Step [1690/1875], Loss: 2.1862, batch time: 0.11\n",
      "Epoch [3/5], Step [1691/1875], Loss: 2.0317, batch time: 0.09\n",
      "Epoch [3/5], Step [1692/1875], Loss: 2.1034, batch time: 0.11\n",
      "Epoch [3/5], Step [1693/1875], Loss: 2.3247, batch time: 0.13\n",
      "Epoch [3/5], Step [1694/1875], Loss: 2.3399, batch time: 0.10\n",
      "Epoch [3/5], Step [1695/1875], Loss: 2.1133, batch time: 0.10\n",
      "Epoch [3/5], Step [1696/1875], Loss: 2.2305, batch time: 0.10\n",
      "Epoch [3/5], Step [1697/1875], Loss: 2.1968, batch time: 0.10\n",
      "Epoch [3/5], Step [1698/1875], Loss: 2.1423, batch time: 0.12\n",
      "Epoch [3/5], Step [1699/1875], Loss: 2.1185, batch time: 0.14\n",
      "Epoch [3/5], Step [1700/1875], Loss: 2.1373, batch time: 0.10\n",
      "Epoch [3/5], Step [1701/1875], Loss: 2.2340, batch time: 0.10\n",
      "Epoch [3/5], Step [1702/1875], Loss: 2.2199, batch time: 0.13\n",
      "Epoch [3/5], Step [1703/1875], Loss: 2.2716, batch time: 0.09\n",
      "Epoch [3/5], Step [1704/1875], Loss: 2.2116, batch time: 0.10\n",
      "Epoch [3/5], Step [1705/1875], Loss: 2.1546, batch time: 0.10\n",
      "Epoch [3/5], Step [1706/1875], Loss: 2.2386, batch time: 0.09\n",
      "Epoch [3/5], Step [1707/1875], Loss: 2.0886, batch time: 0.10\n",
      "Epoch [3/5], Step [1708/1875], Loss: 2.3314, batch time: 0.15\n",
      "Epoch [3/5], Step [1709/1875], Loss: 2.1875, batch time: 0.10\n",
      "Epoch [3/5], Step [1710/1875], Loss: 2.4020, batch time: 0.10\n",
      "Epoch [3/5], Step [1711/1875], Loss: 2.1014, batch time: 0.10\n",
      "Epoch [3/5], Step [1712/1875], Loss: 2.3481, batch time: 0.20\n",
      "Epoch [3/5], Step [1713/1875], Loss: 2.2306, batch time: 0.10\n",
      "Epoch [3/5], Step [1714/1875], Loss: 2.1398, batch time: 0.10\n",
      "Epoch [3/5], Step [1715/1875], Loss: 2.2672, batch time: 0.13\n",
      "Epoch [3/5], Step [1716/1875], Loss: 2.2913, batch time: 0.11\n",
      "Epoch [3/5], Step [1717/1875], Loss: 2.3556, batch time: 0.11\n",
      "Epoch [3/5], Step [1718/1875], Loss: 2.0839, batch time: 0.10\n",
      "Epoch [3/5], Step [1719/1875], Loss: 2.2913, batch time: 0.10\n",
      "Epoch [3/5], Step [1720/1875], Loss: 2.1171, batch time: 0.10\n",
      "Epoch [3/5], Step [1721/1875], Loss: 2.2952, batch time: 0.09\n",
      "Epoch [3/5], Step [1722/1875], Loss: 2.2220, batch time: 0.23\n",
      "Epoch [3/5], Step [1723/1875], Loss: 2.2623, batch time: 0.10\n",
      "Epoch [3/5], Step [1724/1875], Loss: 2.2113, batch time: 0.10\n",
      "Epoch [3/5], Step [1725/1875], Loss: 2.2608, batch time: 0.10\n",
      "Epoch [3/5], Step [1726/1875], Loss: 2.2339, batch time: 0.09\n",
      "Epoch [3/5], Step [1727/1875], Loss: 2.2547, batch time: 0.13\n",
      "Epoch [3/5], Step [1728/1875], Loss: 2.2133, batch time: 0.24\n",
      "Epoch [3/5], Step [1729/1875], Loss: 2.2171, batch time: 0.09\n",
      "Epoch [3/5], Step [1730/1875], Loss: 2.2073, batch time: 0.09\n",
      "Epoch [3/5], Step [1731/1875], Loss: 2.1636, batch time: 0.10\n",
      "Epoch [3/5], Step [1732/1875], Loss: 2.1170, batch time: 0.09\n",
      "Epoch [3/5], Step [1733/1875], Loss: 2.1679, batch time: 0.10\n",
      "Epoch [3/5], Step [1734/1875], Loss: 2.1902, batch time: 0.12\n",
      "Epoch [3/5], Step [1735/1875], Loss: 2.1387, batch time: 0.09\n",
      "Epoch [3/5], Step [1736/1875], Loss: 2.3282, batch time: 0.10\n",
      "Epoch [3/5], Step [1737/1875], Loss: 2.2403, batch time: 0.11\n",
      "Epoch [3/5], Step [1738/1875], Loss: 2.1751, batch time: 0.10\n",
      "Epoch [3/5], Step [1739/1875], Loss: 2.2653, batch time: 0.09\n",
      "Epoch [3/5], Step [1740/1875], Loss: 2.0531, batch time: 0.09\n",
      "Epoch [3/5], Step [1741/1875], Loss: 2.1649, batch time: 0.10\n",
      "Epoch [3/5], Step [1742/1875], Loss: 2.2744, batch time: 0.10\n",
      "Epoch [3/5], Step [1743/1875], Loss: 2.2188, batch time: 0.10\n",
      "Epoch [3/5], Step [1744/1875], Loss: 2.1215, batch time: 0.10\n",
      "Epoch [3/5], Step [1745/1875], Loss: 2.1905, batch time: 0.14\n",
      "Epoch [3/5], Step [1746/1875], Loss: 2.0638, batch time: 0.09\n",
      "Epoch [3/5], Step [1747/1875], Loss: 2.2136, batch time: 0.15\n",
      "Epoch [3/5], Step [1748/1875], Loss: 2.2439, batch time: 0.16\n",
      "Epoch [3/5], Step [1749/1875], Loss: 2.0870, batch time: 0.10\n",
      "Epoch [3/5], Step [1750/1875], Loss: 2.1075, batch time: 0.09\n",
      "Epoch [3/5], Step [1751/1875], Loss: 2.1166, batch time: 0.09\n",
      "Epoch [3/5], Step [1752/1875], Loss: 2.1232, batch time: 0.10\n",
      "Epoch [3/5], Step [1753/1875], Loss: 2.2474, batch time: 0.09\n",
      "Epoch [3/5], Step [1754/1875], Loss: 2.2067, batch time: 0.10\n",
      "Epoch [3/5], Step [1755/1875], Loss: 2.2323, batch time: 0.11\n",
      "Epoch [3/5], Step [1756/1875], Loss: 2.0249, batch time: 0.14\n",
      "Epoch [3/5], Step [1757/1875], Loss: 2.0315, batch time: 0.10\n",
      "Epoch [3/5], Step [1758/1875], Loss: 2.0551, batch time: 0.09\n",
      "Epoch [3/5], Step [1759/1875], Loss: 2.1981, batch time: 0.10\n",
      "Epoch [3/5], Step [1760/1875], Loss: 2.1053, batch time: -2.83\n",
      "Epoch [3/5], Step [1761/1875], Loss: 2.1056, batch time: 0.09\n",
      "Epoch [3/5], Step [1762/1875], Loss: 2.1408, batch time: 0.09\n",
      "Epoch [3/5], Step [1763/1875], Loss: 2.2311, batch time: 0.10\n",
      "Epoch [3/5], Step [1764/1875], Loss: 2.1999, batch time: 0.09\n",
      "Epoch [3/5], Step [1765/1875], Loss: 2.0758, batch time: 0.10\n",
      "Epoch [3/5], Step [1766/1875], Loss: 2.0312, batch time: 0.10\n",
      "Epoch [3/5], Step [1767/1875], Loss: 2.0073, batch time: 0.10\n",
      "Epoch [3/5], Step [1768/1875], Loss: 2.2349, batch time: 0.10\n",
      "Epoch [3/5], Step [1769/1875], Loss: 2.0574, batch time: 0.11\n",
      "Epoch [3/5], Step [1770/1875], Loss: 2.1578, batch time: 0.10\n",
      "Epoch [3/5], Step [1771/1875], Loss: 2.1083, batch time: 0.10\n",
      "Epoch [3/5], Step [1772/1875], Loss: 2.1355, batch time: 0.10\n",
      "Epoch [3/5], Step [1773/1875], Loss: 2.1120, batch time: 0.11\n",
      "Epoch [3/5], Step [1774/1875], Loss: 2.1986, batch time: 0.10\n",
      "Epoch [3/5], Step [1775/1875], Loss: 2.1370, batch time: 0.13\n",
      "Epoch [3/5], Step [1776/1875], Loss: 2.2707, batch time: 0.16\n",
      "Epoch [3/5], Step [1777/1875], Loss: 2.2399, batch time: 0.14\n",
      "Epoch [3/5], Step [1778/1875], Loss: 2.1866, batch time: 0.12\n",
      "Epoch [3/5], Step [1779/1875], Loss: 2.1420, batch time: 0.12\n",
      "Epoch [3/5], Step [1780/1875], Loss: 2.1268, batch time: 0.15\n",
      "Epoch [3/5], Step [1781/1875], Loss: 2.2675, batch time: 0.14\n",
      "Epoch [3/5], Step [1782/1875], Loss: 2.1596, batch time: 0.10\n",
      "Epoch [3/5], Step [1783/1875], Loss: 2.0878, batch time: 0.10\n",
      "Epoch [3/5], Step [1784/1875], Loss: 2.1516, batch time: 0.10\n",
      "Epoch [3/5], Step [1785/1875], Loss: 2.1814, batch time: 0.14\n",
      "Epoch [3/5], Step [1786/1875], Loss: 2.1689, batch time: 0.12\n",
      "Epoch [3/5], Step [1787/1875], Loss: 2.1020, batch time: 0.14\n",
      "Epoch [3/5], Step [1788/1875], Loss: 2.1718, batch time: 0.15\n",
      "Epoch [3/5], Step [1789/1875], Loss: 2.2260, batch time: 0.10\n",
      "Epoch [3/5], Step [1790/1875], Loss: 2.2241, batch time: 0.12\n",
      "Epoch [3/5], Step [1791/1875], Loss: 2.2500, batch time: 0.10\n",
      "Epoch [3/5], Step [1792/1875], Loss: 2.2697, batch time: 0.13\n",
      "Epoch [3/5], Step [1793/1875], Loss: 2.2202, batch time: 0.14\n",
      "Epoch [3/5], Step [1794/1875], Loss: 2.1384, batch time: 0.10\n",
      "Epoch [3/5], Step [1795/1875], Loss: 2.3650, batch time: 0.13\n",
      "Epoch [3/5], Step [1796/1875], Loss: 2.0449, batch time: 0.10\n",
      "Epoch [3/5], Step [1797/1875], Loss: 2.2911, batch time: 0.12\n",
      "Epoch [3/5], Step [1798/1875], Loss: 2.2021, batch time: 0.12\n",
      "Epoch [3/5], Step [1799/1875], Loss: 2.2405, batch time: 0.10\n",
      "Epoch [3/5], Step [1800/1875], Loss: 2.1052, batch time: 0.11\n",
      "Epoch [3/5], Step [1801/1875], Loss: 2.2033, batch time: 0.13\n",
      "Epoch [3/5], Step [1802/1875], Loss: 2.1672, batch time: 0.13\n",
      "Epoch [3/5], Step [1803/1875], Loss: 2.0846, batch time: 0.18\n",
      "Epoch [3/5], Step [1804/1875], Loss: 2.2819, batch time: 0.12\n",
      "Epoch [3/5], Step [1805/1875], Loss: 1.9942, batch time: 0.13\n",
      "Epoch [3/5], Step [1806/1875], Loss: 2.3290, batch time: 0.10\n",
      "Epoch [3/5], Step [1807/1875], Loss: 2.2024, batch time: 0.10\n",
      "Epoch [3/5], Step [1808/1875], Loss: 2.2294, batch time: 0.10\n",
      "Epoch [3/5], Step [1809/1875], Loss: 2.1744, batch time: 0.10\n",
      "Epoch [3/5], Step [1810/1875], Loss: 2.3506, batch time: 0.16\n",
      "Epoch [3/5], Step [1811/1875], Loss: 2.1706, batch time: 0.10\n",
      "Epoch [3/5], Step [1812/1875], Loss: 2.2417, batch time: 0.10\n",
      "Epoch [3/5], Step [1813/1875], Loss: 2.0303, batch time: 0.14\n",
      "Epoch [3/5], Step [1814/1875], Loss: 2.2935, batch time: 0.10\n",
      "Epoch [3/5], Step [1815/1875], Loss: 2.0305, batch time: 0.12\n",
      "Epoch [3/5], Step [1816/1875], Loss: 2.1418, batch time: 0.16\n",
      "Epoch [3/5], Step [1817/1875], Loss: 2.0866, batch time: 0.13\n",
      "Epoch [3/5], Step [1818/1875], Loss: 2.0633, batch time: 0.10\n",
      "Epoch [3/5], Step [1819/1875], Loss: 2.2556, batch time: 0.10\n",
      "Epoch [3/5], Step [1820/1875], Loss: 2.0668, batch time: 0.10\n",
      "Epoch [3/5], Step [1821/1875], Loss: 2.1729, batch time: 0.10\n",
      "Epoch [3/5], Step [1822/1875], Loss: 2.1399, batch time: 0.10\n",
      "Epoch [3/5], Step [1823/1875], Loss: 2.2750, batch time: 0.13\n",
      "Epoch [3/5], Step [1824/1875], Loss: 2.1966, batch time: 0.10\n",
      "Epoch [3/5], Step [1825/1875], Loss: 2.1263, batch time: 0.13\n",
      "Epoch [3/5], Step [1826/1875], Loss: 2.0831, batch time: 0.10\n",
      "Epoch [3/5], Step [1827/1875], Loss: 2.1491, batch time: 0.10\n",
      "Epoch [3/5], Step [1828/1875], Loss: 2.1567, batch time: 0.10\n",
      "Epoch [3/5], Step [1829/1875], Loss: 2.1317, batch time: 0.13\n",
      "Epoch [3/5], Step [1830/1875], Loss: 2.2562, batch time: 0.10\n",
      "Epoch [3/5], Step [1831/1875], Loss: 2.2767, batch time: 0.12\n",
      "Epoch [3/5], Step [1832/1875], Loss: 2.1479, batch time: 0.10\n",
      "Epoch [3/5], Step [1833/1875], Loss: 2.2483, batch time: 0.13\n",
      "Epoch [3/5], Step [1834/1875], Loss: 2.1231, batch time: 0.11\n",
      "Epoch [3/5], Step [1835/1875], Loss: 2.0838, batch time: 0.10\n",
      "Epoch [3/5], Step [1836/1875], Loss: 2.1417, batch time: 0.10\n",
      "Epoch [3/5], Step [1837/1875], Loss: 2.2667, batch time: 0.10\n",
      "Epoch [3/5], Step [1838/1875], Loss: 2.2406, batch time: 0.10\n",
      "Epoch [3/5], Step [1839/1875], Loss: 2.3307, batch time: 0.12\n",
      "Epoch [3/5], Step [1840/1875], Loss: 2.2796, batch time: 0.10\n",
      "Epoch [3/5], Step [1841/1875], Loss: 2.2423, batch time: 0.11\n",
      "Epoch [3/5], Step [1842/1875], Loss: 2.1794, batch time: 0.12\n",
      "Epoch [3/5], Step [1843/1875], Loss: 2.2198, batch time: 0.10\n",
      "Epoch [3/5], Step [1844/1875], Loss: 2.0795, batch time: 0.12\n",
      "Epoch [3/5], Step [1845/1875], Loss: 2.1773, batch time: 0.11\n",
      "Epoch [3/5], Step [1846/1875], Loss: 2.2407, batch time: 0.13\n",
      "Epoch [3/5], Step [1847/1875], Loss: 2.1775, batch time: 0.10\n",
      "Epoch [3/5], Step [1848/1875], Loss: 2.1091, batch time: 0.13\n",
      "Epoch [3/5], Step [1849/1875], Loss: 2.1780, batch time: 0.14\n",
      "Epoch [3/5], Step [1850/1875], Loss: 2.0469, batch time: 0.14\n",
      "Epoch [3/5], Step [1851/1875], Loss: 2.2039, batch time: 0.14\n",
      "Epoch [3/5], Step [1852/1875], Loss: 2.1000, batch time: 0.12\n",
      "Epoch [3/5], Step [1853/1875], Loss: 2.0591, batch time: 0.14\n",
      "Epoch [3/5], Step [1854/1875], Loss: 2.2283, batch time: 0.14\n",
      "Epoch [3/5], Step [1855/1875], Loss: 2.0539, batch time: 0.12\n",
      "Epoch [3/5], Step [1856/1875], Loss: 2.3776, batch time: 0.10\n",
      "Epoch [3/5], Step [1857/1875], Loss: 2.0539, batch time: 0.11\n",
      "Epoch [3/5], Step [1858/1875], Loss: 2.2170, batch time: 0.12\n",
      "Epoch [3/5], Step [1859/1875], Loss: 2.1669, batch time: 0.10\n",
      "Epoch [3/5], Step [1860/1875], Loss: 2.2304, batch time: 0.12\n",
      "Epoch [3/5], Step [1861/1875], Loss: 2.1430, batch time: 0.15\n",
      "Epoch [3/5], Step [1862/1875], Loss: 2.1136, batch time: 0.16\n",
      "Epoch [3/5], Step [1863/1875], Loss: 2.3612, batch time: 0.15\n",
      "Epoch [3/5], Step [1864/1875], Loss: 2.3293, batch time: 0.10\n",
      "Epoch [3/5], Step [1865/1875], Loss: 2.1775, batch time: 0.10\n",
      "Epoch [3/5], Step [1866/1875], Loss: 2.3004, batch time: 0.13\n",
      "Epoch [3/5], Step [1867/1875], Loss: 2.1643, batch time: 0.14\n",
      "Epoch [3/5], Step [1868/1875], Loss: 2.1206, batch time: 0.10\n",
      "Epoch [3/5], Step [1869/1875], Loss: 2.0092, batch time: 0.13\n",
      "Epoch [3/5], Step [1870/1875], Loss: 2.1572, batch time: 0.10\n",
      "Epoch [3/5], Step [1871/1875], Loss: 2.0212, batch time: 0.14\n",
      "Epoch [3/5], Step [1872/1875], Loss: 2.1893, batch time: 0.14\n",
      "Epoch [3/5], Step [1873/1875], Loss: 2.2364, batch time: 0.13\n",
      "Epoch [3/5], Step [1874/1875], Loss: 2.0622, batch time: 0.10\n",
      "Epoch [3/5], Step [1875/1875], Loss: 2.1977, batch time: 0.10\n",
      "Epoch [3/5] Accuracy: 20.00%\n",
      "Epoch [4/5], Step [1/1875], Loss: 2.1872, batch time: 0.10\n",
      "Epoch [4/5], Step [2/1875], Loss: 2.3725, batch time: 0.10\n",
      "Epoch [4/5], Step [3/1875], Loss: 2.2666, batch time: 0.13\n",
      "Epoch [4/5], Step [4/1875], Loss: 2.1867, batch time: 0.10\n",
      "Epoch [4/5], Step [5/1875], Loss: 2.0276, batch time: 0.09\n",
      "Epoch [4/5], Step [6/1875], Loss: 2.2370, batch time: 0.14\n",
      "Epoch [4/5], Step [7/1875], Loss: 2.2495, batch time: 0.14\n",
      "Epoch [4/5], Step [8/1875], Loss: 2.2033, batch time: 0.10\n",
      "Epoch [4/5], Step [9/1875], Loss: 2.1394, batch time: 0.13\n",
      "Epoch [4/5], Step [10/1875], Loss: 2.2968, batch time: 0.13\n",
      "Epoch [4/5], Step [11/1875], Loss: 2.1274, batch time: 0.09\n",
      "Epoch [4/5], Step [12/1875], Loss: 2.3092, batch time: 0.09\n",
      "Epoch [4/5], Step [13/1875], Loss: 2.1865, batch time: 0.11\n",
      "Epoch [4/5], Step [14/1875], Loss: 2.2992, batch time: 0.10\n",
      "Epoch [4/5], Step [15/1875], Loss: 2.2340, batch time: 0.10\n",
      "Epoch [4/5], Step [16/1875], Loss: 2.1647, batch time: 0.10\n",
      "Epoch [4/5], Step [17/1875], Loss: 2.1580, batch time: 0.10\n",
      "Epoch [4/5], Step [18/1875], Loss: 2.2081, batch time: 0.11\n",
      "Epoch [4/5], Step [19/1875], Loss: 2.2182, batch time: 0.10\n",
      "Epoch [4/5], Step [20/1875], Loss: 2.1514, batch time: 0.10\n",
      "Epoch [4/5], Step [21/1875], Loss: 2.1449, batch time: 0.12\n",
      "Epoch [4/5], Step [22/1875], Loss: 2.1155, batch time: 0.10\n",
      "Epoch [4/5], Step [23/1875], Loss: 2.2364, batch time: 0.10\n",
      "Epoch [4/5], Step [24/1875], Loss: 2.2080, batch time: 0.10\n",
      "Epoch [4/5], Step [25/1875], Loss: 1.9570, batch time: 0.10\n",
      "Epoch [4/5], Step [26/1875], Loss: 2.2245, batch time: 0.10\n",
      "Epoch [4/5], Step [27/1875], Loss: 2.2972, batch time: 0.10\n",
      "Epoch [4/5], Step [28/1875], Loss: 2.0493, batch time: 0.15\n",
      "Epoch [4/5], Step [29/1875], Loss: 2.2246, batch time: 0.13\n",
      "Epoch [4/5], Step [30/1875], Loss: 2.1002, batch time: 0.10\n",
      "Epoch [4/5], Step [31/1875], Loss: 2.2982, batch time: 0.16\n",
      "Epoch [4/5], Step [32/1875], Loss: 2.1934, batch time: 0.09\n",
      "Epoch [4/5], Step [33/1875], Loss: 2.2306, batch time: 0.09\n",
      "Epoch [4/5], Step [34/1875], Loss: 2.2632, batch time: 0.10\n",
      "Epoch [4/5], Step [35/1875], Loss: 2.1622, batch time: 0.17\n",
      "Epoch [4/5], Step [36/1875], Loss: 2.1069, batch time: 0.11\n",
      "Epoch [4/5], Step [37/1875], Loss: 2.0802, batch time: 0.14\n",
      "Epoch [4/5], Step [38/1875], Loss: 2.2745, batch time: 0.16\n",
      "Epoch [4/5], Step [39/1875], Loss: 2.3101, batch time: 0.12\n",
      "Epoch [4/5], Step [40/1875], Loss: 2.1147, batch time: 0.10\n",
      "Epoch [4/5], Step [41/1875], Loss: 2.2490, batch time: 0.12\n",
      "Epoch [4/5], Step [42/1875], Loss: 2.2763, batch time: 0.14\n",
      "Epoch [4/5], Step [43/1875], Loss: 2.2886, batch time: 0.13\n",
      "Epoch [4/5], Step [44/1875], Loss: 2.2018, batch time: 0.12\n",
      "Epoch [4/5], Step [45/1875], Loss: 2.3358, batch time: 0.11\n",
      "Epoch [4/5], Step [46/1875], Loss: 2.3154, batch time: 0.18\n",
      "Epoch [4/5], Step [47/1875], Loss: 2.1838, batch time: 0.16\n",
      "Epoch [4/5], Step [48/1875], Loss: 2.0777, batch time: 0.10\n",
      "Epoch [4/5], Step [49/1875], Loss: 2.2459, batch time: 0.14\n",
      "Epoch [4/5], Step [50/1875], Loss: 2.1894, batch time: 0.15\n",
      "Epoch [4/5], Step [51/1875], Loss: 2.2620, batch time: 0.13\n",
      "Epoch [4/5], Step [52/1875], Loss: 2.2306, batch time: 0.10\n",
      "Epoch [4/5], Step [53/1875], Loss: 2.1324, batch time: 0.10\n",
      "Epoch [4/5], Step [54/1875], Loss: 2.3054, batch time: 0.10\n",
      "Epoch [4/5], Step [55/1875], Loss: 2.1248, batch time: 0.19\n",
      "Epoch [4/5], Step [56/1875], Loss: 2.1473, batch time: 0.10\n",
      "Epoch [4/5], Step [57/1875], Loss: 2.0882, batch time: 0.10\n",
      "Epoch [4/5], Step [58/1875], Loss: 2.1789, batch time: 0.10\n",
      "Epoch [4/5], Step [59/1875], Loss: 2.2461, batch time: 0.12\n",
      "Epoch [4/5], Step [60/1875], Loss: 2.2972, batch time: 0.13\n",
      "Epoch [4/5], Step [61/1875], Loss: 2.2097, batch time: 0.10\n",
      "Epoch [4/5], Step [62/1875], Loss: 2.3055, batch time: 0.10\n",
      "Epoch [4/5], Step [63/1875], Loss: 2.0980, batch time: 0.10\n",
      "Epoch [4/5], Step [64/1875], Loss: 2.2855, batch time: 0.10\n",
      "Epoch [4/5], Step [65/1875], Loss: 2.0642, batch time: 0.12\n",
      "Epoch [4/5], Step [66/1875], Loss: 2.2266, batch time: 0.13\n",
      "Epoch [4/5], Step [67/1875], Loss: 2.1368, batch time: 0.12\n",
      "Epoch [4/5], Step [68/1875], Loss: 2.2784, batch time: 0.11\n",
      "Epoch [4/5], Step [69/1875], Loss: 2.0847, batch time: 0.12\n",
      "Epoch [4/5], Step [70/1875], Loss: 2.2102, batch time: 0.11\n",
      "Epoch [4/5], Step [71/1875], Loss: 2.1267, batch time: 0.10\n",
      "Epoch [4/5], Step [72/1875], Loss: 2.1106, batch time: 0.10\n",
      "Epoch [4/5], Step [73/1875], Loss: 2.0963, batch time: 0.10\n",
      "Epoch [4/5], Step [74/1875], Loss: 2.3211, batch time: 0.14\n",
      "Epoch [4/5], Step [75/1875], Loss: 2.4148, batch time: 0.11\n",
      "Epoch [4/5], Step [76/1875], Loss: 2.0574, batch time: 0.10\n",
      "Epoch [4/5], Step [77/1875], Loss: 2.1898, batch time: 0.11\n",
      "Epoch [4/5], Step [78/1875], Loss: 2.0910, batch time: 0.11\n",
      "Epoch [4/5], Step [79/1875], Loss: 2.1804, batch time: 0.13\n",
      "Epoch [4/5], Step [80/1875], Loss: 2.0683, batch time: 0.10\n",
      "Epoch [4/5], Step [81/1875], Loss: 2.2617, batch time: 0.12\n",
      "Epoch [4/5], Step [82/1875], Loss: 2.0405, batch time: 0.11\n",
      "Epoch [4/5], Step [83/1875], Loss: 2.1238, batch time: 0.10\n",
      "Epoch [4/5], Step [84/1875], Loss: 2.2343, batch time: 0.13\n",
      "Epoch [4/5], Step [85/1875], Loss: 2.2707, batch time: 0.10\n",
      "Epoch [4/5], Step [86/1875], Loss: 2.0954, batch time: 0.10\n",
      "Epoch [4/5], Step [87/1875], Loss: 2.2959, batch time: 0.10\n",
      "Epoch [4/5], Step [88/1875], Loss: 2.1070, batch time: 0.12\n",
      "Epoch [4/5], Step [89/1875], Loss: 2.1599, batch time: 0.10\n",
      "Epoch [4/5], Step [90/1875], Loss: 2.2252, batch time: 0.10\n",
      "Epoch [4/5], Step [91/1875], Loss: 2.2315, batch time: 0.10\n",
      "Epoch [4/5], Step [92/1875], Loss: 2.2644, batch time: 0.10\n",
      "Epoch [4/5], Step [93/1875], Loss: 2.1486, batch time: 0.14\n",
      "Epoch [4/5], Step [94/1875], Loss: 2.2600, batch time: 0.12\n",
      "Epoch [4/5], Step [95/1875], Loss: 2.1917, batch time: 0.09\n",
      "Epoch [4/5], Step [96/1875], Loss: 2.0566, batch time: 0.13\n",
      "Epoch [4/5], Step [97/1875], Loss: 2.1566, batch time: 0.10\n",
      "Epoch [4/5], Step [98/1875], Loss: 2.1831, batch time: 0.10\n",
      "Epoch [4/5], Step [99/1875], Loss: 2.1937, batch time: 0.10\n",
      "Epoch [4/5], Step [100/1875], Loss: 2.1879, batch time: 0.11\n",
      "Epoch [4/5], Step [101/1875], Loss: 2.2375, batch time: 0.11\n",
      "Epoch [4/5], Step [102/1875], Loss: 2.2463, batch time: 0.10\n",
      "Epoch [4/5], Step [103/1875], Loss: 2.1180, batch time: 0.13\n",
      "Epoch [4/5], Step [104/1875], Loss: 2.2444, batch time: 0.13\n",
      "Epoch [4/5], Step [105/1875], Loss: 2.1075, batch time: 0.13\n",
      "Epoch [4/5], Step [106/1875], Loss: 2.0505, batch time: 0.10\n",
      "Epoch [4/5], Step [107/1875], Loss: 2.1035, batch time: 0.10\n",
      "Epoch [4/5], Step [108/1875], Loss: 2.1433, batch time: 0.10\n",
      "Epoch [4/5], Step [109/1875], Loss: 2.2308, batch time: 0.11\n",
      "Epoch [4/5], Step [110/1875], Loss: 2.3016, batch time: 0.12\n",
      "Epoch [4/5], Step [111/1875], Loss: 2.3082, batch time: 0.14\n",
      "Epoch [4/5], Step [112/1875], Loss: 2.1566, batch time: 0.10\n",
      "Epoch [4/5], Step [113/1875], Loss: 2.0238, batch time: 0.10\n",
      "Epoch [4/5], Step [114/1875], Loss: 2.2246, batch time: 0.11\n",
      "Epoch [4/5], Step [115/1875], Loss: 2.0991, batch time: 0.10\n",
      "Epoch [4/5], Step [116/1875], Loss: 2.2805, batch time: 0.12\n",
      "Epoch [4/5], Step [117/1875], Loss: 2.0419, batch time: 0.12\n",
      "Epoch [4/5], Step [118/1875], Loss: 2.1215, batch time: 0.14\n",
      "Epoch [4/5], Step [119/1875], Loss: 2.2015, batch time: 0.14\n",
      "Epoch [4/5], Step [120/1875], Loss: 2.2930, batch time: 0.13\n",
      "Epoch [4/5], Step [121/1875], Loss: 2.0576, batch time: 0.13\n",
      "Epoch [4/5], Step [122/1875], Loss: 2.3028, batch time: 0.12\n",
      "Epoch [4/5], Step [123/1875], Loss: 2.1928, batch time: 0.14\n",
      "Epoch [4/5], Step [124/1875], Loss: 2.1897, batch time: 0.10\n",
      "Epoch [4/5], Step [125/1875], Loss: 2.1421, batch time: 0.14\n",
      "Epoch [4/5], Step [126/1875], Loss: 2.1968, batch time: 0.14\n",
      "Epoch [4/5], Step [127/1875], Loss: 2.2584, batch time: 0.19\n",
      "Epoch [4/5], Step [128/1875], Loss: 2.0665, batch time: 0.14\n",
      "Epoch [4/5], Step [129/1875], Loss: 2.3487, batch time: 0.10\n",
      "Epoch [4/5], Step [130/1875], Loss: 2.1149, batch time: 0.10\n",
      "Epoch [4/5], Step [131/1875], Loss: 2.2191, batch time: 0.14\n",
      "Epoch [4/5], Step [132/1875], Loss: 2.0420, batch time: 0.13\n",
      "Epoch [4/5], Step [133/1875], Loss: 2.2001, batch time: 0.14\n",
      "Epoch [4/5], Step [134/1875], Loss: 2.1355, batch time: 0.13\n",
      "Epoch [4/5], Step [135/1875], Loss: 2.2169, batch time: 0.14\n",
      "Epoch [4/5], Step [136/1875], Loss: 2.2518, batch time: 0.13\n",
      "Epoch [4/5], Step [137/1875], Loss: 2.1375, batch time: 0.12\n",
      "Epoch [4/5], Step [138/1875], Loss: 2.1718, batch time: 0.12\n",
      "Epoch [4/5], Step [139/1875], Loss: 2.1952, batch time: 0.12\n",
      "Epoch [4/5], Step [140/1875], Loss: 2.2483, batch time: 0.15\n",
      "Epoch [4/5], Step [141/1875], Loss: 2.2089, batch time: 0.14\n",
      "Epoch [4/5], Step [142/1875], Loss: 2.2544, batch time: 0.19\n",
      "Epoch [4/5], Step [143/1875], Loss: 2.2552, batch time: 0.16\n",
      "Epoch [4/5], Step [144/1875], Loss: 2.0063, batch time: 0.17\n",
      "Epoch [4/5], Step [145/1875], Loss: 2.1482, batch time: 0.12\n",
      "Epoch [4/5], Step [146/1875], Loss: 2.2311, batch time: 0.14\n",
      "Epoch [4/5], Step [147/1875], Loss: 2.1389, batch time: 0.11\n",
      "Epoch [4/5], Step [148/1875], Loss: 2.2283, batch time: 0.14\n",
      "Epoch [4/5], Step [149/1875], Loss: 2.1188, batch time: 0.14\n",
      "Epoch [4/5], Step [150/1875], Loss: 2.1153, batch time: 0.11\n",
      "Epoch [4/5], Step [151/1875], Loss: 2.3005, batch time: 0.12\n",
      "Epoch [4/5], Step [152/1875], Loss: 2.3058, batch time: 0.12\n",
      "Epoch [4/5], Step [153/1875], Loss: 2.0817, batch time: 0.10\n",
      "Epoch [4/5], Step [154/1875], Loss: 2.2873, batch time: 0.09\n",
      "Epoch [4/5], Step [155/1875], Loss: 2.2520, batch time: -2.81\n",
      "Epoch [4/5], Step [156/1875], Loss: 2.0049, batch time: 0.10\n",
      "Epoch [4/5], Step [157/1875], Loss: 2.0748, batch time: 0.11\n",
      "Epoch [4/5], Step [158/1875], Loss: 2.0774, batch time: 0.13\n",
      "Epoch [4/5], Step [159/1875], Loss: 1.9039, batch time: 0.10\n",
      "Epoch [4/5], Step [160/1875], Loss: 2.1689, batch time: 0.14\n",
      "Epoch [4/5], Step [161/1875], Loss: 2.2696, batch time: 0.10\n",
      "Epoch [4/5], Step [162/1875], Loss: 2.2444, batch time: 0.10\n",
      "Epoch [4/5], Step [163/1875], Loss: 2.0401, batch time: 0.09\n",
      "Epoch [4/5], Step [164/1875], Loss: 2.1601, batch time: 0.17\n",
      "Epoch [4/5], Step [165/1875], Loss: 1.9907, batch time: 0.10\n",
      "Epoch [4/5], Step [166/1875], Loss: 2.2934, batch time: 0.15\n",
      "Epoch [4/5], Step [167/1875], Loss: 2.1924, batch time: 0.11\n",
      "Epoch [4/5], Step [168/1875], Loss: 2.1998, batch time: 0.12\n",
      "Epoch [4/5], Step [169/1875], Loss: 2.3301, batch time: 0.14\n",
      "Epoch [4/5], Step [170/1875], Loss: 2.2696, batch time: 0.10\n",
      "Epoch [4/5], Step [171/1875], Loss: 2.0217, batch time: 0.10\n",
      "Epoch [4/5], Step [172/1875], Loss: 2.1913, batch time: 0.17\n",
      "Epoch [4/5], Step [173/1875], Loss: 2.0592, batch time: 0.09\n",
      "Epoch [4/5], Step [174/1875], Loss: 2.3200, batch time: 0.17\n",
      "Epoch [4/5], Step [175/1875], Loss: 2.2025, batch time: 0.10\n",
      "Epoch [4/5], Step [176/1875], Loss: 2.1725, batch time: 0.10\n",
      "Epoch [4/5], Step [177/1875], Loss: 2.0977, batch time: 0.12\n",
      "Epoch [4/5], Step [178/1875], Loss: 2.3045, batch time: 0.15\n",
      "Epoch [4/5], Step [179/1875], Loss: 2.3067, batch time: 0.14\n",
      "Epoch [4/5], Step [180/1875], Loss: 2.1776, batch time: 0.13\n",
      "Epoch [4/5], Step [181/1875], Loss: 2.2333, batch time: 0.14\n",
      "Epoch [4/5], Step [182/1875], Loss: 2.2779, batch time: 0.14\n",
      "Epoch [4/5], Step [183/1875], Loss: 2.3337, batch time: 0.13\n",
      "Epoch [4/5], Step [184/1875], Loss: 2.1395, batch time: 0.13\n",
      "Epoch [4/5], Step [185/1875], Loss: 2.1584, batch time: 0.14\n",
      "Epoch [4/5], Step [186/1875], Loss: 2.0913, batch time: 0.17\n",
      "Epoch [4/5], Step [187/1875], Loss: 2.0807, batch time: 0.17\n",
      "Epoch [4/5], Step [188/1875], Loss: 2.1956, batch time: 0.12\n",
      "Epoch [4/5], Step [189/1875], Loss: 2.1867, batch time: 0.11\n",
      "Epoch [4/5], Step [190/1875], Loss: 2.0422, batch time: 0.11\n",
      "Epoch [4/5], Step [191/1875], Loss: 1.9853, batch time: 0.14\n",
      "Epoch [4/5], Step [192/1875], Loss: 2.2270, batch time: 0.15\n",
      "Epoch [4/5], Step [193/1875], Loss: 2.2330, batch time: 0.13\n",
      "Epoch [4/5], Step [194/1875], Loss: 2.1098, batch time: 0.13\n",
      "Epoch [4/5], Step [195/1875], Loss: 2.1050, batch time: 0.13\n",
      "Epoch [4/5], Step [196/1875], Loss: 2.2282, batch time: 0.12\n",
      "Epoch [4/5], Step [197/1875], Loss: 2.1413, batch time: 0.12\n",
      "Epoch [4/5], Step [198/1875], Loss: 2.1422, batch time: 0.10\n",
      "Epoch [4/5], Step [199/1875], Loss: 2.1212, batch time: 0.14\n",
      "Epoch [4/5], Step [200/1875], Loss: 2.0393, batch time: 0.11\n",
      "Epoch [4/5], Step [201/1875], Loss: 2.1475, batch time: 0.09\n",
      "Epoch [4/5], Step [202/1875], Loss: 2.2042, batch time: 0.10\n",
      "Epoch [4/5], Step [203/1875], Loss: 2.2662, batch time: 0.09\n",
      "Epoch [4/5], Step [204/1875], Loss: 2.2486, batch time: 0.10\n",
      "Epoch [4/5], Step [205/1875], Loss: 2.0600, batch time: 0.10\n",
      "Epoch [4/5], Step [206/1875], Loss: 2.1953, batch time: 0.14\n",
      "Epoch [4/5], Step [207/1875], Loss: 2.0221, batch time: 0.16\n",
      "Epoch [4/5], Step [208/1875], Loss: 2.0504, batch time: 0.18\n",
      "Epoch [4/5], Step [209/1875], Loss: 1.9571, batch time: 0.14\n",
      "Epoch [4/5], Step [210/1875], Loss: 2.1991, batch time: 0.17\n",
      "Epoch [4/5], Step [211/1875], Loss: 2.0742, batch time: 0.12\n",
      "Epoch [4/5], Step [212/1875], Loss: 2.1321, batch time: 0.14\n",
      "Epoch [4/5], Step [213/1875], Loss: 2.2212, batch time: 0.12\n",
      "Epoch [4/5], Step [214/1875], Loss: 2.1639, batch time: 0.13\n",
      "Epoch [4/5], Step [215/1875], Loss: 2.2203, batch time: 0.14\n",
      "Epoch [4/5], Step [216/1875], Loss: 2.1393, batch time: 0.14\n",
      "Epoch [4/5], Step [217/1875], Loss: 2.1394, batch time: 0.10\n",
      "Epoch [4/5], Step [218/1875], Loss: 2.2674, batch time: 0.13\n",
      "Epoch [4/5], Step [219/1875], Loss: 2.2763, batch time: 0.09\n",
      "Epoch [4/5], Step [220/1875], Loss: 2.2057, batch time: 0.28\n",
      "Epoch [4/5], Step [221/1875], Loss: 2.2679, batch time: 0.13\n",
      "Epoch [4/5], Step [222/1875], Loss: 2.0760, batch time: 0.12\n",
      "Epoch [4/5], Step [223/1875], Loss: 2.0947, batch time: 0.10\n",
      "Epoch [4/5], Step [224/1875], Loss: 2.2975, batch time: 0.12\n",
      "Epoch [4/5], Step [225/1875], Loss: 1.9950, batch time: 0.10\n",
      "Epoch [4/5], Step [226/1875], Loss: 2.1926, batch time: 0.11\n",
      "Epoch [4/5], Step [227/1875], Loss: 2.0699, batch time: 0.10\n",
      "Epoch [4/5], Step [228/1875], Loss: 2.1899, batch time: 0.10\n",
      "Epoch [4/5], Step [229/1875], Loss: 2.1808, batch time: 0.10\n",
      "Epoch [4/5], Step [230/1875], Loss: 2.2810, batch time: 0.10\n",
      "Epoch [4/5], Step [231/1875], Loss: 2.0865, batch time: 0.10\n",
      "Epoch [4/5], Step [232/1875], Loss: 2.0944, batch time: 0.10\n",
      "Epoch [4/5], Step [233/1875], Loss: 2.1676, batch time: 0.11\n",
      "Epoch [4/5], Step [234/1875], Loss: 2.3163, batch time: 0.14\n",
      "Epoch [4/5], Step [235/1875], Loss: 2.1827, batch time: 0.10\n",
      "Epoch [4/5], Step [236/1875], Loss: 2.4601, batch time: 0.10\n",
      "Epoch [4/5], Step [237/1875], Loss: 2.0791, batch time: 0.23\n",
      "Epoch [4/5], Step [238/1875], Loss: 2.1199, batch time: 0.17\n",
      "Epoch [4/5], Step [239/1875], Loss: 2.2650, batch time: 0.10\n",
      "Epoch [4/5], Step [240/1875], Loss: 2.1809, batch time: 0.10\n",
      "Epoch [4/5], Step [241/1875], Loss: 2.1340, batch time: 0.15\n",
      "Epoch [4/5], Step [242/1875], Loss: 2.2315, batch time: 0.10\n",
      "Epoch [4/5], Step [243/1875], Loss: 1.9274, batch time: 0.16\n",
      "Epoch [4/5], Step [244/1875], Loss: 2.1962, batch time: 0.09\n",
      "Epoch [4/5], Step [245/1875], Loss: 1.9282, batch time: 0.22\n",
      "Epoch [4/5], Step [246/1875], Loss: 2.1668, batch time: 0.11\n",
      "Epoch [4/5], Step [247/1875], Loss: 2.3987, batch time: 0.17\n",
      "Epoch [4/5], Step [248/1875], Loss: 2.1348, batch time: 0.10\n",
      "Epoch [4/5], Step [249/1875], Loss: 2.1215, batch time: 0.14\n",
      "Epoch [4/5], Step [250/1875], Loss: 2.1812, batch time: 0.10\n",
      "Epoch [4/5], Step [251/1875], Loss: 2.2226, batch time: 0.11\n",
      "Epoch [4/5], Step [252/1875], Loss: 2.1475, batch time: 0.12\n",
      "Epoch [4/5], Step [253/1875], Loss: 2.2099, batch time: 0.12\n",
      "Epoch [4/5], Step [254/1875], Loss: 2.2063, batch time: 0.09\n",
      "Epoch [4/5], Step [255/1875], Loss: 2.2856, batch time: 0.11\n",
      "Epoch [4/5], Step [256/1875], Loss: 2.0998, batch time: 0.14\n",
      "Epoch [4/5], Step [257/1875], Loss: 2.1510, batch time: 0.14\n",
      "Epoch [4/5], Step [258/1875], Loss: 2.1359, batch time: 0.11\n",
      "Epoch [4/5], Step [259/1875], Loss: 2.3601, batch time: 0.10\n",
      "Epoch [4/5], Step [260/1875], Loss: 2.1540, batch time: 0.14\n",
      "Epoch [4/5], Step [261/1875], Loss: 2.1596, batch time: 0.14\n",
      "Epoch [4/5], Step [262/1875], Loss: 2.1790, batch time: 0.12\n",
      "Epoch [4/5], Step [263/1875], Loss: 2.1357, batch time: 0.10\n",
      "Epoch [4/5], Step [264/1875], Loss: 2.2518, batch time: 0.09\n",
      "Epoch [4/5], Step [265/1875], Loss: 2.1847, batch time: 0.13\n",
      "Epoch [4/5], Step [266/1875], Loss: 2.2579, batch time: 0.14\n",
      "Epoch [4/5], Step [267/1875], Loss: 2.2889, batch time: 0.30\n",
      "Epoch [4/5], Step [268/1875], Loss: 2.2717, batch time: 0.11\n",
      "Epoch [4/5], Step [269/1875], Loss: 2.1513, batch time: 0.12\n",
      "Epoch [4/5], Step [270/1875], Loss: 2.1378, batch time: 0.10\n",
      "Epoch [4/5], Step [271/1875], Loss: 2.2209, batch time: 0.12\n",
      "Epoch [4/5], Step [272/1875], Loss: 2.1359, batch time: 0.10\n",
      "Epoch [4/5], Step [273/1875], Loss: 2.1806, batch time: 0.13\n",
      "Epoch [4/5], Step [274/1875], Loss: 2.0843, batch time: 0.12\n",
      "Epoch [4/5], Step [275/1875], Loss: 2.1944, batch time: 0.12\n",
      "Epoch [4/5], Step [276/1875], Loss: 2.2805, batch time: 0.11\n",
      "Epoch [4/5], Step [277/1875], Loss: 2.0993, batch time: 0.10\n",
      "Epoch [4/5], Step [278/1875], Loss: 2.3459, batch time: 0.12\n",
      "Epoch [4/5], Step [279/1875], Loss: 2.2111, batch time: 0.12\n",
      "Epoch [4/5], Step [280/1875], Loss: 2.1531, batch time: 0.10\n",
      "Epoch [4/5], Step [281/1875], Loss: 2.2041, batch time: 0.10\n",
      "Epoch [4/5], Step [282/1875], Loss: 2.2244, batch time: 0.10\n",
      "Epoch [4/5], Step [283/1875], Loss: 2.1735, batch time: 0.10\n",
      "Epoch [4/5], Step [284/1875], Loss: 2.2023, batch time: 0.09\n",
      "Epoch [4/5], Step [285/1875], Loss: 2.2736, batch time: 0.14\n",
      "Epoch [4/5], Step [286/1875], Loss: 2.2418, batch time: 0.10\n",
      "Epoch [4/5], Step [287/1875], Loss: 2.1851, batch time: 0.10\n",
      "Epoch [4/5], Step [288/1875], Loss: 2.2467, batch time: 0.14\n",
      "Epoch [4/5], Step [289/1875], Loss: 2.1183, batch time: 0.15\n",
      "Epoch [4/5], Step [290/1875], Loss: 2.2164, batch time: 0.13\n",
      "Epoch [4/5], Step [291/1875], Loss: 2.4526, batch time: 0.18\n",
      "Epoch [4/5], Step [292/1875], Loss: 2.1825, batch time: 0.12\n",
      "Epoch [4/5], Step [293/1875], Loss: 2.0775, batch time: 0.10\n",
      "Epoch [4/5], Step [294/1875], Loss: 2.2074, batch time: 0.22\n",
      "Epoch [4/5], Step [295/1875], Loss: 2.2430, batch time: 0.10\n",
      "Epoch [4/5], Step [296/1875], Loss: 2.1420, batch time: 0.16\n",
      "Epoch [4/5], Step [297/1875], Loss: 2.0658, batch time: 0.14\n",
      "Epoch [4/5], Step [298/1875], Loss: 2.1947, batch time: 0.10\n",
      "Epoch [4/5], Step [299/1875], Loss: 2.1327, batch time: 0.13\n",
      "Epoch [4/5], Step [300/1875], Loss: 2.1799, batch time: 0.13\n",
      "Epoch [4/5], Step [301/1875], Loss: 2.2119, batch time: 0.20\n",
      "Epoch [4/5], Step [302/1875], Loss: 2.1761, batch time: 0.13\n",
      "Epoch [4/5], Step [303/1875], Loss: 2.3546, batch time: 0.12\n",
      "Epoch [4/5], Step [304/1875], Loss: 2.2561, batch time: 0.10\n",
      "Epoch [4/5], Step [305/1875], Loss: 2.1672, batch time: 0.09\n",
      "Epoch [4/5], Step [306/1875], Loss: 2.0343, batch time: 0.09\n",
      "Epoch [4/5], Step [307/1875], Loss: 2.2846, batch time: 0.09\n",
      "Epoch [4/5], Step [308/1875], Loss: 2.1053, batch time: 0.12\n",
      "Epoch [4/5], Step [309/1875], Loss: 2.0552, batch time: 0.10\n",
      "Epoch [4/5], Step [310/1875], Loss: 2.1694, batch time: 0.14\n",
      "Epoch [4/5], Step [311/1875], Loss: 2.1960, batch time: 0.12\n",
      "Epoch [4/5], Step [312/1875], Loss: 2.2580, batch time: 0.13\n",
      "Epoch [4/5], Step [313/1875], Loss: 2.2393, batch time: 0.13\n",
      "Epoch [4/5], Step [314/1875], Loss: 2.1448, batch time: 0.13\n",
      "Epoch [4/5], Step [315/1875], Loss: 2.2186, batch time: 0.13\n",
      "Epoch [4/5], Step [316/1875], Loss: 2.0871, batch time: 0.09\n",
      "Epoch [4/5], Step [317/1875], Loss: 2.2490, batch time: 0.10\n",
      "Epoch [4/5], Step [318/1875], Loss: 2.2212, batch time: 0.15\n",
      "Epoch [4/5], Step [319/1875], Loss: 2.0484, batch time: 0.13\n",
      "Epoch [4/5], Step [320/1875], Loss: 2.0983, batch time: 0.13\n",
      "Epoch [4/5], Step [321/1875], Loss: 2.0786, batch time: 0.13\n",
      "Epoch [4/5], Step [322/1875], Loss: 2.0579, batch time: 0.11\n",
      "Epoch [4/5], Step [323/1875], Loss: 2.1280, batch time: 0.14\n",
      "Epoch [4/5], Step [324/1875], Loss: 2.1700, batch time: 0.10\n",
      "Epoch [4/5], Step [325/1875], Loss: 2.1624, batch time: 0.10\n",
      "Epoch [4/5], Step [326/1875], Loss: 2.2651, batch time: 0.10\n",
      "Epoch [4/5], Step [327/1875], Loss: 2.2589, batch time: 0.13\n",
      "Epoch [4/5], Step [328/1875], Loss: 2.1331, batch time: 0.10\n",
      "Epoch [4/5], Step [329/1875], Loss: 2.1184, batch time: 0.11\n",
      "Epoch [4/5], Step [330/1875], Loss: 2.1777, batch time: 0.10\n",
      "Epoch [4/5], Step [331/1875], Loss: 2.1604, batch time: 0.09\n",
      "Epoch [4/5], Step [332/1875], Loss: 2.2948, batch time: 0.12\n",
      "Epoch [4/5], Step [333/1875], Loss: 2.3580, batch time: 0.12\n",
      "Epoch [4/5], Step [334/1875], Loss: 2.2074, batch time: 0.12\n",
      "Epoch [4/5], Step [335/1875], Loss: 2.1932, batch time: 0.10\n",
      "Epoch [4/5], Step [336/1875], Loss: 2.1503, batch time: 0.31\n",
      "Epoch [4/5], Step [337/1875], Loss: 2.1903, batch time: 0.10\n",
      "Epoch [4/5], Step [338/1875], Loss: 2.0816, batch time: 0.10\n",
      "Epoch [4/5], Step [339/1875], Loss: 2.0626, batch time: 0.11\n",
      "Epoch [4/5], Step [340/1875], Loss: 2.2199, batch time: 0.10\n",
      "Epoch [4/5], Step [341/1875], Loss: 2.1464, batch time: 0.10\n",
      "Epoch [4/5], Step [342/1875], Loss: 1.9463, batch time: 0.11\n",
      "Epoch [4/5], Step [343/1875], Loss: 2.1997, batch time: 0.11\n",
      "Epoch [4/5], Step [344/1875], Loss: 2.2614, batch time: 0.12\n",
      "Epoch [4/5], Step [345/1875], Loss: 1.9039, batch time: 0.12\n",
      "Epoch [4/5], Step [346/1875], Loss: 2.0679, batch time: 0.10\n",
      "Epoch [4/5], Step [347/1875], Loss: 2.1605, batch time: 0.10\n",
      "Epoch [4/5], Step [348/1875], Loss: 2.2786, batch time: 0.10\n",
      "Epoch [4/5], Step [349/1875], Loss: 2.1994, batch time: 0.11\n",
      "Epoch [4/5], Step [350/1875], Loss: 2.2828, batch time: 0.10\n",
      "Epoch [4/5], Step [351/1875], Loss: 2.0752, batch time: 0.13\n",
      "Epoch [4/5], Step [352/1875], Loss: 2.1612, batch time: 0.12\n",
      "Epoch [4/5], Step [353/1875], Loss: 2.1590, batch time: 0.13\n",
      "Epoch [4/5], Step [354/1875], Loss: 2.0860, batch time: 0.13\n",
      "Epoch [4/5], Step [355/1875], Loss: 2.0706, batch time: 0.10\n",
      "Epoch [4/5], Step [356/1875], Loss: 2.2793, batch time: 0.13\n",
      "Epoch [4/5], Step [357/1875], Loss: 2.0724, batch time: 0.12\n",
      "Epoch [4/5], Step [358/1875], Loss: 2.1284, batch time: 0.10\n",
      "Epoch [4/5], Step [359/1875], Loss: 2.1464, batch time: 0.11\n",
      "Epoch [4/5], Step [360/1875], Loss: 2.1252, batch time: 0.10\n",
      "Epoch [4/5], Step [361/1875], Loss: 2.2554, batch time: 0.09\n",
      "Epoch [4/5], Step [362/1875], Loss: 2.1531, batch time: 0.13\n",
      "Epoch [4/5], Step [363/1875], Loss: 2.2894, batch time: 0.13\n",
      "Epoch [4/5], Step [364/1875], Loss: 2.0946, batch time: 0.10\n",
      "Epoch [4/5], Step [365/1875], Loss: 2.2562, batch time: 0.12\n",
      "Epoch [4/5], Step [366/1875], Loss: 2.2200, batch time: 0.10\n",
      "Epoch [4/5], Step [367/1875], Loss: 2.2142, batch time: 0.10\n",
      "Epoch [4/5], Step [368/1875], Loss: 2.2311, batch time: 0.21\n",
      "Epoch [4/5], Step [369/1875], Loss: 2.2824, batch time: 0.19\n",
      "Epoch [4/5], Step [370/1875], Loss: 1.9654, batch time: 0.13\n",
      "Epoch [4/5], Step [371/1875], Loss: 2.2262, batch time: 0.11\n",
      "Epoch [4/5], Step [372/1875], Loss: 2.3586, batch time: 0.12\n",
      "Epoch [4/5], Step [373/1875], Loss: 2.2829, batch time: 0.10\n",
      "Epoch [4/5], Step [374/1875], Loss: 2.1532, batch time: 0.12\n",
      "Epoch [4/5], Step [375/1875], Loss: 2.1608, batch time: 0.09\n",
      "Epoch [4/5], Step [376/1875], Loss: 1.9388, batch time: 0.12\n",
      "Epoch [4/5], Step [377/1875], Loss: 2.2680, batch time: 0.13\n",
      "Epoch [4/5], Step [378/1875], Loss: 2.2650, batch time: 0.10\n",
      "Epoch [4/5], Step [379/1875], Loss: 2.0756, batch time: 0.11\n",
      "Epoch [4/5], Step [380/1875], Loss: 2.2203, batch time: 0.11\n",
      "Epoch [4/5], Step [381/1875], Loss: 2.1724, batch time: 0.11\n",
      "Epoch [4/5], Step [382/1875], Loss: 2.0823, batch time: 0.10\n",
      "Epoch [4/5], Step [383/1875], Loss: 2.3294, batch time: 0.11\n",
      "Epoch [4/5], Step [384/1875], Loss: 2.1968, batch time: 0.11\n",
      "Epoch [4/5], Step [385/1875], Loss: 2.0561, batch time: 0.10\n",
      "Epoch [4/5], Step [386/1875], Loss: 2.1171, batch time: 0.10\n",
      "Epoch [4/5], Step [387/1875], Loss: 2.0326, batch time: 0.11\n",
      "Epoch [4/5], Step [388/1875], Loss: 2.2360, batch time: 0.14\n",
      "Epoch [4/5], Step [389/1875], Loss: 2.1883, batch time: 0.10\n",
      "Epoch [4/5], Step [390/1875], Loss: 2.1615, batch time: 0.10\n",
      "Epoch [4/5], Step [391/1875], Loss: 2.2152, batch time: 0.13\n",
      "Epoch [4/5], Step [392/1875], Loss: 2.0791, batch time: 0.11\n",
      "Epoch [4/5], Step [393/1875], Loss: 2.2817, batch time: 0.11\n",
      "Epoch [4/5], Step [394/1875], Loss: 2.3878, batch time: 0.14\n",
      "Epoch [4/5], Step [395/1875], Loss: 2.1235, batch time: 0.14\n",
      "Epoch [4/5], Step [396/1875], Loss: 2.1398, batch time: 0.15\n",
      "Epoch [4/5], Step [397/1875], Loss: 2.1259, batch time: 0.12\n",
      "Epoch [4/5], Step [398/1875], Loss: 2.1659, batch time: 0.13\n",
      "Epoch [4/5], Step [399/1875], Loss: 2.2803, batch time: 0.21\n",
      "Epoch [4/5], Step [400/1875], Loss: 2.1553, batch time: 0.14\n",
      "Epoch [4/5], Step [401/1875], Loss: 2.1398, batch time: 0.13\n",
      "Epoch [4/5], Step [402/1875], Loss: 2.2366, batch time: 0.11\n",
      "Epoch [4/5], Step [403/1875], Loss: 2.1158, batch time: 0.13\n",
      "Epoch [4/5], Step [404/1875], Loss: 2.2463, batch time: 0.11\n",
      "Epoch [4/5], Step [405/1875], Loss: 2.2087, batch time: 0.14\n",
      "Epoch [4/5], Step [406/1875], Loss: 2.0985, batch time: 0.16\n",
      "Epoch [4/5], Step [407/1875], Loss: 2.0854, batch time: 0.15\n",
      "Epoch [4/5], Step [408/1875], Loss: 2.0334, batch time: 0.17\n",
      "Epoch [4/5], Step [409/1875], Loss: 2.0379, batch time: 0.13\n",
      "Epoch [4/5], Step [410/1875], Loss: 2.1245, batch time: 0.17\n",
      "Epoch [4/5], Step [411/1875], Loss: 2.0936, batch time: 0.14\n",
      "Epoch [4/5], Step [412/1875], Loss: 1.9959, batch time: 0.10\n",
      "Epoch [4/5], Step [413/1875], Loss: 2.3187, batch time: -2.79\n",
      "Epoch [4/5], Step [414/1875], Loss: 2.0902, batch time: 0.23\n",
      "Epoch [4/5], Step [415/1875], Loss: 2.1569, batch time: 0.11\n",
      "Epoch [4/5], Step [416/1875], Loss: 2.3643, batch time: 0.13\n",
      "Epoch [4/5], Step [417/1875], Loss: 2.1666, batch time: 0.11\n",
      "Epoch [4/5], Step [418/1875], Loss: 2.0248, batch time: 0.10\n",
      "Epoch [4/5], Step [419/1875], Loss: 2.1335, batch time: 0.12\n",
      "Epoch [4/5], Step [420/1875], Loss: 2.0379, batch time: 0.14\n",
      "Epoch [4/5], Step [421/1875], Loss: 2.1905, batch time: 0.14\n",
      "Epoch [4/5], Step [422/1875], Loss: 2.2444, batch time: 0.14\n",
      "Epoch [4/5], Step [423/1875], Loss: 2.1133, batch time: 0.11\n",
      "Epoch [4/5], Step [424/1875], Loss: 2.1840, batch time: 0.12\n",
      "Epoch [4/5], Step [425/1875], Loss: 2.2123, batch time: 0.14\n",
      "Epoch [4/5], Step [426/1875], Loss: 2.3679, batch time: 0.12\n",
      "Epoch [4/5], Step [427/1875], Loss: 2.2080, batch time: 0.13\n",
      "Epoch [4/5], Step [428/1875], Loss: 2.2296, batch time: 0.14\n",
      "Epoch [4/5], Step [429/1875], Loss: 2.2014, batch time: 0.15\n",
      "Epoch [4/5], Step [430/1875], Loss: 2.1674, batch time: 0.14\n",
      "Epoch [4/5], Step [431/1875], Loss: 2.1360, batch time: 0.13\n",
      "Epoch [4/5], Step [432/1875], Loss: 2.0870, batch time: 0.12\n",
      "Epoch [4/5], Step [433/1875], Loss: 2.3464, batch time: 0.15\n",
      "Epoch [4/5], Step [434/1875], Loss: 2.2202, batch time: 0.13\n",
      "Epoch [4/5], Step [435/1875], Loss: 2.0810, batch time: 0.16\n",
      "Epoch [4/5], Step [436/1875], Loss: 2.1364, batch time: 0.15\n",
      "Epoch [4/5], Step [437/1875], Loss: 2.1021, batch time: 0.21\n",
      "Epoch [4/5], Step [438/1875], Loss: 2.0377, batch time: 0.13\n",
      "Epoch [4/5], Step [439/1875], Loss: 2.3211, batch time: 0.13\n",
      "Epoch [4/5], Step [440/1875], Loss: 2.3001, batch time: 0.11\n",
      "Epoch [4/5], Step [441/1875], Loss: 2.2526, batch time: 0.10\n",
      "Epoch [4/5], Step [442/1875], Loss: 2.0181, batch time: 0.10\n",
      "Epoch [4/5], Step [443/1875], Loss: 2.1981, batch time: 0.14\n",
      "Epoch [4/5], Step [444/1875], Loss: 2.3076, batch time: 0.11\n",
      "Epoch [4/5], Step [445/1875], Loss: 2.2766, batch time: 0.10\n",
      "Epoch [4/5], Step [446/1875], Loss: 2.1263, batch time: 0.12\n",
      "Epoch [4/5], Step [447/1875], Loss: 2.1963, batch time: 0.21\n",
      "Epoch [4/5], Step [448/1875], Loss: 2.0959, batch time: 0.10\n",
      "Epoch [4/5], Step [449/1875], Loss: 2.0231, batch time: 0.10\n",
      "Epoch [4/5], Step [450/1875], Loss: 2.1846, batch time: 0.10\n",
      "Epoch [4/5], Step [451/1875], Loss: 2.1221, batch time: 0.10\n",
      "Epoch [4/5], Step [452/1875], Loss: 2.1600, batch time: 0.10\n",
      "Epoch [4/5], Step [453/1875], Loss: 2.0964, batch time: 0.10\n",
      "Epoch [4/5], Step [454/1875], Loss: 2.1585, batch time: 0.11\n",
      "Epoch [4/5], Step [455/1875], Loss: 2.1213, batch time: 0.12\n",
      "Epoch [4/5], Step [456/1875], Loss: 2.2307, batch time: 0.13\n",
      "Epoch [4/5], Step [457/1875], Loss: 2.2517, batch time: 0.11\n",
      "Epoch [4/5], Step [458/1875], Loss: 2.1041, batch time: 0.09\n",
      "Epoch [4/5], Step [459/1875], Loss: 1.9829, batch time: 0.13\n",
      "Epoch [4/5], Step [460/1875], Loss: 2.1532, batch time: 0.13\n",
      "Epoch [4/5], Step [461/1875], Loss: 2.1537, batch time: 0.13\n",
      "Epoch [4/5], Step [462/1875], Loss: 2.1849, batch time: 0.14\n",
      "Epoch [4/5], Step [463/1875], Loss: 2.1270, batch time: 0.11\n",
      "Epoch [4/5], Step [464/1875], Loss: 1.9373, batch time: 0.10\n",
      "Epoch [4/5], Step [465/1875], Loss: 2.3776, batch time: 0.09\n",
      "Epoch [4/5], Step [466/1875], Loss: 2.1861, batch time: 0.18\n",
      "Epoch [4/5], Step [467/1875], Loss: 2.2151, batch time: 0.13\n",
      "Epoch [4/5], Step [468/1875], Loss: 2.2029, batch time: 0.13\n",
      "Epoch [4/5], Step [469/1875], Loss: 2.1135, batch time: 0.10\n",
      "Epoch [4/5], Step [470/1875], Loss: 2.1593, batch time: 0.12\n",
      "Epoch [4/5], Step [471/1875], Loss: 2.1173, batch time: 0.11\n",
      "Epoch [4/5], Step [472/1875], Loss: 2.0222, batch time: 0.35\n",
      "Epoch [4/5], Step [473/1875], Loss: 2.3102, batch time: 0.10\n",
      "Epoch [4/5], Step [474/1875], Loss: 2.2353, batch time: 0.14\n",
      "Epoch [4/5], Step [475/1875], Loss: 2.1799, batch time: 0.12\n",
      "Epoch [4/5], Step [476/1875], Loss: 2.2190, batch time: 0.09\n",
      "Epoch [4/5], Step [477/1875], Loss: 2.3648, batch time: 0.13\n",
      "Epoch [4/5], Step [478/1875], Loss: 2.1325, batch time: 0.11\n",
      "Epoch [4/5], Step [479/1875], Loss: 2.1780, batch time: 0.10\n",
      "Epoch [4/5], Step [480/1875], Loss: 2.2551, batch time: 0.10\n",
      "Epoch [4/5], Step [481/1875], Loss: 2.1915, batch time: 0.11\n",
      "Epoch [4/5], Step [482/1875], Loss: 2.3277, batch time: 0.10\n",
      "Epoch [4/5], Step [483/1875], Loss: 2.1826, batch time: 0.09\n",
      "Epoch [4/5], Step [484/1875], Loss: 2.1575, batch time: 0.13\n",
      "Epoch [4/5], Step [485/1875], Loss: 2.1981, batch time: 0.12\n",
      "Epoch [4/5], Step [486/1875], Loss: 2.2553, batch time: 0.10\n",
      "Epoch [4/5], Step [487/1875], Loss: 2.1203, batch time: 0.16\n",
      "Epoch [4/5], Step [488/1875], Loss: 2.1742, batch time: 0.11\n",
      "Epoch [4/5], Step [489/1875], Loss: 2.1460, batch time: 0.18\n",
      "Epoch [4/5], Step [490/1875], Loss: 2.1635, batch time: 0.10\n",
      "Epoch [4/5], Step [491/1875], Loss: 2.1168, batch time: 0.10\n",
      "Epoch [4/5], Step [492/1875], Loss: 2.2163, batch time: 0.10\n",
      "Epoch [4/5], Step [493/1875], Loss: 2.1984, batch time: 0.10\n",
      "Epoch [4/5], Step [494/1875], Loss: 2.1614, batch time: 0.10\n",
      "Epoch [4/5], Step [495/1875], Loss: 1.9954, batch time: 0.13\n",
      "Epoch [4/5], Step [496/1875], Loss: 2.1496, batch time: 0.12\n",
      "Epoch [4/5], Step [497/1875], Loss: 2.3125, batch time: 0.11\n",
      "Epoch [4/5], Step [498/1875], Loss: 2.0212, batch time: 0.11\n",
      "Epoch [4/5], Step [499/1875], Loss: 2.0397, batch time: 0.10\n",
      "Epoch [4/5], Step [500/1875], Loss: 2.1703, batch time: 0.10\n",
      "Epoch [4/5], Step [501/1875], Loss: 2.3288, batch time: 0.20\n",
      "Epoch [4/5], Step [502/1875], Loss: 2.1377, batch time: 0.14\n",
      "Epoch [4/5], Step [503/1875], Loss: 2.1204, batch time: 0.14\n",
      "Epoch [4/5], Step [504/1875], Loss: 2.2241, batch time: 0.14\n",
      "Epoch [4/5], Step [505/1875], Loss: 2.3369, batch time: 0.10\n",
      "Epoch [4/5], Step [506/1875], Loss: 2.2502, batch time: 0.10\n",
      "Epoch [4/5], Step [507/1875], Loss: 2.1630, batch time: 0.10\n",
      "Epoch [4/5], Step [508/1875], Loss: 2.1921, batch time: 0.15\n",
      "Epoch [4/5], Step [509/1875], Loss: 2.0573, batch time: 0.10\n",
      "Epoch [4/5], Step [510/1875], Loss: 2.1216, batch time: 0.12\n",
      "Epoch [4/5], Step [511/1875], Loss: 2.0449, batch time: 0.10\n",
      "Epoch [4/5], Step [512/1875], Loss: 2.1134, batch time: 0.12\n",
      "Epoch [4/5], Step [513/1875], Loss: 1.9757, batch time: 0.13\n",
      "Epoch [4/5], Step [514/1875], Loss: 2.3684, batch time: 0.13\n",
      "Epoch [4/5], Step [515/1875], Loss: 2.2649, batch time: 0.14\n",
      "Epoch [4/5], Step [516/1875], Loss: 2.2244, batch time: 0.20\n",
      "Epoch [4/5], Step [517/1875], Loss: 2.1262, batch time: 0.10\n",
      "Epoch [4/5], Step [518/1875], Loss: 2.2076, batch time: 0.16\n",
      "Epoch [4/5], Step [519/1875], Loss: 1.9432, batch time: 0.14\n",
      "Epoch [4/5], Step [520/1875], Loss: 2.0624, batch time: 0.10\n",
      "Epoch [4/5], Step [521/1875], Loss: 2.0760, batch time: 0.11\n",
      "Epoch [4/5], Step [522/1875], Loss: 2.0637, batch time: 0.10\n",
      "Epoch [4/5], Step [523/1875], Loss: 2.1519, batch time: 0.10\n",
      "Epoch [4/5], Step [524/1875], Loss: 2.1735, batch time: 0.10\n",
      "Epoch [4/5], Step [525/1875], Loss: 2.2956, batch time: 0.10\n",
      "Epoch [4/5], Step [526/1875], Loss: 2.2739, batch time: 0.11\n",
      "Epoch [4/5], Step [527/1875], Loss: 2.3295, batch time: 0.10\n",
      "Epoch [4/5], Step [528/1875], Loss: 2.2238, batch time: 0.11\n",
      "Epoch [4/5], Step [529/1875], Loss: 2.0389, batch time: 0.15\n",
      "Epoch [4/5], Step [530/1875], Loss: 1.9084, batch time: 0.12\n",
      "Epoch [4/5], Step [531/1875], Loss: 2.2436, batch time: 0.10\n",
      "Epoch [4/5], Step [532/1875], Loss: 2.1246, batch time: 0.13\n",
      "Epoch [4/5], Step [533/1875], Loss: 2.1704, batch time: 0.10\n",
      "Epoch [4/5], Step [534/1875], Loss: 2.1797, batch time: 0.10\n",
      "Epoch [4/5], Step [535/1875], Loss: 2.1896, batch time: 0.10\n",
      "Epoch [4/5], Step [536/1875], Loss: 2.0241, batch time: 0.10\n",
      "Epoch [4/5], Step [537/1875], Loss: 2.2276, batch time: 0.12\n",
      "Epoch [4/5], Step [538/1875], Loss: 2.2170, batch time: 0.11\n",
      "Epoch [4/5], Step [539/1875], Loss: 2.0847, batch time: 0.12\n",
      "Epoch [4/5], Step [540/1875], Loss: 2.1041, batch time: 0.10\n",
      "Epoch [4/5], Step [541/1875], Loss: 2.0650, batch time: 0.11\n",
      "Epoch [4/5], Step [542/1875], Loss: 2.0779, batch time: 0.13\n",
      "Epoch [4/5], Step [543/1875], Loss: 2.3465, batch time: 0.16\n",
      "Epoch [4/5], Step [544/1875], Loss: 2.0236, batch time: 0.16\n",
      "Epoch [4/5], Step [545/1875], Loss: 2.1703, batch time: 0.10\n",
      "Epoch [4/5], Step [546/1875], Loss: 2.0955, batch time: 0.11\n",
      "Epoch [4/5], Step [547/1875], Loss: 2.0956, batch time: 0.10\n",
      "Epoch [4/5], Step [548/1875], Loss: 1.9794, batch time: 0.23\n",
      "Epoch [4/5], Step [549/1875], Loss: 1.9892, batch time: 0.10\n",
      "Epoch [4/5], Step [550/1875], Loss: 2.0815, batch time: 0.09\n",
      "Epoch [4/5], Step [551/1875], Loss: 2.0287, batch time: 0.10\n",
      "Epoch [4/5], Step [552/1875], Loss: 2.1201, batch time: 0.10\n",
      "Epoch [4/5], Step [553/1875], Loss: 2.1422, batch time: 0.15\n",
      "Epoch [4/5], Step [554/1875], Loss: 2.2614, batch time: 0.12\n",
      "Epoch [4/5], Step [555/1875], Loss: 2.1054, batch time: 0.09\n",
      "Epoch [4/5], Step [556/1875], Loss: 2.0524, batch time: 0.13\n",
      "Epoch [4/5], Step [557/1875], Loss: 2.2431, batch time: 0.14\n",
      "Epoch [4/5], Step [558/1875], Loss: 2.3478, batch time: 0.11\n",
      "Epoch [4/5], Step [559/1875], Loss: 2.2341, batch time: 0.15\n",
      "Epoch [4/5], Step [560/1875], Loss: 2.0554, batch time: 0.12\n",
      "Epoch [4/5], Step [561/1875], Loss: 2.1572, batch time: 0.13\n",
      "Epoch [4/5], Step [562/1875], Loss: 2.1234, batch time: 0.14\n",
      "Epoch [4/5], Step [563/1875], Loss: 2.2058, batch time: 0.12\n",
      "Epoch [4/5], Step [564/1875], Loss: 2.0541, batch time: 0.12\n",
      "Epoch [4/5], Step [565/1875], Loss: 2.2866, batch time: 0.09\n",
      "Epoch [4/5], Step [566/1875], Loss: 2.1151, batch time: 0.10\n",
      "Epoch [4/5], Step [567/1875], Loss: 2.2128, batch time: 0.12\n",
      "Epoch [4/5], Step [568/1875], Loss: 2.0797, batch time: 0.10\n",
      "Epoch [4/5], Step [569/1875], Loss: 2.1275, batch time: 0.10\n",
      "Epoch [4/5], Step [570/1875], Loss: 2.1694, batch time: 0.16\n",
      "Epoch [4/5], Step [571/1875], Loss: 2.0686, batch time: 0.10\n",
      "Epoch [4/5], Step [572/1875], Loss: 2.1839, batch time: 0.10\n",
      "Epoch [4/5], Step [573/1875], Loss: 2.0996, batch time: 0.10\n",
      "Epoch [4/5], Step [574/1875], Loss: 2.2582, batch time: 0.12\n",
      "Epoch [4/5], Step [575/1875], Loss: 2.1721, batch time: 0.10\n",
      "Epoch [4/5], Step [576/1875], Loss: 2.2077, batch time: 0.14\n",
      "Epoch [4/5], Step [577/1875], Loss: 2.1170, batch time: 0.11\n",
      "Epoch [4/5], Step [578/1875], Loss: 2.1099, batch time: 0.10\n",
      "Epoch [4/5], Step [579/1875], Loss: 2.0694, batch time: 0.13\n",
      "Epoch [4/5], Step [580/1875], Loss: 2.1634, batch time: 0.15\n",
      "Epoch [4/5], Step [581/1875], Loss: 2.1984, batch time: 0.10\n",
      "Epoch [4/5], Step [582/1875], Loss: 1.9863, batch time: 0.10\n",
      "Epoch [4/5], Step [583/1875], Loss: 2.1870, batch time: 0.10\n",
      "Epoch [4/5], Step [584/1875], Loss: 2.1055, batch time: 0.10\n",
      "Epoch [4/5], Step [585/1875], Loss: 2.3619, batch time: 0.10\n",
      "Epoch [4/5], Step [586/1875], Loss: 2.0237, batch time: 0.10\n",
      "Epoch [4/5], Step [587/1875], Loss: 2.1440, batch time: 0.15\n",
      "Epoch [4/5], Step [588/1875], Loss: 1.9994, batch time: 0.14\n",
      "Epoch [4/5], Step [589/1875], Loss: 2.0749, batch time: 0.11\n",
      "Epoch [4/5], Step [590/1875], Loss: 2.3027, batch time: 0.10\n",
      "Epoch [4/5], Step [591/1875], Loss: 2.1974, batch time: 0.10\n",
      "Epoch [4/5], Step [592/1875], Loss: 2.2867, batch time: 0.13\n",
      "Epoch [4/5], Step [593/1875], Loss: 2.0097, batch time: 0.13\n",
      "Epoch [4/5], Step [594/1875], Loss: 1.9760, batch time: 0.11\n",
      "Epoch [4/5], Step [595/1875], Loss: 1.9377, batch time: 0.21\n",
      "Epoch [4/5], Step [596/1875], Loss: 2.0488, batch time: 0.14\n",
      "Epoch [4/5], Step [597/1875], Loss: 2.2864, batch time: 0.13\n",
      "Epoch [4/5], Step [598/1875], Loss: 2.2258, batch time: 0.12\n",
      "Epoch [4/5], Step [599/1875], Loss: 2.2344, batch time: 0.10\n",
      "Epoch [4/5], Step [600/1875], Loss: 2.2044, batch time: 0.15\n",
      "Epoch [4/5], Step [601/1875], Loss: 2.2207, batch time: 0.12\n",
      "Epoch [4/5], Step [602/1875], Loss: 2.2059, batch time: 0.14\n",
      "Epoch [4/5], Step [603/1875], Loss: 2.0741, batch time: 0.18\n",
      "Epoch [4/5], Step [604/1875], Loss: 2.1627, batch time: 0.11\n",
      "Epoch [4/5], Step [605/1875], Loss: 2.1793, batch time: 0.12\n",
      "Epoch [4/5], Step [606/1875], Loss: 2.0911, batch time: 0.13\n",
      "Epoch [4/5], Step [607/1875], Loss: 2.1456, batch time: 0.11\n",
      "Epoch [4/5], Step [608/1875], Loss: 2.0601, batch time: 0.13\n",
      "Epoch [4/5], Step [609/1875], Loss: 2.0484, batch time: 0.11\n",
      "Epoch [4/5], Step [610/1875], Loss: 1.9652, batch time: 0.12\n",
      "Epoch [4/5], Step [611/1875], Loss: 2.2352, batch time: 0.12\n",
      "Epoch [4/5], Step [612/1875], Loss: 2.0627, batch time: 0.11\n",
      "Epoch [4/5], Step [613/1875], Loss: 2.0550, batch time: 0.10\n",
      "Epoch [4/5], Step [614/1875], Loss: 2.1397, batch time: 0.25\n",
      "Epoch [4/5], Step [615/1875], Loss: 2.2646, batch time: 0.10\n",
      "Epoch [4/5], Step [616/1875], Loss: 2.2098, batch time: 0.11\n",
      "Epoch [4/5], Step [617/1875], Loss: 2.0122, batch time: 0.13\n",
      "Epoch [4/5], Step [618/1875], Loss: 1.9578, batch time: 0.10\n",
      "Epoch [4/5], Step [619/1875], Loss: 2.1959, batch time: 0.10\n",
      "Epoch [4/5], Step [620/1875], Loss: 2.2227, batch time: 0.13\n",
      "Epoch [4/5], Step [621/1875], Loss: 1.9421, batch time: 0.12\n",
      "Epoch [4/5], Step [622/1875], Loss: 2.0684, batch time: 0.12\n",
      "Epoch [4/5], Step [623/1875], Loss: 2.1917, batch time: 0.10\n",
      "Epoch [4/5], Step [624/1875], Loss: 2.0289, batch time: 0.10\n",
      "Epoch [4/5], Step [625/1875], Loss: 2.3063, batch time: 0.11\n",
      "Epoch [4/5], Step [626/1875], Loss: 2.1875, batch time: 0.11\n",
      "Epoch [4/5], Step [627/1875], Loss: 2.1452, batch time: 0.10\n",
      "Epoch [4/5], Step [628/1875], Loss: 2.1904, batch time: 0.10\n",
      "Epoch [4/5], Step [629/1875], Loss: 2.1574, batch time: 0.10\n",
      "Epoch [4/5], Step [630/1875], Loss: 2.0000, batch time: 0.10\n",
      "Epoch [4/5], Step [631/1875], Loss: 2.2945, batch time: 0.15\n",
      "Epoch [4/5], Step [632/1875], Loss: 2.2253, batch time: 0.10\n",
      "Epoch [4/5], Step [633/1875], Loss: 2.0774, batch time: 0.10\n",
      "Epoch [4/5], Step [634/1875], Loss: 1.9754, batch time: 0.10\n",
      "Epoch [4/5], Step [635/1875], Loss: 2.0913, batch time: 0.10\n",
      "Epoch [4/5], Step [636/1875], Loss: 2.2237, batch time: 0.10\n",
      "Epoch [4/5], Step [637/1875], Loss: 2.2025, batch time: 0.11\n",
      "Epoch [4/5], Step [638/1875], Loss: 2.2684, batch time: 0.14\n",
      "Epoch [4/5], Step [639/1875], Loss: 2.0408, batch time: 0.14\n",
      "Epoch [4/5], Step [640/1875], Loss: 2.0861, batch time: 0.14\n",
      "Epoch [4/5], Step [641/1875], Loss: 2.2776, batch time: 0.15\n",
      "Epoch [4/5], Step [642/1875], Loss: 2.0384, batch time: 0.13\n",
      "Epoch [4/5], Step [643/1875], Loss: 2.0843, batch time: 0.17\n",
      "Epoch [4/5], Step [644/1875], Loss: 2.0964, batch time: 0.14\n",
      "Epoch [4/5], Step [645/1875], Loss: 2.1483, batch time: 0.11\n",
      "Epoch [4/5], Step [646/1875], Loss: 2.1752, batch time: 0.14\n",
      "Epoch [4/5], Step [647/1875], Loss: 2.1605, batch time: 0.15\n",
      "Epoch [4/5], Step [648/1875], Loss: 2.1476, batch time: 0.15\n",
      "Epoch [4/5], Step [649/1875], Loss: 2.2639, batch time: 0.14\n",
      "Epoch [4/5], Step [650/1875], Loss: 2.1327, batch time: 0.13\n",
      "Epoch [4/5], Step [651/1875], Loss: 1.9108, batch time: 0.18\n",
      "Epoch [4/5], Step [652/1875], Loss: 2.0805, batch time: 0.10\n",
      "Epoch [4/5], Step [653/1875], Loss: 2.2136, batch time: 0.10\n",
      "Epoch [4/5], Step [654/1875], Loss: 1.8866, batch time: 0.12\n",
      "Epoch [4/5], Step [655/1875], Loss: 2.2478, batch time: 0.13\n",
      "Epoch [4/5], Step [656/1875], Loss: 2.1137, batch time: 0.14\n",
      "Epoch [4/5], Step [657/1875], Loss: 1.9680, batch time: 0.10\n",
      "Epoch [4/5], Step [658/1875], Loss: 2.1065, batch time: 0.13\n",
      "Epoch [4/5], Step [659/1875], Loss: 2.0983, batch time: 0.14\n",
      "Epoch [4/5], Step [660/1875], Loss: 2.2334, batch time: 0.15\n",
      "Epoch [4/5], Step [661/1875], Loss: 2.0220, batch time: 0.14\n",
      "Epoch [4/5], Step [662/1875], Loss: 2.1454, batch time: 0.14\n",
      "Epoch [4/5], Step [663/1875], Loss: 2.2876, batch time: 0.10\n",
      "Epoch [4/5], Step [664/1875], Loss: 1.9591, batch time: 0.10\n",
      "Epoch [4/5], Step [665/1875], Loss: 2.1535, batch time: 0.11\n",
      "Epoch [4/5], Step [666/1875], Loss: 2.2132, batch time: 0.10\n",
      "Epoch [4/5], Step [667/1875], Loss: 2.2385, batch time: 0.12\n",
      "Epoch [4/5], Step [668/1875], Loss: 2.1507, batch time: 0.15\n",
      "Epoch [4/5], Step [669/1875], Loss: 2.2505, batch time: 0.22\n",
      "Epoch [4/5], Step [670/1875], Loss: 2.2462, batch time: -2.72\n",
      "Epoch [4/5], Step [671/1875], Loss: 2.1448, batch time: 0.19\n",
      "Epoch [4/5], Step [672/1875], Loss: 2.2671, batch time: 0.28\n",
      "Epoch [4/5], Step [673/1875], Loss: 2.1398, batch time: 0.22\n",
      "Epoch [4/5], Step [674/1875], Loss: 2.0742, batch time: 0.18\n",
      "Epoch [4/5], Step [675/1875], Loss: 2.0105, batch time: 0.20\n",
      "Epoch [4/5], Step [676/1875], Loss: 2.1178, batch time: 0.22\n",
      "Epoch [4/5], Step [677/1875], Loss: 2.2833, batch time: 0.18\n",
      "Epoch [4/5], Step [678/1875], Loss: 2.1250, batch time: 0.20\n",
      "Epoch [4/5], Step [679/1875], Loss: 2.2108, batch time: 0.14\n",
      "Epoch [4/5], Step [680/1875], Loss: 2.0938, batch time: 0.13\n",
      "Epoch [4/5], Step [681/1875], Loss: 2.2429, batch time: 0.23\n",
      "Epoch [4/5], Step [682/1875], Loss: 2.2197, batch time: 0.14\n",
      "Epoch [4/5], Step [683/1875], Loss: 2.2221, batch time: 0.14\n",
      "Epoch [4/5], Step [684/1875], Loss: 2.2354, batch time: 0.13\n",
      "Epoch [4/5], Step [685/1875], Loss: 2.1191, batch time: 0.18\n",
      "Epoch [4/5], Step [686/1875], Loss: 2.2723, batch time: 0.14\n",
      "Epoch [4/5], Step [687/1875], Loss: 2.1729, batch time: 0.15\n",
      "Epoch [4/5], Step [688/1875], Loss: 2.0908, batch time: 0.12\n",
      "Epoch [4/5], Step [689/1875], Loss: 2.0468, batch time: 0.22\n",
      "Epoch [4/5], Step [690/1875], Loss: 2.2476, batch time: 0.20\n",
      "Epoch [4/5], Step [691/1875], Loss: 2.2787, batch time: 0.20\n",
      "Epoch [4/5], Step [692/1875], Loss: 1.9925, batch time: 0.14\n",
      "Epoch [4/5], Step [693/1875], Loss: 2.1033, batch time: 0.17\n",
      "Epoch [4/5], Step [694/1875], Loss: 2.1356, batch time: 0.16\n",
      "Epoch [4/5], Step [695/1875], Loss: 2.1948, batch time: 0.17\n",
      "Epoch [4/5], Step [696/1875], Loss: 2.1646, batch time: 0.24\n",
      "Epoch [4/5], Step [697/1875], Loss: 2.2948, batch time: 0.18\n",
      "Epoch [4/5], Step [698/1875], Loss: 2.1615, batch time: 0.18\n",
      "Epoch [4/5], Step [699/1875], Loss: 2.1278, batch time: 0.20\n",
      "Epoch [4/5], Step [700/1875], Loss: 2.0733, batch time: 0.15\n",
      "Epoch [4/5], Step [701/1875], Loss: 2.0365, batch time: 0.22\n",
      "Epoch [4/5], Step [702/1875], Loss: 2.0866, batch time: 0.19\n",
      "Epoch [4/5], Step [703/1875], Loss: 2.0671, batch time: 0.19\n",
      "Epoch [4/5], Step [704/1875], Loss: 2.3819, batch time: 0.24\n",
      "Epoch [4/5], Step [705/1875], Loss: 2.2454, batch time: 0.18\n",
      "Epoch [4/5], Step [706/1875], Loss: 2.2679, batch time: 0.19\n",
      "Epoch [4/5], Step [707/1875], Loss: 2.1468, batch time: 0.18\n",
      "Epoch [4/5], Step [708/1875], Loss: 2.1571, batch time: 0.15\n",
      "Epoch [4/5], Step [709/1875], Loss: 2.1485, batch time: 0.19\n",
      "Epoch [4/5], Step [710/1875], Loss: 2.2605, batch time: 0.18\n",
      "Epoch [4/5], Step [711/1875], Loss: 2.2242, batch time: 0.16\n",
      "Epoch [4/5], Step [712/1875], Loss: 2.1999, batch time: 0.23\n",
      "Epoch [4/5], Step [713/1875], Loss: 2.0261, batch time: 0.16\n",
      "Epoch [4/5], Step [714/1875], Loss: 2.2240, batch time: 0.18\n",
      "Epoch [4/5], Step [715/1875], Loss: 2.2365, batch time: 0.19\n",
      "Epoch [4/5], Step [716/1875], Loss: 2.2210, batch time: 0.22\n",
      "Epoch [4/5], Step [717/1875], Loss: 2.2047, batch time: 0.24\n",
      "Epoch [4/5], Step [718/1875], Loss: 2.1300, batch time: 0.14\n",
      "Epoch [4/5], Step [719/1875], Loss: 2.0392, batch time: 0.24\n",
      "Epoch [4/5], Step [720/1875], Loss: 2.1449, batch time: 0.22\n",
      "Epoch [4/5], Step [721/1875], Loss: 2.0341, batch time: 0.14\n",
      "Epoch [4/5], Step [722/1875], Loss: 2.0528, batch time: 0.15\n",
      "Epoch [4/5], Step [723/1875], Loss: 2.1491, batch time: 0.32\n",
      "Epoch [4/5], Step [724/1875], Loss: 2.1668, batch time: 0.24\n",
      "Epoch [4/5], Step [725/1875], Loss: 2.1358, batch time: 0.27\n",
      "Epoch [4/5], Step [726/1875], Loss: 2.2213, batch time: 0.16\n",
      "Epoch [4/5], Step [727/1875], Loss: 2.0697, batch time: 0.17\n",
      "Epoch [4/5], Step [728/1875], Loss: 2.3905, batch time: 0.16\n",
      "Epoch [4/5], Step [729/1875], Loss: 2.2292, batch time: 0.15\n",
      "Epoch [4/5], Step [730/1875], Loss: 2.2199, batch time: 0.17\n",
      "Epoch [4/5], Step [731/1875], Loss: 2.0235, batch time: 0.10\n",
      "Epoch [4/5], Step [732/1875], Loss: 2.0236, batch time: 0.15\n",
      "Epoch [4/5], Step [733/1875], Loss: 2.1355, batch time: 0.20\n",
      "Epoch [4/5], Step [734/1875], Loss: 2.3503, batch time: 0.17\n",
      "Epoch [4/5], Step [735/1875], Loss: 2.1353, batch time: 0.17\n",
      "Epoch [4/5], Step [736/1875], Loss: 2.2210, batch time: 0.16\n",
      "Epoch [4/5], Step [737/1875], Loss: 2.2620, batch time: 0.27\n",
      "Epoch [4/5], Step [738/1875], Loss: 2.0024, batch time: 0.16\n",
      "Epoch [4/5], Step [739/1875], Loss: 2.0587, batch time: 0.13\n",
      "Epoch [4/5], Step [740/1875], Loss: 2.1482, batch time: 0.17\n",
      "Epoch [4/5], Step [741/1875], Loss: 2.2684, batch time: 0.17\n",
      "Epoch [4/5], Step [742/1875], Loss: 2.1782, batch time: 0.14\n",
      "Epoch [4/5], Step [743/1875], Loss: 2.0084, batch time: 0.14\n",
      "Epoch [4/5], Step [744/1875], Loss: 2.2144, batch time: 0.16\n",
      "Epoch [4/5], Step [745/1875], Loss: 2.2810, batch time: 0.18\n",
      "Epoch [4/5], Step [746/1875], Loss: 2.0310, batch time: 0.18\n",
      "Epoch [4/5], Step [747/1875], Loss: 2.1212, batch time: 0.15\n",
      "Epoch [4/5], Step [748/1875], Loss: 1.9331, batch time: 0.17\n",
      "Epoch [4/5], Step [749/1875], Loss: 1.8358, batch time: 0.18\n",
      "Epoch [4/5], Step [750/1875], Loss: 1.9059, batch time: 0.19\n",
      "Epoch [4/5], Step [751/1875], Loss: 2.0961, batch time: 0.21\n",
      "Epoch [4/5], Step [752/1875], Loss: 2.0052, batch time: 0.17\n",
      "Epoch [4/5], Step [753/1875], Loss: 1.9640, batch time: 0.16\n",
      "Epoch [4/5], Step [754/1875], Loss: 2.1470, batch time: 0.19\n",
      "Epoch [4/5], Step [755/1875], Loss: 2.2844, batch time: 0.18\n",
      "Epoch [4/5], Step [756/1875], Loss: 2.1570, batch time: 0.21\n",
      "Epoch [4/5], Step [757/1875], Loss: 2.2554, batch time: 0.18\n",
      "Epoch [4/5], Step [758/1875], Loss: 2.2504, batch time: 0.27\n",
      "Epoch [4/5], Step [759/1875], Loss: 2.2319, batch time: 0.23\n",
      "Epoch [4/5], Step [760/1875], Loss: 2.1184, batch time: 0.18\n",
      "Epoch [4/5], Step [761/1875], Loss: 2.0816, batch time: 0.16\n",
      "Epoch [4/5], Step [762/1875], Loss: 2.1820, batch time: 0.22\n",
      "Epoch [4/5], Step [763/1875], Loss: 2.2313, batch time: 0.17\n",
      "Epoch [4/5], Step [764/1875], Loss: 2.0365, batch time: 0.18\n",
      "Epoch [4/5], Step [765/1875], Loss: 2.2017, batch time: 0.14\n",
      "Epoch [4/5], Step [766/1875], Loss: 1.9639, batch time: 0.17\n",
      "Epoch [4/5], Step [767/1875], Loss: 2.0294, batch time: 0.23\n",
      "Epoch [4/5], Step [768/1875], Loss: 2.4404, batch time: 0.17\n",
      "Epoch [4/5], Step [769/1875], Loss: 2.2215, batch time: 0.10\n",
      "Epoch [4/5], Step [770/1875], Loss: 2.1679, batch time: 0.16\n",
      "Epoch [4/5], Step [771/1875], Loss: 2.1384, batch time: 0.18\n",
      "Epoch [4/5], Step [772/1875], Loss: 2.3121, batch time: 0.16\n",
      "Epoch [4/5], Step [773/1875], Loss: 2.2318, batch time: 0.22\n",
      "Epoch [4/5], Step [774/1875], Loss: 2.3102, batch time: 0.11\n",
      "Epoch [4/5], Step [775/1875], Loss: 2.2416, batch time: 0.21\n",
      "Epoch [4/5], Step [776/1875], Loss: 2.2990, batch time: 0.22\n",
      "Epoch [4/5], Step [777/1875], Loss: 1.9384, batch time: 0.18\n",
      "Epoch [4/5], Step [778/1875], Loss: 1.9883, batch time: 0.14\n",
      "Epoch [4/5], Step [779/1875], Loss: 2.1467, batch time: 0.11\n",
      "Epoch [4/5], Step [780/1875], Loss: 2.1207, batch time: 0.16\n",
      "Epoch [4/5], Step [781/1875], Loss: 2.0818, batch time: 0.13\n",
      "Epoch [4/5], Step [782/1875], Loss: 1.9669, batch time: 0.18\n",
      "Epoch [4/5], Step [783/1875], Loss: 1.8495, batch time: 0.16\n",
      "Epoch [4/5], Step [784/1875], Loss: 2.1533, batch time: 0.14\n",
      "Epoch [4/5], Step [785/1875], Loss: 2.1670, batch time: 0.13\n",
      "Epoch [4/5], Step [786/1875], Loss: 2.2291, batch time: 0.19\n",
      "Epoch [4/5], Step [787/1875], Loss: 2.2259, batch time: 0.19\n",
      "Epoch [4/5], Step [788/1875], Loss: 2.1372, batch time: 0.15\n",
      "Epoch [4/5], Step [789/1875], Loss: 2.2351, batch time: 0.13\n",
      "Epoch [4/5], Step [790/1875], Loss: 1.8984, batch time: 0.14\n",
      "Epoch [4/5], Step [791/1875], Loss: 2.1661, batch time: 0.14\n",
      "Epoch [4/5], Step [792/1875], Loss: 2.0945, batch time: 0.15\n",
      "Epoch [4/5], Step [793/1875], Loss: 2.4240, batch time: 0.11\n",
      "Epoch [4/5], Step [794/1875], Loss: 2.2212, batch time: 0.20\n",
      "Epoch [4/5], Step [795/1875], Loss: 2.0924, batch time: 0.19\n",
      "Epoch [4/5], Step [796/1875], Loss: 1.9628, batch time: 0.14\n",
      "Epoch [4/5], Step [797/1875], Loss: 1.9338, batch time: 0.14\n",
      "Epoch [4/5], Step [798/1875], Loss: 2.2613, batch time: 0.17\n",
      "Epoch [4/5], Step [799/1875], Loss: 2.2002, batch time: 0.24\n",
      "Epoch [4/5], Step [800/1875], Loss: 2.3292, batch time: 0.16\n",
      "Epoch [4/5], Step [801/1875], Loss: 2.1993, batch time: 0.19\n",
      "Epoch [4/5], Step [802/1875], Loss: 2.0991, batch time: 0.15\n",
      "Epoch [4/5], Step [803/1875], Loss: 2.0741, batch time: 0.20\n",
      "Epoch [4/5], Step [804/1875], Loss: 2.0909, batch time: 0.15\n",
      "Epoch [4/5], Step [805/1875], Loss: 2.0122, batch time: 0.16\n",
      "Epoch [4/5], Step [806/1875], Loss: 2.1770, batch time: 0.15\n",
      "Epoch [4/5], Step [807/1875], Loss: 1.9428, batch time: 0.16\n",
      "Epoch [4/5], Step [808/1875], Loss: 1.8762, batch time: 0.21\n",
      "Epoch [4/5], Step [809/1875], Loss: 2.2286, batch time: 0.14\n",
      "Epoch [4/5], Step [810/1875], Loss: 2.1113, batch time: 0.18\n",
      "Epoch [4/5], Step [811/1875], Loss: 2.1728, batch time: 0.17\n",
      "Epoch [4/5], Step [812/1875], Loss: 2.3754, batch time: 0.20\n",
      "Epoch [4/5], Step [813/1875], Loss: 2.2533, batch time: 0.14\n",
      "Epoch [4/5], Step [814/1875], Loss: 2.2642, batch time: 0.16\n",
      "Epoch [4/5], Step [815/1875], Loss: 2.2500, batch time: 0.22\n",
      "Epoch [4/5], Step [816/1875], Loss: 2.0525, batch time: 0.14\n",
      "Epoch [4/5], Step [817/1875], Loss: 2.2214, batch time: 0.16\n",
      "Epoch [4/5], Step [818/1875], Loss: 2.0768, batch time: 0.16\n",
      "Epoch [4/5], Step [819/1875], Loss: 2.2154, batch time: 0.17\n",
      "Epoch [4/5], Step [820/1875], Loss: 2.1370, batch time: 0.14\n",
      "Epoch [4/5], Step [821/1875], Loss: 2.1064, batch time: 0.20\n",
      "Epoch [4/5], Step [822/1875], Loss: 2.0502, batch time: 0.21\n",
      "Epoch [4/5], Step [823/1875], Loss: 2.1241, batch time: 0.18\n",
      "Epoch [4/5], Step [824/1875], Loss: 1.9533, batch time: 0.24\n",
      "Epoch [4/5], Step [825/1875], Loss: 2.2454, batch time: 0.18\n",
      "Epoch [4/5], Step [826/1875], Loss: 1.9495, batch time: 0.15\n",
      "Epoch [4/5], Step [827/1875], Loss: 2.0664, batch time: 0.20\n",
      "Epoch [4/5], Step [828/1875], Loss: 2.0809, batch time: 0.25\n",
      "Epoch [4/5], Step [829/1875], Loss: 2.2847, batch time: 0.12\n",
      "Epoch [4/5], Step [830/1875], Loss: 1.9100, batch time: 0.13\n",
      "Epoch [4/5], Step [831/1875], Loss: 2.0612, batch time: 0.14\n",
      "Epoch [4/5], Step [832/1875], Loss: 2.1818, batch time: 0.19\n",
      "Epoch [4/5], Step [833/1875], Loss: 2.1654, batch time: 0.19\n",
      "Epoch [4/5], Step [834/1875], Loss: 1.9899, batch time: 0.17\n",
      "Epoch [4/5], Step [835/1875], Loss: 2.2197, batch time: 0.22\n",
      "Epoch [4/5], Step [836/1875], Loss: 2.0571, batch time: 0.19\n",
      "Epoch [4/5], Step [837/1875], Loss: 2.3380, batch time: 0.15\n",
      "Epoch [4/5], Step [838/1875], Loss: 1.9150, batch time: 0.21\n",
      "Epoch [4/5], Step [839/1875], Loss: 2.1724, batch time: 0.18\n",
      "Epoch [4/5], Step [840/1875], Loss: 1.9210, batch time: 0.14\n",
      "Epoch [4/5], Step [841/1875], Loss: 2.0545, batch time: 0.15\n",
      "Epoch [4/5], Step [842/1875], Loss: 2.0319, batch time: 0.17\n",
      "Epoch [4/5], Step [843/1875], Loss: 2.2355, batch time: 0.17\n",
      "Epoch [4/5], Step [844/1875], Loss: 2.1168, batch time: 0.26\n",
      "Epoch [4/5], Step [845/1875], Loss: 1.9764, batch time: 0.15\n",
      "Epoch [4/5], Step [846/1875], Loss: 2.1940, batch time: 0.22\n",
      "Epoch [4/5], Step [847/1875], Loss: 1.9764, batch time: 0.21\n",
      "Epoch [4/5], Step [848/1875], Loss: 1.9727, batch time: -2.66\n",
      "Epoch [4/5], Step [849/1875], Loss: 2.3292, batch time: 0.22\n",
      "Epoch [4/5], Step [850/1875], Loss: 2.1122, batch time: 0.17\n",
      "Epoch [4/5], Step [851/1875], Loss: 2.0729, batch time: 0.22\n",
      "Epoch [4/5], Step [852/1875], Loss: 2.2773, batch time: 0.19\n",
      "Epoch [4/5], Step [853/1875], Loss: 2.4172, batch time: 0.17\n",
      "Epoch [4/5], Step [854/1875], Loss: 1.9544, batch time: 0.22\n",
      "Epoch [4/5], Step [855/1875], Loss: 2.1800, batch time: 0.24\n",
      "Epoch [4/5], Step [856/1875], Loss: 2.1899, batch time: 0.17\n",
      "Epoch [4/5], Step [857/1875], Loss: 2.3739, batch time: 0.23\n",
      "Epoch [4/5], Step [858/1875], Loss: 2.0663, batch time: 0.14\n",
      "Epoch [4/5], Step [859/1875], Loss: 2.2943, batch time: 0.14\n",
      "Epoch [4/5], Step [860/1875], Loss: 1.9152, batch time: 0.17\n",
      "Epoch [4/5], Step [861/1875], Loss: 2.2142, batch time: 0.27\n",
      "Epoch [4/5], Step [862/1875], Loss: 2.2584, batch time: 0.19\n",
      "Epoch [4/5], Step [863/1875], Loss: 2.1387, batch time: 0.14\n",
      "Epoch [4/5], Step [864/1875], Loss: 1.8239, batch time: 0.16\n",
      "Epoch [4/5], Step [865/1875], Loss: 2.3174, batch time: 0.23\n",
      "Epoch [4/5], Step [866/1875], Loss: 2.2210, batch time: 0.24\n",
      "Epoch [4/5], Step [867/1875], Loss: 2.1348, batch time: 0.19\n",
      "Epoch [4/5], Step [868/1875], Loss: 2.2718, batch time: 0.16\n",
      "Epoch [4/5], Step [869/1875], Loss: 2.0841, batch time: 0.16\n",
      "Epoch [4/5], Step [870/1875], Loss: 2.0901, batch time: 0.20\n",
      "Epoch [4/5], Step [871/1875], Loss: 2.1101, batch time: 0.19\n",
      "Epoch [4/5], Step [872/1875], Loss: 2.1046, batch time: 0.22\n",
      "Epoch [4/5], Step [873/1875], Loss: 2.0726, batch time: 0.20\n",
      "Epoch [4/5], Step [874/1875], Loss: 1.9670, batch time: 0.19\n",
      "Epoch [4/5], Step [875/1875], Loss: 2.3930, batch time: 0.24\n",
      "Epoch [4/5], Step [876/1875], Loss: 2.1978, batch time: 0.14\n",
      "Epoch [4/5], Step [877/1875], Loss: 2.3008, batch time: 0.19\n",
      "Epoch [4/5], Step [878/1875], Loss: 2.0261, batch time: 0.18\n",
      "Epoch [4/5], Step [879/1875], Loss: 2.1192, batch time: 0.23\n",
      "Epoch [4/5], Step [880/1875], Loss: 2.0761, batch time: 0.17\n",
      "Epoch [4/5], Step [881/1875], Loss: 2.2062, batch time: 0.20\n",
      "Epoch [4/5], Step [882/1875], Loss: 2.2086, batch time: 0.24\n",
      "Epoch [4/5], Step [883/1875], Loss: 2.3112, batch time: 0.19\n",
      "Epoch [4/5], Step [884/1875], Loss: 2.2117, batch time: 0.13\n",
      "Epoch [4/5], Step [885/1875], Loss: 2.1337, batch time: 0.20\n",
      "Epoch [4/5], Step [886/1875], Loss: 2.1085, batch time: 0.13\n",
      "Epoch [4/5], Step [887/1875], Loss: 2.0975, batch time: 0.15\n",
      "Epoch [4/5], Step [888/1875], Loss: 2.2233, batch time: 0.17\n",
      "Epoch [4/5], Step [889/1875], Loss: 2.2039, batch time: 0.19\n",
      "Epoch [4/5], Step [890/1875], Loss: 2.0810, batch time: 0.12\n",
      "Epoch [4/5], Step [891/1875], Loss: 2.1338, batch time: 0.17\n",
      "Epoch [4/5], Step [892/1875], Loss: 2.1522, batch time: 0.18\n",
      "Epoch [4/5], Step [893/1875], Loss: 1.9914, batch time: 0.16\n",
      "Epoch [4/5], Step [894/1875], Loss: 2.1552, batch time: 0.17\n",
      "Epoch [4/5], Step [895/1875], Loss: 2.0635, batch time: 0.17\n",
      "Epoch [4/5], Step [896/1875], Loss: 2.0851, batch time: 0.33\n",
      "Epoch [4/5], Step [897/1875], Loss: 2.0283, batch time: 0.21\n",
      "Epoch [4/5], Step [898/1875], Loss: 2.0525, batch time: 0.26\n",
      "Epoch [4/5], Step [899/1875], Loss: 1.8373, batch time: 0.22\n",
      "Epoch [4/5], Step [900/1875], Loss: 2.2388, batch time: 0.18\n",
      "Epoch [4/5], Step [901/1875], Loss: 2.1065, batch time: 0.19\n",
      "Epoch [4/5], Step [902/1875], Loss: 2.1043, batch time: 0.16\n",
      "Epoch [4/5], Step [903/1875], Loss: 2.1402, batch time: 0.18\n",
      "Epoch [4/5], Step [904/1875], Loss: 2.1609, batch time: 0.19\n",
      "Epoch [4/5], Step [905/1875], Loss: 2.1914, batch time: 0.19\n",
      "Epoch [4/5], Step [906/1875], Loss: 2.0521, batch time: 0.16\n",
      "Epoch [4/5], Step [907/1875], Loss: 2.0166, batch time: 0.17\n",
      "Epoch [4/5], Step [908/1875], Loss: 2.0519, batch time: 0.15\n",
      "Epoch [4/5], Step [909/1875], Loss: 2.1107, batch time: 0.16\n",
      "Epoch [4/5], Step [910/1875], Loss: 2.0303, batch time: 0.24\n",
      "Epoch [4/5], Step [911/1875], Loss: 2.1252, batch time: 0.23\n",
      "Epoch [4/5], Step [912/1875], Loss: 2.2003, batch time: 0.24\n",
      "Epoch [4/5], Step [913/1875], Loss: 1.9924, batch time: 0.17\n",
      "Epoch [4/5], Step [914/1875], Loss: 2.1198, batch time: 0.22\n",
      "Epoch [4/5], Step [915/1875], Loss: 2.3108, batch time: 0.25\n",
      "Epoch [4/5], Step [916/1875], Loss: 1.8433, batch time: 0.20\n",
      "Epoch [4/5], Step [917/1875], Loss: 2.3546, batch time: 0.22\n",
      "Epoch [4/5], Step [918/1875], Loss: 1.8862, batch time: 0.14\n",
      "Epoch [4/5], Step [919/1875], Loss: 2.1450, batch time: 0.20\n",
      "Epoch [4/5], Step [920/1875], Loss: 2.2579, batch time: 0.14\n",
      "Epoch [4/5], Step [921/1875], Loss: 2.1637, batch time: 0.15\n",
      "Epoch [4/5], Step [922/1875], Loss: 2.2740, batch time: 0.10\n",
      "Epoch [4/5], Step [923/1875], Loss: 2.0754, batch time: 0.10\n",
      "Epoch [4/5], Step [924/1875], Loss: 2.0644, batch time: 0.10\n",
      "Epoch [4/5], Step [925/1875], Loss: 2.3341, batch time: 0.13\n",
      "Epoch [4/5], Step [926/1875], Loss: 2.1996, batch time: 0.10\n",
      "Epoch [4/5], Step [927/1875], Loss: 2.1557, batch time: 0.10\n",
      "Epoch [4/5], Step [928/1875], Loss: 2.0271, batch time: 0.13\n",
      "Epoch [4/5], Step [929/1875], Loss: 2.1865, batch time: 0.10\n",
      "Epoch [4/5], Step [930/1875], Loss: 2.1640, batch time: 0.10\n",
      "Epoch [4/5], Step [931/1875], Loss: 2.0610, batch time: 0.15\n",
      "Epoch [4/5], Step [932/1875], Loss: 2.1979, batch time: 0.13\n",
      "Epoch [4/5], Step [933/1875], Loss: 2.1395, batch time: 0.11\n",
      "Epoch [4/5], Step [934/1875], Loss: 2.0633, batch time: 0.10\n",
      "Epoch [4/5], Step [935/1875], Loss: 2.0710, batch time: 0.10\n",
      "Epoch [4/5], Step [936/1875], Loss: 2.0417, batch time: 0.10\n",
      "Epoch [4/5], Step [937/1875], Loss: 2.1431, batch time: 0.13\n",
      "Epoch [4/5], Step [938/1875], Loss: 2.0832, batch time: 0.10\n",
      "Epoch [4/5], Step [939/1875], Loss: 1.9878, batch time: 0.10\n",
      "Epoch [4/5], Step [940/1875], Loss: 2.2323, batch time: 0.10\n",
      "Epoch [4/5], Step [941/1875], Loss: 2.1280, batch time: 0.10\n",
      "Epoch [4/5], Step [942/1875], Loss: 2.3052, batch time: 0.11\n",
      "Epoch [4/5], Step [943/1875], Loss: 2.1097, batch time: 0.10\n",
      "Epoch [4/5], Step [944/1875], Loss: 2.2722, batch time: 0.10\n",
      "Epoch [4/5], Step [945/1875], Loss: 2.1906, batch time: 0.11\n",
      "Epoch [4/5], Step [946/1875], Loss: 2.0096, batch time: 0.10\n",
      "Epoch [4/5], Step [947/1875], Loss: 2.1458, batch time: 0.13\n",
      "Epoch [4/5], Step [948/1875], Loss: 2.1516, batch time: 0.10\n",
      "Epoch [4/5], Step [949/1875], Loss: 2.1760, batch time: 0.10\n",
      "Epoch [4/5], Step [950/1875], Loss: 2.1284, batch time: 0.10\n",
      "Epoch [4/5], Step [951/1875], Loss: 1.9450, batch time: 0.12\n",
      "Epoch [4/5], Step [952/1875], Loss: 2.2205, batch time: 0.10\n",
      "Epoch [4/5], Step [953/1875], Loss: 1.9851, batch time: 0.10\n",
      "Epoch [4/5], Step [954/1875], Loss: 2.2336, batch time: 0.10\n",
      "Epoch [4/5], Step [955/1875], Loss: 2.2075, batch time: 0.10\n",
      "Epoch [4/5], Step [956/1875], Loss: 2.1026, batch time: 0.12\n",
      "Epoch [4/5], Step [957/1875], Loss: 2.1941, batch time: 0.10\n",
      "Epoch [4/5], Step [958/1875], Loss: 2.2727, batch time: 0.11\n",
      "Epoch [4/5], Step [959/1875], Loss: 2.0390, batch time: 0.10\n",
      "Epoch [4/5], Step [960/1875], Loss: 2.2497, batch time: 0.10\n",
      "Epoch [4/5], Step [961/1875], Loss: 2.1027, batch time: 0.12\n",
      "Epoch [4/5], Step [962/1875], Loss: 2.2305, batch time: 0.10\n",
      "Epoch [4/5], Step [963/1875], Loss: 1.9893, batch time: 0.14\n",
      "Epoch [4/5], Step [964/1875], Loss: 2.2975, batch time: 0.13\n",
      "Epoch [4/5], Step [965/1875], Loss: 2.3560, batch time: 0.14\n",
      "Epoch [4/5], Step [966/1875], Loss: 2.0116, batch time: 0.12\n",
      "Epoch [4/5], Step [967/1875], Loss: 2.0026, batch time: 0.12\n",
      "Epoch [4/5], Step [968/1875], Loss: 2.0322, batch time: 0.13\n",
      "Epoch [4/5], Step [969/1875], Loss: 2.0468, batch time: 0.15\n",
      "Epoch [4/5], Step [970/1875], Loss: 2.1414, batch time: 0.10\n",
      "Epoch [4/5], Step [971/1875], Loss: 2.0453, batch time: 0.14\n",
      "Epoch [4/5], Step [972/1875], Loss: 2.2217, batch time: 0.10\n",
      "Epoch [4/5], Step [973/1875], Loss: 2.1277, batch time: 0.10\n",
      "Epoch [4/5], Step [974/1875], Loss: 2.0222, batch time: 0.10\n",
      "Epoch [4/5], Step [975/1875], Loss: 2.1940, batch time: 0.11\n",
      "Epoch [4/5], Step [976/1875], Loss: 1.9445, batch time: 0.11\n",
      "Epoch [4/5], Step [977/1875], Loss: 2.1030, batch time: 0.13\n",
      "Epoch [4/5], Step [978/1875], Loss: 2.2439, batch time: 0.10\n",
      "Epoch [4/5], Step [979/1875], Loss: 2.1539, batch time: 0.10\n",
      "Epoch [4/5], Step [980/1875], Loss: 2.0576, batch time: 0.09\n",
      "Epoch [4/5], Step [981/1875], Loss: 2.1707, batch time: 0.18\n",
      "Epoch [4/5], Step [982/1875], Loss: 2.2473, batch time: 0.10\n",
      "Epoch [4/5], Step [983/1875], Loss: 2.1188, batch time: 0.10\n",
      "Epoch [4/5], Step [984/1875], Loss: 2.1743, batch time: 0.10\n",
      "Epoch [4/5], Step [985/1875], Loss: 2.1629, batch time: 0.10\n",
      "Epoch [4/5], Step [986/1875], Loss: 2.0838, batch time: 0.10\n",
      "Epoch [4/5], Step [987/1875], Loss: 2.1540, batch time: 0.20\n",
      "Epoch [4/5], Step [988/1875], Loss: 2.0341, batch time: 0.10\n",
      "Epoch [4/5], Step [989/1875], Loss: 2.1902, batch time: 0.10\n",
      "Epoch [4/5], Step [990/1875], Loss: 2.0725, batch time: 0.12\n",
      "Epoch [4/5], Step [991/1875], Loss: 2.1632, batch time: 0.15\n",
      "Epoch [4/5], Step [992/1875], Loss: 1.9745, batch time: 0.10\n",
      "Epoch [4/5], Step [993/1875], Loss: 2.1468, batch time: 0.09\n",
      "Epoch [4/5], Step [994/1875], Loss: 2.1848, batch time: 0.12\n",
      "Epoch [4/5], Step [995/1875], Loss: 2.1272, batch time: 0.13\n",
      "Epoch [4/5], Step [996/1875], Loss: 2.0521, batch time: 0.11\n",
      "Epoch [4/5], Step [997/1875], Loss: 2.1626, batch time: 0.10\n",
      "Epoch [4/5], Step [998/1875], Loss: 2.1068, batch time: 0.10\n",
      "Epoch [4/5], Step [999/1875], Loss: 2.2270, batch time: 0.10\n",
      "Epoch [4/5], Step [1000/1875], Loss: 1.7681, batch time: 0.15\n",
      "Epoch [4/5], Step [1001/1875], Loss: 2.2889, batch time: 0.10\n",
      "Epoch [4/5], Step [1002/1875], Loss: 2.0534, batch time: 0.13\n",
      "Epoch [4/5], Step [1003/1875], Loss: 2.1117, batch time: 0.12\n",
      "Epoch [4/5], Step [1004/1875], Loss: 1.9123, batch time: 0.11\n",
      "Epoch [4/5], Step [1005/1875], Loss: 2.1809, batch time: 0.10\n",
      "Epoch [4/5], Step [1006/1875], Loss: 2.1301, batch time: 0.14\n",
      "Epoch [4/5], Step [1007/1875], Loss: 2.0227, batch time: 0.10\n",
      "Epoch [4/5], Step [1008/1875], Loss: 2.0774, batch time: 0.10\n",
      "Epoch [4/5], Step [1009/1875], Loss: 2.1631, batch time: 0.14\n",
      "Epoch [4/5], Step [1010/1875], Loss: 1.9522, batch time: 0.10\n",
      "Epoch [4/5], Step [1011/1875], Loss: 2.2658, batch time: 0.12\n",
      "Epoch [4/5], Step [1012/1875], Loss: 1.9190, batch time: 0.10\n",
      "Epoch [4/5], Step [1013/1875], Loss: 1.9268, batch time: 0.11\n",
      "Epoch [4/5], Step [1014/1875], Loss: 2.2407, batch time: 0.10\n",
      "Epoch [4/5], Step [1015/1875], Loss: 2.2702, batch time: 0.10\n",
      "Epoch [4/5], Step [1016/1875], Loss: 2.1563, batch time: 0.13\n",
      "Epoch [4/5], Step [1017/1875], Loss: 1.9408, batch time: 0.13\n",
      "Epoch [4/5], Step [1018/1875], Loss: 1.9402, batch time: 0.12\n",
      "Epoch [4/5], Step [1019/1875], Loss: 2.2502, batch time: 0.13\n",
      "Epoch [4/5], Step [1020/1875], Loss: 2.0024, batch time: 0.10\n",
      "Epoch [4/5], Step [1021/1875], Loss: 2.2986, batch time: 0.13\n",
      "Epoch [4/5], Step [1022/1875], Loss: 2.1144, batch time: 0.25\n",
      "Epoch [4/5], Step [1023/1875], Loss: 1.9323, batch time: 0.15\n",
      "Epoch [4/5], Step [1024/1875], Loss: 2.3366, batch time: 0.10\n",
      "Epoch [4/5], Step [1025/1875], Loss: 2.1316, batch time: 0.10\n",
      "Epoch [4/5], Step [1026/1875], Loss: 2.0961, batch time: 0.11\n",
      "Epoch [4/5], Step [1027/1875], Loss: 2.1154, batch time: 0.10\n",
      "Epoch [4/5], Step [1028/1875], Loss: 2.1463, batch time: 0.10\n",
      "Epoch [4/5], Step [1029/1875], Loss: 2.2578, batch time: 0.10\n",
      "Epoch [4/5], Step [1030/1875], Loss: 2.0648, batch time: 0.13\n",
      "Epoch [4/5], Step [1031/1875], Loss: 2.1370, batch time: 0.10\n",
      "Epoch [4/5], Step [1032/1875], Loss: 2.1202, batch time: 0.10\n",
      "Epoch [4/5], Step [1033/1875], Loss: 2.0647, batch time: 0.10\n",
      "Epoch [4/5], Step [1034/1875], Loss: 2.2983, batch time: 0.10\n",
      "Epoch [4/5], Step [1035/1875], Loss: 1.9616, batch time: 0.11\n",
      "Epoch [4/5], Step [1036/1875], Loss: 2.2223, batch time: 0.10\n",
      "Epoch [4/5], Step [1037/1875], Loss: 2.3167, batch time: 0.19\n",
      "Epoch [4/5], Step [1038/1875], Loss: 2.1342, batch time: 0.13\n",
      "Epoch [4/5], Step [1039/1875], Loss: 1.9648, batch time: 0.13\n",
      "Epoch [4/5], Step [1040/1875], Loss: 2.1484, batch time: 0.11\n",
      "Epoch [4/5], Step [1041/1875], Loss: 2.1792, batch time: 0.11\n",
      "Epoch [4/5], Step [1042/1875], Loss: 2.1198, batch time: 0.13\n",
      "Epoch [4/5], Step [1043/1875], Loss: 2.1947, batch time: 0.10\n",
      "Epoch [4/5], Step [1044/1875], Loss: 2.2622, batch time: 0.13\n",
      "Epoch [4/5], Step [1045/1875], Loss: 2.0924, batch time: 0.17\n",
      "Epoch [4/5], Step [1046/1875], Loss: 2.3615, batch time: 0.19\n",
      "Epoch [4/5], Step [1047/1875], Loss: 2.1969, batch time: 0.12\n",
      "Epoch [4/5], Step [1048/1875], Loss: 1.9793, batch time: 0.10\n",
      "Epoch [4/5], Step [1049/1875], Loss: 2.1391, batch time: 0.10\n",
      "Epoch [4/5], Step [1050/1875], Loss: 2.0341, batch time: 0.10\n",
      "Epoch [4/5], Step [1051/1875], Loss: 2.0998, batch time: 0.11\n",
      "Epoch [4/5], Step [1052/1875], Loss: 2.1150, batch time: 0.13\n",
      "Epoch [4/5], Step [1053/1875], Loss: 1.9867, batch time: 0.12\n",
      "Epoch [4/5], Step [1054/1875], Loss: 2.0162, batch time: 0.12\n",
      "Epoch [4/5], Step [1055/1875], Loss: 2.0669, batch time: 0.10\n",
      "Epoch [4/5], Step [1056/1875], Loss: 2.1399, batch time: 0.10\n",
      "Epoch [4/5], Step [1057/1875], Loss: 1.9709, batch time: 0.12\n",
      "Epoch [4/5], Step [1058/1875], Loss: 1.9980, batch time: 0.10\n",
      "Epoch [4/5], Step [1059/1875], Loss: 2.1680, batch time: 0.13\n",
      "Epoch [4/5], Step [1060/1875], Loss: 2.1259, batch time: 0.14\n",
      "Epoch [4/5], Step [1061/1875], Loss: 2.3321, batch time: 0.10\n",
      "Epoch [4/5], Step [1062/1875], Loss: 2.1774, batch time: 0.10\n",
      "Epoch [4/5], Step [1063/1875], Loss: 2.1446, batch time: 0.09\n",
      "Epoch [4/5], Step [1064/1875], Loss: 2.2324, batch time: 0.10\n",
      "Epoch [4/5], Step [1065/1875], Loss: 2.1184, batch time: 0.14\n",
      "Epoch [4/5], Step [1066/1875], Loss: 2.0554, batch time: 0.12\n",
      "Epoch [4/5], Step [1067/1875], Loss: 1.9046, batch time: 0.10\n",
      "Epoch [4/5], Step [1068/1875], Loss: 2.3060, batch time: 0.10\n",
      "Epoch [4/5], Step [1069/1875], Loss: 2.1078, batch time: 0.13\n",
      "Epoch [4/5], Step [1070/1875], Loss: 2.1922, batch time: 0.12\n",
      "Epoch [4/5], Step [1071/1875], Loss: 2.2329, batch time: 0.12\n",
      "Epoch [4/5], Step [1072/1875], Loss: 2.2225, batch time: 0.14\n",
      "Epoch [4/5], Step [1073/1875], Loss: 2.0835, batch time: 0.13\n",
      "Epoch [4/5], Step [1074/1875], Loss: 2.2429, batch time: 0.14\n",
      "Epoch [4/5], Step [1075/1875], Loss: 2.3600, batch time: 0.17\n",
      "Epoch [4/5], Step [1076/1875], Loss: 2.0713, batch time: -2.83\n",
      "Epoch [4/5], Step [1077/1875], Loss: 1.9408, batch time: 0.13\n",
      "Epoch [4/5], Step [1078/1875], Loss: 2.2598, batch time: 0.15\n",
      "Epoch [4/5], Step [1079/1875], Loss: 2.1782, batch time: 0.10\n",
      "Epoch [4/5], Step [1080/1875], Loss: 2.1854, batch time: 0.10\n",
      "Epoch [4/5], Step [1081/1875], Loss: 2.3530, batch time: 0.12\n",
      "Epoch [4/5], Step [1082/1875], Loss: 2.1425, batch time: 0.10\n",
      "Epoch [4/5], Step [1083/1875], Loss: 2.1380, batch time: 0.13\n",
      "Epoch [4/5], Step [1084/1875], Loss: 2.1132, batch time: 0.14\n",
      "Epoch [4/5], Step [1085/1875], Loss: 2.1511, batch time: 0.12\n",
      "Epoch [4/5], Step [1086/1875], Loss: 2.0733, batch time: 0.14\n",
      "Epoch [4/5], Step [1087/1875], Loss: 1.9517, batch time: 0.13\n",
      "Epoch [4/5], Step [1088/1875], Loss: 2.1210, batch time: 0.14\n",
      "Epoch [4/5], Step [1089/1875], Loss: 2.2423, batch time: 0.11\n",
      "Epoch [4/5], Step [1090/1875], Loss: 2.2256, batch time: 0.09\n",
      "Epoch [4/5], Step [1091/1875], Loss: 2.0548, batch time: 0.10\n",
      "Epoch [4/5], Step [1092/1875], Loss: 1.9851, batch time: 0.15\n",
      "Epoch [4/5], Step [1093/1875], Loss: 2.0891, batch time: 0.10\n",
      "Epoch [4/5], Step [1094/1875], Loss: 2.2668, batch time: 0.10\n",
      "Epoch [4/5], Step [1095/1875], Loss: 2.0796, batch time: 0.10\n",
      "Epoch [4/5], Step [1096/1875], Loss: 2.1138, batch time: 0.11\n",
      "Epoch [4/5], Step [1097/1875], Loss: 2.1031, batch time: 0.10\n",
      "Epoch [4/5], Step [1098/1875], Loss: 2.0362, batch time: 0.10\n",
      "Epoch [4/5], Step [1099/1875], Loss: 1.9543, batch time: 0.10\n",
      "Epoch [4/5], Step [1100/1875], Loss: 2.0069, batch time: 0.09\n",
      "Epoch [4/5], Step [1101/1875], Loss: 2.0090, batch time: 0.10\n",
      "Epoch [4/5], Step [1102/1875], Loss: 1.9840, batch time: 0.13\n",
      "Epoch [4/5], Step [1103/1875], Loss: 2.1117, batch time: 0.09\n",
      "Epoch [4/5], Step [1104/1875], Loss: 2.2975, batch time: 0.14\n",
      "Epoch [4/5], Step [1105/1875], Loss: 1.9505, batch time: 0.10\n",
      "Epoch [4/5], Step [1106/1875], Loss: 2.2004, batch time: 0.14\n",
      "Epoch [4/5], Step [1107/1875], Loss: 2.1733, batch time: 0.11\n",
      "Epoch [4/5], Step [1108/1875], Loss: 2.2593, batch time: 0.10\n",
      "Epoch [4/5], Step [1109/1875], Loss: 2.0289, batch time: 0.10\n",
      "Epoch [4/5], Step [1110/1875], Loss: 2.0256, batch time: 0.12\n",
      "Epoch [4/5], Step [1111/1875], Loss: 2.1574, batch time: 0.10\n",
      "Epoch [4/5], Step [1112/1875], Loss: 2.3136, batch time: 0.12\n",
      "Epoch [4/5], Step [1113/1875], Loss: 2.1386, batch time: 0.12\n",
      "Epoch [4/5], Step [1114/1875], Loss: 2.1462, batch time: 0.15\n",
      "Epoch [4/5], Step [1115/1875], Loss: 2.0741, batch time: 0.11\n",
      "Epoch [4/5], Step [1116/1875], Loss: 1.9905, batch time: 0.10\n",
      "Epoch [4/5], Step [1117/1875], Loss: 2.0812, batch time: 0.11\n",
      "Epoch [4/5], Step [1118/1875], Loss: 2.1111, batch time: 0.11\n",
      "Epoch [4/5], Step [1119/1875], Loss: 2.1585, batch time: 0.10\n",
      "Epoch [4/5], Step [1120/1875], Loss: 2.1424, batch time: 0.10\n",
      "Epoch [4/5], Step [1121/1875], Loss: 2.0771, batch time: 0.11\n",
      "Epoch [4/5], Step [1122/1875], Loss: 2.0649, batch time: 0.11\n",
      "Epoch [4/5], Step [1123/1875], Loss: 2.1173, batch time: 0.10\n",
      "Epoch [4/5], Step [1124/1875], Loss: 2.1561, batch time: 0.09\n",
      "Epoch [4/5], Step [1125/1875], Loss: 1.9565, batch time: 0.15\n",
      "Epoch [4/5], Step [1126/1875], Loss: 2.0936, batch time: 0.18\n",
      "Epoch [4/5], Step [1127/1875], Loss: 2.1860, batch time: 0.13\n",
      "Epoch [4/5], Step [1128/1875], Loss: 2.1385, batch time: 0.14\n",
      "Epoch [4/5], Step [1129/1875], Loss: 2.4282, batch time: 0.10\n",
      "Epoch [4/5], Step [1130/1875], Loss: 2.0890, batch time: 0.17\n",
      "Epoch [4/5], Step [1131/1875], Loss: 2.0928, batch time: 0.11\n",
      "Epoch [4/5], Step [1132/1875], Loss: 2.0388, batch time: 0.11\n",
      "Epoch [4/5], Step [1133/1875], Loss: 2.0028, batch time: 0.11\n",
      "Epoch [4/5], Step [1134/1875], Loss: 2.1994, batch time: 0.10\n",
      "Epoch [4/5], Step [1135/1875], Loss: 1.9983, batch time: 0.11\n",
      "Epoch [4/5], Step [1136/1875], Loss: 2.1883, batch time: 0.10\n",
      "Epoch [4/5], Step [1137/1875], Loss: 2.2027, batch time: 0.11\n",
      "Epoch [4/5], Step [1138/1875], Loss: 2.0719, batch time: 0.16\n",
      "Epoch [4/5], Step [1139/1875], Loss: 2.2171, batch time: 0.14\n",
      "Epoch [4/5], Step [1140/1875], Loss: 2.2045, batch time: 0.13\n",
      "Epoch [4/5], Step [1141/1875], Loss: 2.0962, batch time: 0.13\n",
      "Epoch [4/5], Step [1142/1875], Loss: 2.0978, batch time: 0.15\n",
      "Epoch [4/5], Step [1143/1875], Loss: 1.9778, batch time: 0.10\n",
      "Epoch [4/5], Step [1144/1875], Loss: 1.9902, batch time: 0.09\n",
      "Epoch [4/5], Step [1145/1875], Loss: 2.0801, batch time: 0.11\n",
      "Epoch [4/5], Step [1146/1875], Loss: 1.9874, batch time: 0.16\n",
      "Epoch [4/5], Step [1147/1875], Loss: 2.3692, batch time: 0.15\n",
      "Epoch [4/5], Step [1148/1875], Loss: 2.2882, batch time: 0.10\n",
      "Epoch [4/5], Step [1149/1875], Loss: 2.4110, batch time: 0.10\n",
      "Epoch [4/5], Step [1150/1875], Loss: 2.1963, batch time: 0.10\n",
      "Epoch [4/5], Step [1151/1875], Loss: 2.2002, batch time: 0.12\n",
      "Epoch [4/5], Step [1152/1875], Loss: 2.1201, batch time: 0.10\n",
      "Epoch [4/5], Step [1153/1875], Loss: 1.9264, batch time: 0.14\n",
      "Epoch [4/5], Step [1154/1875], Loss: 2.1251, batch time: 0.10\n",
      "Epoch [4/5], Step [1155/1875], Loss: 2.2875, batch time: 0.12\n",
      "Epoch [4/5], Step [1156/1875], Loss: 1.9978, batch time: 0.12\n",
      "Epoch [4/5], Step [1157/1875], Loss: 2.1384, batch time: 0.14\n",
      "Epoch [4/5], Step [1158/1875], Loss: 2.1349, batch time: 0.15\n",
      "Epoch [4/5], Step [1159/1875], Loss: 2.3397, batch time: 0.10\n",
      "Epoch [4/5], Step [1160/1875], Loss: 2.1252, batch time: 0.10\n",
      "Epoch [4/5], Step [1161/1875], Loss: 2.2203, batch time: 0.11\n",
      "Epoch [4/5], Step [1162/1875], Loss: 2.0160, batch time: 0.12\n",
      "Epoch [4/5], Step [1163/1875], Loss: 2.0946, batch time: 0.13\n",
      "Epoch [4/5], Step [1164/1875], Loss: 2.2141, batch time: 0.10\n",
      "Epoch [4/5], Step [1165/1875], Loss: 2.0864, batch time: 0.10\n",
      "Epoch [4/5], Step [1166/1875], Loss: 2.0222, batch time: 0.10\n",
      "Epoch [4/5], Step [1167/1875], Loss: 2.1384, batch time: 0.10\n",
      "Epoch [4/5], Step [1168/1875], Loss: 2.0163, batch time: 0.16\n",
      "Epoch [4/5], Step [1169/1875], Loss: 2.1195, batch time: 0.09\n",
      "Epoch [4/5], Step [1170/1875], Loss: 2.1907, batch time: 0.12\n",
      "Epoch [4/5], Step [1171/1875], Loss: 2.0076, batch time: 0.11\n",
      "Epoch [4/5], Step [1172/1875], Loss: 2.3527, batch time: 0.19\n",
      "Epoch [4/5], Step [1173/1875], Loss: 2.1724, batch time: 0.10\n",
      "Epoch [4/5], Step [1174/1875], Loss: 2.1676, batch time: 0.12\n",
      "Epoch [4/5], Step [1175/1875], Loss: 2.2337, batch time: 0.14\n",
      "Epoch [4/5], Step [1176/1875], Loss: 2.0510, batch time: 0.13\n",
      "Epoch [4/5], Step [1177/1875], Loss: 1.9987, batch time: 0.09\n",
      "Epoch [4/5], Step [1178/1875], Loss: 2.1398, batch time: 0.12\n",
      "Epoch [4/5], Step [1179/1875], Loss: 2.2084, batch time: 0.12\n",
      "Epoch [4/5], Step [1180/1875], Loss: 2.0913, batch time: 0.10\n",
      "Epoch [4/5], Step [1181/1875], Loss: 2.1007, batch time: 0.12\n",
      "Epoch [4/5], Step [1182/1875], Loss: 2.0909, batch time: 0.10\n",
      "Epoch [4/5], Step [1183/1875], Loss: 2.0516, batch time: 0.22\n",
      "Epoch [4/5], Step [1184/1875], Loss: 2.0875, batch time: 0.11\n",
      "Epoch [4/5], Step [1185/1875], Loss: 2.0609, batch time: 0.14\n",
      "Epoch [4/5], Step [1186/1875], Loss: 2.2346, batch time: 0.13\n",
      "Epoch [4/5], Step [1187/1875], Loss: 2.0515, batch time: 0.13\n",
      "Epoch [4/5], Step [1188/1875], Loss: 2.3219, batch time: 0.14\n",
      "Epoch [4/5], Step [1189/1875], Loss: 2.2000, batch time: 0.10\n",
      "Epoch [4/5], Step [1190/1875], Loss: 2.2777, batch time: 0.16\n",
      "Epoch [4/5], Step [1191/1875], Loss: 2.3746, batch time: 0.13\n",
      "Epoch [4/5], Step [1192/1875], Loss: 1.9445, batch time: 0.13\n",
      "Epoch [4/5], Step [1193/1875], Loss: 1.9833, batch time: 0.17\n",
      "Epoch [4/5], Step [1194/1875], Loss: 2.2004, batch time: 0.14\n",
      "Epoch [4/5], Step [1195/1875], Loss: 2.1124, batch time: 0.13\n",
      "Epoch [4/5], Step [1196/1875], Loss: 2.1381, batch time: 0.10\n",
      "Epoch [4/5], Step [1197/1875], Loss: 2.0642, batch time: 0.12\n",
      "Epoch [4/5], Step [1198/1875], Loss: 2.0083, batch time: 0.14\n",
      "Epoch [4/5], Step [1199/1875], Loss: 2.1573, batch time: 0.10\n",
      "Epoch [4/5], Step [1200/1875], Loss: 2.3488, batch time: 0.10\n",
      "Epoch [4/5], Step [1201/1875], Loss: 2.1515, batch time: 0.12\n",
      "Epoch [4/5], Step [1202/1875], Loss: 1.9385, batch time: 0.10\n",
      "Epoch [4/5], Step [1203/1875], Loss: 2.1655, batch time: 0.13\n",
      "Epoch [4/5], Step [1204/1875], Loss: 2.1638, batch time: 0.21\n",
      "Epoch [4/5], Step [1205/1875], Loss: 2.0917, batch time: 0.12\n",
      "Epoch [4/5], Step [1206/1875], Loss: 2.0644, batch time: 0.10\n",
      "Epoch [4/5], Step [1207/1875], Loss: 2.0602, batch time: 0.10\n",
      "Epoch [4/5], Step [1208/1875], Loss: 2.1875, batch time: 0.15\n",
      "Epoch [4/5], Step [1209/1875], Loss: 2.1674, batch time: 0.11\n",
      "Epoch [4/5], Step [1210/1875], Loss: 2.1611, batch time: 0.13\n",
      "Epoch [4/5], Step [1211/1875], Loss: 2.1346, batch time: 0.10\n",
      "Epoch [4/5], Step [1212/1875], Loss: 2.1335, batch time: 0.10\n",
      "Epoch [4/5], Step [1213/1875], Loss: 2.0719, batch time: 0.13\n",
      "Epoch [4/5], Step [1214/1875], Loss: 1.9043, batch time: 0.14\n",
      "Epoch [4/5], Step [1215/1875], Loss: 2.2161, batch time: 0.10\n",
      "Epoch [4/5], Step [1216/1875], Loss: 2.0108, batch time: 0.22\n",
      "Epoch [4/5], Step [1217/1875], Loss: 2.1903, batch time: 0.09\n",
      "Epoch [4/5], Step [1218/1875], Loss: 2.0933, batch time: 0.10\n",
      "Epoch [4/5], Step [1219/1875], Loss: 1.9980, batch time: 0.11\n",
      "Epoch [4/5], Step [1220/1875], Loss: 2.1448, batch time: 0.25\n",
      "Epoch [4/5], Step [1221/1875], Loss: 2.2524, batch time: 0.10\n",
      "Epoch [4/5], Step [1222/1875], Loss: 2.1661, batch time: 0.10\n",
      "Epoch [4/5], Step [1223/1875], Loss: 2.1070, batch time: 0.10\n",
      "Epoch [4/5], Step [1224/1875], Loss: 2.0749, batch time: 0.15\n",
      "Epoch [4/5], Step [1225/1875], Loss: 2.1532, batch time: 0.12\n",
      "Epoch [4/5], Step [1226/1875], Loss: 2.0617, batch time: 0.13\n",
      "Epoch [4/5], Step [1227/1875], Loss: 2.1477, batch time: 0.14\n",
      "Epoch [4/5], Step [1228/1875], Loss: 2.1263, batch time: 0.13\n",
      "Epoch [4/5], Step [1229/1875], Loss: 2.1779, batch time: 0.15\n",
      "Epoch [4/5], Step [1230/1875], Loss: 2.0598, batch time: 0.12\n",
      "Epoch [4/5], Step [1231/1875], Loss: 2.1460, batch time: 0.12\n",
      "Epoch [4/5], Step [1232/1875], Loss: 1.9876, batch time: 0.13\n",
      "Epoch [4/5], Step [1233/1875], Loss: 2.1445, batch time: 0.11\n",
      "Epoch [4/5], Step [1234/1875], Loss: 1.9431, batch time: 0.10\n",
      "Epoch [4/5], Step [1235/1875], Loss: 1.9740, batch time: 0.14\n",
      "Epoch [4/5], Step [1236/1875], Loss: 2.2023, batch time: 0.11\n",
      "Epoch [4/5], Step [1237/1875], Loss: 2.1456, batch time: 0.11\n",
      "Epoch [4/5], Step [1238/1875], Loss: 2.1072, batch time: 0.10\n",
      "Epoch [4/5], Step [1239/1875], Loss: 2.0144, batch time: 0.10\n",
      "Epoch [4/5], Step [1240/1875], Loss: 2.1013, batch time: 0.25\n",
      "Epoch [4/5], Step [1241/1875], Loss: 2.0860, batch time: 0.10\n",
      "Epoch [4/5], Step [1242/1875], Loss: 1.9557, batch time: 0.10\n",
      "Epoch [4/5], Step [1243/1875], Loss: 1.8769, batch time: 0.23\n",
      "Epoch [4/5], Step [1244/1875], Loss: 2.0908, batch time: 0.11\n",
      "Epoch [4/5], Step [1245/1875], Loss: 2.2229, batch time: 0.14\n",
      "Epoch [4/5], Step [1246/1875], Loss: 2.1071, batch time: 0.13\n",
      "Epoch [4/5], Step [1247/1875], Loss: 2.0036, batch time: 0.12\n",
      "Epoch [4/5], Step [1248/1875], Loss: 1.9443, batch time: 0.17\n",
      "Epoch [4/5], Step [1249/1875], Loss: 2.1893, batch time: 0.12\n",
      "Epoch [4/5], Step [1250/1875], Loss: 2.2852, batch time: 0.10\n",
      "Epoch [4/5], Step [1251/1875], Loss: 2.1760, batch time: 0.13\n",
      "Epoch [4/5], Step [1252/1875], Loss: 1.9883, batch time: 0.13\n",
      "Epoch [4/5], Step [1253/1875], Loss: 2.1508, batch time: 0.11\n",
      "Epoch [4/5], Step [1254/1875], Loss: 2.1723, batch time: 0.10\n",
      "Epoch [4/5], Step [1255/1875], Loss: 2.0747, batch time: 0.11\n",
      "Epoch [4/5], Step [1256/1875], Loss: 2.2152, batch time: 0.23\n",
      "Epoch [4/5], Step [1257/1875], Loss: 2.1416, batch time: 0.11\n",
      "Epoch [4/5], Step [1258/1875], Loss: 2.2648, batch time: 0.13\n",
      "Epoch [4/5], Step [1259/1875], Loss: 2.0602, batch time: 0.12\n",
      "Epoch [4/5], Step [1260/1875], Loss: 2.1503, batch time: 0.16\n",
      "Epoch [4/5], Step [1261/1875], Loss: 1.9370, batch time: 0.12\n",
      "Epoch [4/5], Step [1262/1875], Loss: 2.0051, batch time: 0.16\n",
      "Epoch [4/5], Step [1263/1875], Loss: 1.9435, batch time: 0.17\n",
      "Epoch [4/5], Step [1264/1875], Loss: 2.1806, batch time: 0.16\n",
      "Epoch [4/5], Step [1265/1875], Loss: 1.9858, batch time: 0.13\n",
      "Epoch [4/5], Step [1266/1875], Loss: 2.1543, batch time: 0.12\n",
      "Epoch [4/5], Step [1267/1875], Loss: 2.1370, batch time: 0.11\n",
      "Epoch [4/5], Step [1268/1875], Loss: 2.2033, batch time: 0.10\n",
      "Epoch [4/5], Step [1269/1875], Loss: 2.1564, batch time: 0.14\n",
      "Epoch [4/5], Step [1270/1875], Loss: 2.0749, batch time: 0.11\n",
      "Epoch [4/5], Step [1271/1875], Loss: 2.2207, batch time: 0.10\n",
      "Epoch [4/5], Step [1272/1875], Loss: 2.0194, batch time: 0.12\n",
      "Epoch [4/5], Step [1273/1875], Loss: 1.9133, batch time: 0.10\n",
      "Epoch [4/5], Step [1274/1875], Loss: 2.0836, batch time: 0.09\n",
      "Epoch [4/5], Step [1275/1875], Loss: 2.0751, batch time: 0.10\n",
      "Epoch [4/5], Step [1276/1875], Loss: 2.1976, batch time: 0.11\n",
      "Epoch [4/5], Step [1277/1875], Loss: 2.0202, batch time: 0.10\n",
      "Epoch [4/5], Step [1278/1875], Loss: 1.9665, batch time: 0.11\n",
      "Epoch [4/5], Step [1279/1875], Loss: 2.0798, batch time: 0.10\n",
      "Epoch [4/5], Step [1280/1875], Loss: 2.1467, batch time: 0.10\n",
      "Epoch [4/5], Step [1281/1875], Loss: 2.0598, batch time: 0.10\n",
      "Epoch [4/5], Step [1282/1875], Loss: 2.1291, batch time: 0.14\n",
      "Epoch [4/5], Step [1283/1875], Loss: 2.1203, batch time: 0.11\n",
      "Epoch [4/5], Step [1284/1875], Loss: 1.9936, batch time: 0.11\n",
      "Epoch [4/5], Step [1285/1875], Loss: 2.0261, batch time: 0.11\n",
      "Epoch [4/5], Step [1286/1875], Loss: 1.9356, batch time: 0.10\n",
      "Epoch [4/5], Step [1287/1875], Loss: 2.2113, batch time: 0.11\n",
      "Epoch [4/5], Step [1288/1875], Loss: 1.6843, batch time: 0.10\n",
      "Epoch [4/5], Step [1289/1875], Loss: 2.0735, batch time: 0.21\n",
      "Epoch [4/5], Step [1290/1875], Loss: 1.9337, batch time: 0.16\n",
      "Epoch [4/5], Step [1291/1875], Loss: 2.0920, batch time: 0.13\n",
      "Epoch [4/5], Step [1292/1875], Loss: 1.8889, batch time: 0.10\n",
      "Epoch [4/5], Step [1293/1875], Loss: 2.0616, batch time: 0.14\n",
      "Epoch [4/5], Step [1294/1875], Loss: 2.0640, batch time: 0.11\n",
      "Epoch [4/5], Step [1295/1875], Loss: 2.2780, batch time: 0.12\n",
      "Epoch [4/5], Step [1296/1875], Loss: 2.0022, batch time: 0.13\n",
      "Epoch [4/5], Step [1297/1875], Loss: 2.1895, batch time: 0.10\n",
      "Epoch [4/5], Step [1298/1875], Loss: 1.9075, batch time: 0.12\n",
      "Epoch [4/5], Step [1299/1875], Loss: 1.9299, batch time: 0.15\n",
      "Epoch [4/5], Step [1300/1875], Loss: 1.9330, batch time: 0.10\n",
      "Epoch [4/5], Step [1301/1875], Loss: 1.8643, batch time: 0.13\n",
      "Epoch [4/5], Step [1302/1875], Loss: 2.1411, batch time: 0.10\n",
      "Epoch [4/5], Step [1303/1875], Loss: 2.0381, batch time: 0.12\n",
      "Epoch [4/5], Step [1304/1875], Loss: 1.8785, batch time: 0.12\n",
      "Epoch [4/5], Step [1305/1875], Loss: 2.0374, batch time: 0.11\n",
      "Epoch [4/5], Step [1306/1875], Loss: 2.1012, batch time: 0.10\n",
      "Epoch [4/5], Step [1307/1875], Loss: 2.1722, batch time: 0.12\n",
      "Epoch [4/5], Step [1308/1875], Loss: 2.1974, batch time: 0.10\n",
      "Epoch [4/5], Step [1309/1875], Loss: 2.1823, batch time: 0.09\n",
      "Epoch [4/5], Step [1310/1875], Loss: 2.1397, batch time: 0.10\n",
      "Epoch [4/5], Step [1311/1875], Loss: 2.1271, batch time: 0.10\n",
      "Epoch [4/5], Step [1312/1875], Loss: 2.2561, batch time: 0.10\n",
      "Epoch [4/5], Step [1313/1875], Loss: 2.1478, batch time: 0.14\n",
      "Epoch [4/5], Step [1314/1875], Loss: 2.2409, batch time: 0.13\n",
      "Epoch [4/5], Step [1315/1875], Loss: 2.3022, batch time: 0.10\n",
      "Epoch [4/5], Step [1316/1875], Loss: 2.1842, batch time: 0.15\n",
      "Epoch [4/5], Step [1317/1875], Loss: 2.3795, batch time: 0.10\n",
      "Epoch [4/5], Step [1318/1875], Loss: 2.1832, batch time: 0.10\n",
      "Epoch [4/5], Step [1319/1875], Loss: 2.2622, batch time: 0.12\n",
      "Epoch [4/5], Step [1320/1875], Loss: 2.0163, batch time: 0.14\n",
      "Epoch [4/5], Step [1321/1875], Loss: 2.1044, batch time: 0.11\n",
      "Epoch [4/5], Step [1322/1875], Loss: 2.3628, batch time: 0.13\n",
      "Epoch [4/5], Step [1323/1875], Loss: 2.0725, batch time: 0.10\n",
      "Epoch [4/5], Step [1324/1875], Loss: 1.9176, batch time: 0.12\n",
      "Epoch [4/5], Step [1325/1875], Loss: 2.1218, batch time: 0.10\n",
      "Epoch [4/5], Step [1326/1875], Loss: 2.3141, batch time: 0.11\n",
      "Epoch [4/5], Step [1327/1875], Loss: 2.0456, batch time: 0.13\n",
      "Epoch [4/5], Step [1328/1875], Loss: 2.0315, batch time: 0.11\n",
      "Epoch [4/5], Step [1329/1875], Loss: 2.1311, batch time: 0.13\n",
      "Epoch [4/5], Step [1330/1875], Loss: 2.0031, batch time: 0.11\n",
      "Epoch [4/5], Step [1331/1875], Loss: 1.8504, batch time: 0.18\n",
      "Epoch [4/5], Step [1332/1875], Loss: 2.1335, batch time: 0.11\n",
      "Epoch [4/5], Step [1333/1875], Loss: 1.8910, batch time: 0.12\n",
      "Epoch [4/5], Step [1334/1875], Loss: 1.8038, batch time: 0.11\n",
      "Epoch [4/5], Step [1335/1875], Loss: 2.2951, batch time: 0.15\n",
      "Epoch [4/5], Step [1336/1875], Loss: 2.0249, batch time: 0.12\n",
      "Epoch [4/5], Step [1337/1875], Loss: 2.2039, batch time: 0.13\n",
      "Epoch [4/5], Step [1338/1875], Loss: 2.1052, batch time: -2.81\n",
      "Epoch [4/5], Step [1339/1875], Loss: 1.9598, batch time: 0.14\n",
      "Epoch [4/5], Step [1340/1875], Loss: 2.0607, batch time: 0.13\n",
      "Epoch [4/5], Step [1341/1875], Loss: 2.0676, batch time: 0.13\n",
      "Epoch [4/5], Step [1342/1875], Loss: 2.1017, batch time: 0.11\n",
      "Epoch [4/5], Step [1343/1875], Loss: 2.3526, batch time: 0.10\n",
      "Epoch [4/5], Step [1344/1875], Loss: 2.1750, batch time: 0.10\n",
      "Epoch [4/5], Step [1345/1875], Loss: 2.0487, batch time: 0.10\n",
      "Epoch [4/5], Step [1346/1875], Loss: 2.2393, batch time: 0.10\n",
      "Epoch [4/5], Step [1347/1875], Loss: 2.0968, batch time: 0.09\n",
      "Epoch [4/5], Step [1348/1875], Loss: 2.0854, batch time: 0.11\n",
      "Epoch [4/5], Step [1349/1875], Loss: 2.0881, batch time: 0.10\n",
      "Epoch [4/5], Step [1350/1875], Loss: 2.0880, batch time: 0.10\n",
      "Epoch [4/5], Step [1351/1875], Loss: 2.2025, batch time: 0.11\n",
      "Epoch [4/5], Step [1352/1875], Loss: 2.1102, batch time: 0.12\n",
      "Epoch [4/5], Step [1353/1875], Loss: 2.0265, batch time: 0.10\n",
      "Epoch [4/5], Step [1354/1875], Loss: 2.3384, batch time: 0.10\n",
      "Epoch [4/5], Step [1355/1875], Loss: 2.0977, batch time: 0.09\n",
      "Epoch [4/5], Step [1356/1875], Loss: 2.1299, batch time: 0.10\n",
      "Epoch [4/5], Step [1357/1875], Loss: 1.9888, batch time: 0.09\n",
      "Epoch [4/5], Step [1358/1875], Loss: 2.0762, batch time: 0.16\n",
      "Epoch [4/5], Step [1359/1875], Loss: 2.0642, batch time: 0.10\n",
      "Epoch [4/5], Step [1360/1875], Loss: 1.9183, batch time: 0.10\n",
      "Epoch [4/5], Step [1361/1875], Loss: 2.0676, batch time: 0.10\n",
      "Epoch [4/5], Step [1362/1875], Loss: 2.1396, batch time: 0.11\n",
      "Epoch [4/5], Step [1363/1875], Loss: 2.1252, batch time: 0.09\n",
      "Epoch [4/5], Step [1364/1875], Loss: 2.0257, batch time: 0.10\n",
      "Epoch [4/5], Step [1365/1875], Loss: 2.0776, batch time: 0.10\n",
      "Epoch [4/5], Step [1366/1875], Loss: 2.1419, batch time: 0.16\n",
      "Epoch [4/5], Step [1367/1875], Loss: 2.1341, batch time: 0.09\n",
      "Epoch [4/5], Step [1368/1875], Loss: 1.9956, batch time: 0.10\n",
      "Epoch [4/5], Step [1369/1875], Loss: 2.3015, batch time: 0.09\n",
      "Epoch [4/5], Step [1370/1875], Loss: 2.1913, batch time: 0.12\n",
      "Epoch [4/5], Step [1371/1875], Loss: 2.0362, batch time: 0.10\n",
      "Epoch [4/5], Step [1372/1875], Loss: 2.0069, batch time: 0.10\n",
      "Epoch [4/5], Step [1373/1875], Loss: 1.9826, batch time: 0.12\n",
      "Epoch [4/5], Step [1374/1875], Loss: 2.2175, batch time: 0.16\n",
      "Epoch [4/5], Step [1375/1875], Loss: 2.1882, batch time: 0.10\n",
      "Epoch [4/5], Step [1376/1875], Loss: 2.0186, batch time: 0.13\n",
      "Epoch [4/5], Step [1377/1875], Loss: 2.1733, batch time: 0.10\n",
      "Epoch [4/5], Step [1378/1875], Loss: 1.8764, batch time: 0.11\n",
      "Epoch [4/5], Step [1379/1875], Loss: 1.9549, batch time: 0.14\n",
      "Epoch [4/5], Step [1380/1875], Loss: 2.0014, batch time: 0.11\n",
      "Epoch [4/5], Step [1381/1875], Loss: 2.0178, batch time: 0.10\n",
      "Epoch [4/5], Step [1382/1875], Loss: 2.0491, batch time: 0.12\n",
      "Epoch [4/5], Step [1383/1875], Loss: 1.7791, batch time: 0.12\n",
      "Epoch [4/5], Step [1384/1875], Loss: 1.9302, batch time: 0.17\n",
      "Epoch [4/5], Step [1385/1875], Loss: 2.2785, batch time: 0.12\n",
      "Epoch [4/5], Step [1386/1875], Loss: 1.9827, batch time: 0.10\n",
      "Epoch [4/5], Step [1387/1875], Loss: 2.0541, batch time: 0.12\n",
      "Epoch [4/5], Step [1388/1875], Loss: 2.2371, batch time: 0.11\n",
      "Epoch [4/5], Step [1389/1875], Loss: 2.0743, batch time: 0.15\n",
      "Epoch [4/5], Step [1390/1875], Loss: 2.0971, batch time: 0.14\n",
      "Epoch [4/5], Step [1391/1875], Loss: 2.1276, batch time: 0.12\n",
      "Epoch [4/5], Step [1392/1875], Loss: 2.2974, batch time: 0.10\n",
      "Epoch [4/5], Step [1393/1875], Loss: 2.4219, batch time: 0.14\n",
      "Epoch [4/5], Step [1394/1875], Loss: 2.0625, batch time: 0.10\n",
      "Epoch [4/5], Step [1395/1875], Loss: 2.0022, batch time: 0.14\n",
      "Epoch [4/5], Step [1396/1875], Loss: 2.2404, batch time: 0.14\n",
      "Epoch [4/5], Step [1397/1875], Loss: 2.0469, batch time: 0.35\n",
      "Epoch [4/5], Step [1398/1875], Loss: 2.1126, batch time: 0.10\n",
      "Epoch [4/5], Step [1399/1875], Loss: 1.9956, batch time: 0.13\n",
      "Epoch [4/5], Step [1400/1875], Loss: 2.0349, batch time: 0.11\n",
      "Epoch [4/5], Step [1401/1875], Loss: 1.9023, batch time: 0.10\n",
      "Epoch [4/5], Step [1402/1875], Loss: 1.9615, batch time: 0.14\n",
      "Epoch [4/5], Step [1403/1875], Loss: 2.3455, batch time: 0.13\n",
      "Epoch [4/5], Step [1404/1875], Loss: 1.8511, batch time: 0.10\n",
      "Epoch [4/5], Step [1405/1875], Loss: 2.1572, batch time: 0.11\n",
      "Epoch [4/5], Step [1406/1875], Loss: 2.0206, batch time: 0.18\n",
      "Epoch [4/5], Step [1407/1875], Loss: 1.8281, batch time: 0.20\n",
      "Epoch [4/5], Step [1408/1875], Loss: 2.0234, batch time: 0.21\n",
      "Epoch [4/5], Step [1409/1875], Loss: 2.2026, batch time: 0.24\n",
      "Epoch [4/5], Step [1410/1875], Loss: 2.2176, batch time: 0.22\n",
      "Epoch [4/5], Step [1411/1875], Loss: 2.1857, batch time: 0.28\n",
      "Epoch [4/5], Step [1412/1875], Loss: 1.9498, batch time: 0.25\n",
      "Epoch [4/5], Step [1413/1875], Loss: 2.0010, batch time: 0.27\n",
      "Epoch [4/5], Step [1414/1875], Loss: 2.1930, batch time: 0.27\n",
      "Epoch [4/5], Step [1415/1875], Loss: 2.0398, batch time: 0.26\n",
      "Epoch [4/5], Step [1416/1875], Loss: 1.9998, batch time: 0.32\n",
      "Epoch [4/5], Step [1417/1875], Loss: 2.0930, batch time: 0.24\n",
      "Epoch [4/5], Step [1418/1875], Loss: 2.0248, batch time: 0.15\n",
      "Epoch [4/5], Step [1419/1875], Loss: 1.9783, batch time: 0.17\n",
      "Epoch [4/5], Step [1420/1875], Loss: 2.2207, batch time: 0.19\n",
      "Epoch [4/5], Step [1421/1875], Loss: 1.9519, batch time: 0.18\n",
      "Epoch [4/5], Step [1422/1875], Loss: 2.0446, batch time: 0.19\n",
      "Epoch [4/5], Step [1423/1875], Loss: 2.1371, batch time: 0.21\n",
      "Epoch [4/5], Step [1424/1875], Loss: 2.1215, batch time: 0.20\n",
      "Epoch [4/5], Step [1425/1875], Loss: 2.1083, batch time: 0.19\n",
      "Epoch [4/5], Step [1426/1875], Loss: 2.1498, batch time: 0.22\n",
      "Epoch [4/5], Step [1427/1875], Loss: 2.0159, batch time: 0.17\n",
      "Epoch [4/5], Step [1428/1875], Loss: 2.0721, batch time: 0.22\n",
      "Epoch [4/5], Step [1429/1875], Loss: 1.9102, batch time: 0.18\n",
      "Epoch [4/5], Step [1430/1875], Loss: 2.0916, batch time: 0.17\n",
      "Epoch [4/5], Step [1431/1875], Loss: 2.1277, batch time: 0.11\n",
      "Epoch [4/5], Step [1432/1875], Loss: 2.1197, batch time: 0.12\n",
      "Epoch [4/5], Step [1433/1875], Loss: 2.0380, batch time: 0.11\n",
      "Epoch [4/5], Step [1434/1875], Loss: 1.8142, batch time: 0.11\n",
      "Epoch [4/5], Step [1435/1875], Loss: 2.2333, batch time: 0.10\n",
      "Epoch [4/5], Step [1436/1875], Loss: 1.9258, batch time: 0.16\n",
      "Epoch [4/5], Step [1437/1875], Loss: 1.9097, batch time: 0.12\n",
      "Epoch [4/5], Step [1438/1875], Loss: 2.0582, batch time: 0.13\n",
      "Epoch [4/5], Step [1439/1875], Loss: 2.0392, batch time: 0.13\n",
      "Epoch [4/5], Step [1440/1875], Loss: 2.1894, batch time: 0.14\n",
      "Epoch [4/5], Step [1441/1875], Loss: 2.1346, batch time: 0.14\n",
      "Epoch [4/5], Step [1442/1875], Loss: 1.9524, batch time: 0.12\n",
      "Epoch [4/5], Step [1443/1875], Loss: 2.1795, batch time: 0.18\n",
      "Epoch [4/5], Step [1444/1875], Loss: 2.1813, batch time: 0.13\n",
      "Epoch [4/5], Step [1445/1875], Loss: 1.8839, batch time: 0.15\n",
      "Epoch [4/5], Step [1446/1875], Loss: 2.3118, batch time: 0.11\n",
      "Epoch [4/5], Step [1447/1875], Loss: 2.0983, batch time: 0.11\n",
      "Epoch [4/5], Step [1448/1875], Loss: 2.0339, batch time: 0.17\n",
      "Epoch [4/5], Step [1449/1875], Loss: 2.0420, batch time: 0.15\n",
      "Epoch [4/5], Step [1450/1875], Loss: 1.9149, batch time: 0.16\n",
      "Epoch [4/5], Step [1451/1875], Loss: 2.0881, batch time: 0.13\n",
      "Epoch [4/5], Step [1452/1875], Loss: 1.9773, batch time: 0.13\n",
      "Epoch [4/5], Step [1453/1875], Loss: 1.9863, batch time: 0.12\n",
      "Epoch [4/5], Step [1454/1875], Loss: 2.1862, batch time: 0.14\n",
      "Epoch [4/5], Step [1455/1875], Loss: 2.0660, batch time: 0.10\n",
      "Epoch [4/5], Step [1456/1875], Loss: 2.1323, batch time: 0.17\n",
      "Epoch [4/5], Step [1457/1875], Loss: 2.1967, batch time: 0.10\n",
      "Epoch [4/5], Step [1458/1875], Loss: 2.1224, batch time: 0.11\n",
      "Epoch [4/5], Step [1459/1875], Loss: 2.0608, batch time: 0.14\n",
      "Epoch [4/5], Step [1460/1875], Loss: 2.0809, batch time: 0.13\n",
      "Epoch [4/5], Step [1461/1875], Loss: 2.2070, batch time: 0.17\n",
      "Epoch [4/5], Step [1462/1875], Loss: 2.0512, batch time: 0.10\n",
      "Epoch [4/5], Step [1463/1875], Loss: 2.0761, batch time: 0.10\n",
      "Epoch [4/5], Step [1464/1875], Loss: 2.0243, batch time: 0.10\n",
      "Epoch [4/5], Step [1465/1875], Loss: 1.9699, batch time: 0.10\n",
      "Epoch [4/5], Step [1466/1875], Loss: 2.0034, batch time: 0.12\n",
      "Epoch [4/5], Step [1467/1875], Loss: 2.0953, batch time: 0.12\n",
      "Epoch [4/5], Step [1468/1875], Loss: 2.1867, batch time: 0.11\n",
      "Epoch [4/5], Step [1469/1875], Loss: 2.1175, batch time: 0.13\n",
      "Epoch [4/5], Step [1470/1875], Loss: 2.1409, batch time: 0.12\n",
      "Epoch [4/5], Step [1471/1875], Loss: 2.0206, batch time: 0.10\n",
      "Epoch [4/5], Step [1472/1875], Loss: 2.1213, batch time: 0.10\n",
      "Epoch [4/5], Step [1473/1875], Loss: 2.0971, batch time: 0.13\n",
      "Epoch [4/5], Step [1474/1875], Loss: 2.0907, batch time: 0.12\n",
      "Epoch [4/5], Step [1475/1875], Loss: 2.0713, batch time: 0.11\n",
      "Epoch [4/5], Step [1476/1875], Loss: 1.9999, batch time: 0.10\n",
      "Epoch [4/5], Step [1477/1875], Loss: 2.2368, batch time: 0.10\n",
      "Epoch [4/5], Step [1478/1875], Loss: 1.9646, batch time: 0.26\n",
      "Epoch [4/5], Step [1479/1875], Loss: 1.9782, batch time: 0.10\n",
      "Epoch [4/5], Step [1480/1875], Loss: 2.1011, batch time: 0.10\n",
      "Epoch [4/5], Step [1481/1875], Loss: 2.1303, batch time: 0.10\n",
      "Epoch [4/5], Step [1482/1875], Loss: 1.9346, batch time: 0.10\n",
      "Epoch [4/5], Step [1483/1875], Loss: 2.0567, batch time: 0.10\n",
      "Epoch [4/5], Step [1484/1875], Loss: 1.9398, batch time: 0.11\n",
      "Epoch [4/5], Step [1485/1875], Loss: 2.0043, batch time: 0.10\n",
      "Epoch [4/5], Step [1486/1875], Loss: 2.2375, batch time: 0.26\n",
      "Epoch [4/5], Step [1487/1875], Loss: 2.1300, batch time: 0.11\n",
      "Epoch [4/5], Step [1488/1875], Loss: 2.0987, batch time: 0.10\n",
      "Epoch [4/5], Step [1489/1875], Loss: 2.2206, batch time: 0.10\n",
      "Epoch [4/5], Step [1490/1875], Loss: 1.9063, batch time: 0.11\n",
      "Epoch [4/5], Step [1491/1875], Loss: 2.1474, batch time: 0.14\n",
      "Epoch [4/5], Step [1492/1875], Loss: 2.3606, batch time: 0.11\n",
      "Epoch [4/5], Step [1493/1875], Loss: 2.1170, batch time: 0.10\n",
      "Epoch [4/5], Step [1494/1875], Loss: 2.3128, batch time: 0.13\n",
      "Epoch [4/5], Step [1495/1875], Loss: 2.1271, batch time: 0.11\n",
      "Epoch [4/5], Step [1496/1875], Loss: 1.9760, batch time: 0.10\n",
      "Epoch [4/5], Step [1497/1875], Loss: 2.0355, batch time: 0.10\n",
      "Epoch [4/5], Step [1498/1875], Loss: 2.2146, batch time: 0.10\n",
      "Epoch [4/5], Step [1499/1875], Loss: 2.0763, batch time: 0.17\n",
      "Epoch [4/5], Step [1500/1875], Loss: 1.9194, batch time: 0.10\n",
      "Epoch [4/5], Step [1501/1875], Loss: 2.3049, batch time: 0.11\n",
      "Epoch [4/5], Step [1502/1875], Loss: 2.1200, batch time: 0.10\n",
      "Epoch [4/5], Step [1503/1875], Loss: 2.1115, batch time: 0.10\n",
      "Epoch [4/5], Step [1504/1875], Loss: 2.2280, batch time: 0.12\n",
      "Epoch [4/5], Step [1505/1875], Loss: 2.1995, batch time: 0.10\n",
      "Epoch [4/5], Step [1506/1875], Loss: 2.2703, batch time: 0.10\n",
      "Epoch [4/5], Step [1507/1875], Loss: 1.9712, batch time: 0.10\n",
      "Epoch [4/5], Step [1508/1875], Loss: 2.1413, batch time: 0.12\n",
      "Epoch [4/5], Step [1509/1875], Loss: 2.0796, batch time: 0.10\n",
      "Epoch [4/5], Step [1510/1875], Loss: 2.1471, batch time: 0.10\n",
      "Epoch [4/5], Step [1511/1875], Loss: 2.1708, batch time: 0.10\n",
      "Epoch [4/5], Step [1512/1875], Loss: 2.0708, batch time: 0.10\n",
      "Epoch [4/5], Step [1513/1875], Loss: 2.0135, batch time: 0.16\n",
      "Epoch [4/5], Step [1514/1875], Loss: 2.0766, batch time: 0.10\n",
      "Epoch [4/5], Step [1515/1875], Loss: 1.9658, batch time: 0.10\n",
      "Epoch [4/5], Step [1516/1875], Loss: 2.1648, batch time: 0.10\n",
      "Epoch [4/5], Step [1517/1875], Loss: 1.9848, batch time: 0.10\n",
      "Epoch [4/5], Step [1518/1875], Loss: 2.0287, batch time: 0.13\n",
      "Epoch [4/5], Step [1519/1875], Loss: 2.0335, batch time: 0.10\n",
      "Epoch [4/5], Step [1520/1875], Loss: 2.1897, batch time: 0.10\n",
      "Epoch [4/5], Step [1521/1875], Loss: 1.7168, batch time: 0.10\n",
      "Epoch [4/5], Step [1522/1875], Loss: 2.0806, batch time: 0.12\n",
      "Epoch [4/5], Step [1523/1875], Loss: 2.1352, batch time: 0.12\n",
      "Epoch [4/5], Step [1524/1875], Loss: 2.0125, batch time: 0.10\n",
      "Epoch [4/5], Step [1525/1875], Loss: 2.2474, batch time: 0.10\n",
      "Epoch [4/5], Step [1526/1875], Loss: 1.9969, batch time: 0.11\n",
      "Epoch [4/5], Step [1527/1875], Loss: 1.9816, batch time: 0.13\n",
      "Epoch [4/5], Step [1528/1875], Loss: 1.8763, batch time: 0.14\n",
      "Epoch [4/5], Step [1529/1875], Loss: 1.8354, batch time: 0.10\n",
      "Epoch [4/5], Step [1530/1875], Loss: 2.0007, batch time: 0.10\n",
      "Epoch [4/5], Step [1531/1875], Loss: 2.2145, batch time: 0.14\n",
      "Epoch [4/5], Step [1532/1875], Loss: 1.7700, batch time: 0.10\n",
      "Epoch [4/5], Step [1533/1875], Loss: 2.0764, batch time: 0.10\n",
      "Epoch [4/5], Step [1534/1875], Loss: 2.1663, batch time: 0.12\n",
      "Epoch [4/5], Step [1535/1875], Loss: 2.2211, batch time: 0.10\n",
      "Epoch [4/5], Step [1536/1875], Loss: 2.1381, batch time: 0.10\n",
      "Epoch [4/5], Step [1537/1875], Loss: 2.1153, batch time: 0.10\n",
      "Epoch [4/5], Step [1538/1875], Loss: 1.8064, batch time: 0.10\n",
      "Epoch [4/5], Step [1539/1875], Loss: 1.9842, batch time: 0.10\n",
      "Epoch [4/5], Step [1540/1875], Loss: 1.9923, batch time: 0.11\n",
      "Epoch [4/5], Step [1541/1875], Loss: 2.0844, batch time: 0.10\n",
      "Epoch [4/5], Step [1542/1875], Loss: 1.9991, batch time: 0.10\n",
      "Epoch [4/5], Step [1543/1875], Loss: 1.7455, batch time: 0.10\n",
      "Epoch [4/5], Step [1544/1875], Loss: 2.0436, batch time: 0.10\n",
      "Epoch [4/5], Step [1545/1875], Loss: 1.8546, batch time: 0.10\n",
      "Epoch [4/5], Step [1546/1875], Loss: 1.9745, batch time: 0.10\n",
      "Epoch [4/5], Step [1547/1875], Loss: 1.8943, batch time: 0.10\n",
      "Epoch [4/5], Step [1548/1875], Loss: 1.7648, batch time: 0.10\n",
      "Epoch [4/5], Step [1549/1875], Loss: 1.9591, batch time: 0.11\n",
      "Epoch [4/5], Step [1550/1875], Loss: 1.8902, batch time: 0.10\n",
      "Epoch [4/5], Step [1551/1875], Loss: 1.9590, batch time: 0.11\n",
      "Epoch [4/5], Step [1552/1875], Loss: 2.0156, batch time: 0.10\n",
      "Epoch [4/5], Step [1553/1875], Loss: 2.2192, batch time: 0.10\n",
      "Epoch [4/5], Step [1554/1875], Loss: 2.0447, batch time: 0.11\n",
      "Epoch [4/5], Step [1555/1875], Loss: 2.1902, batch time: 0.11\n",
      "Epoch [4/5], Step [1556/1875], Loss: 1.9768, batch time: 0.11\n",
      "Epoch [4/5], Step [1557/1875], Loss: 2.1016, batch time: 0.15\n",
      "Epoch [4/5], Step [1558/1875], Loss: 2.0909, batch time: 0.10\n",
      "Epoch [4/5], Step [1559/1875], Loss: 2.1145, batch time: 0.11\n",
      "Epoch [4/5], Step [1560/1875], Loss: 2.1759, batch time: 0.10\n",
      "Epoch [4/5], Step [1561/1875], Loss: 2.0339, batch time: 0.14\n",
      "Epoch [4/5], Step [1562/1875], Loss: 2.0760, batch time: 0.10\n",
      "Epoch [4/5], Step [1563/1875], Loss: 2.1424, batch time: 0.11\n",
      "Epoch [4/5], Step [1564/1875], Loss: 1.9586, batch time: 0.16\n",
      "Epoch [4/5], Step [1565/1875], Loss: 1.9932, batch time: 0.16\n",
      "Epoch [4/5], Step [1566/1875], Loss: 2.3371, batch time: 0.14\n",
      "Epoch [4/5], Step [1567/1875], Loss: 2.0231, batch time: 0.11\n",
      "Epoch [4/5], Step [1568/1875], Loss: 1.9534, batch time: 0.11\n",
      "Epoch [4/5], Step [1569/1875], Loss: 2.1823, batch time: 0.10\n",
      "Epoch [4/5], Step [1570/1875], Loss: 2.0719, batch time: 0.11\n",
      "Epoch [4/5], Step [1571/1875], Loss: 2.1238, batch time: 0.10\n",
      "Epoch [4/5], Step [1572/1875], Loss: 1.7587, batch time: 0.10\n",
      "Epoch [4/5], Step [1573/1875], Loss: 1.8711, batch time: 0.10\n",
      "Epoch [4/5], Step [1574/1875], Loss: 2.0448, batch time: 0.10\n",
      "Epoch [4/5], Step [1575/1875], Loss: 1.9293, batch time: 0.11\n",
      "Epoch [4/5], Step [1576/1875], Loss: 1.8905, batch time: 0.10\n",
      "Epoch [4/5], Step [1577/1875], Loss: 1.9736, batch time: 0.10\n",
      "Epoch [4/5], Step [1578/1875], Loss: 2.1170, batch time: 0.19\n",
      "Epoch [4/5], Step [1579/1875], Loss: 2.1770, batch time: 0.10\n",
      "Epoch [4/5], Step [1580/1875], Loss: 2.1813, batch time: 0.13\n",
      "Epoch [4/5], Step [1581/1875], Loss: 2.2155, batch time: 0.13\n",
      "Epoch [4/5], Step [1582/1875], Loss: 1.9037, batch time: 0.12\n",
      "Epoch [4/5], Step [1583/1875], Loss: 1.9709, batch time: 0.14\n",
      "Epoch [4/5], Step [1584/1875], Loss: 1.8769, batch time: 0.15\n",
      "Epoch [4/5], Step [1585/1875], Loss: 2.0626, batch time: 0.10\n",
      "Epoch [4/5], Step [1586/1875], Loss: 2.1383, batch time: 0.13\n",
      "Epoch [4/5], Step [1587/1875], Loss: 2.0655, batch time: 0.11\n",
      "Epoch [4/5], Step [1588/1875], Loss: 1.9651, batch time: -2.83\n",
      "Epoch [4/5], Step [1589/1875], Loss: 2.1184, batch time: 0.20\n",
      "Epoch [4/5], Step [1590/1875], Loss: 2.0905, batch time: 0.13\n",
      "Epoch [4/5], Step [1591/1875], Loss: 2.3689, batch time: 0.13\n",
      "Epoch [4/5], Step [1592/1875], Loss: 1.9655, batch time: 0.10\n",
      "Epoch [4/5], Step [1593/1875], Loss: 1.9897, batch time: 0.11\n",
      "Epoch [4/5], Step [1594/1875], Loss: 2.0042, batch time: 0.10\n",
      "Epoch [4/5], Step [1595/1875], Loss: 2.3847, batch time: 0.12\n",
      "Epoch [4/5], Step [1596/1875], Loss: 1.9378, batch time: 0.10\n",
      "Epoch [4/5], Step [1597/1875], Loss: 1.9394, batch time: 0.10\n",
      "Epoch [4/5], Step [1598/1875], Loss: 1.9465, batch time: 0.10\n",
      "Epoch [4/5], Step [1599/1875], Loss: 2.0696, batch time: 0.11\n",
      "Epoch [4/5], Step [1600/1875], Loss: 2.1656, batch time: 0.10\n",
      "Epoch [4/5], Step [1601/1875], Loss: 1.9893, batch time: 0.13\n",
      "Epoch [4/5], Step [1602/1875], Loss: 2.1454, batch time: 0.18\n",
      "Epoch [4/5], Step [1603/1875], Loss: 1.7580, batch time: 0.10\n",
      "Epoch [4/5], Step [1604/1875], Loss: 2.0631, batch time: 0.10\n",
      "Epoch [4/5], Step [1605/1875], Loss: 1.8701, batch time: 0.10\n",
      "Epoch [4/5], Step [1606/1875], Loss: 2.0283, batch time: 0.14\n",
      "Epoch [4/5], Step [1607/1875], Loss: 1.9836, batch time: 0.10\n",
      "Epoch [4/5], Step [1608/1875], Loss: 1.9215, batch time: 0.12\n",
      "Epoch [4/5], Step [1609/1875], Loss: 1.9933, batch time: 0.10\n",
      "Epoch [4/5], Step [1610/1875], Loss: 2.0945, batch time: 0.16\n",
      "Epoch [4/5], Step [1611/1875], Loss: 1.7831, batch time: 0.13\n",
      "Epoch [4/5], Step [1612/1875], Loss: 2.0237, batch time: 0.15\n",
      "Epoch [4/5], Step [1613/1875], Loss: 2.1263, batch time: 0.13\n",
      "Epoch [4/5], Step [1614/1875], Loss: 1.9891, batch time: 0.10\n",
      "Epoch [4/5], Step [1615/1875], Loss: 2.0670, batch time: 0.10\n",
      "Epoch [4/5], Step [1616/1875], Loss: 1.8185, batch time: 0.10\n",
      "Epoch [4/5], Step [1617/1875], Loss: 2.1037, batch time: 0.12\n",
      "Epoch [4/5], Step [1618/1875], Loss: 2.2279, batch time: 0.10\n",
      "Epoch [4/5], Step [1619/1875], Loss: 2.1491, batch time: 0.13\n",
      "Epoch [4/5], Step [1620/1875], Loss: 2.2053, batch time: 0.10\n",
      "Epoch [4/5], Step [1621/1875], Loss: 2.1238, batch time: 0.10\n",
      "Epoch [4/5], Step [1622/1875], Loss: 1.8654, batch time: 0.10\n",
      "Epoch [4/5], Step [1623/1875], Loss: 1.8275, batch time: 0.10\n",
      "Epoch [4/5], Step [1624/1875], Loss: 2.2313, batch time: 0.13\n",
      "Epoch [4/5], Step [1625/1875], Loss: 1.9803, batch time: 0.11\n",
      "Epoch [4/5], Step [1626/1875], Loss: 2.2112, batch time: 0.10\n",
      "Epoch [4/5], Step [1627/1875], Loss: 1.8969, batch time: 0.12\n",
      "Epoch [4/5], Step [1628/1875], Loss: 2.0210, batch time: 0.10\n",
      "Epoch [4/5], Step [1629/1875], Loss: 2.0329, batch time: 0.11\n",
      "Epoch [4/5], Step [1630/1875], Loss: 2.0208, batch time: 0.10\n",
      "Epoch [4/5], Step [1631/1875], Loss: 1.9131, batch time: 0.12\n",
      "Epoch [4/5], Step [1632/1875], Loss: 1.9870, batch time: 0.10\n",
      "Epoch [4/5], Step [1633/1875], Loss: 1.8767, batch time: 0.24\n",
      "Epoch [4/5], Step [1634/1875], Loss: 1.9284, batch time: 0.12\n",
      "Epoch [4/5], Step [1635/1875], Loss: 2.0030, batch time: 0.11\n",
      "Epoch [4/5], Step [1636/1875], Loss: 1.8461, batch time: 0.14\n",
      "Epoch [4/5], Step [1637/1875], Loss: 1.6361, batch time: 0.12\n",
      "Epoch [4/5], Step [1638/1875], Loss: 2.1260, batch time: 0.12\n",
      "Epoch [4/5], Step [1639/1875], Loss: 1.9580, batch time: 0.10\n",
      "Epoch [4/5], Step [1640/1875], Loss: 1.9372, batch time: 0.13\n",
      "Epoch [4/5], Step [1641/1875], Loss: 2.1627, batch time: 0.10\n",
      "Epoch [4/5], Step [1642/1875], Loss: 2.1708, batch time: 0.11\n",
      "Epoch [4/5], Step [1643/1875], Loss: 2.0228, batch time: 0.12\n",
      "Epoch [4/5], Step [1644/1875], Loss: 2.2180, batch time: 0.10\n",
      "Epoch [4/5], Step [1645/1875], Loss: 1.8843, batch time: 0.11\n",
      "Epoch [4/5], Step [1646/1875], Loss: 2.0945, batch time: 0.12\n",
      "Epoch [4/5], Step [1647/1875], Loss: 1.9174, batch time: 0.12\n",
      "Epoch [4/5], Step [1648/1875], Loss: 2.1111, batch time: 0.13\n",
      "Epoch [4/5], Step [1649/1875], Loss: 2.2037, batch time: 0.12\n",
      "Epoch [4/5], Step [1650/1875], Loss: 2.2324, batch time: 0.10\n",
      "Epoch [4/5], Step [1651/1875], Loss: 2.0917, batch time: 0.11\n",
      "Epoch [4/5], Step [1652/1875], Loss: 1.8913, batch time: 0.12\n",
      "Epoch [4/5], Step [1653/1875], Loss: 2.0719, batch time: 0.13\n",
      "Epoch [4/5], Step [1654/1875], Loss: 2.1832, batch time: 0.13\n",
      "Epoch [4/5], Step [1655/1875], Loss: 2.2475, batch time: 0.12\n",
      "Epoch [4/5], Step [1656/1875], Loss: 2.1210, batch time: 0.13\n",
      "Epoch [4/5], Step [1657/1875], Loss: 2.0313, batch time: 0.11\n",
      "Epoch [4/5], Step [1658/1875], Loss: 2.1581, batch time: 0.10\n",
      "Epoch [4/5], Step [1659/1875], Loss: 2.1374, batch time: 0.10\n",
      "Epoch [4/5], Step [1660/1875], Loss: 2.0921, batch time: 0.10\n",
      "Epoch [4/5], Step [1661/1875], Loss: 2.0529, batch time: 0.12\n",
      "Epoch [4/5], Step [1662/1875], Loss: 2.1410, batch time: 0.10\n",
      "Epoch [4/5], Step [1663/1875], Loss: 2.1293, batch time: 0.10\n",
      "Epoch [4/5], Step [1664/1875], Loss: 1.8926, batch time: 0.10\n",
      "Epoch [4/5], Step [1665/1875], Loss: 1.9109, batch time: 0.13\n",
      "Epoch [4/5], Step [1666/1875], Loss: 2.1407, batch time: 0.19\n",
      "Epoch [4/5], Step [1667/1875], Loss: 2.1617, batch time: 0.10\n",
      "Epoch [4/5], Step [1668/1875], Loss: 2.0196, batch time: 0.11\n",
      "Epoch [4/5], Step [1669/1875], Loss: 2.0148, batch time: 0.12\n",
      "Epoch [4/5], Step [1670/1875], Loss: 1.9613, batch time: 0.10\n",
      "Epoch [4/5], Step [1671/1875], Loss: 2.1427, batch time: 0.10\n",
      "Epoch [4/5], Step [1672/1875], Loss: 2.2075, batch time: 0.11\n",
      "Epoch [4/5], Step [1673/1875], Loss: 1.9534, batch time: 0.16\n",
      "Epoch [4/5], Step [1674/1875], Loss: 2.0992, batch time: 0.13\n",
      "Epoch [4/5], Step [1675/1875], Loss: 2.1558, batch time: 0.24\n",
      "Epoch [4/5], Step [1676/1875], Loss: 1.7489, batch time: 0.10\n",
      "Epoch [4/5], Step [1677/1875], Loss: 2.0539, batch time: 0.10\n",
      "Epoch [4/5], Step [1678/1875], Loss: 2.0451, batch time: 0.10\n",
      "Epoch [4/5], Step [1679/1875], Loss: 1.9833, batch time: 0.10\n",
      "Epoch [4/5], Step [1680/1875], Loss: 2.2103, batch time: 0.12\n",
      "Epoch [4/5], Step [1681/1875], Loss: 1.9254, batch time: 0.14\n",
      "Epoch [4/5], Step [1682/1875], Loss: 2.1681, batch time: 0.10\n",
      "Epoch [4/5], Step [1683/1875], Loss: 2.1312, batch time: 0.10\n",
      "Epoch [4/5], Step [1684/1875], Loss: 2.1178, batch time: 0.10\n",
      "Epoch [4/5], Step [1685/1875], Loss: 2.0118, batch time: 0.29\n",
      "Epoch [4/5], Step [1686/1875], Loss: 2.0466, batch time: 0.18\n",
      "Epoch [4/5], Step [1687/1875], Loss: 2.0858, batch time: 0.11\n",
      "Epoch [4/5], Step [1688/1875], Loss: 2.1315, batch time: 0.16\n",
      "Epoch [4/5], Step [1689/1875], Loss: 2.1992, batch time: 0.10\n",
      "Epoch [4/5], Step [1690/1875], Loss: 1.6950, batch time: 0.10\n",
      "Epoch [4/5], Step [1691/1875], Loss: 1.8757, batch time: 0.11\n",
      "Epoch [4/5], Step [1692/1875], Loss: 2.0796, batch time: 0.14\n",
      "Epoch [4/5], Step [1693/1875], Loss: 2.0270, batch time: 0.14\n",
      "Epoch [4/5], Step [1694/1875], Loss: 2.0240, batch time: 0.11\n",
      "Epoch [4/5], Step [1695/1875], Loss: 1.9782, batch time: 0.13\n",
      "Epoch [4/5], Step [1696/1875], Loss: 2.1057, batch time: 0.13\n",
      "Epoch [4/5], Step [1697/1875], Loss: 1.9478, batch time: 0.13\n",
      "Epoch [4/5], Step [1698/1875], Loss: 2.1896, batch time: 0.12\n",
      "Epoch [4/5], Step [1699/1875], Loss: 2.1926, batch time: 0.10\n",
      "Epoch [4/5], Step [1700/1875], Loss: 2.0616, batch time: 0.12\n",
      "Epoch [4/5], Step [1701/1875], Loss: 1.9784, batch time: 0.16\n",
      "Epoch [4/5], Step [1702/1875], Loss: 2.0538, batch time: 0.14\n",
      "Epoch [4/5], Step [1703/1875], Loss: 2.1935, batch time: 0.10\n",
      "Epoch [4/5], Step [1704/1875], Loss: 1.7361, batch time: 0.10\n",
      "Epoch [4/5], Step [1705/1875], Loss: 2.0178, batch time: 0.13\n",
      "Epoch [4/5], Step [1706/1875], Loss: 1.9505, batch time: 0.10\n",
      "Epoch [4/5], Step [1707/1875], Loss: 2.1093, batch time: 0.29\n",
      "Epoch [4/5], Step [1708/1875], Loss: 1.8658, batch time: 0.10\n",
      "Epoch [4/5], Step [1709/1875], Loss: 2.0989, batch time: 0.12\n",
      "Epoch [4/5], Step [1710/1875], Loss: 2.0811, batch time: 0.10\n",
      "Epoch [4/5], Step [1711/1875], Loss: 2.0800, batch time: 0.11\n",
      "Epoch [4/5], Step [1712/1875], Loss: 2.2583, batch time: 0.12\n",
      "Epoch [4/5], Step [1713/1875], Loss: 2.2813, batch time: 0.10\n",
      "Epoch [4/5], Step [1714/1875], Loss: 2.1592, batch time: 0.10\n",
      "Epoch [4/5], Step [1715/1875], Loss: 2.1342, batch time: 0.15\n",
      "Epoch [4/5], Step [1716/1875], Loss: 1.9380, batch time: 0.10\n",
      "Epoch [4/5], Step [1717/1875], Loss: 1.9194, batch time: 0.10\n",
      "Epoch [4/5], Step [1718/1875], Loss: 2.0402, batch time: 0.13\n",
      "Epoch [4/5], Step [1719/1875], Loss: 2.0845, batch time: 0.12\n",
      "Epoch [4/5], Step [1720/1875], Loss: 2.0404, batch time: 0.10\n",
      "Epoch [4/5], Step [1721/1875], Loss: 1.9022, batch time: 0.11\n",
      "Epoch [4/5], Step [1722/1875], Loss: 2.1279, batch time: 0.11\n",
      "Epoch [4/5], Step [1723/1875], Loss: 2.1029, batch time: 0.13\n",
      "Epoch [4/5], Step [1724/1875], Loss: 2.0779, batch time: 0.10\n",
      "Epoch [4/5], Step [1725/1875], Loss: 2.1884, batch time: 0.13\n",
      "Epoch [4/5], Step [1726/1875], Loss: 1.8258, batch time: 0.22\n",
      "Epoch [4/5], Step [1727/1875], Loss: 1.9860, batch time: 0.12\n",
      "Epoch [4/5], Step [1728/1875], Loss: 2.0245, batch time: 0.13\n",
      "Epoch [4/5], Step [1729/1875], Loss: 2.0176, batch time: 0.12\n",
      "Epoch [4/5], Step [1730/1875], Loss: 1.9279, batch time: 0.10\n",
      "Epoch [4/5], Step [1731/1875], Loss: 1.9756, batch time: 0.13\n",
      "Epoch [4/5], Step [1732/1875], Loss: 2.0395, batch time: 0.12\n",
      "Epoch [4/5], Step [1733/1875], Loss: 1.9713, batch time: 0.12\n",
      "Epoch [4/5], Step [1734/1875], Loss: 2.1058, batch time: 0.10\n",
      "Epoch [4/5], Step [1735/1875], Loss: 1.7339, batch time: 0.11\n",
      "Epoch [4/5], Step [1736/1875], Loss: 2.0805, batch time: 0.12\n",
      "Epoch [4/5], Step [1737/1875], Loss: 1.9652, batch time: 0.10\n",
      "Epoch [4/5], Step [1738/1875], Loss: 2.0833, batch time: 0.10\n",
      "Epoch [4/5], Step [1739/1875], Loss: 2.2647, batch time: 0.10\n",
      "Epoch [4/5], Step [1740/1875], Loss: 2.1101, batch time: 0.10\n",
      "Epoch [4/5], Step [1741/1875], Loss: 2.2023, batch time: 0.19\n",
      "Epoch [4/5], Step [1742/1875], Loss: 1.7529, batch time: 0.13\n",
      "Epoch [4/5], Step [1743/1875], Loss: 1.9327, batch time: 0.10\n",
      "Epoch [4/5], Step [1744/1875], Loss: 2.1302, batch time: 0.10\n",
      "Epoch [4/5], Step [1745/1875], Loss: 1.9489, batch time: 0.13\n",
      "Epoch [4/5], Step [1746/1875], Loss: 2.1276, batch time: 0.14\n",
      "Epoch [4/5], Step [1747/1875], Loss: 2.0402, batch time: 0.11\n",
      "Epoch [4/5], Step [1748/1875], Loss: 1.9086, batch time: 0.11\n",
      "Epoch [4/5], Step [1749/1875], Loss: 2.1293, batch time: 0.14\n",
      "Epoch [4/5], Step [1750/1875], Loss: 2.0943, batch time: 0.12\n",
      "Epoch [4/5], Step [1751/1875], Loss: 2.0839, batch time: 0.12\n",
      "Epoch [4/5], Step [1752/1875], Loss: 1.9774, batch time: 0.10\n",
      "Epoch [4/5], Step [1753/1875], Loss: 2.0868, batch time: 0.14\n",
      "Epoch [4/5], Step [1754/1875], Loss: 1.9607, batch time: 0.18\n",
      "Epoch [4/5], Step [1755/1875], Loss: 2.0763, batch time: 0.14\n",
      "Epoch [4/5], Step [1756/1875], Loss: 2.1256, batch time: 0.10\n",
      "Epoch [4/5], Step [1757/1875], Loss: 2.0402, batch time: 0.10\n",
      "Epoch [4/5], Step [1758/1875], Loss: 1.9621, batch time: 0.17\n",
      "Epoch [4/5], Step [1759/1875], Loss: 2.0235, batch time: 0.10\n",
      "Epoch [4/5], Step [1760/1875], Loss: 1.9321, batch time: 0.11\n",
      "Epoch [4/5], Step [1761/1875], Loss: 1.9636, batch time: 0.10\n",
      "Epoch [4/5], Step [1762/1875], Loss: 1.9474, batch time: 0.13\n",
      "Epoch [4/5], Step [1763/1875], Loss: 2.0877, batch time: 0.10\n",
      "Epoch [4/5], Step [1764/1875], Loss: 2.0017, batch time: 0.12\n",
      "Epoch [4/5], Step [1765/1875], Loss: 1.8725, batch time: 0.10\n",
      "Epoch [4/5], Step [1766/1875], Loss: 1.8666, batch time: 0.11\n",
      "Epoch [4/5], Step [1767/1875], Loss: 2.1783, batch time: 0.10\n",
      "Epoch [4/5], Step [1768/1875], Loss: 1.8857, batch time: 0.10\n",
      "Epoch [4/5], Step [1769/1875], Loss: 1.9975, batch time: 0.13\n",
      "Epoch [4/5], Step [1770/1875], Loss: 1.9246, batch time: 0.12\n",
      "Epoch [4/5], Step [1771/1875], Loss: 1.9211, batch time: 0.12\n",
      "Epoch [4/5], Step [1772/1875], Loss: 1.9960, batch time: 0.10\n",
      "Epoch [4/5], Step [1773/1875], Loss: 2.1259, batch time: 0.13\n",
      "Epoch [4/5], Step [1774/1875], Loss: 2.0569, batch time: 0.10\n",
      "Epoch [4/5], Step [1775/1875], Loss: 2.0857, batch time: 0.12\n",
      "Epoch [4/5], Step [1776/1875], Loss: 1.7553, batch time: 0.11\n",
      "Epoch [4/5], Step [1777/1875], Loss: 2.0865, batch time: 0.16\n",
      "Epoch [4/5], Step [1778/1875], Loss: 2.0660, batch time: 0.17\n",
      "Epoch [4/5], Step [1779/1875], Loss: 1.7724, batch time: 0.12\n",
      "Epoch [4/5], Step [1780/1875], Loss: 1.9598, batch time: 0.11\n",
      "Epoch [4/5], Step [1781/1875], Loss: 2.0226, batch time: 0.15\n",
      "Epoch [4/5], Step [1782/1875], Loss: 1.8867, batch time: 0.14\n",
      "Epoch [4/5], Step [1783/1875], Loss: 1.8174, batch time: 0.11\n",
      "Epoch [4/5], Step [1784/1875], Loss: 2.1290, batch time: 0.14\n",
      "Epoch [4/5], Step [1785/1875], Loss: 1.8830, batch time: 0.12\n",
      "Epoch [4/5], Step [1786/1875], Loss: 1.9509, batch time: 0.15\n",
      "Epoch [4/5], Step [1787/1875], Loss: 1.9348, batch time: 0.13\n",
      "Epoch [4/5], Step [1788/1875], Loss: 1.9696, batch time: 0.13\n",
      "Epoch [4/5], Step [1789/1875], Loss: 1.7559, batch time: 0.13\n",
      "Epoch [4/5], Step [1790/1875], Loss: 1.8682, batch time: 0.10\n",
      "Epoch [4/5], Step [1791/1875], Loss: 1.9364, batch time: 0.10\n",
      "Epoch [4/5], Step [1792/1875], Loss: 2.0438, batch time: 0.15\n",
      "Epoch [4/5], Step [1793/1875], Loss: 2.0528, batch time: 0.11\n",
      "Epoch [4/5], Step [1794/1875], Loss: 2.1875, batch time: 0.13\n",
      "Epoch [4/5], Step [1795/1875], Loss: 1.9005, batch time: 0.10\n",
      "Epoch [4/5], Step [1796/1875], Loss: 1.9748, batch time: 0.10\n",
      "Epoch [4/5], Step [1797/1875], Loss: 2.0431, batch time: 0.10\n",
      "Epoch [4/5], Step [1798/1875], Loss: 2.1108, batch time: 0.13\n",
      "Epoch [4/5], Step [1799/1875], Loss: 1.9186, batch time: 0.10\n",
      "Epoch [4/5], Step [1800/1875], Loss: 1.8694, batch time: 0.12\n",
      "Epoch [4/5], Step [1801/1875], Loss: 2.1370, batch time: 0.12\n",
      "Epoch [4/5], Step [1802/1875], Loss: 1.9334, batch time: 0.10\n",
      "Epoch [4/5], Step [1803/1875], Loss: 2.1822, batch time: 0.10\n",
      "Epoch [4/5], Step [1804/1875], Loss: 2.0084, batch time: 0.12\n",
      "Epoch [4/5], Step [1805/1875], Loss: 2.2068, batch time: 0.10\n",
      "Epoch [4/5], Step [1806/1875], Loss: 2.0613, batch time: 0.16\n",
      "Epoch [4/5], Step [1807/1875], Loss: 2.0518, batch time: 0.11\n",
      "Epoch [4/5], Step [1808/1875], Loss: 2.0043, batch time: 0.11\n",
      "Epoch [4/5], Step [1809/1875], Loss: 2.1071, batch time: 0.21\n",
      "Epoch [4/5], Step [1810/1875], Loss: 1.9634, batch time: 0.10\n",
      "Epoch [4/5], Step [1811/1875], Loss: 1.8761, batch time: 0.10\n",
      "Epoch [4/5], Step [1812/1875], Loss: 2.0790, batch time: 0.14\n",
      "Epoch [4/5], Step [1813/1875], Loss: 2.0146, batch time: 0.12\n",
      "Epoch [4/5], Step [1814/1875], Loss: 2.2469, batch time: 0.10\n",
      "Epoch [4/5], Step [1815/1875], Loss: 1.7726, batch time: 0.11\n",
      "Epoch [4/5], Step [1816/1875], Loss: 1.9327, batch time: 0.14\n",
      "Epoch [4/5], Step [1817/1875], Loss: 2.1031, batch time: 0.10\n",
      "Epoch [4/5], Step [1818/1875], Loss: 2.1603, batch time: 0.14\n",
      "Epoch [4/5], Step [1819/1875], Loss: 2.0921, batch time: 0.10\n",
      "Epoch [4/5], Step [1820/1875], Loss: 2.1003, batch time: 0.11\n",
      "Epoch [4/5], Step [1821/1875], Loss: 1.8798, batch time: 0.10\n",
      "Epoch [4/5], Step [1822/1875], Loss: 2.1372, batch time: 0.10\n",
      "Epoch [4/5], Step [1823/1875], Loss: 2.1635, batch time: 0.10\n",
      "Epoch [4/5], Step [1824/1875], Loss: 1.8621, batch time: 0.10\n",
      "Epoch [4/5], Step [1825/1875], Loss: 1.9882, batch time: 0.10\n",
      "Epoch [4/5], Step [1826/1875], Loss: 1.9920, batch time: 0.10\n",
      "Epoch [4/5], Step [1827/1875], Loss: 1.7367, batch time: 0.10\n",
      "Epoch [4/5], Step [1828/1875], Loss: 1.8013, batch time: 0.10\n",
      "Epoch [4/5], Step [1829/1875], Loss: 2.1350, batch time: 0.10\n",
      "Epoch [4/5], Step [1830/1875], Loss: 1.9598, batch time: 0.19\n",
      "Epoch [4/5], Step [1831/1875], Loss: 1.9384, batch time: 0.12\n",
      "Epoch [4/5], Step [1832/1875], Loss: 2.0046, batch time: 0.10\n",
      "Epoch [4/5], Step [1833/1875], Loss: 2.0887, batch time: 0.10\n",
      "Epoch [4/5], Step [1834/1875], Loss: 2.1257, batch time: 0.10\n",
      "Epoch [4/5], Step [1835/1875], Loss: 2.0475, batch time: 0.10\n",
      "Epoch [4/5], Step [1836/1875], Loss: 2.2082, batch time: 0.18\n",
      "Epoch [4/5], Step [1837/1875], Loss: 1.6626, batch time: 0.12\n",
      "Epoch [4/5], Step [1838/1875], Loss: 1.9028, batch time: 0.11\n",
      "Epoch [4/5], Step [1839/1875], Loss: 2.1491, batch time: 0.10\n",
      "Epoch [4/5], Step [1840/1875], Loss: 1.9007, batch time: 0.12\n",
      "Epoch [4/5], Step [1841/1875], Loss: 1.8758, batch time: 0.10\n",
      "Epoch [4/5], Step [1842/1875], Loss: 1.8021, batch time: 0.10\n",
      "Epoch [4/5], Step [1843/1875], Loss: 1.8664, batch time: 0.16\n",
      "Epoch [4/5], Step [1844/1875], Loss: 1.9644, batch time: 0.10\n",
      "Epoch [4/5], Step [1845/1875], Loss: 2.1688, batch time: 0.10\n",
      "Epoch [4/5], Step [1846/1875], Loss: 2.1681, batch time: 0.12\n",
      "Epoch [4/5], Step [1847/1875], Loss: 1.8337, batch time: 0.10\n",
      "Epoch [4/5], Step [1848/1875], Loss: 1.9879, batch time: 0.14\n",
      "Epoch [4/5], Step [1849/1875], Loss: 2.0033, batch time: 0.13\n",
      "Epoch [4/5], Step [1850/1875], Loss: 2.0542, batch time: 0.14\n",
      "Epoch [4/5], Step [1851/1875], Loss: 2.1904, batch time: 0.10\n",
      "Epoch [4/5], Step [1852/1875], Loss: 2.1146, batch time: 0.12\n",
      "Epoch [4/5], Step [1853/1875], Loss: 1.9046, batch time: 0.10\n",
      "Epoch [4/5], Step [1854/1875], Loss: 1.8810, batch time: -2.80\n",
      "Epoch [4/5], Step [1855/1875], Loss: 1.8779, batch time: 0.13\n",
      "Epoch [4/5], Step [1856/1875], Loss: 1.8515, batch time: 0.20\n",
      "Epoch [4/5], Step [1857/1875], Loss: 2.1555, batch time: 0.11\n",
      "Epoch [4/5], Step [1858/1875], Loss: 1.9718, batch time: 0.16\n",
      "Epoch [4/5], Step [1859/1875], Loss: 2.2357, batch time: 0.10\n",
      "Epoch [4/5], Step [1860/1875], Loss: 1.9072, batch time: 0.10\n",
      "Epoch [4/5], Step [1861/1875], Loss: 1.9424, batch time: 0.10\n",
      "Epoch [4/5], Step [1862/1875], Loss: 1.9698, batch time: 0.10\n",
      "Epoch [4/5], Step [1863/1875], Loss: 2.1139, batch time: 0.10\n",
      "Epoch [4/5], Step [1864/1875], Loss: 2.0747, batch time: 0.10\n",
      "Epoch [4/5], Step [1865/1875], Loss: 1.9408, batch time: 0.10\n",
      "Epoch [4/5], Step [1866/1875], Loss: 2.0060, batch time: 0.11\n",
      "Epoch [4/5], Step [1867/1875], Loss: 1.9109, batch time: 0.10\n",
      "Epoch [4/5], Step [1868/1875], Loss: 2.0005, batch time: 0.19\n",
      "Epoch [4/5], Step [1869/1875], Loss: 2.3425, batch time: 0.11\n",
      "Epoch [4/5], Step [1870/1875], Loss: 1.8873, batch time: 0.11\n",
      "Epoch [4/5], Step [1871/1875], Loss: 2.1800, batch time: 0.14\n",
      "Epoch [4/5], Step [1872/1875], Loss: 1.9376, batch time: 0.14\n",
      "Epoch [4/5], Step [1873/1875], Loss: 1.8819, batch time: 0.19\n",
      "Epoch [4/5], Step [1874/1875], Loss: 1.8750, batch time: 0.18\n",
      "Epoch [4/5], Step [1875/1875], Loss: 1.9186, batch time: 0.11\n",
      "Epoch [4/5] Accuracy: 23.77%\n",
      "Epoch [5/5], Step [1/1875], Loss: 2.0414, batch time: 0.12\n",
      "Epoch [5/5], Step [2/1875], Loss: 2.0600, batch time: 0.14\n",
      "Epoch [5/5], Step [3/1875], Loss: 2.0875, batch time: 0.14\n",
      "Epoch [5/5], Step [4/1875], Loss: 1.9789, batch time: 0.14\n",
      "Epoch [5/5], Step [5/1875], Loss: 1.9758, batch time: 0.11\n",
      "Epoch [5/5], Step [6/1875], Loss: 1.9021, batch time: 0.13\n",
      "Epoch [5/5], Step [7/1875], Loss: 2.1397, batch time: 0.13\n",
      "Epoch [5/5], Step [8/1875], Loss: 1.8996, batch time: 0.14\n",
      "Epoch [5/5], Step [9/1875], Loss: 1.9569, batch time: 0.11\n",
      "Epoch [5/5], Step [10/1875], Loss: 1.9593, batch time: 0.12\n",
      "Epoch [5/5], Step [11/1875], Loss: 2.0180, batch time: 0.13\n",
      "Epoch [5/5], Step [12/1875], Loss: 1.8349, batch time: 0.10\n",
      "Epoch [5/5], Step [13/1875], Loss: 1.7122, batch time: 0.12\n",
      "Epoch [5/5], Step [14/1875], Loss: 1.9630, batch time: 0.14\n",
      "Epoch [5/5], Step [15/1875], Loss: 2.1367, batch time: 0.10\n",
      "Epoch [5/5], Step [16/1875], Loss: 1.8913, batch time: 0.11\n",
      "Epoch [5/5], Step [17/1875], Loss: 1.8251, batch time: 0.12\n",
      "Epoch [5/5], Step [18/1875], Loss: 2.1570, batch time: 0.25\n",
      "Epoch [5/5], Step [19/1875], Loss: 1.8352, batch time: 0.15\n",
      "Epoch [5/5], Step [20/1875], Loss: 1.9602, batch time: 0.14\n",
      "Epoch [5/5], Step [21/1875], Loss: 1.7827, batch time: 0.19\n",
      "Epoch [5/5], Step [22/1875], Loss: 1.9692, batch time: 0.19\n",
      "Epoch [5/5], Step [23/1875], Loss: 1.9293, batch time: 0.19\n",
      "Epoch [5/5], Step [24/1875], Loss: 2.1310, batch time: 0.20\n",
      "Epoch [5/5], Step [25/1875], Loss: 2.0722, batch time: 0.17\n",
      "Epoch [5/5], Step [26/1875], Loss: 1.8396, batch time: 0.14\n",
      "Epoch [5/5], Step [27/1875], Loss: 1.8555, batch time: 0.12\n",
      "Epoch [5/5], Step [28/1875], Loss: 2.2086, batch time: 0.11\n",
      "Epoch [5/5], Step [29/1875], Loss: 1.9965, batch time: 0.11\n",
      "Epoch [5/5], Step [30/1875], Loss: 1.8086, batch time: 0.14\n",
      "Epoch [5/5], Step [31/1875], Loss: 2.1263, batch time: 0.10\n",
      "Epoch [5/5], Step [32/1875], Loss: 1.8842, batch time: 0.16\n",
      "Epoch [5/5], Step [33/1875], Loss: 1.9532, batch time: 0.10\n",
      "Epoch [5/5], Step [34/1875], Loss: 2.2914, batch time: 0.11\n",
      "Epoch [5/5], Step [35/1875], Loss: 2.1059, batch time: 0.10\n",
      "Epoch [5/5], Step [36/1875], Loss: 2.0248, batch time: 0.10\n",
      "Epoch [5/5], Step [37/1875], Loss: 1.8789, batch time: 0.14\n",
      "Epoch [5/5], Step [38/1875], Loss: 1.9706, batch time: 0.12\n",
      "Epoch [5/5], Step [39/1875], Loss: 2.1307, batch time: 0.14\n",
      "Epoch [5/5], Step [40/1875], Loss: 2.1324, batch time: 0.14\n",
      "Epoch [5/5], Step [41/1875], Loss: 2.0817, batch time: 0.14\n",
      "Epoch [5/5], Step [42/1875], Loss: 1.9892, batch time: 0.18\n",
      "Epoch [5/5], Step [43/1875], Loss: 2.0473, batch time: 0.12\n",
      "Epoch [5/5], Step [44/1875], Loss: 1.9857, batch time: 0.13\n",
      "Epoch [5/5], Step [45/1875], Loss: 1.9529, batch time: 0.13\n",
      "Epoch [5/5], Step [46/1875], Loss: 1.9734, batch time: 0.10\n",
      "Epoch [5/5], Step [47/1875], Loss: 1.9963, batch time: 0.12\n",
      "Epoch [5/5], Step [48/1875], Loss: 1.9834, batch time: 0.12\n",
      "Epoch [5/5], Step [49/1875], Loss: 1.7312, batch time: 0.10\n",
      "Epoch [5/5], Step [50/1875], Loss: 2.0091, batch time: 0.11\n",
      "Epoch [5/5], Step [51/1875], Loss: 2.2339, batch time: 0.10\n",
      "Epoch [5/5], Step [52/1875], Loss: 1.8471, batch time: 0.12\n",
      "Epoch [5/5], Step [53/1875], Loss: 1.9471, batch time: 0.10\n",
      "Epoch [5/5], Step [54/1875], Loss: 1.9574, batch time: 0.10\n",
      "Epoch [5/5], Step [55/1875], Loss: 1.8837, batch time: 0.10\n",
      "Epoch [5/5], Step [56/1875], Loss: 1.9314, batch time: 0.15\n",
      "Epoch [5/5], Step [57/1875], Loss: 2.0720, batch time: 0.11\n",
      "Epoch [5/5], Step [58/1875], Loss: 2.1424, batch time: 0.13\n",
      "Epoch [5/5], Step [59/1875], Loss: 2.0741, batch time: 0.12\n",
      "Epoch [5/5], Step [60/1875], Loss: 1.9451, batch time: 0.10\n",
      "Epoch [5/5], Step [61/1875], Loss: 1.9493, batch time: 0.16\n",
      "Epoch [5/5], Step [62/1875], Loss: 2.0142, batch time: 0.11\n",
      "Epoch [5/5], Step [63/1875], Loss: 2.0284, batch time: 0.11\n",
      "Epoch [5/5], Step [64/1875], Loss: 2.0732, batch time: 0.13\n",
      "Epoch [5/5], Step [65/1875], Loss: 1.9528, batch time: 0.23\n",
      "Epoch [5/5], Step [66/1875], Loss: 1.9766, batch time: 0.13\n",
      "Epoch [5/5], Step [67/1875], Loss: 2.0563, batch time: 0.10\n",
      "Epoch [5/5], Step [68/1875], Loss: 1.7612, batch time: 0.10\n",
      "Epoch [5/5], Step [69/1875], Loss: 1.9900, batch time: 0.10\n",
      "Epoch [5/5], Step [70/1875], Loss: 2.0681, batch time: 0.11\n",
      "Epoch [5/5], Step [71/1875], Loss: 1.8954, batch time: 0.12\n",
      "Epoch [5/5], Step [72/1875], Loss: 1.9449, batch time: 0.11\n",
      "Epoch [5/5], Step [73/1875], Loss: 2.0447, batch time: 0.10\n",
      "Epoch [5/5], Step [74/1875], Loss: 2.0129, batch time: 0.12\n",
      "Epoch [5/5], Step [75/1875], Loss: 1.7473, batch time: 0.10\n",
      "Epoch [5/5], Step [76/1875], Loss: 1.9665, batch time: 0.10\n",
      "Epoch [5/5], Step [77/1875], Loss: 1.8896, batch time: 0.11\n",
      "Epoch [5/5], Step [78/1875], Loss: 2.0923, batch time: 0.10\n",
      "Epoch [5/5], Step [79/1875], Loss: 2.1208, batch time: 0.11\n",
      "Epoch [5/5], Step [80/1875], Loss: 2.1457, batch time: 0.12\n",
      "Epoch [5/5], Step [81/1875], Loss: 2.0202, batch time: 0.13\n",
      "Epoch [5/5], Step [82/1875], Loss: 2.0994, batch time: 0.10\n",
      "Epoch [5/5], Step [83/1875], Loss: 1.9214, batch time: 0.12\n",
      "Epoch [5/5], Step [84/1875], Loss: 1.9429, batch time: 0.10\n",
      "Epoch [5/5], Step [85/1875], Loss: 2.1034, batch time: 0.10\n",
      "Epoch [5/5], Step [86/1875], Loss: 1.5543, batch time: 0.13\n",
      "Epoch [5/5], Step [87/1875], Loss: 1.9252, batch time: 0.17\n",
      "Epoch [5/5], Step [88/1875], Loss: 2.2985, batch time: 0.13\n",
      "Epoch [5/5], Step [89/1875], Loss: 1.9805, batch time: 0.10\n",
      "Epoch [5/5], Step [90/1875], Loss: 2.1510, batch time: 0.10\n",
      "Epoch [5/5], Step [91/1875], Loss: 1.9862, batch time: 0.11\n",
      "Epoch [5/5], Step [92/1875], Loss: 1.8370, batch time: 0.10\n",
      "Epoch [5/5], Step [93/1875], Loss: 1.9897, batch time: 0.10\n",
      "Epoch [5/5], Step [94/1875], Loss: 1.8701, batch time: 0.11\n",
      "Epoch [5/5], Step [95/1875], Loss: 2.1355, batch time: 0.10\n",
      "Epoch [5/5], Step [96/1875], Loss: 1.9326, batch time: 0.10\n",
      "Epoch [5/5], Step [97/1875], Loss: 2.1158, batch time: 0.10\n",
      "Epoch [5/5], Step [98/1875], Loss: 2.1143, batch time: 0.10\n",
      "Epoch [5/5], Step [99/1875], Loss: 2.0142, batch time: 0.11\n",
      "Epoch [5/5], Step [100/1875], Loss: 2.1265, batch time: 0.11\n",
      "Epoch [5/5], Step [101/1875], Loss: 1.9607, batch time: 0.13\n",
      "Epoch [5/5], Step [102/1875], Loss: 1.7012, batch time: 0.13\n",
      "Epoch [5/5], Step [103/1875], Loss: 1.8987, batch time: 0.12\n",
      "Epoch [5/5], Step [104/1875], Loss: 2.0325, batch time: 0.12\n",
      "Epoch [5/5], Step [105/1875], Loss: 1.8724, batch time: 0.13\n",
      "Epoch [5/5], Step [106/1875], Loss: 1.9977, batch time: 0.12\n",
      "Epoch [5/5], Step [107/1875], Loss: 1.8826, batch time: 0.10\n",
      "Epoch [5/5], Step [108/1875], Loss: 1.9857, batch time: 0.14\n",
      "Epoch [5/5], Step [109/1875], Loss: 2.1186, batch time: 0.11\n",
      "Epoch [5/5], Step [110/1875], Loss: 1.9528, batch time: 0.12\n",
      "Epoch [5/5], Step [111/1875], Loss: 1.9383, batch time: 0.13\n",
      "Epoch [5/5], Step [112/1875], Loss: 2.0263, batch time: 0.13\n",
      "Epoch [5/5], Step [113/1875], Loss: 1.9979, batch time: 0.10\n",
      "Epoch [5/5], Step [114/1875], Loss: 1.7226, batch time: 0.15\n",
      "Epoch [5/5], Step [115/1875], Loss: 1.9719, batch time: 0.10\n",
      "Epoch [5/5], Step [116/1875], Loss: 2.0570, batch time: 0.10\n",
      "Epoch [5/5], Step [117/1875], Loss: 1.9277, batch time: 0.10\n",
      "Epoch [5/5], Step [118/1875], Loss: 1.8738, batch time: 0.10\n",
      "Epoch [5/5], Step [119/1875], Loss: 1.8204, batch time: 0.10\n",
      "Epoch [5/5], Step [120/1875], Loss: 2.0788, batch time: 0.10\n",
      "Epoch [5/5], Step [121/1875], Loss: 2.1180, batch time: 0.12\n",
      "Epoch [5/5], Step [122/1875], Loss: 1.8297, batch time: 0.10\n",
      "Epoch [5/5], Step [123/1875], Loss: 2.0383, batch time: 0.10\n",
      "Epoch [5/5], Step [124/1875], Loss: 1.8863, batch time: 0.10\n",
      "Epoch [5/5], Step [125/1875], Loss: 2.0524, batch time: 0.10\n",
      "Epoch [5/5], Step [126/1875], Loss: 2.2783, batch time: 0.10\n",
      "Epoch [5/5], Step [127/1875], Loss: 2.2601, batch time: 0.13\n",
      "Epoch [5/5], Step [128/1875], Loss: 2.1651, batch time: 0.12\n",
      "Epoch [5/5], Step [129/1875], Loss: 2.0771, batch time: 0.14\n",
      "Epoch [5/5], Step [130/1875], Loss: 2.0550, batch time: 0.11\n",
      "Epoch [5/5], Step [131/1875], Loss: 2.2331, batch time: 0.10\n",
      "Epoch [5/5], Step [132/1875], Loss: 1.8415, batch time: 0.12\n",
      "Epoch [5/5], Step [133/1875], Loss: 2.1288, batch time: 0.10\n",
      "Epoch [5/5], Step [134/1875], Loss: 2.0121, batch time: 0.13\n",
      "Epoch [5/5], Step [135/1875], Loss: 1.8262, batch time: 0.16\n",
      "Epoch [5/5], Step [136/1875], Loss: 1.8542, batch time: 0.14\n",
      "Epoch [5/5], Step [137/1875], Loss: 1.8673, batch time: 0.14\n",
      "Epoch [5/5], Step [138/1875], Loss: 1.7476, batch time: 0.10\n",
      "Epoch [5/5], Step [139/1875], Loss: 1.8707, batch time: 0.11\n",
      "Epoch [5/5], Step [140/1875], Loss: 1.9379, batch time: 0.12\n",
      "Epoch [5/5], Step [141/1875], Loss: 1.9115, batch time: 0.10\n",
      "Epoch [5/5], Step [142/1875], Loss: 2.0388, batch time: 0.13\n",
      "Epoch [5/5], Step [143/1875], Loss: 1.9679, batch time: 0.10\n",
      "Epoch [5/5], Step [144/1875], Loss: 2.0293, batch time: 0.19\n",
      "Epoch [5/5], Step [145/1875], Loss: 2.0164, batch time: 0.14\n",
      "Epoch [5/5], Step [146/1875], Loss: 1.7466, batch time: 0.22\n",
      "Epoch [5/5], Step [147/1875], Loss: 1.9061, batch time: 0.11\n",
      "Epoch [5/5], Step [148/1875], Loss: 2.0460, batch time: 0.10\n",
      "Epoch [5/5], Step [149/1875], Loss: 1.9754, batch time: 0.14\n",
      "Epoch [5/5], Step [150/1875], Loss: 2.1546, batch time: 0.10\n",
      "Epoch [5/5], Step [151/1875], Loss: 1.9131, batch time: 0.10\n",
      "Epoch [5/5], Step [152/1875], Loss: 1.8899, batch time: 0.10\n",
      "Epoch [5/5], Step [153/1875], Loss: 1.8985, batch time: 0.11\n",
      "Epoch [5/5], Step [154/1875], Loss: 2.1597, batch time: 0.20\n",
      "Epoch [5/5], Step [155/1875], Loss: 1.9313, batch time: 0.10\n",
      "Epoch [5/5], Step [156/1875], Loss: 2.0982, batch time: 0.10\n",
      "Epoch [5/5], Step [157/1875], Loss: 2.0106, batch time: 0.11\n",
      "Epoch [5/5], Step [158/1875], Loss: 2.0377, batch time: 0.13\n",
      "Epoch [5/5], Step [159/1875], Loss: 1.8886, batch time: 0.10\n",
      "Epoch [5/5], Step [160/1875], Loss: 1.9839, batch time: 0.10\n",
      "Epoch [5/5], Step [161/1875], Loss: 2.0739, batch time: 0.12\n",
      "Epoch [5/5], Step [162/1875], Loss: 1.9476, batch time: 0.12\n",
      "Epoch [5/5], Step [163/1875], Loss: 1.9634, batch time: 0.10\n",
      "Epoch [5/5], Step [164/1875], Loss: 1.9604, batch time: 0.19\n",
      "Epoch [5/5], Step [165/1875], Loss: 1.9708, batch time: 0.11\n",
      "Epoch [5/5], Step [166/1875], Loss: 2.2530, batch time: 0.10\n",
      "Epoch [5/5], Step [167/1875], Loss: 2.0367, batch time: 0.15\n",
      "Epoch [5/5], Step [168/1875], Loss: 1.8944, batch time: 0.13\n",
      "Epoch [5/5], Step [169/1875], Loss: 1.8814, batch time: 0.10\n",
      "Epoch [5/5], Step [170/1875], Loss: 1.8622, batch time: 0.10\n",
      "Epoch [5/5], Step [171/1875], Loss: 1.8487, batch time: 0.11\n",
      "Epoch [5/5], Step [172/1875], Loss: 1.7364, batch time: 0.11\n",
      "Epoch [5/5], Step [173/1875], Loss: 2.1082, batch time: 0.13\n",
      "Epoch [5/5], Step [174/1875], Loss: 1.8757, batch time: 0.11\n",
      "Epoch [5/5], Step [175/1875], Loss: 1.8355, batch time: 0.10\n",
      "Epoch [5/5], Step [176/1875], Loss: 2.0208, batch time: 0.10\n",
      "Epoch [5/5], Step [177/1875], Loss: 1.9352, batch time: 0.11\n",
      "Epoch [5/5], Step [178/1875], Loss: 2.0452, batch time: 0.10\n",
      "Epoch [5/5], Step [179/1875], Loss: 2.0110, batch time: 0.11\n",
      "Epoch [5/5], Step [180/1875], Loss: 1.6877, batch time: 0.10\n",
      "Epoch [5/5], Step [181/1875], Loss: 2.0261, batch time: 0.10\n",
      "Epoch [5/5], Step [182/1875], Loss: 2.0313, batch time: 0.13\n",
      "Epoch [5/5], Step [183/1875], Loss: 2.0515, batch time: 0.14\n",
      "Epoch [5/5], Step [184/1875], Loss: 2.1963, batch time: 0.12\n",
      "Epoch [5/5], Step [185/1875], Loss: 1.7986, batch time: 0.16\n",
      "Epoch [5/5], Step [186/1875], Loss: 1.8732, batch time: 0.10\n",
      "Epoch [5/5], Step [187/1875], Loss: 1.7982, batch time: 0.10\n",
      "Epoch [5/5], Step [188/1875], Loss: 2.0517, batch time: 0.12\n",
      "Epoch [5/5], Step [189/1875], Loss: 1.9412, batch time: 0.12\n",
      "Epoch [5/5], Step [190/1875], Loss: 1.9974, batch time: 0.10\n",
      "Epoch [5/5], Step [191/1875], Loss: 1.8322, batch time: 0.10\n",
      "Epoch [5/5], Step [192/1875], Loss: 2.1051, batch time: 0.10\n",
      "Epoch [5/5], Step [193/1875], Loss: 2.1214, batch time: 0.11\n",
      "Epoch [5/5], Step [194/1875], Loss: 1.9584, batch time: 0.10\n",
      "Epoch [5/5], Step [195/1875], Loss: 2.0508, batch time: 0.11\n",
      "Epoch [5/5], Step [196/1875], Loss: 1.9667, batch time: 0.16\n",
      "Epoch [5/5], Step [197/1875], Loss: 1.8292, batch time: 0.10\n",
      "Epoch [5/5], Step [198/1875], Loss: 1.8694, batch time: 0.10\n",
      "Epoch [5/5], Step [199/1875], Loss: 2.0872, batch time: 0.10\n",
      "Epoch [5/5], Step [200/1875], Loss: 2.0322, batch time: 0.10\n",
      "Epoch [5/5], Step [201/1875], Loss: 1.8778, batch time: 0.10\n",
      "Epoch [5/5], Step [202/1875], Loss: 1.9387, batch time: 0.10\n",
      "Epoch [5/5], Step [203/1875], Loss: 1.9500, batch time: 0.10\n",
      "Epoch [5/5], Step [204/1875], Loss: 2.0394, batch time: 0.11\n",
      "Epoch [5/5], Step [205/1875], Loss: 2.0405, batch time: 0.10\n",
      "Epoch [5/5], Step [206/1875], Loss: 1.9584, batch time: 0.10\n",
      "Epoch [5/5], Step [207/1875], Loss: 2.0153, batch time: 0.10\n",
      "Epoch [5/5], Step [208/1875], Loss: 1.8503, batch time: 0.10\n",
      "Epoch [5/5], Step [209/1875], Loss: 1.8928, batch time: 0.15\n",
      "Epoch [5/5], Step [210/1875], Loss: 1.8911, batch time: 0.18\n",
      "Epoch [5/5], Step [211/1875], Loss: 2.2190, batch time: 0.10\n",
      "Epoch [5/5], Step [212/1875], Loss: 2.1401, batch time: 0.11\n",
      "Epoch [5/5], Step [213/1875], Loss: 1.9074, batch time: 0.12\n",
      "Epoch [5/5], Step [214/1875], Loss: 1.9137, batch time: 0.10\n",
      "Epoch [5/5], Step [215/1875], Loss: 1.9345, batch time: 0.10\n",
      "Epoch [5/5], Step [216/1875], Loss: 1.9163, batch time: 0.10\n",
      "Epoch [5/5], Step [217/1875], Loss: 1.8513, batch time: 0.10\n",
      "Epoch [5/5], Step [218/1875], Loss: 1.7466, batch time: 0.14\n",
      "Epoch [5/5], Step [219/1875], Loss: 1.9248, batch time: 0.10\n",
      "Epoch [5/5], Step [220/1875], Loss: 1.8117, batch time: 0.11\n",
      "Epoch [5/5], Step [221/1875], Loss: 2.1186, batch time: 0.10\n",
      "Epoch [5/5], Step [222/1875], Loss: 2.1646, batch time: 0.11\n",
      "Epoch [5/5], Step [223/1875], Loss: 1.9664, batch time: 0.10\n",
      "Epoch [5/5], Step [224/1875], Loss: 1.9333, batch time: 0.10\n",
      "Epoch [5/5], Step [225/1875], Loss: 2.0108, batch time: 0.10\n",
      "Epoch [5/5], Step [226/1875], Loss: 1.7007, batch time: 0.11\n",
      "Epoch [5/5], Step [227/1875], Loss: 1.7767, batch time: 0.16\n",
      "Epoch [5/5], Step [228/1875], Loss: 2.0242, batch time: 0.10\n",
      "Epoch [5/5], Step [229/1875], Loss: 1.9278, batch time: 0.10\n",
      "Epoch [5/5], Step [230/1875], Loss: 1.9600, batch time: 0.11\n",
      "Epoch [5/5], Step [231/1875], Loss: 2.1096, batch time: 0.10\n",
      "Epoch [5/5], Step [232/1875], Loss: 2.1039, batch time: 0.10\n",
      "Epoch [5/5], Step [233/1875], Loss: 2.0300, batch time: 0.10\n",
      "Epoch [5/5], Step [234/1875], Loss: 1.9615, batch time: 0.14\n",
      "Epoch [5/5], Step [235/1875], Loss: 2.1051, batch time: 0.12\n",
      "Epoch [5/5], Step [236/1875], Loss: 1.7751, batch time: 0.10\n",
      "Epoch [5/5], Step [237/1875], Loss: 1.9634, batch time: 0.13\n",
      "Epoch [5/5], Step [238/1875], Loss: 2.1583, batch time: 0.18\n",
      "Epoch [5/5], Step [239/1875], Loss: 1.9487, batch time: 0.13\n",
      "Epoch [5/5], Step [240/1875], Loss: 1.9864, batch time: 0.14\n",
      "Epoch [5/5], Step [241/1875], Loss: 1.9071, batch time: 0.10\n",
      "Epoch [5/5], Step [242/1875], Loss: 2.0462, batch time: 0.10\n",
      "Epoch [5/5], Step [243/1875], Loss: 2.2536, batch time: 0.14\n",
      "Epoch [5/5], Step [244/1875], Loss: 2.1019, batch time: 0.18\n",
      "Epoch [5/5], Step [245/1875], Loss: 1.9160, batch time: -2.84\n",
      "Epoch [5/5], Step [246/1875], Loss: 2.0456, batch time: 0.10\n",
      "Epoch [5/5], Step [247/1875], Loss: 1.9203, batch time: 0.10\n",
      "Epoch [5/5], Step [248/1875], Loss: 1.8888, batch time: 0.10\n",
      "Epoch [5/5], Step [249/1875], Loss: 1.9381, batch time: 0.14\n",
      "Epoch [5/5], Step [250/1875], Loss: 2.0121, batch time: 0.13\n",
      "Epoch [5/5], Step [251/1875], Loss: 2.0924, batch time: 0.12\n",
      "Epoch [5/5], Step [252/1875], Loss: 1.8806, batch time: 0.10\n",
      "Epoch [5/5], Step [253/1875], Loss: 1.9529, batch time: 0.11\n",
      "Epoch [5/5], Step [254/1875], Loss: 2.1548, batch time: 0.10\n",
      "Epoch [5/5], Step [255/1875], Loss: 2.0156, batch time: 0.12\n",
      "Epoch [5/5], Step [256/1875], Loss: 1.7436, batch time: 0.10\n",
      "Epoch [5/5], Step [257/1875], Loss: 2.0253, batch time: 0.10\n",
      "Epoch [5/5], Step [258/1875], Loss: 1.8958, batch time: 0.10\n",
      "Epoch [5/5], Step [259/1875], Loss: 1.8634, batch time: 0.10\n",
      "Epoch [5/5], Step [260/1875], Loss: 1.8510, batch time: 0.20\n",
      "Epoch [5/5], Step [261/1875], Loss: 1.9990, batch time: 0.10\n",
      "Epoch [5/5], Step [262/1875], Loss: 2.1298, batch time: 0.10\n",
      "Epoch [5/5], Step [263/1875], Loss: 1.9983, batch time: 0.10\n",
      "Epoch [5/5], Step [264/1875], Loss: 1.7740, batch time: 0.10\n",
      "Epoch [5/5], Step [265/1875], Loss: 1.9817, batch time: 0.11\n",
      "Epoch [5/5], Step [266/1875], Loss: 2.0028, batch time: 0.11\n",
      "Epoch [5/5], Step [267/1875], Loss: 1.7325, batch time: 0.14\n",
      "Epoch [5/5], Step [268/1875], Loss: 1.8663, batch time: 0.13\n",
      "Epoch [5/5], Step [269/1875], Loss: 2.1472, batch time: 0.10\n",
      "Epoch [5/5], Step [270/1875], Loss: 2.1140, batch time: 0.14\n",
      "Epoch [5/5], Step [271/1875], Loss: 1.8557, batch time: 0.13\n",
      "Epoch [5/5], Step [272/1875], Loss: 1.9257, batch time: 0.11\n",
      "Epoch [5/5], Step [273/1875], Loss: 1.7694, batch time: 0.10\n",
      "Epoch [5/5], Step [274/1875], Loss: 1.8671, batch time: 0.10\n",
      "Epoch [5/5], Step [275/1875], Loss: 1.9011, batch time: 0.14\n",
      "Epoch [5/5], Step [276/1875], Loss: 1.8224, batch time: 0.10\n",
      "Epoch [5/5], Step [277/1875], Loss: 1.9871, batch time: 0.10\n",
      "Epoch [5/5], Step [278/1875], Loss: 2.1195, batch time: 0.16\n",
      "Epoch [5/5], Step [279/1875], Loss: 2.1537, batch time: 0.10\n",
      "Epoch [5/5], Step [280/1875], Loss: 2.0688, batch time: 0.14\n",
      "Epoch [5/5], Step [281/1875], Loss: 2.1741, batch time: 0.10\n",
      "Epoch [5/5], Step [282/1875], Loss: 1.8631, batch time: 0.10\n",
      "Epoch [5/5], Step [283/1875], Loss: 2.0449, batch time: 0.13\n",
      "Epoch [5/5], Step [284/1875], Loss: 2.0974, batch time: 0.12\n",
      "Epoch [5/5], Step [285/1875], Loss: 1.9209, batch time: 0.11\n",
      "Epoch [5/5], Step [286/1875], Loss: 1.9709, batch time: 0.12\n",
      "Epoch [5/5], Step [287/1875], Loss: 2.0809, batch time: 0.19\n",
      "Epoch [5/5], Step [288/1875], Loss: 1.9239, batch time: 0.14\n",
      "Epoch [5/5], Step [289/1875], Loss: 1.9401, batch time: 0.12\n",
      "Epoch [5/5], Step [290/1875], Loss: 1.9157, batch time: 0.17\n",
      "Epoch [5/5], Step [291/1875], Loss: 2.0927, batch time: 0.10\n",
      "Epoch [5/5], Step [292/1875], Loss: 1.6929, batch time: 0.14\n",
      "Epoch [5/5], Step [293/1875], Loss: 2.1177, batch time: 0.13\n",
      "Epoch [5/5], Step [294/1875], Loss: 2.0581, batch time: 0.10\n",
      "Epoch [5/5], Step [295/1875], Loss: 1.9709, batch time: 0.12\n",
      "Epoch [5/5], Step [296/1875], Loss: 2.1422, batch time: 0.11\n",
      "Epoch [5/5], Step [297/1875], Loss: 1.9268, batch time: 0.10\n",
      "Epoch [5/5], Step [298/1875], Loss: 2.3585, batch time: 0.10\n",
      "Epoch [5/5], Step [299/1875], Loss: 1.8799, batch time: 0.14\n",
      "Epoch [5/5], Step [300/1875], Loss: 1.9763, batch time: 0.10\n",
      "Epoch [5/5], Step [301/1875], Loss: 1.9948, batch time: 0.10\n",
      "Epoch [5/5], Step [302/1875], Loss: 1.6673, batch time: 0.11\n",
      "Epoch [5/5], Step [303/1875], Loss: 1.9600, batch time: 0.10\n",
      "Epoch [5/5], Step [304/1875], Loss: 1.8097, batch time: 0.11\n",
      "Epoch [5/5], Step [305/1875], Loss: 2.0024, batch time: 0.10\n",
      "Epoch [5/5], Step [306/1875], Loss: 1.9694, batch time: 0.10\n",
      "Epoch [5/5], Step [307/1875], Loss: 2.0360, batch time: 0.10\n",
      "Epoch [5/5], Step [308/1875], Loss: 1.8986, batch time: 0.10\n",
      "Epoch [5/5], Step [309/1875], Loss: 1.9570, batch time: 0.10\n",
      "Epoch [5/5], Step [310/1875], Loss: 1.9712, batch time: 0.10\n",
      "Epoch [5/5], Step [311/1875], Loss: 1.9125, batch time: 0.10\n",
      "Epoch [5/5], Step [312/1875], Loss: 1.9913, batch time: 0.10\n",
      "Epoch [5/5], Step [313/1875], Loss: 1.8351, batch time: 0.10\n",
      "Epoch [5/5], Step [314/1875], Loss: 2.1243, batch time: 0.12\n",
      "Epoch [5/5], Step [315/1875], Loss: 2.0366, batch time: 0.11\n",
      "Epoch [5/5], Step [316/1875], Loss: 2.1572, batch time: 0.10\n",
      "Epoch [5/5], Step [317/1875], Loss: 1.7086, batch time: 0.10\n",
      "Epoch [5/5], Step [318/1875], Loss: 1.8922, batch time: 0.15\n",
      "Epoch [5/5], Step [319/1875], Loss: 1.9658, batch time: 0.10\n",
      "Epoch [5/5], Step [320/1875], Loss: 2.1035, batch time: 0.13\n",
      "Epoch [5/5], Step [321/1875], Loss: 1.9929, batch time: 0.13\n",
      "Epoch [5/5], Step [322/1875], Loss: 1.9192, batch time: 0.13\n",
      "Epoch [5/5], Step [323/1875], Loss: 1.8177, batch time: 0.11\n",
      "Epoch [5/5], Step [324/1875], Loss: 1.9429, batch time: 0.10\n",
      "Epoch [5/5], Step [325/1875], Loss: 2.0828, batch time: 0.18\n",
      "Epoch [5/5], Step [326/1875], Loss: 1.9369, batch time: 0.10\n",
      "Epoch [5/5], Step [327/1875], Loss: 2.0006, batch time: 0.10\n",
      "Epoch [5/5], Step [328/1875], Loss: 2.0623, batch time: 0.10\n",
      "Epoch [5/5], Step [329/1875], Loss: 1.8105, batch time: 0.10\n",
      "Epoch [5/5], Step [330/1875], Loss: 1.7937, batch time: 0.15\n",
      "Epoch [5/5], Step [331/1875], Loss: 2.2166, batch time: 0.14\n",
      "Epoch [5/5], Step [332/1875], Loss: 1.9077, batch time: 0.14\n",
      "Epoch [5/5], Step [333/1875], Loss: 1.7949, batch time: 0.10\n",
      "Epoch [5/5], Step [334/1875], Loss: 1.9846, batch time: 0.10\n",
      "Epoch [5/5], Step [335/1875], Loss: 1.6604, batch time: 0.09\n",
      "Epoch [5/5], Step [336/1875], Loss: 1.9222, batch time: 0.10\n",
      "Epoch [5/5], Step [337/1875], Loss: 1.7609, batch time: 0.12\n",
      "Epoch [5/5], Step [338/1875], Loss: 2.0424, batch time: 0.13\n",
      "Epoch [5/5], Step [339/1875], Loss: 2.1436, batch time: 0.12\n",
      "Epoch [5/5], Step [340/1875], Loss: 2.0632, batch time: 0.09\n",
      "Epoch [5/5], Step [341/1875], Loss: 1.8909, batch time: 0.10\n",
      "Epoch [5/5], Step [342/1875], Loss: 2.0900, batch time: 0.11\n",
      "Epoch [5/5], Step [343/1875], Loss: 1.9464, batch time: 0.10\n",
      "Epoch [5/5], Step [344/1875], Loss: 2.0494, batch time: 0.13\n",
      "Epoch [5/5], Step [345/1875], Loss: 1.9611, batch time: 0.13\n",
      "Epoch [5/5], Step [346/1875], Loss: 1.8459, batch time: 0.12\n",
      "Epoch [5/5], Step [347/1875], Loss: 1.7903, batch time: 0.13\n",
      "Epoch [5/5], Step [348/1875], Loss: 1.7905, batch time: 0.11\n",
      "Epoch [5/5], Step [349/1875], Loss: 1.8311, batch time: 0.10\n",
      "Epoch [5/5], Step [350/1875], Loss: 1.8953, batch time: 0.09\n",
      "Epoch [5/5], Step [351/1875], Loss: 1.8854, batch time: 0.09\n",
      "Epoch [5/5], Step [352/1875], Loss: 1.8525, batch time: 0.09\n",
      "Epoch [5/5], Step [353/1875], Loss: 1.5839, batch time: 0.10\n",
      "Epoch [5/5], Step [354/1875], Loss: 2.0292, batch time: 0.09\n",
      "Epoch [5/5], Step [355/1875], Loss: 1.7917, batch time: 0.09\n",
      "Epoch [5/5], Step [356/1875], Loss: 1.7830, batch time: 0.09\n",
      "Epoch [5/5], Step [357/1875], Loss: 1.8355, batch time: 0.12\n",
      "Epoch [5/5], Step [358/1875], Loss: 1.9099, batch time: 0.09\n",
      "Epoch [5/5], Step [359/1875], Loss: 1.9542, batch time: 0.09\n",
      "Epoch [5/5], Step [360/1875], Loss: 1.7954, batch time: 0.09\n",
      "Epoch [5/5], Step [361/1875], Loss: 2.0960, batch time: 0.10\n",
      "Epoch [5/5], Step [362/1875], Loss: 1.8945, batch time: 0.09\n",
      "Epoch [5/5], Step [363/1875], Loss: 1.7900, batch time: 0.09\n",
      "Epoch [5/5], Step [364/1875], Loss: 2.0799, batch time: 0.09\n",
      "Epoch [5/5], Step [365/1875], Loss: 2.1615, batch time: 0.09\n",
      "Epoch [5/5], Step [366/1875], Loss: 1.8672, batch time: 0.09\n",
      "Epoch [5/5], Step [367/1875], Loss: 1.9956, batch time: 0.09\n",
      "Epoch [5/5], Step [368/1875], Loss: 1.9405, batch time: 0.09\n",
      "Epoch [5/5], Step [369/1875], Loss: 1.9555, batch time: 0.09\n",
      "Epoch [5/5], Step [370/1875], Loss: 1.8084, batch time: 0.11\n",
      "Epoch [5/5], Step [371/1875], Loss: 2.0381, batch time: 0.09\n",
      "Epoch [5/5], Step [372/1875], Loss: 1.8377, batch time: 0.09\n",
      "Epoch [5/5], Step [373/1875], Loss: 2.2529, batch time: 0.09\n",
      "Epoch [5/5], Step [374/1875], Loss: 1.9095, batch time: 0.10\n",
      "Epoch [5/5], Step [375/1875], Loss: 1.9317, batch time: 0.10\n",
      "Epoch [5/5], Step [376/1875], Loss: 2.0748, batch time: 0.09\n",
      "Epoch [5/5], Step [377/1875], Loss: 2.1764, batch time: 0.09\n",
      "Epoch [5/5], Step [378/1875], Loss: 1.7408, batch time: 0.09\n",
      "Epoch [5/5], Step [379/1875], Loss: 1.7916, batch time: 0.09\n",
      "Epoch [5/5], Step [380/1875], Loss: 1.7710, batch time: 0.09\n",
      "Epoch [5/5], Step [381/1875], Loss: 2.0292, batch time: 0.09\n",
      "Epoch [5/5], Step [382/1875], Loss: 2.1014, batch time: 0.09\n",
      "Epoch [5/5], Step [383/1875], Loss: 2.0842, batch time: 0.09\n",
      "Epoch [5/5], Step [384/1875], Loss: 1.7916, batch time: 0.10\n",
      "Epoch [5/5], Step [385/1875], Loss: 1.9727, batch time: 0.09\n",
      "Epoch [5/5], Step [386/1875], Loss: 1.8029, batch time: 0.09\n",
      "Epoch [5/5], Step [387/1875], Loss: 1.8668, batch time: 0.09\n",
      "Epoch [5/5], Step [388/1875], Loss: 1.7503, batch time: 0.10\n",
      "Epoch [5/5], Step [389/1875], Loss: 1.9902, batch time: 0.09\n",
      "Epoch [5/5], Step [390/1875], Loss: 1.7127, batch time: 0.09\n",
      "Epoch [5/5], Step [391/1875], Loss: 2.2580, batch time: 0.13\n",
      "Epoch [5/5], Step [392/1875], Loss: 2.0536, batch time: 0.12\n",
      "Epoch [5/5], Step [393/1875], Loss: 1.5907, batch time: 0.11\n",
      "Epoch [5/5], Step [394/1875], Loss: 1.9736, batch time: 0.09\n",
      "Epoch [5/5], Step [395/1875], Loss: 2.0295, batch time: 0.09\n",
      "Epoch [5/5], Step [396/1875], Loss: 2.0008, batch time: 0.09\n",
      "Epoch [5/5], Step [397/1875], Loss: 1.9350, batch time: 0.09\n",
      "Epoch [5/5], Step [398/1875], Loss: 1.8836, batch time: 0.10\n",
      "Epoch [5/5], Step [399/1875], Loss: 1.9410, batch time: 0.10\n",
      "Epoch [5/5], Step [400/1875], Loss: 1.7385, batch time: 0.13\n",
      "Epoch [5/5], Step [401/1875], Loss: 2.0980, batch time: 0.09\n",
      "Epoch [5/5], Step [402/1875], Loss: 1.9919, batch time: 0.09\n",
      "Epoch [5/5], Step [403/1875], Loss: 2.0268, batch time: 0.09\n",
      "Epoch [5/5], Step [404/1875], Loss: 1.9907, batch time: 0.10\n",
      "Epoch [5/5], Step [405/1875], Loss: 1.7401, batch time: 0.10\n",
      "Epoch [5/5], Step [406/1875], Loss: 1.9241, batch time: 0.12\n",
      "Epoch [5/5], Step [407/1875], Loss: 1.9544, batch time: 0.13\n",
      "Epoch [5/5], Step [408/1875], Loss: 1.9539, batch time: 0.12\n",
      "Epoch [5/5], Step [409/1875], Loss: 1.8753, batch time: 0.13\n",
      "Epoch [5/5], Step [410/1875], Loss: 1.9358, batch time: 0.17\n",
      "Epoch [5/5], Step [411/1875], Loss: 1.6924, batch time: 0.14\n",
      "Epoch [5/5], Step [412/1875], Loss: 1.8496, batch time: 0.14\n",
      "Epoch [5/5], Step [413/1875], Loss: 1.7110, batch time: 0.15\n",
      "Epoch [5/5], Step [414/1875], Loss: 1.5897, batch time: 0.12\n",
      "Epoch [5/5], Step [415/1875], Loss: 2.0305, batch time: 0.10\n",
      "Epoch [5/5], Step [416/1875], Loss: 1.8802, batch time: 0.14\n",
      "Epoch [5/5], Step [417/1875], Loss: 2.1674, batch time: 0.18\n",
      "Epoch [5/5], Step [418/1875], Loss: 1.5868, batch time: 0.15\n",
      "Epoch [5/5], Step [419/1875], Loss: 1.9585, batch time: 0.13\n",
      "Epoch [5/5], Step [420/1875], Loss: 1.7977, batch time: 0.11\n",
      "Epoch [5/5], Step [421/1875], Loss: 2.0019, batch time: 0.12\n",
      "Epoch [5/5], Step [422/1875], Loss: 2.1202, batch time: 0.13\n",
      "Epoch [5/5], Step [423/1875], Loss: 1.9996, batch time: 0.14\n",
      "Epoch [5/5], Step [424/1875], Loss: 1.9397, batch time: 0.11\n",
      "Epoch [5/5], Step [425/1875], Loss: 2.1119, batch time: 0.10\n",
      "Epoch [5/5], Step [426/1875], Loss: 1.8469, batch time: 0.10\n",
      "Epoch [5/5], Step [427/1875], Loss: 1.9045, batch time: 0.14\n",
      "Epoch [5/5], Step [428/1875], Loss: 2.0343, batch time: 0.13\n",
      "Epoch [5/5], Step [429/1875], Loss: 1.8121, batch time: 0.10\n",
      "Epoch [5/5], Step [430/1875], Loss: 2.1864, batch time: 0.16\n",
      "Epoch [5/5], Step [431/1875], Loss: 1.8892, batch time: 0.13\n",
      "Epoch [5/5], Step [432/1875], Loss: 1.9927, batch time: 0.10\n",
      "Epoch [5/5], Step [433/1875], Loss: 1.7638, batch time: 0.10\n",
      "Epoch [5/5], Step [434/1875], Loss: 1.8846, batch time: 0.12\n",
      "Epoch [5/5], Step [435/1875], Loss: 2.0334, batch time: 0.10\n",
      "Epoch [5/5], Step [436/1875], Loss: 1.7666, batch time: 0.10\n",
      "Epoch [5/5], Step [437/1875], Loss: 1.7277, batch time: 0.10\n",
      "Epoch [5/5], Step [438/1875], Loss: 2.0564, batch time: 0.13\n",
      "Epoch [5/5], Step [439/1875], Loss: 2.0858, batch time: 0.16\n",
      "Epoch [5/5], Step [440/1875], Loss: 1.9889, batch time: 0.10\n",
      "Epoch [5/5], Step [441/1875], Loss: 2.0190, batch time: 0.13\n",
      "Epoch [5/5], Step [442/1875], Loss: 1.8629, batch time: 0.10\n",
      "Epoch [5/5], Step [443/1875], Loss: 1.8575, batch time: 0.10\n",
      "Epoch [5/5], Step [444/1875], Loss: 1.9931, batch time: 0.14\n",
      "Epoch [5/5], Step [445/1875], Loss: 1.9242, batch time: 0.13\n",
      "Epoch [5/5], Step [446/1875], Loss: 1.5364, batch time: 0.11\n",
      "Epoch [5/5], Step [447/1875], Loss: 1.9538, batch time: 0.13\n",
      "Epoch [5/5], Step [448/1875], Loss: 2.1890, batch time: 0.11\n",
      "Epoch [5/5], Step [449/1875], Loss: 1.6054, batch time: 0.12\n",
      "Epoch [5/5], Step [450/1875], Loss: 2.0738, batch time: 0.13\n",
      "Epoch [5/5], Step [451/1875], Loss: 1.9128, batch time: 0.11\n",
      "Epoch [5/5], Step [452/1875], Loss: 1.9448, batch time: 0.11\n",
      "Epoch [5/5], Step [453/1875], Loss: 2.0870, batch time: 0.10\n",
      "Epoch [5/5], Step [454/1875], Loss: 1.7884, batch time: 0.10\n",
      "Epoch [5/5], Step [455/1875], Loss: 2.2698, batch time: 0.13\n",
      "Epoch [5/5], Step [456/1875], Loss: 2.1235, batch time: 0.10\n",
      "Epoch [5/5], Step [457/1875], Loss: 1.8554, batch time: 0.10\n",
      "Epoch [5/5], Step [458/1875], Loss: 1.8231, batch time: 0.10\n",
      "Epoch [5/5], Step [459/1875], Loss: 1.8903, batch time: 0.10\n",
      "Epoch [5/5], Step [460/1875], Loss: 2.1697, batch time: 0.10\n",
      "Epoch [5/5], Step [461/1875], Loss: 1.9045, batch time: 0.10\n",
      "Epoch [5/5], Step [462/1875], Loss: 2.0086, batch time: 0.10\n",
      "Epoch [5/5], Step [463/1875], Loss: 1.9057, batch time: 0.10\n",
      "Epoch [5/5], Step [464/1875], Loss: 2.0611, batch time: 0.10\n",
      "Epoch [5/5], Step [465/1875], Loss: 2.0745, batch time: 0.16\n",
      "Epoch [5/5], Step [466/1875], Loss: 2.2780, batch time: 0.12\n",
      "Epoch [5/5], Step [467/1875], Loss: 1.8067, batch time: 0.09\n",
      "Epoch [5/5], Step [468/1875], Loss: 1.9500, batch time: 0.12\n",
      "Epoch [5/5], Step [469/1875], Loss: 1.7720, batch time: 0.10\n",
      "Epoch [5/5], Step [470/1875], Loss: 1.9290, batch time: 0.09\n",
      "Epoch [5/5], Step [471/1875], Loss: 1.8416, batch time: 0.09\n",
      "Epoch [5/5], Step [472/1875], Loss: 1.8059, batch time: 0.14\n",
      "Epoch [5/5], Step [473/1875], Loss: 2.1586, batch time: 0.11\n",
      "Epoch [5/5], Step [474/1875], Loss: 1.8616, batch time: 0.09\n",
      "Epoch [5/5], Step [475/1875], Loss: 1.9932, batch time: 0.09\n",
      "Epoch [5/5], Step [476/1875], Loss: 1.7989, batch time: 0.11\n",
      "Epoch [5/5], Step [477/1875], Loss: 1.8830, batch time: 0.10\n",
      "Epoch [5/5], Step [478/1875], Loss: 1.9675, batch time: 0.10\n",
      "Epoch [5/5], Step [479/1875], Loss: 2.2474, batch time: 0.10\n",
      "Epoch [5/5], Step [480/1875], Loss: 1.8486, batch time: 0.11\n",
      "Epoch [5/5], Step [481/1875], Loss: 2.2443, batch time: 0.10\n",
      "Epoch [5/5], Step [482/1875], Loss: 1.9757, batch time: 0.10\n",
      "Epoch [5/5], Step [483/1875], Loss: 2.1465, batch time: 0.13\n",
      "Epoch [5/5], Step [484/1875], Loss: 2.0345, batch time: 0.09\n",
      "Epoch [5/5], Step [485/1875], Loss: 1.9937, batch time: 0.10\n",
      "Epoch [5/5], Step [486/1875], Loss: 1.8498, batch time: 0.11\n",
      "Epoch [5/5], Step [487/1875], Loss: 1.8647, batch time: 0.09\n",
      "Epoch [5/5], Step [488/1875], Loss: 2.1739, batch time: 0.09\n",
      "Epoch [5/5], Step [489/1875], Loss: 1.8757, batch time: 0.10\n",
      "Epoch [5/5], Step [490/1875], Loss: 2.0036, batch time: 0.20\n",
      "Epoch [5/5], Step [491/1875], Loss: 2.0606, batch time: 0.10\n",
      "Epoch [5/5], Step [492/1875], Loss: 2.1345, batch time: 0.10\n",
      "Epoch [5/5], Step [493/1875], Loss: 1.8733, batch time: 0.10\n",
      "Epoch [5/5], Step [494/1875], Loss: 1.9887, batch time: 0.09\n",
      "Epoch [5/5], Step [495/1875], Loss: 1.9413, batch time: 0.09\n",
      "Epoch [5/5], Step [496/1875], Loss: 1.9421, batch time: 0.09\n",
      "Epoch [5/5], Step [497/1875], Loss: 1.8904, batch time: 0.09\n",
      "Epoch [5/5], Step [498/1875], Loss: 1.6977, batch time: 0.09\n",
      "Epoch [5/5], Step [499/1875], Loss: 1.6421, batch time: 0.09\n",
      "Epoch [5/5], Step [500/1875], Loss: 1.8829, batch time: 0.09\n",
      "Epoch [5/5], Step [501/1875], Loss: 1.8258, batch time: 0.09\n",
      "Epoch [5/5], Step [502/1875], Loss: 2.0289, batch time: 0.09\n",
      "Epoch [5/5], Step [503/1875], Loss: 1.6308, batch time: 0.10\n",
      "Epoch [5/5], Step [504/1875], Loss: 1.7823, batch time: 0.09\n",
      "Epoch [5/5], Step [505/1875], Loss: 1.8442, batch time: 0.10\n",
      "Epoch [5/5], Step [506/1875], Loss: 1.9198, batch time: 0.09\n",
      "Epoch [5/5], Step [507/1875], Loss: 2.1062, batch time: 0.10\n",
      "Epoch [5/5], Step [508/1875], Loss: 1.9096, batch time: 0.10\n",
      "Epoch [5/5], Step [509/1875], Loss: 1.8748, batch time: 0.09\n",
      "Epoch [5/5], Step [510/1875], Loss: 1.8631, batch time: 0.09\n",
      "Epoch [5/5], Step [511/1875], Loss: 2.2642, batch time: 0.09\n",
      "Epoch [5/5], Step [512/1875], Loss: 2.0243, batch time: 0.14\n",
      "Epoch [5/5], Step [513/1875], Loss: 1.9090, batch time: 0.09\n",
      "Epoch [5/5], Step [514/1875], Loss: 2.0114, batch time: 0.09\n",
      "Epoch [5/5], Step [515/1875], Loss: 1.9939, batch time: 0.18\n",
      "Epoch [5/5], Step [516/1875], Loss: 1.8499, batch time: 0.09\n",
      "Epoch [5/5], Step [517/1875], Loss: 2.0600, batch time: 0.09\n",
      "Epoch [5/5], Step [518/1875], Loss: 1.8506, batch time: 0.09\n",
      "Epoch [5/5], Step [519/1875], Loss: 1.9846, batch time: 0.09\n",
      "Epoch [5/5], Step [520/1875], Loss: 1.9310, batch time: 0.09\n",
      "Epoch [5/5], Step [521/1875], Loss: 1.8829, batch time: 0.17\n",
      "Epoch [5/5], Step [522/1875], Loss: 2.0410, batch time: 0.09\n",
      "Epoch [5/5], Step [523/1875], Loss: 1.7056, batch time: 0.10\n",
      "Epoch [5/5], Step [524/1875], Loss: 2.0594, batch time: 0.13\n",
      "Epoch [5/5], Step [525/1875], Loss: 1.8094, batch time: 0.10\n",
      "Epoch [5/5], Step [526/1875], Loss: 1.8514, batch time: 0.09\n",
      "Epoch [5/5], Step [527/1875], Loss: 1.6782, batch time: 0.12\n",
      "Epoch [5/5], Step [528/1875], Loss: 2.0131, batch time: 0.09\n",
      "Epoch [5/5], Step [529/1875], Loss: 2.0733, batch time: 0.10\n",
      "Epoch [5/5], Step [530/1875], Loss: 2.0905, batch time: 0.10\n",
      "Epoch [5/5], Step [531/1875], Loss: 2.0513, batch time: 0.14\n",
      "Epoch [5/5], Step [532/1875], Loss: 2.0251, batch time: 0.10\n",
      "Epoch [5/5], Step [533/1875], Loss: 1.9310, batch time: 0.10\n",
      "Epoch [5/5], Step [534/1875], Loss: 1.8720, batch time: -1.12\n",
      "Epoch [5/5], Step [535/1875], Loss: 1.9136, batch time: 0.09\n",
      "Epoch [5/5], Step [536/1875], Loss: 2.0877, batch time: 0.11\n",
      "Epoch [5/5], Step [537/1875], Loss: 1.7576, batch time: 0.10\n",
      "Epoch [5/5], Step [538/1875], Loss: 1.8675, batch time: 0.10\n",
      "Epoch [5/5], Step [539/1875], Loss: 1.9657, batch time: 0.11\n",
      "Epoch [5/5], Step [540/1875], Loss: 1.8096, batch time: 0.11\n",
      "Epoch [5/5], Step [541/1875], Loss: 1.9792, batch time: 0.12\n",
      "Epoch [5/5], Step [542/1875], Loss: 2.0707, batch time: 0.13\n",
      "Epoch [5/5], Step [543/1875], Loss: 1.8839, batch time: 0.09\n",
      "Epoch [5/5], Step [544/1875], Loss: 1.9603, batch time: 0.10\n",
      "Epoch [5/5], Step [545/1875], Loss: 1.8978, batch time: 0.11\n",
      "Epoch [5/5], Step [546/1875], Loss: 1.7813, batch time: 0.10\n",
      "Epoch [5/5], Step [547/1875], Loss: 1.8714, batch time: 0.14\n",
      "Epoch [5/5], Step [548/1875], Loss: 1.9812, batch time: 0.15\n",
      "Epoch [5/5], Step [549/1875], Loss: 1.7100, batch time: 0.11\n",
      "Epoch [5/5], Step [550/1875], Loss: 2.3014, batch time: 0.09\n",
      "Epoch [5/5], Step [551/1875], Loss: 1.7808, batch time: 0.10\n",
      "Epoch [5/5], Step [552/1875], Loss: 1.8798, batch time: 0.10\n",
      "Epoch [5/5], Step [553/1875], Loss: 2.1652, batch time: 0.09\n",
      "Epoch [5/5], Step [554/1875], Loss: 2.1663, batch time: 0.12\n",
      "Epoch [5/5], Step [555/1875], Loss: 1.8516, batch time: 0.09\n",
      "Epoch [5/5], Step [556/1875], Loss: 2.0031, batch time: 0.09\n",
      "Epoch [5/5], Step [557/1875], Loss: 1.7969, batch time: 0.11\n",
      "Epoch [5/5], Step [558/1875], Loss: 1.8968, batch time: 0.09\n",
      "Epoch [5/5], Step [559/1875], Loss: 1.9444, batch time: 0.11\n",
      "Epoch [5/5], Step [560/1875], Loss: 1.7801, batch time: 0.10\n",
      "Epoch [5/5], Step [561/1875], Loss: 1.7925, batch time: 0.09\n",
      "Epoch [5/5], Step [562/1875], Loss: 1.8238, batch time: 0.09\n",
      "Epoch [5/5], Step [563/1875], Loss: 1.9644, batch time: 0.09\n",
      "Epoch [5/5], Step [564/1875], Loss: 2.0191, batch time: 0.13\n",
      "Epoch [5/5], Step [565/1875], Loss: 2.1439, batch time: 0.09\n",
      "Epoch [5/5], Step [566/1875], Loss: 1.9564, batch time: 0.16\n",
      "Epoch [5/5], Step [567/1875], Loss: 2.0085, batch time: 0.10\n",
      "Epoch [5/5], Step [568/1875], Loss: 2.1994, batch time: 0.09\n",
      "Epoch [5/5], Step [569/1875], Loss: 2.0797, batch time: 0.14\n",
      "Epoch [5/5], Step [570/1875], Loss: 2.0923, batch time: 0.16\n",
      "Epoch [5/5], Step [571/1875], Loss: 1.9177, batch time: 0.10\n",
      "Epoch [5/5], Step [572/1875], Loss: 1.7386, batch time: 0.10\n",
      "Epoch [5/5], Step [573/1875], Loss: 1.7248, batch time: 0.11\n",
      "Epoch [5/5], Step [574/1875], Loss: 1.9773, batch time: 0.10\n",
      "Epoch [5/5], Step [575/1875], Loss: 1.7782, batch time: 0.10\n",
      "Epoch [5/5], Step [576/1875], Loss: 1.9093, batch time: 0.10\n",
      "Epoch [5/5], Step [577/1875], Loss: 2.0086, batch time: 0.11\n",
      "Epoch [5/5], Step [578/1875], Loss: 2.2202, batch time: 0.10\n",
      "Epoch [5/5], Step [579/1875], Loss: 1.9251, batch time: 0.11\n",
      "Epoch [5/5], Step [580/1875], Loss: 1.8975, batch time: 0.10\n",
      "Epoch [5/5], Step [581/1875], Loss: 1.9938, batch time: 0.10\n",
      "Epoch [5/5], Step [582/1875], Loss: 2.2403, batch time: 0.11\n",
      "Epoch [5/5], Step [583/1875], Loss: 1.7149, batch time: 0.10\n",
      "Epoch [5/5], Step [584/1875], Loss: 1.8292, batch time: 0.10\n",
      "Epoch [5/5], Step [585/1875], Loss: 1.9948, batch time: 0.17\n",
      "Epoch [5/5], Step [586/1875], Loss: 1.9504, batch time: 0.12\n",
      "Epoch [5/5], Step [587/1875], Loss: 2.0521, batch time: 0.11\n",
      "Epoch [5/5], Step [588/1875], Loss: 1.7890, batch time: 0.12\n",
      "Epoch [5/5], Step [589/1875], Loss: 1.9402, batch time: 0.13\n",
      "Epoch [5/5], Step [590/1875], Loss: 2.1575, batch time: 0.10\n",
      "Epoch [5/5], Step [591/1875], Loss: 1.8725, batch time: 0.10\n",
      "Epoch [5/5], Step [592/1875], Loss: 1.9736, batch time: 0.12\n",
      "Epoch [5/5], Step [593/1875], Loss: 2.1021, batch time: 0.11\n",
      "Epoch [5/5], Step [594/1875], Loss: 1.9774, batch time: 0.13\n",
      "Epoch [5/5], Step [595/1875], Loss: 1.8819, batch time: 0.10\n",
      "Epoch [5/5], Step [596/1875], Loss: 1.9940, batch time: 0.12\n",
      "Epoch [5/5], Step [597/1875], Loss: 1.9404, batch time: 0.13\n",
      "Epoch [5/5], Step [598/1875], Loss: 2.0551, batch time: 0.14\n",
      "Epoch [5/5], Step [599/1875], Loss: 1.9196, batch time: 0.11\n",
      "Epoch [5/5], Step [600/1875], Loss: 1.8184, batch time: 0.10\n",
      "Epoch [5/5], Step [601/1875], Loss: 1.9428, batch time: 0.10\n",
      "Epoch [5/5], Step [602/1875], Loss: 1.9579, batch time: 0.10\n",
      "Epoch [5/5], Step [603/1875], Loss: 2.1101, batch time: 0.10\n",
      "Epoch [5/5], Step [604/1875], Loss: 1.8261, batch time: 0.10\n",
      "Epoch [5/5], Step [605/1875], Loss: 2.0874, batch time: 0.11\n",
      "Epoch [5/5], Step [606/1875], Loss: 1.7411, batch time: 0.14\n",
      "Epoch [5/5], Step [607/1875], Loss: 1.9249, batch time: 0.14\n",
      "Epoch [5/5], Step [608/1875], Loss: 2.1547, batch time: 0.14\n",
      "Epoch [5/5], Step [609/1875], Loss: 1.8882, batch time: 0.10\n",
      "Epoch [5/5], Step [610/1875], Loss: 1.9782, batch time: 0.13\n",
      "Epoch [5/5], Step [611/1875], Loss: 1.9522, batch time: 0.10\n",
      "Epoch [5/5], Step [612/1875], Loss: 2.0266, batch time: 0.12\n",
      "Epoch [5/5], Step [613/1875], Loss: 1.9992, batch time: 0.13\n",
      "Epoch [5/5], Step [614/1875], Loss: 1.7202, batch time: 0.13\n",
      "Epoch [5/5], Step [615/1875], Loss: 1.8376, batch time: 0.10\n",
      "Epoch [5/5], Step [616/1875], Loss: 1.8374, batch time: 0.20\n",
      "Epoch [5/5], Step [617/1875], Loss: 1.8256, batch time: 0.11\n",
      "Epoch [5/5], Step [618/1875], Loss: 2.0454, batch time: 0.12\n",
      "Epoch [5/5], Step [619/1875], Loss: 1.9786, batch time: 0.12\n",
      "Epoch [5/5], Step [620/1875], Loss: 1.8586, batch time: 0.13\n",
      "Epoch [5/5], Step [621/1875], Loss: 1.7862, batch time: 0.13\n",
      "Epoch [5/5], Step [622/1875], Loss: 2.1241, batch time: 0.11\n",
      "Epoch [5/5], Step [623/1875], Loss: 2.0053, batch time: 0.12\n",
      "Epoch [5/5], Step [624/1875], Loss: 2.0586, batch time: 0.13\n",
      "Epoch [5/5], Step [625/1875], Loss: 1.9048, batch time: 0.12\n",
      "Epoch [5/5], Step [626/1875], Loss: 2.1108, batch time: 0.10\n",
      "Epoch [5/5], Step [627/1875], Loss: 1.9380, batch time: 0.12\n",
      "Epoch [5/5], Step [628/1875], Loss: 1.9842, batch time: 0.13\n",
      "Epoch [5/5], Step [629/1875], Loss: 2.1154, batch time: 0.10\n",
      "Epoch [5/5], Step [630/1875], Loss: 1.7670, batch time: 0.09\n",
      "Epoch [5/5], Step [631/1875], Loss: 2.1242, batch time: 0.10\n",
      "Epoch [5/5], Step [632/1875], Loss: 1.9465, batch time: 0.10\n",
      "Epoch [5/5], Step [633/1875], Loss: 2.2673, batch time: 0.10\n",
      "Epoch [5/5], Step [634/1875], Loss: 1.8308, batch time: 0.10\n",
      "Epoch [5/5], Step [635/1875], Loss: 2.2503, batch time: 0.11\n",
      "Epoch [5/5], Step [636/1875], Loss: 1.8228, batch time: 0.10\n",
      "Epoch [5/5], Step [637/1875], Loss: 2.0138, batch time: 0.11\n",
      "Epoch [5/5], Step [638/1875], Loss: 2.0586, batch time: 0.10\n",
      "Epoch [5/5], Step [639/1875], Loss: 1.7328, batch time: 0.10\n",
      "Epoch [5/5], Step [640/1875], Loss: 2.0263, batch time: 0.13\n",
      "Epoch [5/5], Step [641/1875], Loss: 1.9413, batch time: 0.10\n",
      "Epoch [5/5], Step [642/1875], Loss: 1.9998, batch time: 0.10\n",
      "Epoch [5/5], Step [643/1875], Loss: 1.9540, batch time: 0.11\n",
      "Epoch [5/5], Step [644/1875], Loss: 1.8163, batch time: 0.10\n",
      "Epoch [5/5], Step [645/1875], Loss: 1.9625, batch time: 0.10\n",
      "Epoch [5/5], Step [646/1875], Loss: 2.1993, batch time: 0.12\n",
      "Epoch [5/5], Step [647/1875], Loss: 1.6650, batch time: 0.18\n",
      "Epoch [5/5], Step [648/1875], Loss: 2.0618, batch time: 0.10\n",
      "Epoch [5/5], Step [649/1875], Loss: 1.8853, batch time: 0.10\n",
      "Epoch [5/5], Step [650/1875], Loss: 2.1701, batch time: 0.10\n",
      "Epoch [5/5], Step [651/1875], Loss: 1.9100, batch time: 0.17\n",
      "Epoch [5/5], Step [652/1875], Loss: 2.1602, batch time: 0.17\n",
      "Epoch [5/5], Step [653/1875], Loss: 1.7123, batch time: 0.11\n",
      "Epoch [5/5], Step [654/1875], Loss: 1.9522, batch time: 0.13\n",
      "Epoch [5/5], Step [655/1875], Loss: 1.7280, batch time: 0.10\n",
      "Epoch [5/5], Step [656/1875], Loss: 1.8859, batch time: 0.14\n",
      "Epoch [5/5], Step [657/1875], Loss: 2.1452, batch time: 0.13\n",
      "Epoch [5/5], Step [658/1875], Loss: 2.1509, batch time: 0.10\n",
      "Epoch [5/5], Step [659/1875], Loss: 2.0035, batch time: 0.10\n",
      "Epoch [5/5], Step [660/1875], Loss: 1.9112, batch time: 0.10\n",
      "Epoch [5/5], Step [661/1875], Loss: 1.7463, batch time: 0.12\n",
      "Epoch [5/5], Step [662/1875], Loss: 1.9061, batch time: 0.10\n",
      "Epoch [5/5], Step [663/1875], Loss: 1.7654, batch time: 0.13\n",
      "Epoch [5/5], Step [664/1875], Loss: 2.0438, batch time: 0.13\n",
      "Epoch [5/5], Step [665/1875], Loss: 1.9369, batch time: 0.09\n",
      "Epoch [5/5], Step [666/1875], Loss: 1.9303, batch time: 0.11\n",
      "Epoch [5/5], Step [667/1875], Loss: 1.8109, batch time: 0.10\n",
      "Epoch [5/5], Step [668/1875], Loss: 1.8855, batch time: 0.10\n",
      "Epoch [5/5], Step [669/1875], Loss: 1.9145, batch time: 0.14\n",
      "Epoch [5/5], Step [670/1875], Loss: 2.0139, batch time: 0.13\n",
      "Epoch [5/5], Step [671/1875], Loss: 1.8108, batch time: 0.10\n",
      "Epoch [5/5], Step [672/1875], Loss: 1.9553, batch time: 0.13\n",
      "Epoch [5/5], Step [673/1875], Loss: 2.0260, batch time: 0.10\n",
      "Epoch [5/5], Step [674/1875], Loss: 1.7865, batch time: 0.12\n",
      "Epoch [5/5], Step [675/1875], Loss: 1.8052, batch time: 0.10\n",
      "Epoch [5/5], Step [676/1875], Loss: 1.8407, batch time: 0.10\n",
      "Epoch [5/5], Step [677/1875], Loss: 2.1973, batch time: 0.25\n",
      "Epoch [5/5], Step [678/1875], Loss: 2.0644, batch time: 0.10\n",
      "Epoch [5/5], Step [679/1875], Loss: 1.9924, batch time: 0.10\n",
      "Epoch [5/5], Step [680/1875], Loss: 1.9825, batch time: 0.14\n",
      "Epoch [5/5], Step [681/1875], Loss: 1.6832, batch time: 0.17\n",
      "Epoch [5/5], Step [682/1875], Loss: 1.9383, batch time: 0.10\n",
      "Epoch [5/5], Step [683/1875], Loss: 1.7924, batch time: 0.13\n",
      "Epoch [5/5], Step [684/1875], Loss: 1.9247, batch time: 0.10\n",
      "Epoch [5/5], Step [685/1875], Loss: 1.9128, batch time: 0.14\n",
      "Epoch [5/5], Step [686/1875], Loss: 2.0133, batch time: 0.10\n",
      "Epoch [5/5], Step [687/1875], Loss: 1.9461, batch time: 0.10\n",
      "Epoch [5/5], Step [688/1875], Loss: 2.0754, batch time: 0.10\n",
      "Epoch [5/5], Step [689/1875], Loss: 1.8185, batch time: 0.13\n",
      "Epoch [5/5], Step [690/1875], Loss: 2.0147, batch time: 0.13\n",
      "Epoch [5/5], Step [691/1875], Loss: 1.9272, batch time: 0.11\n",
      "Epoch [5/5], Step [692/1875], Loss: 2.0303, batch time: 0.13\n",
      "Epoch [5/5], Step [693/1875], Loss: 2.0561, batch time: 0.10\n",
      "Epoch [5/5], Step [694/1875], Loss: 1.6337, batch time: 0.10\n",
      "Epoch [5/5], Step [695/1875], Loss: 1.8423, batch time: 0.12\n",
      "Epoch [5/5], Step [696/1875], Loss: 1.8782, batch time: 0.14\n",
      "Epoch [5/5], Step [697/1875], Loss: 1.9835, batch time: 0.18\n",
      "Epoch [5/5], Step [698/1875], Loss: 1.7920, batch time: 0.11\n",
      "Epoch [5/5], Step [699/1875], Loss: 1.9155, batch time: 0.13\n",
      "Epoch [5/5], Step [700/1875], Loss: 2.0922, batch time: 0.14\n",
      "Epoch [5/5], Step [701/1875], Loss: 2.0276, batch time: 0.13\n",
      "Epoch [5/5], Step [702/1875], Loss: 1.9905, batch time: 0.13\n",
      "Epoch [5/5], Step [703/1875], Loss: 1.8189, batch time: 0.15\n",
      "Epoch [5/5], Step [704/1875], Loss: 1.8842, batch time: 0.12\n",
      "Epoch [5/5], Step [705/1875], Loss: 1.8439, batch time: 0.13\n",
      "Epoch [5/5], Step [706/1875], Loss: 2.1073, batch time: 0.11\n",
      "Epoch [5/5], Step [707/1875], Loss: 2.0066, batch time: 0.10\n",
      "Epoch [5/5], Step [708/1875], Loss: 1.8388, batch time: 0.10\n",
      "Epoch [5/5], Step [709/1875], Loss: 1.9595, batch time: 0.24\n",
      "Epoch [5/5], Step [710/1875], Loss: 1.7205, batch time: 0.12\n",
      "Epoch [5/5], Step [711/1875], Loss: 1.9990, batch time: 0.09\n",
      "Epoch [5/5], Step [712/1875], Loss: 1.7010, batch time: 0.10\n",
      "Epoch [5/5], Step [713/1875], Loss: 1.7223, batch time: 0.09\n",
      "Epoch [5/5], Step [714/1875], Loss: 2.0577, batch time: 0.11\n",
      "Epoch [5/5], Step [715/1875], Loss: 2.1004, batch time: 0.09\n",
      "Epoch [5/5], Step [716/1875], Loss: 2.0811, batch time: 0.09\n",
      "Epoch [5/5], Step [717/1875], Loss: 2.1079, batch time: 0.13\n",
      "Epoch [5/5], Step [718/1875], Loss: 2.0639, batch time: 0.09\n",
      "Epoch [5/5], Step [719/1875], Loss: 2.0949, batch time: 0.09\n",
      "Epoch [5/5], Step [720/1875], Loss: 1.8571, batch time: 0.09\n",
      "Epoch [5/5], Step [721/1875], Loss: 2.1622, batch time: 0.12\n",
      "Epoch [5/5], Step [722/1875], Loss: 2.0052, batch time: 0.09\n",
      "Epoch [5/5], Step [723/1875], Loss: 1.9113, batch time: 0.17\n",
      "Epoch [5/5], Step [724/1875], Loss: 1.7040, batch time: 0.14\n",
      "Epoch [5/5], Step [725/1875], Loss: 1.8958, batch time: 0.13\n",
      "Epoch [5/5], Step [726/1875], Loss: 1.9208, batch time: 0.11\n",
      "Epoch [5/5], Step [727/1875], Loss: 1.7837, batch time: 0.09\n",
      "Epoch [5/5], Step [728/1875], Loss: 1.8708, batch time: 0.09\n",
      "Epoch [5/5], Step [729/1875], Loss: 1.8225, batch time: 0.15\n",
      "Epoch [5/5], Step [730/1875], Loss: 2.0537, batch time: 0.09\n",
      "Epoch [5/5], Step [731/1875], Loss: 2.0637, batch time: 0.09\n",
      "Epoch [5/5], Step [732/1875], Loss: 1.7909, batch time: 0.10\n",
      "Epoch [5/5], Step [733/1875], Loss: 2.1002, batch time: 0.09\n",
      "Epoch [5/5], Step [734/1875], Loss: 1.8004, batch time: 0.10\n",
      "Epoch [5/5], Step [735/1875], Loss: 1.8602, batch time: 0.11\n",
      "Epoch [5/5], Step [736/1875], Loss: 1.8628, batch time: 0.09\n",
      "Epoch [5/5], Step [737/1875], Loss: 1.9938, batch time: 0.09\n",
      "Epoch [5/5], Step [738/1875], Loss: 1.8253, batch time: 0.10\n",
      "Epoch [5/5], Step [739/1875], Loss: 1.9805, batch time: 0.09\n",
      "Epoch [5/5], Step [740/1875], Loss: 1.9746, batch time: 0.11\n",
      "Epoch [5/5], Step [741/1875], Loss: 2.0555, batch time: 0.09\n",
      "Epoch [5/5], Step [742/1875], Loss: 1.9516, batch time: 0.09\n",
      "Epoch [5/5], Step [743/1875], Loss: 2.0924, batch time: 0.10\n",
      "Epoch [5/5], Step [744/1875], Loss: 1.8225, batch time: 0.15\n",
      "Epoch [5/5], Step [745/1875], Loss: 1.8083, batch time: 0.09\n",
      "Epoch [5/5], Step [746/1875], Loss: 2.0987, batch time: 0.14\n",
      "Epoch [5/5], Step [747/1875], Loss: 1.6714, batch time: 0.10\n",
      "Epoch [5/5], Step [748/1875], Loss: 1.7387, batch time: 0.11\n",
      "Epoch [5/5], Step [749/1875], Loss: 1.9114, batch time: 0.10\n",
      "Epoch [5/5], Step [750/1875], Loss: 1.8943, batch time: 0.16\n",
      "Epoch [5/5], Step [751/1875], Loss: 2.0197, batch time: 0.12\n",
      "Epoch [5/5], Step [752/1875], Loss: 1.8200, batch time: 0.19\n",
      "Epoch [5/5], Step [753/1875], Loss: 1.9871, batch time: 0.09\n",
      "Epoch [5/5], Step [754/1875], Loss: 2.0309, batch time: 0.09\n",
      "Epoch [5/5], Step [755/1875], Loss: 1.9321, batch time: 0.10\n",
      "Epoch [5/5], Step [756/1875], Loss: 1.7717, batch time: 0.13\n",
      "Epoch [5/5], Step [757/1875], Loss: 1.9278, batch time: 0.09\n",
      "Epoch [5/5], Step [758/1875], Loss: 1.9579, batch time: 0.10\n",
      "Epoch [5/5], Step [759/1875], Loss: 2.0239, batch time: 0.09\n",
      "Epoch [5/5], Step [760/1875], Loss: 1.7753, batch time: 0.09\n",
      "Epoch [5/5], Step [761/1875], Loss: 1.9339, batch time: 0.09\n",
      "Epoch [5/5], Step [762/1875], Loss: 1.9963, batch time: 0.10\n",
      "Epoch [5/5], Step [763/1875], Loss: 1.8025, batch time: 0.09\n",
      "Epoch [5/5], Step [764/1875], Loss: 1.7417, batch time: 0.09\n",
      "Epoch [5/5], Step [765/1875], Loss: 1.9910, batch time: 0.12\n",
      "Epoch [5/5], Step [766/1875], Loss: 1.9338, batch time: 0.09\n",
      "Epoch [5/5], Step [767/1875], Loss: 1.9824, batch time: 0.10\n",
      "Epoch [5/5], Step [768/1875], Loss: 1.9205, batch time: 0.12\n",
      "Epoch [5/5], Step [769/1875], Loss: 1.8116, batch time: 0.11\n",
      "Epoch [5/5], Step [770/1875], Loss: 1.9566, batch time: 0.10\n",
      "Epoch [5/5], Step [771/1875], Loss: 1.9387, batch time: 0.11\n",
      "Epoch [5/5], Step [772/1875], Loss: 2.1062, batch time: 0.09\n",
      "Epoch [5/5], Step [773/1875], Loss: 1.9159, batch time: 0.11\n",
      "Epoch [5/5], Step [774/1875], Loss: 1.9481, batch time: 0.09\n",
      "Epoch [5/5], Step [775/1875], Loss: 2.1348, batch time: 0.09\n",
      "Epoch [5/5], Step [776/1875], Loss: 1.9940, batch time: 0.15\n",
      "Epoch [5/5], Step [777/1875], Loss: 1.8614, batch time: 0.10\n",
      "Epoch [5/5], Step [778/1875], Loss: 1.9212, batch time: 0.09\n",
      "Epoch [5/5], Step [779/1875], Loss: 2.1659, batch time: 0.12\n",
      "Epoch [5/5], Step [780/1875], Loss: 1.9422, batch time: 0.09\n",
      "Epoch [5/5], Step [781/1875], Loss: 1.9522, batch time: 0.11\n",
      "Epoch [5/5], Step [782/1875], Loss: 1.8333, batch time: 0.09\n",
      "Epoch [5/5], Step [783/1875], Loss: 2.1161, batch time: 0.10\n",
      "Epoch [5/5], Step [784/1875], Loss: 1.8024, batch time: 0.09\n",
      "Epoch [5/5], Step [785/1875], Loss: 1.7846, batch time: 0.09\n",
      "Epoch [5/5], Step [786/1875], Loss: 1.8787, batch time: 0.09\n",
      "Epoch [5/5], Step [787/1875], Loss: 2.0147, batch time: 0.13\n",
      "Epoch [5/5], Step [788/1875], Loss: 1.9705, batch time: 0.09\n",
      "Epoch [5/5], Step [789/1875], Loss: 1.7859, batch time: 0.10\n",
      "Epoch [5/5], Step [790/1875], Loss: 2.0558, batch time: 0.09\n",
      "Epoch [5/5], Step [791/1875], Loss: 1.9765, batch time: 0.15\n",
      "Epoch [5/5], Step [792/1875], Loss: 2.0101, batch time: 0.09\n",
      "Epoch [5/5], Step [793/1875], Loss: 1.8978, batch time: 0.09\n",
      "Epoch [5/5], Step [794/1875], Loss: 2.0404, batch time: 0.17\n",
      "Epoch [5/5], Step [795/1875], Loss: 1.9181, batch time: 0.09\n",
      "Epoch [5/5], Step [796/1875], Loss: 1.6766, batch time: 0.10\n",
      "Epoch [5/5], Step [797/1875], Loss: 1.8833, batch time: 0.10\n",
      "Epoch [5/5], Step [798/1875], Loss: 1.8358, batch time: 0.09\n",
      "Epoch [5/5], Step [799/1875], Loss: 1.8887, batch time: 0.09\n",
      "Epoch [5/5], Step [800/1875], Loss: 1.8461, batch time: 0.13\n",
      "Epoch [5/5], Step [801/1875], Loss: 1.8860, batch time: 0.12\n",
      "Epoch [5/5], Step [802/1875], Loss: 1.9679, batch time: 0.09\n",
      "Epoch [5/5], Step [803/1875], Loss: 1.8994, batch time: 0.09\n",
      "Epoch [5/5], Step [804/1875], Loss: 1.8170, batch time: 0.12\n",
      "Epoch [5/5], Step [805/1875], Loss: 2.0811, batch time: 0.11\n",
      "Epoch [5/5], Step [806/1875], Loss: 1.8746, batch time: 0.10\n",
      "Epoch [5/5], Step [807/1875], Loss: 1.9140, batch time: 0.12\n",
      "Epoch [5/5], Step [808/1875], Loss: 2.0730, batch time: 0.11\n",
      "Epoch [5/5], Step [809/1875], Loss: 2.1885, batch time: 0.11\n",
      "Epoch [5/5], Step [810/1875], Loss: 1.6336, batch time: 0.09\n",
      "Epoch [5/5], Step [811/1875], Loss: 1.7922, batch time: 0.09\n",
      "Epoch [5/5], Step [812/1875], Loss: 2.0174, batch time: 0.09\n",
      "Epoch [5/5], Step [813/1875], Loss: 1.9077, batch time: 0.10\n",
      "Epoch [5/5], Step [814/1875], Loss: 1.8601, batch time: 0.10\n",
      "Epoch [5/5], Step [815/1875], Loss: 1.7205, batch time: 0.11\n",
      "Epoch [5/5], Step [816/1875], Loss: 2.0501, batch time: 0.16\n",
      "Epoch [5/5], Step [817/1875], Loss: 1.8544, batch time: -0.97\n",
      "Epoch [5/5], Step [818/1875], Loss: 1.9956, batch time: 0.09\n",
      "Epoch [5/5], Step [819/1875], Loss: 1.9224, batch time: 0.17\n",
      "Epoch [5/5], Step [820/1875], Loss: 2.0022, batch time: 0.13\n",
      "Epoch [5/5], Step [821/1875], Loss: 1.7413, batch time: 0.11\n",
      "Epoch [5/5], Step [822/1875], Loss: 2.0338, batch time: 0.09\n",
      "Epoch [5/5], Step [823/1875], Loss: 2.0324, batch time: 0.12\n",
      "Epoch [5/5], Step [824/1875], Loss: 1.9040, batch time: 0.09\n",
      "Epoch [5/5], Step [825/1875], Loss: 1.7644, batch time: 0.09\n",
      "Epoch [5/5], Step [826/1875], Loss: 2.0564, batch time: 0.12\n",
      "Epoch [5/5], Step [827/1875], Loss: 1.9725, batch time: 0.10\n",
      "Epoch [5/5], Step [828/1875], Loss: 1.9152, batch time: 0.09\n",
      "Epoch [5/5], Step [829/1875], Loss: 1.8384, batch time: 0.15\n",
      "Epoch [5/5], Step [830/1875], Loss: 2.0924, batch time: 0.12\n",
      "Epoch [5/5], Step [831/1875], Loss: 1.7851, batch time: 0.13\n",
      "Epoch [5/5], Step [832/1875], Loss: 2.0511, batch time: 0.12\n",
      "Epoch [5/5], Step [833/1875], Loss: 1.8769, batch time: 0.09\n",
      "Epoch [5/5], Step [834/1875], Loss: 1.9150, batch time: 0.10\n",
      "Epoch [5/5], Step [835/1875], Loss: 1.9224, batch time: 0.10\n",
      "Epoch [5/5], Step [836/1875], Loss: 1.7317, batch time: 0.11\n",
      "Epoch [5/5], Step [837/1875], Loss: 1.8372, batch time: 0.13\n",
      "Epoch [5/5], Step [838/1875], Loss: 1.9718, batch time: 0.12\n",
      "Epoch [5/5], Step [839/1875], Loss: 1.7562, batch time: 0.09\n",
      "Epoch [5/5], Step [840/1875], Loss: 2.1578, batch time: 0.09\n",
      "Epoch [5/5], Step [841/1875], Loss: 1.8056, batch time: 0.09\n",
      "Epoch [5/5], Step [842/1875], Loss: 1.6936, batch time: 0.09\n",
      "Epoch [5/5], Step [843/1875], Loss: 1.7090, batch time: 0.09\n",
      "Epoch [5/5], Step [844/1875], Loss: 1.9584, batch time: 0.13\n",
      "Epoch [5/5], Step [845/1875], Loss: 1.8936, batch time: 0.09\n",
      "Epoch [5/5], Step [846/1875], Loss: 1.8023, batch time: 0.10\n",
      "Epoch [5/5], Step [847/1875], Loss: 1.8971, batch time: 0.09\n",
      "Epoch [5/5], Step [848/1875], Loss: 1.7597, batch time: 0.09\n",
      "Epoch [5/5], Step [849/1875], Loss: 1.7766, batch time: 0.10\n",
      "Epoch [5/5], Step [850/1875], Loss: 1.7624, batch time: 0.10\n",
      "Epoch [5/5], Step [851/1875], Loss: 1.8736, batch time: 0.09\n",
      "Epoch [5/5], Step [852/1875], Loss: 1.9556, batch time: 0.10\n",
      "Epoch [5/5], Step [853/1875], Loss: 1.6714, batch time: 0.09\n",
      "Epoch [5/5], Step [854/1875], Loss: 1.8952, batch time: 0.11\n",
      "Epoch [5/5], Step [855/1875], Loss: 1.8429, batch time: 0.10\n",
      "Epoch [5/5], Step [856/1875], Loss: 2.1695, batch time: 0.09\n",
      "Epoch [5/5], Step [857/1875], Loss: 1.8578, batch time: 0.09\n",
      "Epoch [5/5], Step [858/1875], Loss: 1.8819, batch time: 0.09\n",
      "Epoch [5/5], Step [859/1875], Loss: 2.0648, batch time: 0.09\n",
      "Epoch [5/5], Step [860/1875], Loss: 2.1308, batch time: 0.12\n",
      "Epoch [5/5], Step [861/1875], Loss: 1.8626, batch time: 0.09\n",
      "Epoch [5/5], Step [862/1875], Loss: 2.0102, batch time: 0.10\n",
      "Epoch [5/5], Step [863/1875], Loss: 1.8051, batch time: 0.09\n",
      "Epoch [5/5], Step [864/1875], Loss: 2.1262, batch time: 0.11\n",
      "Epoch [5/5], Step [865/1875], Loss: 2.0104, batch time: 0.09\n",
      "Epoch [5/5], Step [866/1875], Loss: 1.9612, batch time: 0.09\n",
      "Epoch [5/5], Step [867/1875], Loss: 1.8535, batch time: 0.12\n",
      "Epoch [5/5], Step [868/1875], Loss: 1.5960, batch time: 0.09\n",
      "Epoch [5/5], Step [869/1875], Loss: 1.9778, batch time: 0.09\n",
      "Epoch [5/5], Step [870/1875], Loss: 1.9267, batch time: 0.10\n",
      "Epoch [5/5], Step [871/1875], Loss: 2.0127, batch time: 0.09\n",
      "Epoch [5/5], Step [872/1875], Loss: 1.7801, batch time: 0.09\n",
      "Epoch [5/5], Step [873/1875], Loss: 2.2171, batch time: 0.16\n",
      "Epoch [5/5], Step [874/1875], Loss: 1.7458, batch time: 0.12\n",
      "Epoch [5/5], Step [875/1875], Loss: 1.8425, batch time: 0.13\n",
      "Epoch [5/5], Step [876/1875], Loss: 2.0878, batch time: 0.14\n",
      "Epoch [5/5], Step [877/1875], Loss: 1.9264, batch time: 0.10\n",
      "Epoch [5/5], Step [878/1875], Loss: 1.8807, batch time: 0.09\n",
      "Epoch [5/5], Step [879/1875], Loss: 1.7877, batch time: 0.10\n",
      "Epoch [5/5], Step [880/1875], Loss: 2.0505, batch time: 0.10\n",
      "Epoch [5/5], Step [881/1875], Loss: 1.9274, batch time: 0.14\n",
      "Epoch [5/5], Step [882/1875], Loss: 1.8817, batch time: 0.10\n",
      "Epoch [5/5], Step [883/1875], Loss: 2.0834, batch time: 0.12\n",
      "Epoch [5/5], Step [884/1875], Loss: 1.7086, batch time: 0.11\n",
      "Epoch [5/5], Step [885/1875], Loss: 1.7140, batch time: 0.10\n",
      "Epoch [5/5], Step [886/1875], Loss: 1.7838, batch time: 0.12\n",
      "Epoch [5/5], Step [887/1875], Loss: 1.6493, batch time: 0.13\n",
      "Epoch [5/5], Step [888/1875], Loss: 1.9898, batch time: 0.15\n",
      "Epoch [5/5], Step [889/1875], Loss: 1.8099, batch time: 0.14\n",
      "Epoch [5/5], Step [890/1875], Loss: 1.7838, batch time: 0.12\n",
      "Epoch [5/5], Step [891/1875], Loss: 1.9953, batch time: 0.13\n",
      "Epoch [5/5], Step [892/1875], Loss: 1.9434, batch time: 0.10\n",
      "Epoch [5/5], Step [893/1875], Loss: 2.0475, batch time: 0.10\n",
      "Epoch [5/5], Step [894/1875], Loss: 1.9222, batch time: 0.09\n",
      "Epoch [5/5], Step [895/1875], Loss: 2.0428, batch time: 0.12\n",
      "Epoch [5/5], Step [896/1875], Loss: 1.9756, batch time: 0.09\n",
      "Epoch [5/5], Step [897/1875], Loss: 1.8675, batch time: 0.09\n",
      "Epoch [5/5], Step [898/1875], Loss: 2.0210, batch time: 0.16\n",
      "Epoch [5/5], Step [899/1875], Loss: 1.9830, batch time: 0.14\n",
      "Epoch [5/5], Step [900/1875], Loss: 1.9038, batch time: 0.10\n",
      "Epoch [5/5], Step [901/1875], Loss: 1.9634, batch time: 0.13\n",
      "Epoch [5/5], Step [902/1875], Loss: 1.9560, batch time: 0.10\n",
      "Epoch [5/5], Step [903/1875], Loss: 1.8082, batch time: 0.17\n",
      "Epoch [5/5], Step [904/1875], Loss: 1.7948, batch time: 0.12\n",
      "Epoch [5/5], Step [905/1875], Loss: 1.8228, batch time: 0.09\n",
      "Epoch [5/5], Step [906/1875], Loss: 1.5814, batch time: 0.12\n",
      "Epoch [5/5], Step [907/1875], Loss: 1.8455, batch time: 0.10\n",
      "Epoch [5/5], Step [908/1875], Loss: 1.9093, batch time: 0.10\n",
      "Epoch [5/5], Step [909/1875], Loss: 1.8680, batch time: 0.10\n",
      "Epoch [5/5], Step [910/1875], Loss: 1.8781, batch time: 0.10\n",
      "Epoch [5/5], Step [911/1875], Loss: 1.8358, batch time: 0.09\n",
      "Epoch [5/5], Step [912/1875], Loss: 1.9244, batch time: 0.10\n",
      "Epoch [5/5], Step [913/1875], Loss: 1.9924, batch time: 0.09\n",
      "Epoch [5/5], Step [914/1875], Loss: 1.9376, batch time: 0.09\n",
      "Epoch [5/5], Step [915/1875], Loss: 1.9245, batch time: 0.10\n",
      "Epoch [5/5], Step [916/1875], Loss: 2.0220, batch time: 0.09\n",
      "Epoch [5/5], Step [917/1875], Loss: 1.8717, batch time: 0.16\n",
      "Epoch [5/5], Step [918/1875], Loss: 1.8581, batch time: 0.12\n",
      "Epoch [5/5], Step [919/1875], Loss: 1.9372, batch time: 0.10\n",
      "Epoch [5/5], Step [920/1875], Loss: 1.6587, batch time: 0.11\n",
      "Epoch [5/5], Step [921/1875], Loss: 1.9899, batch time: 0.14\n",
      "Epoch [5/5], Step [922/1875], Loss: 1.8826, batch time: 0.09\n",
      "Epoch [5/5], Step [923/1875], Loss: 1.8708, batch time: 0.12\n",
      "Epoch [5/5], Step [924/1875], Loss: 2.0526, batch time: 0.10\n",
      "Epoch [5/5], Step [925/1875], Loss: 1.9111, batch time: 0.12\n",
      "Epoch [5/5], Step [926/1875], Loss: 1.9223, batch time: 0.10\n",
      "Epoch [5/5], Step [927/1875], Loss: 2.0093, batch time: 0.11\n",
      "Epoch [5/5], Step [928/1875], Loss: 1.8323, batch time: 0.13\n",
      "Epoch [5/5], Step [929/1875], Loss: 1.9561, batch time: 0.11\n",
      "Epoch [5/5], Step [930/1875], Loss: 1.6733, batch time: 0.13\n",
      "Epoch [5/5], Step [931/1875], Loss: 1.8174, batch time: 0.10\n",
      "Epoch [5/5], Step [932/1875], Loss: 2.0997, batch time: 0.16\n",
      "Epoch [5/5], Step [933/1875], Loss: 1.9384, batch time: 0.10\n",
      "Epoch [5/5], Step [934/1875], Loss: 1.8558, batch time: 0.12\n",
      "Epoch [5/5], Step [935/1875], Loss: 2.0477, batch time: 0.09\n",
      "Epoch [5/5], Step [936/1875], Loss: 1.8540, batch time: 0.10\n",
      "Epoch [5/5], Step [937/1875], Loss: 1.8946, batch time: 0.13\n",
      "Epoch [5/5], Step [938/1875], Loss: 1.8710, batch time: 0.09\n",
      "Epoch [5/5], Step [939/1875], Loss: 2.0828, batch time: 0.10\n",
      "Epoch [5/5], Step [940/1875], Loss: 1.9642, batch time: 0.13\n",
      "Epoch [5/5], Step [941/1875], Loss: 1.6519, batch time: 0.13\n",
      "Epoch [5/5], Step [942/1875], Loss: 1.9692, batch time: 0.12\n",
      "Epoch [5/5], Step [943/1875], Loss: 1.8571, batch time: 0.13\n",
      "Epoch [5/5], Step [944/1875], Loss: 1.6594, batch time: 0.10\n",
      "Epoch [5/5], Step [945/1875], Loss: 1.8020, batch time: 0.10\n",
      "Epoch [5/5], Step [946/1875], Loss: 1.7947, batch time: 0.10\n",
      "Epoch [5/5], Step [947/1875], Loss: 1.6948, batch time: 0.10\n",
      "Epoch [5/5], Step [948/1875], Loss: 1.7241, batch time: 0.09\n",
      "Epoch [5/5], Step [949/1875], Loss: 1.8120, batch time: 0.09\n",
      "Epoch [5/5], Step [950/1875], Loss: 2.0707, batch time: 0.10\n",
      "Epoch [5/5], Step [951/1875], Loss: 1.7827, batch time: 0.10\n",
      "Epoch [5/5], Step [952/1875], Loss: 1.8648, batch time: 0.11\n",
      "Epoch [5/5], Step [953/1875], Loss: 1.8185, batch time: 0.13\n",
      "Epoch [5/5], Step [954/1875], Loss: 1.8784, batch time: 0.10\n",
      "Epoch [5/5], Step [955/1875], Loss: 1.9639, batch time: 0.09\n",
      "Epoch [5/5], Step [956/1875], Loss: 1.9716, batch time: 0.10\n",
      "Epoch [5/5], Step [957/1875], Loss: 1.7933, batch time: 0.13\n",
      "Epoch [5/5], Step [958/1875], Loss: 1.7190, batch time: 0.10\n",
      "Epoch [5/5], Step [959/1875], Loss: 2.1219, batch time: 0.12\n",
      "Epoch [5/5], Step [960/1875], Loss: 2.0040, batch time: 0.10\n",
      "Epoch [5/5], Step [961/1875], Loss: 1.9636, batch time: 0.10\n",
      "Epoch [5/5], Step [962/1875], Loss: 1.9156, batch time: 0.10\n",
      "Epoch [5/5], Step [963/1875], Loss: 1.9662, batch time: 0.09\n",
      "Epoch [5/5], Step [964/1875], Loss: 1.8568, batch time: 0.10\n",
      "Epoch [5/5], Step [965/1875], Loss: 2.1377, batch time: 0.10\n",
      "Epoch [5/5], Step [966/1875], Loss: 1.9506, batch time: 0.10\n",
      "Epoch [5/5], Step [967/1875], Loss: 1.8917, batch time: 0.10\n",
      "Epoch [5/5], Step [968/1875], Loss: 1.9079, batch time: 0.10\n",
      "Epoch [5/5], Step [969/1875], Loss: 1.8985, batch time: 0.09\n",
      "Epoch [5/5], Step [970/1875], Loss: 1.8926, batch time: 0.09\n",
      "Epoch [5/5], Step [971/1875], Loss: 1.7277, batch time: 0.12\n",
      "Epoch [5/5], Step [972/1875], Loss: 1.8431, batch time: 0.10\n",
      "Epoch [5/5], Step [973/1875], Loss: 1.7898, batch time: 0.10\n",
      "Epoch [5/5], Step [974/1875], Loss: 1.9011, batch time: 0.10\n",
      "Epoch [5/5], Step [975/1875], Loss: 2.0337, batch time: 0.19\n",
      "Epoch [5/5], Step [976/1875], Loss: 2.0052, batch time: 0.10\n",
      "Epoch [5/5], Step [977/1875], Loss: 2.0766, batch time: 0.20\n",
      "Epoch [5/5], Step [978/1875], Loss: 1.6809, batch time: 0.15\n",
      "Epoch [5/5], Step [979/1875], Loss: 1.6755, batch time: 0.11\n",
      "Epoch [5/5], Step [980/1875], Loss: 1.8921, batch time: 0.10\n",
      "Epoch [5/5], Step [981/1875], Loss: 1.8229, batch time: 0.10\n",
      "Epoch [5/5], Step [982/1875], Loss: 2.0263, batch time: 0.10\n",
      "Epoch [5/5], Step [983/1875], Loss: 1.8448, batch time: 0.10\n",
      "Epoch [5/5], Step [984/1875], Loss: 1.9029, batch time: 0.11\n",
      "Epoch [5/5], Step [985/1875], Loss: 2.0757, batch time: 0.12\n",
      "Epoch [5/5], Step [986/1875], Loss: 1.7424, batch time: 0.13\n",
      "Epoch [5/5], Step [987/1875], Loss: 1.6866, batch time: 0.10\n",
      "Epoch [5/5], Step [988/1875], Loss: 1.9500, batch time: 0.11\n",
      "Epoch [5/5], Step [989/1875], Loss: 1.7690, batch time: 0.12\n",
      "Epoch [5/5], Step [990/1875], Loss: 1.9404, batch time: 0.15\n",
      "Epoch [5/5], Step [991/1875], Loss: 1.9159, batch time: 0.12\n",
      "Epoch [5/5], Step [992/1875], Loss: 1.6749, batch time: 0.10\n",
      "Epoch [5/5], Step [993/1875], Loss: 1.6841, batch time: 0.10\n",
      "Epoch [5/5], Step [994/1875], Loss: 1.7497, batch time: 0.10\n",
      "Epoch [5/5], Step [995/1875], Loss: 1.7058, batch time: 0.10\n",
      "Epoch [5/5], Step [996/1875], Loss: 2.0107, batch time: 0.10\n",
      "Epoch [5/5], Step [997/1875], Loss: 1.7111, batch time: 0.10\n",
      "Epoch [5/5], Step [998/1875], Loss: 2.1155, batch time: 0.11\n",
      "Epoch [5/5], Step [999/1875], Loss: 2.0320, batch time: 0.11\n",
      "Epoch [5/5], Step [1000/1875], Loss: 1.9140, batch time: 0.10\n",
      "Epoch [5/5], Step [1001/1875], Loss: 1.7166, batch time: 0.12\n",
      "Epoch [5/5], Step [1002/1875], Loss: 1.7596, batch time: 0.17\n",
      "Epoch [5/5], Step [1003/1875], Loss: 2.3057, batch time: 0.11\n",
      "Epoch [5/5], Step [1004/1875], Loss: 2.0178, batch time: 0.10\n",
      "Epoch [5/5], Step [1005/1875], Loss: 1.6310, batch time: 0.10\n",
      "Epoch [5/5], Step [1006/1875], Loss: 2.1653, batch time: 0.12\n",
      "Epoch [5/5], Step [1007/1875], Loss: 2.0452, batch time: 0.10\n",
      "Epoch [5/5], Step [1008/1875], Loss: 1.9915, batch time: 0.09\n",
      "Epoch [5/5], Step [1009/1875], Loss: 2.0370, batch time: 0.10\n",
      "Epoch [5/5], Step [1010/1875], Loss: 1.9869, batch time: 0.10\n",
      "Epoch [5/5], Step [1011/1875], Loss: 1.8561, batch time: 0.10\n",
      "Epoch [5/5], Step [1012/1875], Loss: 1.7630, batch time: 0.10\n",
      "Epoch [5/5], Step [1013/1875], Loss: 1.9009, batch time: 0.09\n",
      "Epoch [5/5], Step [1014/1875], Loss: 1.8258, batch time: 0.17\n",
      "Epoch [5/5], Step [1015/1875], Loss: 1.7542, batch time: 0.09\n",
      "Epoch [5/5], Step [1016/1875], Loss: 1.9622, batch time: 0.09\n",
      "Epoch [5/5], Step [1017/1875], Loss: 1.9792, batch time: 0.10\n",
      "Epoch [5/5], Step [1018/1875], Loss: 1.7864, batch time: 0.09\n",
      "Epoch [5/5], Step [1019/1875], Loss: 1.9430, batch time: 0.09\n",
      "Epoch [5/5], Step [1020/1875], Loss: 2.0092, batch time: 0.10\n",
      "Epoch [5/5], Step [1021/1875], Loss: 1.9345, batch time: 0.23\n",
      "Epoch [5/5], Step [1022/1875], Loss: 1.9544, batch time: 0.12\n",
      "Epoch [5/5], Step [1023/1875], Loss: 2.0015, batch time: 0.11\n",
      "Epoch [5/5], Step [1024/1875], Loss: 2.0329, batch time: 0.09\n",
      "Epoch [5/5], Step [1025/1875], Loss: 1.8475, batch time: 0.11\n",
      "Epoch [5/5], Step [1026/1875], Loss: 1.9616, batch time: 0.09\n",
      "Epoch [5/5], Step [1027/1875], Loss: 1.7583, batch time: 0.09\n",
      "Epoch [5/5], Step [1028/1875], Loss: 1.6644, batch time: 0.09\n",
      "Epoch [5/5], Step [1029/1875], Loss: 1.8274, batch time: 0.10\n",
      "Epoch [5/5], Step [1030/1875], Loss: 1.8209, batch time: 0.20\n",
      "Epoch [5/5], Step [1031/1875], Loss: 1.9252, batch time: 0.17\n",
      "Epoch [5/5], Step [1032/1875], Loss: 1.6018, batch time: 0.09\n",
      "Epoch [5/5], Step [1033/1875], Loss: 1.7595, batch time: 0.09\n",
      "Epoch [5/5], Step [1034/1875], Loss: 1.8772, batch time: 0.09\n",
      "Epoch [5/5], Step [1035/1875], Loss: 2.1325, batch time: 0.15\n",
      "Epoch [5/5], Step [1036/1875], Loss: 1.6553, batch time: 0.09\n",
      "Epoch [5/5], Step [1037/1875], Loss: 1.9416, batch time: 0.15\n",
      "Epoch [5/5], Step [1038/1875], Loss: 1.9120, batch time: 0.09\n",
      "Epoch [5/5], Step [1039/1875], Loss: 2.1790, batch time: 0.09\n",
      "Epoch [5/5], Step [1040/1875], Loss: 1.9186, batch time: 0.09\n",
      "Epoch [5/5], Step [1041/1875], Loss: 1.7505, batch time: 0.09\n",
      "Epoch [5/5], Step [1042/1875], Loss: 1.8289, batch time: 0.09\n",
      "Epoch [5/5], Step [1043/1875], Loss: 1.7712, batch time: 0.14\n",
      "Epoch [5/5], Step [1044/1875], Loss: 2.2453, batch time: 0.09\n",
      "Epoch [5/5], Step [1045/1875], Loss: 1.8536, batch time: 0.09\n",
      "Epoch [5/5], Step [1046/1875], Loss: 1.9106, batch time: 0.10\n",
      "Epoch [5/5], Step [1047/1875], Loss: 1.8052, batch time: 0.09\n",
      "Epoch [5/5], Step [1048/1875], Loss: 1.7703, batch time: 0.09\n",
      "Epoch [5/5], Step [1049/1875], Loss: 2.0092, batch time: 0.09\n",
      "Epoch [5/5], Step [1050/1875], Loss: 1.6528, batch time: 0.09\n",
      "Epoch [5/5], Step [1051/1875], Loss: 1.8635, batch time: 0.09\n",
      "Epoch [5/5], Step [1052/1875], Loss: 1.8917, batch time: 0.09\n",
      "Epoch [5/5], Step [1053/1875], Loss: 1.8196, batch time: 0.09\n",
      "Epoch [5/5], Step [1054/1875], Loss: 1.7972, batch time: 0.11\n",
      "Epoch [5/5], Step [1055/1875], Loss: 1.6961, batch time: 0.16\n",
      "Epoch [5/5], Step [1056/1875], Loss: 1.7602, batch time: 0.10\n",
      "Epoch [5/5], Step [1057/1875], Loss: 1.9402, batch time: 0.10\n",
      "Epoch [5/5], Step [1058/1875], Loss: 2.0450, batch time: 0.09\n",
      "Epoch [5/5], Step [1059/1875], Loss: 1.8013, batch time: 0.10\n",
      "Epoch [5/5], Step [1060/1875], Loss: 1.6768, batch time: 0.09\n",
      "Epoch [5/5], Step [1061/1875], Loss: 1.8451, batch time: 0.11\n",
      "Epoch [5/5], Step [1062/1875], Loss: 1.8866, batch time: 0.09\n",
      "Epoch [5/5], Step [1063/1875], Loss: 1.6791, batch time: 0.12\n",
      "Epoch [5/5], Step [1064/1875], Loss: 1.9766, batch time: 0.12\n",
      "Epoch [5/5], Step [1065/1875], Loss: 2.0092, batch time: 0.15\n",
      "Epoch [5/5], Step [1066/1875], Loss: 1.8437, batch time: 0.10\n",
      "Epoch [5/5], Step [1067/1875], Loss: 2.1345, batch time: 0.12\n",
      "Epoch [5/5], Step [1068/1875], Loss: 1.8621, batch time: 0.13\n",
      "Epoch [5/5], Step [1069/1875], Loss: 1.6629, batch time: 0.10\n",
      "Epoch [5/5], Step [1070/1875], Loss: 1.9853, batch time: 0.09\n",
      "Epoch [5/5], Step [1071/1875], Loss: 1.7980, batch time: 0.13\n",
      "Epoch [5/5], Step [1072/1875], Loss: 1.7034, batch time: 0.09\n",
      "Epoch [5/5], Step [1073/1875], Loss: 2.0018, batch time: 0.09\n",
      "Epoch [5/5], Step [1074/1875], Loss: 1.7203, batch time: 0.10\n",
      "Epoch [5/5], Step [1075/1875], Loss: 1.9394, batch time: 0.10\n",
      "Epoch [5/5], Step [1076/1875], Loss: 1.9292, batch time: 0.11\n",
      "Epoch [5/5], Step [1077/1875], Loss: 2.0342, batch time: 0.10\n",
      "Epoch [5/5], Step [1078/1875], Loss: 2.1214, batch time: 0.10\n",
      "Epoch [5/5], Step [1079/1875], Loss: 1.7198, batch time: 0.10\n",
      "Epoch [5/5], Step [1080/1875], Loss: 1.5184, batch time: 0.09\n",
      "Epoch [5/5], Step [1081/1875], Loss: 2.0427, batch time: 0.10\n",
      "Epoch [5/5], Step [1082/1875], Loss: 1.7245, batch time: 0.13\n",
      "Epoch [5/5], Step [1083/1875], Loss: 2.2015, batch time: 0.09\n",
      "Epoch [5/5], Step [1084/1875], Loss: 1.8816, batch time: 0.10\n",
      "Epoch [5/5], Step [1085/1875], Loss: 1.9458, batch time: 0.13\n",
      "Epoch [5/5], Step [1086/1875], Loss: 1.5674, batch time: 0.10\n",
      "Epoch [5/5], Step [1087/1875], Loss: 2.1173, batch time: 0.12\n",
      "Epoch [5/5], Step [1088/1875], Loss: 2.2335, batch time: 0.19\n",
      "Epoch [5/5], Step [1089/1875], Loss: 1.7615, batch time: 0.11\n",
      "Epoch [5/5], Step [1090/1875], Loss: 1.7029, batch time: 0.09\n",
      "Epoch [5/5], Step [1091/1875], Loss: 1.8186, batch time: 0.15\n",
      "Epoch [5/5], Step [1092/1875], Loss: 1.8896, batch time: 0.09\n",
      "Epoch [5/5], Step [1093/1875], Loss: 1.8850, batch time: 0.09\n",
      "Epoch [5/5], Step [1094/1875], Loss: 2.0130, batch time: 0.10\n",
      "Epoch [5/5], Step [1095/1875], Loss: 1.7646, batch time: 0.10\n",
      "Epoch [5/5], Step [1096/1875], Loss: 1.8591, batch time: 0.13\n",
      "Epoch [5/5], Step [1097/1875], Loss: 1.9730, batch time: 0.16\n",
      "Epoch [5/5], Step [1098/1875], Loss: 1.6413, batch time: 0.12\n",
      "Epoch [5/5], Step [1099/1875], Loss: 2.0591, batch time: 0.11\n",
      "Epoch [5/5], Step [1100/1875], Loss: 1.9448, batch time: 0.09\n",
      "Epoch [5/5], Step [1101/1875], Loss: 2.0429, batch time: 0.16\n",
      "Epoch [5/5], Step [1102/1875], Loss: 1.5626, batch time: 0.25\n",
      "Epoch [5/5], Step [1103/1875], Loss: 2.2159, batch time: 0.10\n",
      "Epoch [5/5], Step [1104/1875], Loss: 1.9217, batch time: 0.13\n",
      "Epoch [5/5], Step [1105/1875], Loss: 1.9558, batch time: 0.10\n",
      "Epoch [5/5], Step [1106/1875], Loss: 1.9489, batch time: 0.09\n",
      "Epoch [5/5], Step [1107/1875], Loss: 1.8666, batch time: -0.84\n",
      "Epoch [5/5], Step [1108/1875], Loss: 2.0009, batch time: 0.09\n",
      "Epoch [5/5], Step [1109/1875], Loss: 2.1548, batch time: 0.09\n",
      "Epoch [5/5], Step [1110/1875], Loss: 2.1429, batch time: 0.15\n",
      "Epoch [5/5], Step [1111/1875], Loss: 2.0375, batch time: 0.12\n",
      "Epoch [5/5], Step [1112/1875], Loss: 1.9077, batch time: 0.11\n",
      "Epoch [5/5], Step [1113/1875], Loss: 2.0309, batch time: 0.13\n",
      "Epoch [5/5], Step [1114/1875], Loss: 1.9920, batch time: 0.10\n",
      "Epoch [5/5], Step [1115/1875], Loss: 1.9463, batch time: 0.09\n",
      "Epoch [5/5], Step [1116/1875], Loss: 1.9676, batch time: 0.11\n",
      "Epoch [5/5], Step [1117/1875], Loss: 1.8839, batch time: 0.13\n",
      "Epoch [5/5], Step [1118/1875], Loss: 1.9652, batch time: 0.13\n",
      "Epoch [5/5], Step [1119/1875], Loss: 1.7770, batch time: 0.10\n",
      "Epoch [5/5], Step [1120/1875], Loss: 1.7901, batch time: 0.09\n",
      "Epoch [5/5], Step [1121/1875], Loss: 1.9410, batch time: 0.10\n",
      "Epoch [5/5], Step [1122/1875], Loss: 1.9999, batch time: 0.09\n",
      "Epoch [5/5], Step [1123/1875], Loss: 1.5989, batch time: 0.09\n",
      "Epoch [5/5], Step [1124/1875], Loss: 1.9306, batch time: 0.10\n",
      "Epoch [5/5], Step [1125/1875], Loss: 1.8556, batch time: 0.09\n",
      "Epoch [5/5], Step [1126/1875], Loss: 1.9241, batch time: 0.09\n",
      "Epoch [5/5], Step [1127/1875], Loss: 1.9665, batch time: 0.09\n",
      "Epoch [5/5], Step [1128/1875], Loss: 1.8083, batch time: 0.09\n",
      "Epoch [5/5], Step [1129/1875], Loss: 1.8439, batch time: 0.10\n",
      "Epoch [5/5], Step [1130/1875], Loss: 1.7982, batch time: 0.10\n",
      "Epoch [5/5], Step [1131/1875], Loss: 1.8246, batch time: 0.11\n",
      "Epoch [5/5], Step [1132/1875], Loss: 1.9323, batch time: 0.10\n",
      "Epoch [5/5], Step [1133/1875], Loss: 1.7690, batch time: 0.16\n",
      "Epoch [5/5], Step [1134/1875], Loss: 1.7096, batch time: 0.10\n",
      "Epoch [5/5], Step [1135/1875], Loss: 1.8584, batch time: 0.09\n",
      "Epoch [5/5], Step [1136/1875], Loss: 1.8363, batch time: 0.09\n",
      "Epoch [5/5], Step [1137/1875], Loss: 2.0170, batch time: 0.10\n",
      "Epoch [5/5], Step [1138/1875], Loss: 1.6367, batch time: 0.09\n",
      "Epoch [5/5], Step [1139/1875], Loss: 1.8653, batch time: 0.09\n",
      "Epoch [5/5], Step [1140/1875], Loss: 1.7972, batch time: 0.10\n",
      "Epoch [5/5], Step [1141/1875], Loss: 1.8181, batch time: 0.09\n",
      "Epoch [5/5], Step [1142/1875], Loss: 1.7892, batch time: 0.10\n",
      "Epoch [5/5], Step [1143/1875], Loss: 1.9307, batch time: 0.10\n",
      "Epoch [5/5], Step [1144/1875], Loss: 1.8381, batch time: 0.09\n",
      "Epoch [5/5], Step [1145/1875], Loss: 1.9302, batch time: 0.09\n",
      "Epoch [5/5], Step [1146/1875], Loss: 1.8764, batch time: 0.10\n",
      "Epoch [5/5], Step [1147/1875], Loss: 1.8881, batch time: 0.09\n",
      "Epoch [5/5], Step [1148/1875], Loss: 2.0400, batch time: 0.10\n",
      "Epoch [5/5], Step [1149/1875], Loss: 1.9302, batch time: 0.12\n",
      "Epoch [5/5], Step [1150/1875], Loss: 1.6681, batch time: 0.16\n",
      "Epoch [5/5], Step [1151/1875], Loss: 1.8431, batch time: 0.10\n",
      "Epoch [5/5], Step [1152/1875], Loss: 1.9554, batch time: 0.13\n",
      "Epoch [5/5], Step [1153/1875], Loss: 1.3749, batch time: 0.12\n",
      "Epoch [5/5], Step [1154/1875], Loss: 1.8574, batch time: 0.09\n",
      "Epoch [5/5], Step [1155/1875], Loss: 1.9668, batch time: 0.10\n",
      "Epoch [5/5], Step [1156/1875], Loss: 1.9406, batch time: 0.10\n",
      "Epoch [5/5], Step [1157/1875], Loss: 2.0380, batch time: 0.10\n",
      "Epoch [5/5], Step [1158/1875], Loss: 1.8045, batch time: 0.18\n",
      "Epoch [5/5], Step [1159/1875], Loss: 1.7027, batch time: 0.10\n",
      "Epoch [5/5], Step [1160/1875], Loss: 1.8293, batch time: 0.13\n",
      "Epoch [5/5], Step [1161/1875], Loss: 1.9173, batch time: 0.13\n",
      "Epoch [5/5], Step [1162/1875], Loss: 1.9928, batch time: 0.14\n",
      "Epoch [5/5], Step [1163/1875], Loss: 1.8331, batch time: 0.13\n",
      "Epoch [5/5], Step [1164/1875], Loss: 1.9304, batch time: 0.13\n",
      "Epoch [5/5], Step [1165/1875], Loss: 1.8932, batch time: 0.11\n",
      "Epoch [5/5], Step [1166/1875], Loss: 1.8015, batch time: 0.10\n",
      "Epoch [5/5], Step [1167/1875], Loss: 1.8972, batch time: 0.13\n",
      "Epoch [5/5], Step [1168/1875], Loss: 1.8590, batch time: 0.20\n",
      "Epoch [5/5], Step [1169/1875], Loss: 1.6843, batch time: 0.13\n",
      "Epoch [5/5], Step [1170/1875], Loss: 1.9665, batch time: 0.10\n",
      "Epoch [5/5], Step [1171/1875], Loss: 1.8840, batch time: 0.09\n",
      "Epoch [5/5], Step [1172/1875], Loss: 2.0422, batch time: 0.13\n",
      "Epoch [5/5], Step [1173/1875], Loss: 1.8967, batch time: 0.13\n",
      "Epoch [5/5], Step [1174/1875], Loss: 1.9060, batch time: 0.09\n",
      "Epoch [5/5], Step [1175/1875], Loss: 1.7733, batch time: 0.17\n",
      "Epoch [5/5], Step [1176/1875], Loss: 1.8700, batch time: 0.13\n",
      "Epoch [5/5], Step [1177/1875], Loss: 1.7984, batch time: 0.11\n",
      "Epoch [5/5], Step [1178/1875], Loss: 1.8700, batch time: 0.09\n",
      "Epoch [5/5], Step [1179/1875], Loss: 1.8082, batch time: 0.19\n",
      "Epoch [5/5], Step [1180/1875], Loss: 1.9332, batch time: 0.12\n",
      "Epoch [5/5], Step [1181/1875], Loss: 1.7733, batch time: 0.09\n",
      "Epoch [5/5], Step [1182/1875], Loss: 1.7741, batch time: 0.09\n",
      "Epoch [5/5], Step [1183/1875], Loss: 1.7496, batch time: 0.13\n",
      "Epoch [5/5], Step [1184/1875], Loss: 1.9052, batch time: 0.10\n",
      "Epoch [5/5], Step [1185/1875], Loss: 1.8275, batch time: 0.10\n",
      "Epoch [5/5], Step [1186/1875], Loss: 2.0369, batch time: 0.10\n",
      "Epoch [5/5], Step [1187/1875], Loss: 1.9132, batch time: 0.12\n",
      "Epoch [5/5], Step [1188/1875], Loss: 1.9304, batch time: 0.09\n",
      "Epoch [5/5], Step [1189/1875], Loss: 1.9232, batch time: 0.17\n",
      "Epoch [5/5], Step [1190/1875], Loss: 2.0962, batch time: 0.13\n",
      "Epoch [5/5], Step [1191/1875], Loss: 2.0516, batch time: 0.09\n",
      "Epoch [5/5], Step [1192/1875], Loss: 1.9604, batch time: 0.09\n",
      "Epoch [5/5], Step [1193/1875], Loss: 1.8906, batch time: 0.15\n",
      "Epoch [5/5], Step [1194/1875], Loss: 1.5955, batch time: 0.10\n",
      "Epoch [5/5], Step [1195/1875], Loss: 1.9966, batch time: 0.09\n",
      "Epoch [5/5], Step [1196/1875], Loss: 1.6053, batch time: 0.12\n",
      "Epoch [5/5], Step [1197/1875], Loss: 1.6127, batch time: 0.10\n",
      "Epoch [5/5], Step [1198/1875], Loss: 1.5784, batch time: 0.13\n",
      "Epoch [5/5], Step [1199/1875], Loss: 1.9378, batch time: 0.09\n",
      "Epoch [5/5], Step [1200/1875], Loss: 1.6859, batch time: 0.09\n",
      "Epoch [5/5], Step [1201/1875], Loss: 1.9781, batch time: 0.10\n",
      "Epoch [5/5], Step [1202/1875], Loss: 2.0193, batch time: 0.09\n",
      "Epoch [5/5], Step [1203/1875], Loss: 1.7815, batch time: 0.14\n",
      "Epoch [5/5], Step [1204/1875], Loss: 1.5589, batch time: 0.18\n",
      "Epoch [5/5], Step [1205/1875], Loss: 2.0630, batch time: 0.10\n",
      "Epoch [5/5], Step [1206/1875], Loss: 1.8083, batch time: 0.10\n",
      "Epoch [5/5], Step [1207/1875], Loss: 1.7654, batch time: 0.12\n",
      "Epoch [5/5], Step [1208/1875], Loss: 1.8862, batch time: 0.10\n",
      "Epoch [5/5], Step [1209/1875], Loss: 1.8026, batch time: 0.13\n",
      "Epoch [5/5], Step [1210/1875], Loss: 1.8330, batch time: 0.12\n",
      "Epoch [5/5], Step [1211/1875], Loss: 1.5920, batch time: 0.10\n",
      "Epoch [5/5], Step [1212/1875], Loss: 1.6979, batch time: 0.10\n",
      "Epoch [5/5], Step [1213/1875], Loss: 1.9440, batch time: 0.09\n",
      "Epoch [5/5], Step [1214/1875], Loss: 1.9492, batch time: 0.10\n",
      "Epoch [5/5], Step [1215/1875], Loss: 1.8455, batch time: 0.10\n",
      "Epoch [5/5], Step [1216/1875], Loss: 1.7786, batch time: 0.09\n",
      "Epoch [5/5], Step [1217/1875], Loss: 1.8660, batch time: 0.13\n",
      "Epoch [5/5], Step [1218/1875], Loss: 1.7528, batch time: 0.11\n",
      "Epoch [5/5], Step [1219/1875], Loss: 1.8661, batch time: 0.10\n",
      "Epoch [5/5], Step [1220/1875], Loss: 1.8882, batch time: 0.10\n",
      "Epoch [5/5], Step [1221/1875], Loss: 1.9226, batch time: 0.18\n",
      "Epoch [5/5], Step [1222/1875], Loss: 1.8953, batch time: 0.12\n",
      "Epoch [5/5], Step [1223/1875], Loss: 1.6869, batch time: 0.11\n",
      "Epoch [5/5], Step [1224/1875], Loss: 1.9069, batch time: 0.09\n",
      "Epoch [5/5], Step [1225/1875], Loss: 2.0606, batch time: 0.09\n",
      "Epoch [5/5], Step [1226/1875], Loss: 1.4918, batch time: 0.12\n",
      "Epoch [5/5], Step [1227/1875], Loss: 1.9603, batch time: 0.09\n",
      "Epoch [5/5], Step [1228/1875], Loss: 1.9328, batch time: 0.09\n",
      "Epoch [5/5], Step [1229/1875], Loss: 1.7904, batch time: 0.12\n",
      "Epoch [5/5], Step [1230/1875], Loss: 1.7856, batch time: 0.10\n",
      "Epoch [5/5], Step [1231/1875], Loss: 1.7920, batch time: 0.10\n",
      "Epoch [5/5], Step [1232/1875], Loss: 1.8124, batch time: 0.11\n",
      "Epoch [5/5], Step [1233/1875], Loss: 1.8699, batch time: 0.11\n",
      "Epoch [5/5], Step [1234/1875], Loss: 1.7125, batch time: 0.09\n",
      "Epoch [5/5], Step [1235/1875], Loss: 2.0533, batch time: 0.11\n",
      "Epoch [5/5], Step [1236/1875], Loss: 1.8856, batch time: 0.10\n",
      "Epoch [5/5], Step [1237/1875], Loss: 1.6181, batch time: 0.09\n",
      "Epoch [5/5], Step [1238/1875], Loss: 1.8207, batch time: 0.10\n",
      "Epoch [5/5], Step [1239/1875], Loss: 1.9015, batch time: 0.11\n",
      "Epoch [5/5], Step [1240/1875], Loss: 1.9888, batch time: 0.10\n",
      "Epoch [5/5], Step [1241/1875], Loss: 1.9082, batch time: 0.12\n",
      "Epoch [5/5], Step [1242/1875], Loss: 1.7288, batch time: 0.09\n",
      "Epoch [5/5], Step [1243/1875], Loss: 1.7511, batch time: 0.09\n",
      "Epoch [5/5], Step [1244/1875], Loss: 1.7450, batch time: 0.09\n",
      "Epoch [5/5], Step [1245/1875], Loss: 2.0001, batch time: 0.09\n",
      "Epoch [5/5], Step [1246/1875], Loss: 1.8426, batch time: 0.09\n",
      "Epoch [5/5], Step [1247/1875], Loss: 1.7546, batch time: 0.09\n",
      "Epoch [5/5], Step [1248/1875], Loss: 1.7882, batch time: 0.10\n",
      "Epoch [5/5], Step [1249/1875], Loss: 1.8165, batch time: 0.12\n",
      "Epoch [5/5], Step [1250/1875], Loss: 1.7932, batch time: 0.13\n",
      "Epoch [5/5], Step [1251/1875], Loss: 1.8311, batch time: 0.09\n",
      "Epoch [5/5], Step [1252/1875], Loss: 1.6732, batch time: 0.09\n",
      "Epoch [5/5], Step [1253/1875], Loss: 1.9462, batch time: 0.10\n",
      "Epoch [5/5], Step [1254/1875], Loss: 2.1502, batch time: 0.10\n",
      "Epoch [5/5], Step [1255/1875], Loss: 1.7685, batch time: 0.09\n",
      "Epoch [5/5], Step [1256/1875], Loss: 1.8131, batch time: 0.25\n",
      "Epoch [5/5], Step [1257/1875], Loss: 1.8941, batch time: 0.09\n",
      "Epoch [5/5], Step [1258/1875], Loss: 2.0729, batch time: 0.11\n",
      "Epoch [5/5], Step [1259/1875], Loss: 1.7454, batch time: 0.10\n",
      "Epoch [5/5], Step [1260/1875], Loss: 2.1518, batch time: 0.10\n",
      "Epoch [5/5], Step [1261/1875], Loss: 1.7132, batch time: 0.12\n",
      "Epoch [5/5], Step [1262/1875], Loss: 1.5384, batch time: 0.09\n",
      "Epoch [5/5], Step [1263/1875], Loss: 1.9634, batch time: 0.09\n",
      "Epoch [5/5], Step [1264/1875], Loss: 1.9220, batch time: 0.16\n",
      "Epoch [5/5], Step [1265/1875], Loss: 2.0011, batch time: 0.09\n",
      "Epoch [5/5], Step [1266/1875], Loss: 1.5929, batch time: 0.09\n",
      "Epoch [5/5], Step [1267/1875], Loss: 1.8014, batch time: 0.10\n",
      "Epoch [5/5], Step [1268/1875], Loss: 1.9097, batch time: 0.09\n",
      "Epoch [5/5], Step [1269/1875], Loss: 2.0229, batch time: 0.18\n",
      "Epoch [5/5], Step [1270/1875], Loss: 1.7966, batch time: 0.09\n",
      "Epoch [5/5], Step [1271/1875], Loss: 1.8845, batch time: 0.14\n",
      "Epoch [5/5], Step [1272/1875], Loss: 2.0270, batch time: 0.09\n",
      "Epoch [5/5], Step [1273/1875], Loss: 1.7519, batch time: 0.12\n",
      "Epoch [5/5], Step [1274/1875], Loss: 1.8416, batch time: 0.12\n",
      "Epoch [5/5], Step [1275/1875], Loss: 2.1561, batch time: 0.13\n",
      "Epoch [5/5], Step [1276/1875], Loss: 2.0157, batch time: 0.11\n",
      "Epoch [5/5], Step [1277/1875], Loss: 1.8154, batch time: 0.10\n",
      "Epoch [5/5], Step [1278/1875], Loss: 1.8298, batch time: 0.14\n",
      "Epoch [5/5], Step [1279/1875], Loss: 1.7954, batch time: 0.11\n",
      "Epoch [5/5], Step [1280/1875], Loss: 1.7690, batch time: 0.11\n",
      "Epoch [5/5], Step [1281/1875], Loss: 1.8213, batch time: 0.12\n",
      "Epoch [5/5], Step [1282/1875], Loss: 1.9751, batch time: 0.13\n",
      "Epoch [5/5], Step [1283/1875], Loss: 1.7880, batch time: 0.13\n",
      "Epoch [5/5], Step [1284/1875], Loss: 1.6210, batch time: 0.11\n",
      "Epoch [5/5], Step [1285/1875], Loss: 1.8920, batch time: 0.09\n",
      "Epoch [5/5], Step [1286/1875], Loss: 2.1824, batch time: 0.10\n",
      "Epoch [5/5], Step [1287/1875], Loss: 2.2581, batch time: 0.09\n",
      "Epoch [5/5], Step [1288/1875], Loss: 2.0263, batch time: 0.09\n",
      "Epoch [5/5], Step [1289/1875], Loss: 1.8690, batch time: 0.10\n",
      "Epoch [5/5], Step [1290/1875], Loss: 1.8947, batch time: 0.10\n",
      "Epoch [5/5], Step [1291/1875], Loss: 1.6331, batch time: 0.10\n",
      "Epoch [5/5], Step [1292/1875], Loss: 1.6671, batch time: 0.10\n",
      "Epoch [5/5], Step [1293/1875], Loss: 1.8959, batch time: 0.09\n",
      "Epoch [5/5], Step [1294/1875], Loss: 2.1106, batch time: 0.10\n",
      "Epoch [5/5], Step [1295/1875], Loss: 1.7614, batch time: 0.09\n",
      "Epoch [5/5], Step [1296/1875], Loss: 1.7675, batch time: 0.11\n",
      "Epoch [5/5], Step [1297/1875], Loss: 1.8727, batch time: 0.10\n",
      "Epoch [5/5], Step [1298/1875], Loss: 1.9653, batch time: 0.10\n",
      "Epoch [5/5], Step [1299/1875], Loss: 1.8692, batch time: 0.11\n",
      "Epoch [5/5], Step [1300/1875], Loss: 1.5929, batch time: 0.10\n",
      "Epoch [5/5], Step [1301/1875], Loss: 1.9766, batch time: 0.12\n",
      "Epoch [5/5], Step [1302/1875], Loss: 1.8161, batch time: 0.10\n",
      "Epoch [5/5], Step [1303/1875], Loss: 2.0460, batch time: 0.10\n",
      "Epoch [5/5], Step [1304/1875], Loss: 2.2559, batch time: 0.09\n",
      "Epoch [5/5], Step [1305/1875], Loss: 1.9096, batch time: 0.12\n",
      "Epoch [5/5], Step [1306/1875], Loss: 1.7914, batch time: 0.12\n",
      "Epoch [5/5], Step [1307/1875], Loss: 1.8012, batch time: 0.10\n",
      "Epoch [5/5], Step [1308/1875], Loss: 1.8089, batch time: 0.18\n",
      "Epoch [5/5], Step [1309/1875], Loss: 2.1162, batch time: 0.10\n",
      "Epoch [5/5], Step [1310/1875], Loss: 1.9852, batch time: 0.12\n",
      "Epoch [5/5], Step [1311/1875], Loss: 2.3130, batch time: 0.09\n",
      "Epoch [5/5], Step [1312/1875], Loss: 2.0025, batch time: 0.10\n",
      "Epoch [5/5], Step [1313/1875], Loss: 1.8154, batch time: 0.12\n",
      "Epoch [5/5], Step [1314/1875], Loss: 1.8397, batch time: 0.12\n",
      "Epoch [5/5], Step [1315/1875], Loss: 1.7627, batch time: 0.09\n",
      "Epoch [5/5], Step [1316/1875], Loss: 1.8759, batch time: 0.10\n",
      "Epoch [5/5], Step [1317/1875], Loss: 1.8306, batch time: 0.10\n",
      "Epoch [5/5], Step [1318/1875], Loss: 1.9740, batch time: 0.09\n",
      "Epoch [5/5], Step [1319/1875], Loss: 2.0113, batch time: 0.09\n",
      "Epoch [5/5], Step [1320/1875], Loss: 1.7503, batch time: 0.12\n",
      "Epoch [5/5], Step [1321/1875], Loss: 1.6027, batch time: 0.10\n",
      "Epoch [5/5], Step [1322/1875], Loss: 2.0651, batch time: 0.14\n",
      "Epoch [5/5], Step [1323/1875], Loss: 1.8966, batch time: 0.09\n",
      "Epoch [5/5], Step [1324/1875], Loss: 1.9160, batch time: 0.12\n",
      "Epoch [5/5], Step [1325/1875], Loss: 1.9027, batch time: 0.11\n",
      "Epoch [5/5], Step [1326/1875], Loss: 2.0236, batch time: 0.10\n",
      "Epoch [5/5], Step [1327/1875], Loss: 1.9620, batch time: 0.10\n",
      "Epoch [5/5], Step [1328/1875], Loss: 1.8495, batch time: 0.09\n",
      "Epoch [5/5], Step [1329/1875], Loss: 1.9915, batch time: 0.13\n",
      "Epoch [5/5], Step [1330/1875], Loss: 1.9150, batch time: 0.14\n",
      "Epoch [5/5], Step [1331/1875], Loss: 1.9724, batch time: 0.10\n",
      "Epoch [5/5], Step [1332/1875], Loss: 1.8100, batch time: 0.10\n",
      "Epoch [5/5], Step [1333/1875], Loss: 1.7266, batch time: 0.11\n",
      "Epoch [5/5], Step [1334/1875], Loss: 1.8255, batch time: 0.10\n",
      "Epoch [5/5], Step [1335/1875], Loss: 2.0771, batch time: 0.09\n",
      "Epoch [5/5], Step [1336/1875], Loss: 1.8597, batch time: 0.13\n",
      "Epoch [5/5], Step [1337/1875], Loss: 1.6423, batch time: 0.09\n",
      "Epoch [5/5], Step [1338/1875], Loss: 1.8793, batch time: 0.09\n",
      "Epoch [5/5], Step [1339/1875], Loss: 1.8178, batch time: 0.12\n",
      "Epoch [5/5], Step [1340/1875], Loss: 1.8734, batch time: 0.09\n",
      "Epoch [5/5], Step [1341/1875], Loss: 1.7944, batch time: 0.10\n",
      "Epoch [5/5], Step [1342/1875], Loss: 1.9827, batch time: 0.10\n",
      "Epoch [5/5], Step [1343/1875], Loss: 1.8929, batch time: 0.10\n",
      "Epoch [5/5], Step [1344/1875], Loss: 1.9434, batch time: 0.09\n",
      "Epoch [5/5], Step [1345/1875], Loss: 1.9648, batch time: 0.10\n",
      "Epoch [5/5], Step [1346/1875], Loss: 1.6800, batch time: 0.09\n",
      "Epoch [5/5], Step [1347/1875], Loss: 1.9823, batch time: 0.09\n",
      "Epoch [5/5], Step [1348/1875], Loss: 1.6707, batch time: 0.10\n",
      "Epoch [5/5], Step [1349/1875], Loss: 1.5867, batch time: 0.09\n",
      "Epoch [5/5], Step [1350/1875], Loss: 1.9355, batch time: 0.09\n",
      "Epoch [5/5], Step [1351/1875], Loss: 1.7787, batch time: 0.10\n",
      "Epoch [5/5], Step [1352/1875], Loss: 1.8940, batch time: 0.09\n",
      "Epoch [5/5], Step [1353/1875], Loss: 2.0299, batch time: 0.09\n",
      "Epoch [5/5], Step [1354/1875], Loss: 1.8445, batch time: 0.14\n",
      "Epoch [5/5], Step [1355/1875], Loss: 1.8349, batch time: 0.09\n",
      "Epoch [5/5], Step [1356/1875], Loss: 1.7113, batch time: 0.10\n",
      "Epoch [5/5], Step [1357/1875], Loss: 1.7053, batch time: 0.13\n",
      "Epoch [5/5], Step [1358/1875], Loss: 2.0313, batch time: 0.13\n",
      "Epoch [5/5], Step [1359/1875], Loss: 1.9038, batch time: 0.13\n",
      "Epoch [5/5], Step [1360/1875], Loss: 2.0474, batch time: 0.09\n",
      "Epoch [5/5], Step [1361/1875], Loss: 1.7615, batch time: 0.10\n",
      "Epoch [5/5], Step [1362/1875], Loss: 1.9382, batch time: 0.10\n",
      "Epoch [5/5], Step [1363/1875], Loss: 2.0069, batch time: 0.13\n",
      "Epoch [5/5], Step [1364/1875], Loss: 1.7277, batch time: 0.09\n",
      "Epoch [5/5], Step [1365/1875], Loss: 1.8437, batch time: 0.16\n",
      "Epoch [5/5], Step [1366/1875], Loss: 1.8327, batch time: 0.12\n",
      "Epoch [5/5], Step [1367/1875], Loss: 1.8602, batch time: 0.12\n",
      "Epoch [5/5], Step [1368/1875], Loss: 1.8134, batch time: 0.10\n",
      "Epoch [5/5], Step [1369/1875], Loss: 1.8273, batch time: 0.13\n",
      "Epoch [5/5], Step [1370/1875], Loss: 1.7070, batch time: 0.09\n",
      "Epoch [5/5], Step [1371/1875], Loss: 1.9212, batch time: 0.09\n",
      "Epoch [5/5], Step [1372/1875], Loss: 1.7713, batch time: 0.10\n",
      "Epoch [5/5], Step [1373/1875], Loss: 1.7898, batch time: 0.10\n",
      "Epoch [5/5], Step [1374/1875], Loss: 1.8596, batch time: 0.12\n",
      "Epoch [5/5], Step [1375/1875], Loss: 1.8731, batch time: 0.09\n",
      "Epoch [5/5], Step [1376/1875], Loss: 1.9037, batch time: 0.10\n",
      "Epoch [5/5], Step [1377/1875], Loss: 1.8516, batch time: 0.10\n",
      "Epoch [5/5], Step [1378/1875], Loss: 2.0484, batch time: 0.10\n",
      "Epoch [5/5], Step [1379/1875], Loss: 1.7075, batch time: 0.14\n",
      "Epoch [5/5], Step [1380/1875], Loss: 1.3447, batch time: 0.11\n",
      "Epoch [5/5], Step [1381/1875], Loss: 1.7880, batch time: 0.13\n",
      "Epoch [5/5], Step [1382/1875], Loss: 1.8689, batch time: 0.10\n",
      "Epoch [5/5], Step [1383/1875], Loss: 1.9205, batch time: 0.10\n",
      "Epoch [5/5], Step [1384/1875], Loss: 1.6690, batch time: 0.15\n",
      "Epoch [5/5], Step [1385/1875], Loss: 2.1136, batch time: 0.10\n",
      "Epoch [5/5], Step [1386/1875], Loss: 1.7299, batch time: 0.10\n",
      "Epoch [5/5], Step [1387/1875], Loss: 1.5941, batch time: 0.10\n",
      "Epoch [5/5], Step [1388/1875], Loss: 1.6618, batch time: 0.10\n",
      "Epoch [5/5], Step [1389/1875], Loss: 1.7915, batch time: 0.10\n",
      "Epoch [5/5], Step [1390/1875], Loss: 1.7844, batch time: 0.09\n",
      "Epoch [5/5], Step [1391/1875], Loss: 1.7921, batch time: 0.11\n",
      "Epoch [5/5], Step [1392/1875], Loss: 1.8132, batch time: 0.09\n",
      "Epoch [5/5], Step [1393/1875], Loss: 1.8052, batch time: 0.12\n",
      "Epoch [5/5], Step [1394/1875], Loss: 1.8396, batch time: 0.09\n",
      "Epoch [5/5], Step [1395/1875], Loss: 1.7296, batch time: 0.09\n",
      "Epoch [5/5], Step [1396/1875], Loss: 1.7603, batch time: 0.11\n",
      "Epoch [5/5], Step [1397/1875], Loss: 1.9686, batch time: 0.11\n",
      "Epoch [5/5], Step [1398/1875], Loss: 1.8970, batch time: 0.09\n",
      "Epoch [5/5], Step [1399/1875], Loss: 1.7217, batch time: -0.83\n",
      "Epoch [5/5], Step [1400/1875], Loss: 1.9859, batch time: 0.09\n",
      "Epoch [5/5], Step [1401/1875], Loss: 1.6351, batch time: 0.11\n",
      "Epoch [5/5], Step [1402/1875], Loss: 1.8079, batch time: 0.09\n",
      "Epoch [5/5], Step [1403/1875], Loss: 1.6558, batch time: 0.09\n",
      "Epoch [5/5], Step [1404/1875], Loss: 1.7596, batch time: 0.09\n",
      "Epoch [5/5], Step [1405/1875], Loss: 1.6757, batch time: 0.11\n",
      "Epoch [5/5], Step [1406/1875], Loss: 1.7636, batch time: 0.09\n",
      "Epoch [5/5], Step [1407/1875], Loss: 1.5637, batch time: 0.10\n",
      "Epoch [5/5], Step [1408/1875], Loss: 1.9512, batch time: 0.09\n",
      "Epoch [5/5], Step [1409/1875], Loss: 1.6235, batch time: 0.14\n",
      "Epoch [5/5], Step [1410/1875], Loss: 1.9300, batch time: 0.09\n",
      "Epoch [5/5], Step [1411/1875], Loss: 2.1579, batch time: 0.11\n",
      "Epoch [5/5], Step [1412/1875], Loss: 1.7433, batch time: 0.09\n",
      "Epoch [5/5], Step [1413/1875], Loss: 1.6008, batch time: 0.09\n",
      "Epoch [5/5], Step [1414/1875], Loss: 2.1078, batch time: 0.10\n",
      "Epoch [5/5], Step [1415/1875], Loss: 2.0661, batch time: 0.10\n",
      "Epoch [5/5], Step [1416/1875], Loss: 1.9708, batch time: 0.12\n",
      "Epoch [5/5], Step [1417/1875], Loss: 2.0847, batch time: 0.18\n",
      "Epoch [5/5], Step [1418/1875], Loss: 1.5652, batch time: 0.10\n",
      "Epoch [5/5], Step [1419/1875], Loss: 1.8403, batch time: 0.15\n",
      "Epoch [5/5], Step [1420/1875], Loss: 1.7507, batch time: 0.10\n",
      "Epoch [5/5], Step [1421/1875], Loss: 2.1054, batch time: 0.11\n",
      "Epoch [5/5], Step [1422/1875], Loss: 1.7337, batch time: 0.09\n",
      "Epoch [5/5], Step [1423/1875], Loss: 1.8827, batch time: 0.12\n",
      "Epoch [5/5], Step [1424/1875], Loss: 1.6914, batch time: 0.10\n",
      "Epoch [5/5], Step [1425/1875], Loss: 1.9247, batch time: 0.09\n",
      "Epoch [5/5], Step [1426/1875], Loss: 2.0476, batch time: 0.11\n",
      "Epoch [5/5], Step [1427/1875], Loss: 1.8874, batch time: 0.09\n",
      "Epoch [5/5], Step [1428/1875], Loss: 1.8096, batch time: 0.13\n",
      "Epoch [5/5], Step [1429/1875], Loss: 2.2177, batch time: 0.09\n",
      "Epoch [5/5], Step [1430/1875], Loss: 1.5676, batch time: 0.09\n",
      "Epoch [5/5], Step [1431/1875], Loss: 2.0920, batch time: 0.09\n",
      "Epoch [5/5], Step [1432/1875], Loss: 1.8262, batch time: 0.12\n",
      "Epoch [5/5], Step [1433/1875], Loss: 1.9049, batch time: 0.09\n",
      "Epoch [5/5], Step [1434/1875], Loss: 1.8262, batch time: 0.09\n",
      "Epoch [5/5], Step [1435/1875], Loss: 1.8470, batch time: 0.09\n",
      "Epoch [5/5], Step [1436/1875], Loss: 1.7781, batch time: 0.09\n",
      "Epoch [5/5], Step [1437/1875], Loss: 1.6932, batch time: 0.09\n",
      "Epoch [5/5], Step [1438/1875], Loss: 1.9823, batch time: 0.12\n",
      "Epoch [5/5], Step [1439/1875], Loss: 1.7392, batch time: 0.12\n",
      "Epoch [5/5], Step [1440/1875], Loss: 1.9554, batch time: 0.09\n",
      "Epoch [5/5], Step [1441/1875], Loss: 1.7517, batch time: 0.10\n",
      "Epoch [5/5], Step [1442/1875], Loss: 1.7531, batch time: 0.10\n",
      "Epoch [5/5], Step [1443/1875], Loss: 2.1270, batch time: 0.19\n",
      "Epoch [5/5], Step [1444/1875], Loss: 2.2009, batch time: 0.10\n",
      "Epoch [5/5], Step [1445/1875], Loss: 2.0338, batch time: 0.10\n",
      "Epoch [5/5], Step [1446/1875], Loss: 1.6889, batch time: 0.09\n",
      "Epoch [5/5], Step [1447/1875], Loss: 1.8606, batch time: 0.11\n",
      "Epoch [5/5], Step [1448/1875], Loss: 1.8110, batch time: 0.11\n",
      "Epoch [5/5], Step [1449/1875], Loss: 1.8948, batch time: 0.10\n",
      "Epoch [5/5], Step [1450/1875], Loss: 2.0733, batch time: 0.10\n",
      "Epoch [5/5], Step [1451/1875], Loss: 1.9530, batch time: 0.10\n",
      "Epoch [5/5], Step [1452/1875], Loss: 1.9880, batch time: 0.10\n",
      "Epoch [5/5], Step [1453/1875], Loss: 1.6088, batch time: 0.10\n",
      "Epoch [5/5], Step [1454/1875], Loss: 1.7145, batch time: 0.10\n",
      "Epoch [5/5], Step [1455/1875], Loss: 1.8211, batch time: 0.10\n",
      "Epoch [5/5], Step [1456/1875], Loss: 1.6607, batch time: 0.17\n",
      "Epoch [5/5], Step [1457/1875], Loss: 2.1043, batch time: 0.18\n",
      "Epoch [5/5], Step [1458/1875], Loss: 1.5886, batch time: 0.10\n",
      "Epoch [5/5], Step [1459/1875], Loss: 1.8798, batch time: 0.10\n",
      "Epoch [5/5], Step [1460/1875], Loss: 1.7683, batch time: 0.12\n",
      "Epoch [5/5], Step [1461/1875], Loss: 1.7456, batch time: 0.10\n",
      "Epoch [5/5], Step [1462/1875], Loss: 1.7595, batch time: 0.09\n",
      "Epoch [5/5], Step [1463/1875], Loss: 1.6838, batch time: 0.10\n",
      "Epoch [5/5], Step [1464/1875], Loss: 1.9272, batch time: 0.09\n",
      "Epoch [5/5], Step [1465/1875], Loss: 1.7971, batch time: 0.14\n",
      "Epoch [5/5], Step [1466/1875], Loss: 1.6978, batch time: 0.10\n",
      "Epoch [5/5], Step [1467/1875], Loss: 1.8353, batch time: 0.10\n",
      "Epoch [5/5], Step [1468/1875], Loss: 1.8920, batch time: 0.10\n",
      "Epoch [5/5], Step [1469/1875], Loss: 1.9707, batch time: 0.10\n",
      "Epoch [5/5], Step [1470/1875], Loss: 1.9618, batch time: 0.09\n",
      "Epoch [5/5], Step [1471/1875], Loss: 1.8835, batch time: 0.12\n",
      "Epoch [5/5], Step [1472/1875], Loss: 1.4551, batch time: 0.10\n",
      "Epoch [5/5], Step [1473/1875], Loss: 1.8009, batch time: 0.09\n",
      "Epoch [5/5], Step [1474/1875], Loss: 2.0593, batch time: 0.10\n",
      "Epoch [5/5], Step [1475/1875], Loss: 1.9200, batch time: 0.17\n",
      "Epoch [5/5], Step [1476/1875], Loss: 1.9392, batch time: 0.12\n",
      "Epoch [5/5], Step [1477/1875], Loss: 1.7168, batch time: 0.13\n",
      "Epoch [5/5], Step [1478/1875], Loss: 2.0277, batch time: 0.13\n",
      "Epoch [5/5], Step [1479/1875], Loss: 1.8093, batch time: 0.12\n",
      "Epoch [5/5], Step [1480/1875], Loss: 1.7726, batch time: 0.10\n",
      "Epoch [5/5], Step [1481/1875], Loss: 1.8637, batch time: 0.10\n",
      "Epoch [5/5], Step [1482/1875], Loss: 1.6103, batch time: 0.09\n",
      "Epoch [5/5], Step [1483/1875], Loss: 1.7745, batch time: 0.10\n",
      "Epoch [5/5], Step [1484/1875], Loss: 1.9563, batch time: 0.12\n",
      "Epoch [5/5], Step [1485/1875], Loss: 1.8426, batch time: 0.14\n",
      "Epoch [5/5], Step [1486/1875], Loss: 1.9910, batch time: 0.12\n",
      "Epoch [5/5], Step [1487/1875], Loss: 1.6324, batch time: 0.11\n",
      "Epoch [5/5], Step [1488/1875], Loss: 1.8713, batch time: 0.13\n",
      "Epoch [5/5], Step [1489/1875], Loss: 1.7174, batch time: 0.09\n",
      "Epoch [5/5], Step [1490/1875], Loss: 1.8039, batch time: 0.13\n",
      "Epoch [5/5], Step [1491/1875], Loss: 1.7268, batch time: 0.11\n",
      "Epoch [5/5], Step [1492/1875], Loss: 2.0335, batch time: 0.10\n",
      "Epoch [5/5], Step [1493/1875], Loss: 1.7351, batch time: 0.09\n",
      "Epoch [5/5], Step [1494/1875], Loss: 2.0844, batch time: 0.12\n",
      "Epoch [5/5], Step [1495/1875], Loss: 1.6862, batch time: 0.10\n",
      "Epoch [5/5], Step [1496/1875], Loss: 1.7839, batch time: 0.10\n",
      "Epoch [5/5], Step [1497/1875], Loss: 1.9252, batch time: 0.10\n",
      "Epoch [5/5], Step [1498/1875], Loss: 1.8225, batch time: 0.13\n",
      "Epoch [5/5], Step [1499/1875], Loss: 1.8181, batch time: 0.12\n",
      "Epoch [5/5], Step [1500/1875], Loss: 1.7421, batch time: 0.10\n",
      "Epoch [5/5], Step [1501/1875], Loss: 1.8832, batch time: 0.10\n",
      "Epoch [5/5], Step [1502/1875], Loss: 1.9022, batch time: 0.12\n",
      "Epoch [5/5], Step [1503/1875], Loss: 1.7093, batch time: 0.13\n",
      "Epoch [5/5], Step [1504/1875], Loss: 1.9134, batch time: 0.12\n",
      "Epoch [5/5], Step [1505/1875], Loss: 2.0618, batch time: 0.09\n",
      "Epoch [5/5], Step [1506/1875], Loss: 1.9153, batch time: 0.13\n",
      "Epoch [5/5], Step [1507/1875], Loss: 1.7202, batch time: 0.10\n",
      "Epoch [5/5], Step [1508/1875], Loss: 2.0196, batch time: 0.10\n",
      "Epoch [5/5], Step [1509/1875], Loss: 2.0912, batch time: 0.10\n",
      "Epoch [5/5], Step [1510/1875], Loss: 1.7020, batch time: 0.10\n",
      "Epoch [5/5], Step [1511/1875], Loss: 2.0267, batch time: 0.09\n",
      "Epoch [5/5], Step [1512/1875], Loss: 1.7907, batch time: 0.10\n",
      "Epoch [5/5], Step [1513/1875], Loss: 1.7884, batch time: 0.09\n",
      "Epoch [5/5], Step [1514/1875], Loss: 2.0179, batch time: 0.11\n",
      "Epoch [5/5], Step [1515/1875], Loss: 1.9311, batch time: 0.15\n",
      "Epoch [5/5], Step [1516/1875], Loss: 1.9525, batch time: 0.12\n",
      "Epoch [5/5], Step [1517/1875], Loss: 1.9144, batch time: 0.11\n",
      "Epoch [5/5], Step [1518/1875], Loss: 1.9201, batch time: 0.09\n",
      "Epoch [5/5], Step [1519/1875], Loss: 1.6358, batch time: 0.10\n",
      "Epoch [5/5], Step [1520/1875], Loss: 1.8354, batch time: 0.12\n",
      "Epoch [5/5], Step [1521/1875], Loss: 1.7513, batch time: 0.10\n",
      "Epoch [5/5], Step [1522/1875], Loss: 1.7844, batch time: 0.10\n",
      "Epoch [5/5], Step [1523/1875], Loss: 1.8626, batch time: 0.15\n",
      "Epoch [5/5], Step [1524/1875], Loss: 1.9262, batch time: 0.13\n",
      "Epoch [5/5], Step [1525/1875], Loss: 1.8057, batch time: 0.10\n",
      "Epoch [5/5], Step [1526/1875], Loss: 1.7856, batch time: 0.10\n",
      "Epoch [5/5], Step [1527/1875], Loss: 1.5392, batch time: 0.10\n",
      "Epoch [5/5], Step [1528/1875], Loss: 2.0271, batch time: 0.12\n",
      "Epoch [5/5], Step [1529/1875], Loss: 1.7496, batch time: 0.09\n",
      "Epoch [5/5], Step [1530/1875], Loss: 1.9329, batch time: 0.10\n",
      "Epoch [5/5], Step [1531/1875], Loss: 1.8060, batch time: 0.22\n",
      "Epoch [5/5], Step [1532/1875], Loss: 1.5594, batch time: 0.10\n",
      "Epoch [5/5], Step [1533/1875], Loss: 1.8103, batch time: 0.09\n",
      "Epoch [5/5], Step [1534/1875], Loss: 1.8121, batch time: 0.10\n",
      "Epoch [5/5], Step [1535/1875], Loss: 1.6885, batch time: 0.10\n",
      "Epoch [5/5], Step [1536/1875], Loss: 1.7187, batch time: 0.10\n",
      "Epoch [5/5], Step [1537/1875], Loss: 2.0541, batch time: 0.10\n",
      "Epoch [5/5], Step [1538/1875], Loss: 1.9317, batch time: 0.10\n",
      "Epoch [5/5], Step [1539/1875], Loss: 2.1442, batch time: 0.11\n",
      "Epoch [5/5], Step [1540/1875], Loss: 1.8683, batch time: 0.09\n",
      "Epoch [5/5], Step [1541/1875], Loss: 1.8537, batch time: 0.09\n",
      "Epoch [5/5], Step [1542/1875], Loss: 1.5942, batch time: 0.14\n",
      "Epoch [5/5], Step [1543/1875], Loss: 1.7185, batch time: 0.10\n",
      "Epoch [5/5], Step [1544/1875], Loss: 1.6575, batch time: 0.12\n",
      "Epoch [5/5], Step [1545/1875], Loss: 1.7353, batch time: 0.09\n",
      "Epoch [5/5], Step [1546/1875], Loss: 1.6338, batch time: 0.09\n",
      "Epoch [5/5], Step [1547/1875], Loss: 1.7035, batch time: 0.12\n",
      "Epoch [5/5], Step [1548/1875], Loss: 1.8561, batch time: 0.09\n",
      "Epoch [5/5], Step [1549/1875], Loss: 1.7558, batch time: 0.15\n",
      "Epoch [5/5], Step [1550/1875], Loss: 1.8735, batch time: 0.09\n",
      "Epoch [5/5], Step [1551/1875], Loss: 2.1393, batch time: 0.09\n",
      "Epoch [5/5], Step [1552/1875], Loss: 1.5919, batch time: 0.14\n",
      "Epoch [5/5], Step [1553/1875], Loss: 1.8823, batch time: 0.09\n",
      "Epoch [5/5], Step [1554/1875], Loss: 1.9522, batch time: 0.09\n",
      "Epoch [5/5], Step [1555/1875], Loss: 1.9177, batch time: 0.11\n",
      "Epoch [5/5], Step [1556/1875], Loss: 1.7244, batch time: 0.09\n",
      "Epoch [5/5], Step [1557/1875], Loss: 1.8991, batch time: 0.08\n",
      "Epoch [5/5], Step [1558/1875], Loss: 1.9304, batch time: 0.13\n",
      "Epoch [5/5], Step [1559/1875], Loss: 1.6809, batch time: 0.11\n",
      "Epoch [5/5], Step [1560/1875], Loss: 2.0835, batch time: 0.09\n",
      "Epoch [5/5], Step [1561/1875], Loss: 2.1102, batch time: 0.11\n",
      "Epoch [5/5], Step [1562/1875], Loss: 1.9536, batch time: 0.13\n",
      "Epoch [5/5], Step [1563/1875], Loss: 1.8659, batch time: 0.16\n",
      "Epoch [5/5], Step [1564/1875], Loss: 2.1296, batch time: 0.09\n",
      "Epoch [5/5], Step [1565/1875], Loss: 1.9660, batch time: 0.16\n",
      "Epoch [5/5], Step [1566/1875], Loss: 1.7846, batch time: 0.11\n",
      "Epoch [5/5], Step [1567/1875], Loss: 2.0549, batch time: 0.09\n",
      "Epoch [5/5], Step [1568/1875], Loss: 1.6669, batch time: 0.09\n",
      "Epoch [5/5], Step [1569/1875], Loss: 1.7478, batch time: 0.10\n",
      "Epoch [5/5], Step [1570/1875], Loss: 1.9850, batch time: 0.09\n",
      "Epoch [5/5], Step [1571/1875], Loss: 1.9098, batch time: 0.09\n",
      "Epoch [5/5], Step [1572/1875], Loss: 1.7987, batch time: 0.09\n",
      "Epoch [5/5], Step [1573/1875], Loss: 1.9320, batch time: 0.10\n",
      "Epoch [5/5], Step [1574/1875], Loss: 1.8937, batch time: 0.12\n",
      "Epoch [5/5], Step [1575/1875], Loss: 1.9061, batch time: 0.09\n",
      "Epoch [5/5], Step [1576/1875], Loss: 1.8031, batch time: 0.09\n",
      "Epoch [5/5], Step [1577/1875], Loss: 1.8942, batch time: 0.11\n",
      "Epoch [5/5], Step [1578/1875], Loss: 1.8890, batch time: 0.20\n",
      "Epoch [5/5], Step [1579/1875], Loss: 2.0155, batch time: 0.10\n",
      "Epoch [5/5], Step [1580/1875], Loss: 2.0389, batch time: 0.10\n",
      "Epoch [5/5], Step [1581/1875], Loss: 1.7069, batch time: 0.10\n",
      "Epoch [5/5], Step [1582/1875], Loss: 1.7586, batch time: 0.09\n",
      "Epoch [5/5], Step [1583/1875], Loss: 1.8897, batch time: 0.15\n",
      "Epoch [5/5], Step [1584/1875], Loss: 1.8101, batch time: 0.10\n",
      "Epoch [5/5], Step [1585/1875], Loss: 1.9821, batch time: 0.11\n",
      "Epoch [5/5], Step [1586/1875], Loss: 1.8706, batch time: 0.10\n",
      "Epoch [5/5], Step [1587/1875], Loss: 1.7321, batch time: 0.14\n",
      "Epoch [5/5], Step [1588/1875], Loss: 2.0200, batch time: 0.10\n",
      "Epoch [5/5], Step [1589/1875], Loss: 1.8615, batch time: 0.16\n",
      "Epoch [5/5], Step [1590/1875], Loss: 2.0095, batch time: 0.09\n",
      "Epoch [5/5], Step [1591/1875], Loss: 1.7304, batch time: 0.10\n",
      "Epoch [5/5], Step [1592/1875], Loss: 1.5258, batch time: 0.11\n",
      "Epoch [5/5], Step [1593/1875], Loss: 1.8567, batch time: 0.11\n",
      "Epoch [5/5], Step [1594/1875], Loss: 1.8390, batch time: 0.11\n",
      "Epoch [5/5], Step [1595/1875], Loss: 1.8188, batch time: 0.10\n",
      "Epoch [5/5], Step [1596/1875], Loss: 1.7662, batch time: 0.09\n",
      "Epoch [5/5], Step [1597/1875], Loss: 2.0312, batch time: 0.11\n",
      "Epoch [5/5], Step [1598/1875], Loss: 1.6038, batch time: 0.10\n",
      "Epoch [5/5], Step [1599/1875], Loss: 1.7804, batch time: 0.12\n",
      "Epoch [5/5], Step [1600/1875], Loss: 2.0971, batch time: 0.10\n",
      "Epoch [5/5], Step [1601/1875], Loss: 1.7051, batch time: 0.09\n",
      "Epoch [5/5], Step [1602/1875], Loss: 1.8665, batch time: 0.15\n",
      "Epoch [5/5], Step [1603/1875], Loss: 1.9371, batch time: 0.13\n",
      "Epoch [5/5], Step [1604/1875], Loss: 1.8886, batch time: 0.14\n",
      "Epoch [5/5], Step [1605/1875], Loss: 1.8934, batch time: 0.10\n",
      "Epoch [5/5], Step [1606/1875], Loss: 1.7220, batch time: 0.12\n",
      "Epoch [5/5], Step [1607/1875], Loss: 1.8055, batch time: 0.13\n",
      "Epoch [5/5], Step [1608/1875], Loss: 1.8753, batch time: 0.12\n",
      "Epoch [5/5], Step [1609/1875], Loss: 1.7055, batch time: 0.10\n",
      "Epoch [5/5], Step [1610/1875], Loss: 1.8936, batch time: 0.10\n",
      "Epoch [5/5], Step [1611/1875], Loss: 1.8285, batch time: 0.10\n",
      "Epoch [5/5], Step [1612/1875], Loss: 1.8947, batch time: 0.12\n",
      "Epoch [5/5], Step [1613/1875], Loss: 1.7159, batch time: 0.12\n",
      "Epoch [5/5], Step [1614/1875], Loss: 1.6459, batch time: 0.11\n",
      "Epoch [5/5], Step [1615/1875], Loss: 1.8845, batch time: 0.10\n",
      "Epoch [5/5], Step [1616/1875], Loss: 1.6875, batch time: 0.11\n",
      "Epoch [5/5], Step [1617/1875], Loss: 1.6322, batch time: 0.12\n",
      "Epoch [5/5], Step [1618/1875], Loss: 1.8434, batch time: 0.09\n",
      "Epoch [5/5], Step [1619/1875], Loss: 1.9266, batch time: 0.09\n",
      "Epoch [5/5], Step [1620/1875], Loss: 1.8173, batch time: 0.10\n",
      "Epoch [5/5], Step [1621/1875], Loss: 1.8726, batch time: 0.12\n",
      "Epoch [5/5], Step [1622/1875], Loss: 1.8302, batch time: 0.13\n",
      "Epoch [5/5], Step [1623/1875], Loss: 2.0942, batch time: 0.09\n",
      "Epoch [5/5], Step [1624/1875], Loss: 1.5557, batch time: 0.13\n",
      "Epoch [5/5], Step [1625/1875], Loss: 1.8841, batch time: 0.13\n",
      "Epoch [5/5], Step [1626/1875], Loss: 1.9591, batch time: 0.10\n",
      "Epoch [5/5], Step [1627/1875], Loss: 1.5176, batch time: 0.16\n",
      "Epoch [5/5], Step [1628/1875], Loss: 1.8843, batch time: 0.11\n",
      "Epoch [5/5], Step [1629/1875], Loss: 1.8497, batch time: 0.12\n",
      "Epoch [5/5], Step [1630/1875], Loss: 1.6845, batch time: 0.13\n",
      "Epoch [5/5], Step [1631/1875], Loss: 1.7527, batch time: 0.12\n",
      "Epoch [5/5], Step [1632/1875], Loss: 1.7961, batch time: 0.11\n",
      "Epoch [5/5], Step [1633/1875], Loss: 1.6699, batch time: 0.10\n",
      "Epoch [5/5], Step [1634/1875], Loss: 1.7927, batch time: 0.11\n",
      "Epoch [5/5], Step [1635/1875], Loss: 1.5007, batch time: 0.09\n",
      "Epoch [5/5], Step [1636/1875], Loss: 1.7949, batch time: 0.10\n",
      "Epoch [5/5], Step [1637/1875], Loss: 1.7604, batch time: 0.13\n",
      "Epoch [5/5], Step [1638/1875], Loss: 1.8450, batch time: 0.12\n",
      "Epoch [5/5], Step [1639/1875], Loss: 1.8538, batch time: 0.11\n",
      "Epoch [5/5], Step [1640/1875], Loss: 1.7901, batch time: 0.12\n",
      "Epoch [5/5], Step [1641/1875], Loss: 1.8071, batch time: 0.10\n",
      "Epoch [5/5], Step [1642/1875], Loss: 1.8501, batch time: 0.11\n",
      "Epoch [5/5], Step [1643/1875], Loss: 1.6413, batch time: 0.12\n",
      "Epoch [5/5], Step [1644/1875], Loss: 1.8762, batch time: 0.12\n",
      "Epoch [5/5], Step [1645/1875], Loss: 1.9526, batch time: 0.11\n",
      "Epoch [5/5], Step [1646/1875], Loss: 1.8156, batch time: 0.10\n",
      "Epoch [5/5], Step [1647/1875], Loss: 1.6946, batch time: 0.11\n",
      "Epoch [5/5], Step [1648/1875], Loss: 1.8394, batch time: 0.10\n",
      "Epoch [5/5], Step [1649/1875], Loss: 1.8886, batch time: 0.09\n",
      "Epoch [5/5], Step [1650/1875], Loss: 1.7102, batch time: 0.12\n",
      "Epoch [5/5], Step [1651/1875], Loss: 1.5973, batch time: 0.18\n",
      "Epoch [5/5], Step [1652/1875], Loss: 1.9984, batch time: 0.14\n",
      "Epoch [5/5], Step [1653/1875], Loss: 1.7697, batch time: 0.10\n",
      "Epoch [5/5], Step [1654/1875], Loss: 1.5976, batch time: 0.10\n",
      "Epoch [5/5], Step [1655/1875], Loss: 1.8053, batch time: 0.10\n",
      "Epoch [5/5], Step [1656/1875], Loss: 1.6982, batch time: 0.12\n",
      "Epoch [5/5], Step [1657/1875], Loss: 1.7902, batch time: 0.10\n",
      "Epoch [5/5], Step [1658/1875], Loss: 1.6362, batch time: 0.10\n",
      "Epoch [5/5], Step [1659/1875], Loss: 1.7769, batch time: 0.19\n",
      "Epoch [5/5], Step [1660/1875], Loss: 1.6686, batch time: 0.11\n",
      "Epoch [5/5], Step [1661/1875], Loss: 1.8316, batch time: 0.11\n",
      "Epoch [5/5], Step [1662/1875], Loss: 1.7847, batch time: 0.12\n",
      "Epoch [5/5], Step [1663/1875], Loss: 1.6112, batch time: 0.10\n",
      "Epoch [5/5], Step [1664/1875], Loss: 1.7053, batch time: 0.10\n",
      "Epoch [5/5], Step [1665/1875], Loss: 1.7955, batch time: 0.10\n",
      "Epoch [5/5], Step [1666/1875], Loss: 1.9829, batch time: 0.14\n",
      "Epoch [5/5], Step [1667/1875], Loss: 1.7075, batch time: 0.11\n",
      "Epoch [5/5], Step [1668/1875], Loss: 1.6546, batch time: 0.15\n",
      "Epoch [5/5], Step [1669/1875], Loss: 1.9120, batch time: 0.14\n",
      "Epoch [5/5], Step [1670/1875], Loss: 1.7200, batch time: 0.12\n",
      "Epoch [5/5], Step [1671/1875], Loss: 1.8239, batch time: 0.13\n",
      "Epoch [5/5], Step [1672/1875], Loss: 1.6339, batch time: 0.15\n",
      "Epoch [5/5], Step [1673/1875], Loss: 1.6979, batch time: 0.10\n",
      "Epoch [5/5], Step [1674/1875], Loss: 1.7565, batch time: 0.10\n",
      "Epoch [5/5], Step [1675/1875], Loss: 1.6422, batch time: 0.11\n",
      "Epoch [5/5], Step [1676/1875], Loss: 1.6732, batch time: 0.11\n",
      "Epoch [5/5], Step [1677/1875], Loss: 1.8232, batch time: 0.10\n",
      "Epoch [5/5], Step [1678/1875], Loss: 1.7866, batch time: 0.10\n",
      "Epoch [5/5], Step [1679/1875], Loss: 1.6116, batch time: 0.10\n",
      "Epoch [5/5], Step [1680/1875], Loss: 1.8321, batch time: 0.09\n",
      "Epoch [5/5], Step [1681/1875], Loss: 1.9249, batch time: 0.13\n",
      "Epoch [5/5], Step [1682/1875], Loss: 1.8934, batch time: 0.11\n",
      "Epoch [5/5], Step [1683/1875], Loss: 1.8728, batch time: 0.17\n",
      "Epoch [5/5], Step [1684/1875], Loss: 1.7651, batch time: 0.11\n",
      "Epoch [5/5], Step [1685/1875], Loss: 1.9245, batch time: 0.13\n",
      "Epoch [5/5], Step [1686/1875], Loss: 1.7266, batch time: 0.12\n",
      "Epoch [5/5], Step [1687/1875], Loss: 1.7344, batch time: -0.66\n",
      "Epoch [5/5], Step [1688/1875], Loss: 1.7810, batch time: 0.19\n",
      "Epoch [5/5], Step [1689/1875], Loss: 1.6955, batch time: 0.12\n",
      "Epoch [5/5], Step [1690/1875], Loss: 1.4759, batch time: 0.13\n",
      "Epoch [5/5], Step [1691/1875], Loss: 1.8925, batch time: 0.12\n",
      "Epoch [5/5], Step [1692/1875], Loss: 1.5546, batch time: 0.10\n",
      "Epoch [5/5], Step [1693/1875], Loss: 1.8177, batch time: 0.09\n",
      "Epoch [5/5], Step [1694/1875], Loss: 1.8095, batch time: 0.14\n",
      "Epoch [5/5], Step [1695/1875], Loss: 1.8653, batch time: 0.09\n",
      "Epoch [5/5], Step [1696/1875], Loss: 1.7268, batch time: 0.13\n",
      "Epoch [5/5], Step [1697/1875], Loss: 1.7719, batch time: 0.09\n",
      "Epoch [5/5], Step [1698/1875], Loss: 1.7986, batch time: 0.09\n",
      "Epoch [5/5], Step [1699/1875], Loss: 1.8011, batch time: 0.11\n",
      "Epoch [5/5], Step [1700/1875], Loss: 2.0445, batch time: 0.09\n",
      "Epoch [5/5], Step [1701/1875], Loss: 2.1435, batch time: 0.09\n",
      "Epoch [5/5], Step [1702/1875], Loss: 1.9053, batch time: 0.14\n",
      "Epoch [5/5], Step [1703/1875], Loss: 1.9099, batch time: 0.09\n",
      "Epoch [5/5], Step [1704/1875], Loss: 1.8055, batch time: 0.09\n",
      "Epoch [5/5], Step [1705/1875], Loss: 1.8807, batch time: 0.09\n",
      "Epoch [5/5], Step [1706/1875], Loss: 1.6711, batch time: 0.09\n",
      "Epoch [5/5], Step [1707/1875], Loss: 2.0582, batch time: 0.09\n",
      "Epoch [5/5], Step [1708/1875], Loss: 1.4752, batch time: 0.12\n",
      "Epoch [5/5], Step [1709/1875], Loss: 1.8396, batch time: 0.09\n",
      "Epoch [5/5], Step [1710/1875], Loss: 2.0130, batch time: 0.09\n",
      "Epoch [5/5], Step [1711/1875], Loss: 1.7246, batch time: 0.09\n",
      "Epoch [5/5], Step [1712/1875], Loss: 1.6638, batch time: 0.10\n",
      "Epoch [5/5], Step [1713/1875], Loss: 1.9866, batch time: 0.12\n",
      "Epoch [5/5], Step [1714/1875], Loss: 1.9572, batch time: 0.09\n",
      "Epoch [5/5], Step [1715/1875], Loss: 1.7558, batch time: 0.09\n",
      "Epoch [5/5], Step [1716/1875], Loss: 1.7842, batch time: 0.09\n",
      "Epoch [5/5], Step [1717/1875], Loss: 1.7712, batch time: 0.10\n",
      "Epoch [5/5], Step [1718/1875], Loss: 1.7552, batch time: 0.09\n",
      "Epoch [5/5], Step [1719/1875], Loss: 1.8214, batch time: 0.12\n",
      "Epoch [5/5], Step [1720/1875], Loss: 1.6433, batch time: 0.10\n",
      "Epoch [5/5], Step [1721/1875], Loss: 1.7529, batch time: 0.09\n",
      "Epoch [5/5], Step [1722/1875], Loss: 1.6255, batch time: 0.09\n",
      "Epoch [5/5], Step [1723/1875], Loss: 2.1639, batch time: 0.12\n",
      "Epoch [5/5], Step [1724/1875], Loss: 1.7453, batch time: 0.12\n",
      "Epoch [5/5], Step [1725/1875], Loss: 1.8766, batch time: 0.09\n",
      "Epoch [5/5], Step [1726/1875], Loss: 1.8384, batch time: 0.11\n",
      "Epoch [5/5], Step [1727/1875], Loss: 1.7914, batch time: 0.09\n",
      "Epoch [5/5], Step [1728/1875], Loss: 1.6745, batch time: 0.11\n",
      "Epoch [5/5], Step [1729/1875], Loss: 1.8526, batch time: 0.09\n",
      "Epoch [5/5], Step [1730/1875], Loss: 1.8287, batch time: 0.10\n",
      "Epoch [5/5], Step [1731/1875], Loss: 1.8498, batch time: 0.09\n",
      "Epoch [5/5], Step [1732/1875], Loss: 1.8619, batch time: 0.09\n",
      "Epoch [5/5], Step [1733/1875], Loss: 1.6339, batch time: 0.09\n",
      "Epoch [5/5], Step [1734/1875], Loss: 1.3430, batch time: 0.14\n",
      "Epoch [5/5], Step [1735/1875], Loss: 1.9749, batch time: 0.10\n",
      "Epoch [5/5], Step [1736/1875], Loss: 1.6261, batch time: 0.09\n",
      "Epoch [5/5], Step [1737/1875], Loss: 1.5209, batch time: 0.09\n",
      "Epoch [5/5], Step [1738/1875], Loss: 1.7018, batch time: 0.11\n",
      "Epoch [5/5], Step [1739/1875], Loss: 1.8721, batch time: 0.10\n",
      "Epoch [5/5], Step [1740/1875], Loss: 1.8575, batch time: 0.11\n",
      "Epoch [5/5], Step [1741/1875], Loss: 1.9453, batch time: 0.09\n",
      "Epoch [5/5], Step [1742/1875], Loss: 1.9636, batch time: 0.10\n",
      "Epoch [5/5], Step [1743/1875], Loss: 1.3103, batch time: 0.10\n",
      "Epoch [5/5], Step [1744/1875], Loss: 1.7699, batch time: 0.09\n",
      "Epoch [5/5], Step [1745/1875], Loss: 1.8430, batch time: 0.09\n",
      "Epoch [5/5], Step [1746/1875], Loss: 1.8675, batch time: 0.09\n",
      "Epoch [5/5], Step [1747/1875], Loss: 1.7334, batch time: 0.09\n",
      "Epoch [5/5], Step [1748/1875], Loss: 1.7928, batch time: 0.12\n",
      "Epoch [5/5], Step [1749/1875], Loss: 1.6679, batch time: 0.09\n",
      "Epoch [5/5], Step [1750/1875], Loss: 1.7804, batch time: 0.10\n",
      "Epoch [5/5], Step [1751/1875], Loss: 1.9667, batch time: 0.10\n",
      "Epoch [5/5], Step [1752/1875], Loss: 1.7459, batch time: 0.15\n",
      "Epoch [5/5], Step [1753/1875], Loss: 1.6587, batch time: 0.11\n",
      "Epoch [5/5], Step [1754/1875], Loss: 1.8405, batch time: 0.11\n",
      "Epoch [5/5], Step [1755/1875], Loss: 1.8861, batch time: 0.12\n",
      "Epoch [5/5], Step [1756/1875], Loss: 1.5609, batch time: 0.09\n",
      "Epoch [5/5], Step [1757/1875], Loss: 1.9139, batch time: 0.13\n",
      "Epoch [5/5], Step [1758/1875], Loss: 1.8479, batch time: 0.10\n",
      "Epoch [5/5], Step [1759/1875], Loss: 1.8568, batch time: 0.12\n",
      "Epoch [5/5], Step [1760/1875], Loss: 1.6612, batch time: 0.09\n",
      "Epoch [5/5], Step [1761/1875], Loss: 1.9535, batch time: 0.17\n",
      "Epoch [5/5], Step [1762/1875], Loss: 1.9383, batch time: 0.16\n",
      "Epoch [5/5], Step [1763/1875], Loss: 1.5141, batch time: 0.10\n",
      "Epoch [5/5], Step [1764/1875], Loss: 1.8808, batch time: 0.10\n",
      "Epoch [5/5], Step [1765/1875], Loss: 1.7848, batch time: 0.21\n",
      "Epoch [5/5], Step [1766/1875], Loss: 1.9293, batch time: 0.11\n",
      "Epoch [5/5], Step [1767/1875], Loss: 1.8704, batch time: 0.11\n",
      "Epoch [5/5], Step [1768/1875], Loss: 1.6191, batch time: 0.09\n",
      "Epoch [5/5], Step [1769/1875], Loss: 1.6074, batch time: 0.12\n",
      "Epoch [5/5], Step [1770/1875], Loss: 1.8396, batch time: 0.13\n",
      "Epoch [5/5], Step [1771/1875], Loss: 1.6505, batch time: 0.10\n",
      "Epoch [5/5], Step [1772/1875], Loss: 1.8198, batch time: 0.10\n",
      "Epoch [5/5], Step [1773/1875], Loss: 1.8440, batch time: 0.09\n",
      "Epoch [5/5], Step [1774/1875], Loss: 1.8560, batch time: 0.10\n",
      "Epoch [5/5], Step [1775/1875], Loss: 1.8362, batch time: 0.10\n",
      "Epoch [5/5], Step [1776/1875], Loss: 1.7026, batch time: 0.09\n",
      "Epoch [5/5], Step [1777/1875], Loss: 2.0863, batch time: 0.09\n",
      "Epoch [5/5], Step [1778/1875], Loss: 1.7413, batch time: 0.10\n",
      "Epoch [5/5], Step [1779/1875], Loss: 1.6940, batch time: 0.11\n",
      "Epoch [5/5], Step [1780/1875], Loss: 1.7656, batch time: 0.10\n",
      "Epoch [5/5], Step [1781/1875], Loss: 1.4912, batch time: 0.11\n",
      "Epoch [5/5], Step [1782/1875], Loss: 1.7690, batch time: 0.10\n",
      "Epoch [5/5], Step [1783/1875], Loss: 1.9341, batch time: 0.09\n",
      "Epoch [5/5], Step [1784/1875], Loss: 1.9659, batch time: 0.09\n",
      "Epoch [5/5], Step [1785/1875], Loss: 1.9347, batch time: 0.10\n",
      "Epoch [5/5], Step [1786/1875], Loss: 1.7337, batch time: 0.13\n",
      "Epoch [5/5], Step [1787/1875], Loss: 1.5895, batch time: 0.12\n",
      "Epoch [5/5], Step [1788/1875], Loss: 1.4270, batch time: 0.12\n",
      "Epoch [5/5], Step [1789/1875], Loss: 2.0383, batch time: 0.11\n",
      "Epoch [5/5], Step [1790/1875], Loss: 1.7691, batch time: 0.16\n",
      "Epoch [5/5], Step [1791/1875], Loss: 1.6580, batch time: 0.13\n",
      "Epoch [5/5], Step [1792/1875], Loss: 1.9928, batch time: 0.09\n",
      "Epoch [5/5], Step [1793/1875], Loss: 1.6464, batch time: 0.12\n",
      "Epoch [5/5], Step [1794/1875], Loss: 1.7005, batch time: 0.12\n",
      "Epoch [5/5], Step [1795/1875], Loss: 1.7555, batch time: 0.15\n",
      "Epoch [5/5], Step [1796/1875], Loss: 1.8256, batch time: 0.10\n",
      "Epoch [5/5], Step [1797/1875], Loss: 1.7274, batch time: 0.12\n",
      "Epoch [5/5], Step [1798/1875], Loss: 1.7318, batch time: 0.12\n",
      "Epoch [5/5], Step [1799/1875], Loss: 1.6425, batch time: 0.09\n",
      "Epoch [5/5], Step [1800/1875], Loss: 1.8671, batch time: 0.09\n",
      "Epoch [5/5], Step [1801/1875], Loss: 2.0984, batch time: 0.10\n",
      "Epoch [5/5], Step [1802/1875], Loss: 1.8500, batch time: 0.11\n",
      "Epoch [5/5], Step [1803/1875], Loss: 1.5648, batch time: 0.14\n",
      "Epoch [5/5], Step [1804/1875], Loss: 1.7647, batch time: 0.10\n",
      "Epoch [5/5], Step [1805/1875], Loss: 1.6334, batch time: 0.11\n",
      "Epoch [5/5], Step [1806/1875], Loss: 1.4593, batch time: 0.10\n",
      "Epoch [5/5], Step [1807/1875], Loss: 1.4619, batch time: 0.09\n",
      "Epoch [5/5], Step [1808/1875], Loss: 1.9656, batch time: 0.10\n",
      "Epoch [5/5], Step [1809/1875], Loss: 2.0449, batch time: 0.09\n",
      "Epoch [5/5], Step [1810/1875], Loss: 1.7776, batch time: 0.09\n",
      "Epoch [5/5], Step [1811/1875], Loss: 1.8677, batch time: 0.10\n",
      "Epoch [5/5], Step [1812/1875], Loss: 1.7679, batch time: 0.09\n",
      "Epoch [5/5], Step [1813/1875], Loss: 1.7024, batch time: 0.10\n",
      "Epoch [5/5], Step [1814/1875], Loss: 1.8190, batch time: 0.10\n",
      "Epoch [5/5], Step [1815/1875], Loss: 1.7267, batch time: 0.09\n",
      "Epoch [5/5], Step [1816/1875], Loss: 1.7021, batch time: 0.09\n",
      "Epoch [5/5], Step [1817/1875], Loss: 2.1220, batch time: 0.10\n",
      "Epoch [5/5], Step [1818/1875], Loss: 1.8457, batch time: 0.09\n",
      "Epoch [5/5], Step [1819/1875], Loss: 1.9898, batch time: 0.12\n",
      "Epoch [5/5], Step [1820/1875], Loss: 1.8798, batch time: 0.09\n",
      "Epoch [5/5], Step [1821/1875], Loss: 1.6727, batch time: 0.10\n",
      "Epoch [5/5], Step [1822/1875], Loss: 1.8600, batch time: 0.10\n",
      "Epoch [5/5], Step [1823/1875], Loss: 1.8021, batch time: 0.09\n",
      "Epoch [5/5], Step [1824/1875], Loss: 1.7286, batch time: 0.10\n",
      "Epoch [5/5], Step [1825/1875], Loss: 1.8743, batch time: 0.10\n",
      "Epoch [5/5], Step [1826/1875], Loss: 1.8903, batch time: 0.09\n",
      "Epoch [5/5], Step [1827/1875], Loss: 1.8244, batch time: 0.10\n",
      "Epoch [5/5], Step [1828/1875], Loss: 1.7445, batch time: 0.10\n",
      "Epoch [5/5], Step [1829/1875], Loss: 2.0254, batch time: 0.10\n",
      "Epoch [5/5], Step [1830/1875], Loss: 1.9688, batch time: 0.09\n",
      "Epoch [5/5], Step [1831/1875], Loss: 1.7175, batch time: 0.10\n",
      "Epoch [5/5], Step [1832/1875], Loss: 1.7030, batch time: 0.10\n",
      "Epoch [5/5], Step [1833/1875], Loss: 1.8130, batch time: 0.09\n",
      "Epoch [5/5], Step [1834/1875], Loss: 1.8085, batch time: 0.10\n",
      "Epoch [5/5], Step [1835/1875], Loss: 1.7975, batch time: 0.10\n",
      "Epoch [5/5], Step [1836/1875], Loss: 2.2408, batch time: 0.10\n",
      "Epoch [5/5], Step [1837/1875], Loss: 1.8558, batch time: 0.09\n",
      "Epoch [5/5], Step [1838/1875], Loss: 1.6798, batch time: 0.10\n",
      "Epoch [5/5], Step [1839/1875], Loss: 1.9925, batch time: 0.09\n",
      "Epoch [5/5], Step [1840/1875], Loss: 1.8598, batch time: 0.13\n",
      "Epoch [5/5], Step [1841/1875], Loss: 1.8637, batch time: 0.09\n",
      "Epoch [5/5], Step [1842/1875], Loss: 2.0878, batch time: 0.18\n",
      "Epoch [5/5], Step [1843/1875], Loss: 1.9784, batch time: 0.15\n",
      "Epoch [5/5], Step [1844/1875], Loss: 2.1988, batch time: 0.11\n",
      "Epoch [5/5], Step [1845/1875], Loss: 1.8325, batch time: 0.09\n",
      "Epoch [5/5], Step [1846/1875], Loss: 1.7475, batch time: 0.09\n",
      "Epoch [5/5], Step [1847/1875], Loss: 1.5187, batch time: 0.10\n",
      "Epoch [5/5], Step [1848/1875], Loss: 1.7923, batch time: 0.09\n",
      "Epoch [5/5], Step [1849/1875], Loss: 1.5335, batch time: 0.10\n",
      "Epoch [5/5], Step [1850/1875], Loss: 1.9219, batch time: 0.10\n",
      "Epoch [5/5], Step [1851/1875], Loss: 1.4938, batch time: 0.09\n",
      "Epoch [5/5], Step [1852/1875], Loss: 1.9386, batch time: 0.12\n",
      "Epoch [5/5], Step [1853/1875], Loss: 1.8877, batch time: 0.09\n",
      "Epoch [5/5], Step [1854/1875], Loss: 1.9115, batch time: 0.09\n",
      "Epoch [5/5], Step [1855/1875], Loss: 1.7199, batch time: 0.09\n",
      "Epoch [5/5], Step [1856/1875], Loss: 1.4998, batch time: 0.09\n",
      "Epoch [5/5], Step [1857/1875], Loss: 1.7470, batch time: 0.11\n",
      "Epoch [5/5], Step [1858/1875], Loss: 2.1913, batch time: 0.12\n",
      "Epoch [5/5], Step [1859/1875], Loss: 2.0704, batch time: 0.09\n",
      "Epoch [5/5], Step [1860/1875], Loss: 1.6693, batch time: 0.09\n",
      "Epoch [5/5], Step [1861/1875], Loss: 1.9922, batch time: 0.11\n",
      "Epoch [5/5], Step [1862/1875], Loss: 1.8836, batch time: 0.09\n",
      "Epoch [5/5], Step [1863/1875], Loss: 1.6603, batch time: 0.09\n",
      "Epoch [5/5], Step [1864/1875], Loss: 1.7461, batch time: 0.09\n",
      "Epoch [5/5], Step [1865/1875], Loss: 1.8770, batch time: 0.13\n",
      "Epoch [5/5], Step [1866/1875], Loss: 1.8830, batch time: 0.11\n",
      "Epoch [5/5], Step [1867/1875], Loss: 1.7727, batch time: 0.10\n",
      "Epoch [5/5], Step [1868/1875], Loss: 1.8650, batch time: 0.09\n",
      "Epoch [5/5], Step [1869/1875], Loss: 1.6038, batch time: 0.09\n",
      "Epoch [5/5], Step [1870/1875], Loss: 1.7668, batch time: 0.09\n",
      "Epoch [5/5], Step [1871/1875], Loss: 1.7383, batch time: 0.09\n",
      "Epoch [5/5], Step [1872/1875], Loss: 2.0522, batch time: 0.09\n",
      "Epoch [5/5], Step [1873/1875], Loss: 1.5342, batch time: 0.09\n",
      "Epoch [5/5], Step [1874/1875], Loss: 1.7244, batch time: 0.11\n",
      "Epoch [5/5], Step [1875/1875], Loss: 1.7851, batch time: 0.09\n",
      "Epoch [5/5] Accuracy: 33.48%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################################\n",
    "### Training loop ###########################\n",
    "\n",
    "### (Optional) Start from pretrained model ##\n",
    "# model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# model.eval()  # Set the model to evaluation mode\n",
    "#############################################\n",
    "\n",
    "loss_list = [] \n",
    "acc_list = [] \n",
    "acc_best = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0   # ← moved here\n",
    "    total = 0     # ← moved here\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        since_batch = time.time()\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_one_hot)\n",
    "\n",
    "        # Track loss\n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}\")\n",
    "\n",
    "    # 🔵 End of epoch\n",
    "    acc = 100 * correct / total\n",
    "    acc_list.append(acc)\n",
    "    train_loss /= len(train_loader)\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if acc > acc_best:\n",
    "        torch.save(model, 'L16/tq_mm_acc_' + str(int(acc)) + '_bsf')\n",
    "        acc_best = acc\n",
    "\n",
    "# 📝 Save logs\n",
    "# np.save(\"loss_train_list.npy\", loss_list)\n",
    "# np.save(\"acc_train_list.npy\", acc_list)\n",
    "\n",
    "    \n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step = 1e-2                # Learning rate\n",
    "# batch_size = 64       # Number of samples for each training step\n",
    "# num_epochs = 1             # Number of training epochs\n",
    "# q_depth = 13             # Depth of the quantum circuit (number of variational layers)\n",
    "# gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "# q_delta = 0.1              # Initial spread of random quantum weights\n",
    "\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# #############################################\n",
    "# ### Training loop ###########################\n",
    "\n",
    "# ### (Optional) Start from pretrained model ##\n",
    "# # model = torch.load('result_FF_mm_b1000_40_200_40/tq_mm_acc_70_bsf')\n",
    "# # model.eval()  # Set the model to evaluation mode\n",
    "# #############################################\n",
    "\n",
    "# loss_list = [] \n",
    "# acc_list = [] \n",
    "# acc_best = 0\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         since_batch = time.time()\n",
    "        \n",
    "#         images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "#         optimizer.zero_grad()\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         # print(\"output: \", outputs)\n",
    "#         labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "#         # Compute loss\n",
    "#         loss = criterion(outputs, labels_one_hot)\n",
    "#         # log_loss = torch.log(loss + 1e-6)\n",
    "        \n",
    "#         loss_list.append(loss.cpu().detach().numpy())\n",
    "#         acc = 100 * correct / total\n",
    "#         acc_list.append(acc)\n",
    "#         train_loss += loss.cpu().detach().numpy()\n",
    "        \n",
    "#         # np.array(loss_list).dump(\"result_FF_mm_L38_b1000_40_200_40/loss_list.dat\")\n",
    "#         # np.array(acc_list).dump(\"result_FF_mm_L38_b1000_40_200_40/acc_list.dat\")\n",
    "#         if acc > acc_best:\n",
    "#             # torch.save(model, 'result_FF_mm_L38_b1000_40_200_40/tq_mm_acc_'+str(int(acc))+'_bsf')\n",
    "#             acc_best = acc\n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "#         # if (i+1) % 100 == 0:\n",
    "#         print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, batch time: {time.time() - since_batch:.2f}, accuracy:  {(acc):.2f}%\")\n",
    "    \n",
    "#     train_loss /= len(train_loader)\n",
    "#     scheduler.step(train_loss)\n",
    "    \n",
    "# #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 37.36%\n",
      "Loss on the train set: 1.79\n"
     ]
    }
   ],
   "source": [
    "# Testing train loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_train_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_train = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_train_list.append(loss_train)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the train set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the train set: {np.mean(loss_train_list):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 37.10%\n",
      "Loss on the test set: 1.80\n",
      "Generalization error: 0.006307721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Assuming testset is your original test dataset\n",
    "test_size = int(len(test_dataset) * 0.1)  # 80% of the original testset size\n",
    "validation_size = len(test_dataset) - test_size  # The remaining 20% for validation\n",
    "\n",
    "# Split the testset into new testset and validation set\n",
    "new_testset, validationset = random_split(test_dataset, [test_size, validation_size])\n",
    "\n",
    "# Create DataLoader for the new testset and validation set\n",
    "new_testloader = DataLoader(new_testset, batch_size=64, shuffle=True)\n",
    "validationloader = DataLoader(validationset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "loss_test_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in new_testloader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels).cpu().detach().numpy()\n",
    "        loss_test_list.append(loss_test)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n",
    "print(f\"Loss on the test set: {np.mean(loss_test_list):.2f}\")\n",
    "\n",
    "print(\"Generalization error:\", np.mean(loss_test_list) - np.mean(loss_train_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39faaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved loss_train_list.npy and acc_train_list.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save training metrics\n",
    "np.save(\"loss_train_list_q.npy\", loss_list)\n",
    "np.save(\"acc_train_list_q.npy\", acc_list)\n",
    "print(\"Saved loss_train_list.npy and acc_train_list.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ae8bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAl8hJREFUeJzs3XdcleX/x/E3IEsRFAc4cGvukZPcWzNTIc1RapmmoTn6ZmnlLC0bmmWmpebCTFNbPzO1XLlSUzPL1MyRghNwgQj37487jh4BRThwM17Px+M8uM917nOfz31AuXif67puJ8MwDAEAAAAAAAAZyNnqAgAAAAAAAJDzEEoBAAAAAAAgwxFKAQAAAAAAIMMRSgEAAAAAACDDEUoBAAAAAAAgwxFKAQAAAAAAIMMRSgEAAAAAACDDEUoBAAAAAAAgwxFKAQAAAAAAIMMRSgEOMGXKFFWsWFHx8fH39bzY2FgFBAToo48+SqfK7t9nn30mJycn/fPPP/f93A0bNsjJyUkbNmxweF0AACBzubP/888//8jJyUnvvPPOPZ/78ssvq379+uld4n1xcnLSuHHjUvXcUqVKqW/fvg6tB8hMnJycNHjwYKvLQDZEKAWkUVRUlN566y299NJLcna+v39Srq6uGjFihN544w1FR0ffdd9mzZrJycnpnrfUdqayuoQwbdeuXVaXkm2cO3dOQ4cOVcWKFeXp6anChQurXr16eumll3TlyhXbfqGhoZo2bZp1hQIAMlxa+j+SNGzYMO3bt09ff/31XfdL+P1+r1upUqVSeSbZR0REhDw8POTk5KQ//vjD6nJwn+728z1w4ECrywPSTS6rCwCyurlz5+rmzZvq0aNHqp7/1FNP6eWXX1ZoaKiefvrpZPd75ZVX9Mwzz9ju//LLL5o+fbpGjx6tSpUq2dqrV6+eqjoSPPnkk+revbvc3d3v+7lNmjTR9evX5ebmlqYaYL2LFy+qTp06ioqK0tNPP62KFSvqwoUL2r9/v2bOnKlBgwbJy8tLkhlKHThwQMOGDbO2aABAhklr/8ff31+dOnXSO++8o0cffTTZ/Zo0aaKFCxfatT3zzDOqV6+eBgwYYGtL+J2UFtevX1euXKn78+jQoUOpCuccadmyZXJycpK/v78WL16s119/3dJ6cP9at26t3r17J2qvUKGCBdUAGYNQCkijefPm6dFHH5WHh0eqnp8vXz61adNGn3322V1DqdatW9vd9/Dw0PTp09W6dWs1a9Ys2eddvXpVefLkSXE9Li4ucnFxSfH+t3N2dk71+4CMd7efjTlz5ujEiRP6+eef9dBDD9k9FhUVRfAIADlcWvs/ktStWzd17dpVf//9t8qUKZPkPmXKlEn02MCBA1WmTBk98cQTyR775s2bio+Pv6/fV2k5l9R8mOdoixYt0sMPP6ySJUsqNDQ004ZS0dHRcnNzszzEy2gpOe8KFSrc9ecayI5y1v8EgIMdO3ZM+/fvV6tWrRI99s477+ihhx5SgQIF5Onpqdq1a2v58uVJHqd169basmWLLl68mKZ6xo0bJycnJx08eFA9e/ZU/vz51ahRI0nS/v371bdvX5UpU0YeHh7y9/fX008/rQsXLtgdI6k1pUqVKqVHHnlEW7ZsUb169eTh4aEyZcpowYIFds9Nak2pZs2aqWrVqjp48KCaN2+u3Llzq1ixYpoyZUqi+o8fP65HH31UefLkUeHChTV8+HCtWbPGoetU/frrr2rfvr28vb3l5eWlli1bavv27Xb7xMbGavz48Spfvrw8PDxUoEABNWrUSGvXrrXtExYWpqeeekrFixeXu7u7ihQpok6dOqVoLa4ff/xRjRs3Vp48eZQvXz516tTJbpj98uXL5eTkpI0bNyZ67qxZs+Tk5KQDBw7Y2v7880899thj8vX1lYeHh+rUqZNoOkTC93Xjxo167rnnVLhwYRUvXjzZGo8ePSoXFxc1aNAg0WPe3t62jnuzZs303Xff6fjx40lOoYiJidHYsWNVrlw5ubu7KyAgQCNHjlRMTIzdMRPWKVi8eLEeeOABeXh4qHbt2tq0aZPdfpcvX9awYcNUqlQpubu7q3DhwmrdurX27NmT7LkAABzrbv2fBFOnTlXJkiXl6emppk2b2v3eSpDw/K+++ipN9dy+ltW0adNUtmxZubu76+DBg7px44bGjBmj2rVry8fHR3ny5FHjxo31008/JTrOncsgJPSrjhw5or59+ypfvnzy8fHRU089pWvXrtk99841pRJ+7/78888aMWKEChUqpDx58qhLly46d+6c3XPj4+M1btw4FS1aVLlz51bz5s118ODB+1qn6sSJE9q8ebO6d++u7t2769ixY9q6dWuS+y5atEj16tVT7ty5lT9/fjVp0kQ//PCD3T6rV69W06ZNlTdvXnl7e6tu3boKDQ1N9nwTNGvWzO7D0oS+4eeff65XX31VxYoVU+7cuRUVFaWLFy/qf//7n6pVqyYvLy95e3urffv22rdvX6LjRkdHa9y4capQoYI8PDxUpEgRBQUF6ejRozIMQ6VKlVKnTp2SfJ6Pj4+effbZu75/Ke2HSNK///6rp59+Wn5+fnJ3d1eVKlU0d+5cu33udt5pldC33r17tx566CF5enqqdOnS+vjjjxPte/bsWfXr109+fn7y8PBQjRo1NH/+/ET7xcfH6/3331e1atXk4eGhQoUKqV27dkkui7Fq1SpVrVrVdu7ff/99ms8JORsjpYA0SPhl/+CDDyZ67P3339ejjz6qXr166caNG/r888/VtWtXffvtt+rQoYPdvrVr15ZhGNq6daseeeSRNNfVtWtXlS9fXpMmTZJhGJKktWvX6u+//9ZTTz0lf39//f7775o9e7Z+//13bd++XU5OTnc95pEjR/TYY4+pX79+6tOnj+bOnau+ffuqdu3aqlKlyl2fe+nSJbVr105BQUHq1q2bli9frpdeeknVqlVT+/btJZmjdlq0aKEzZ85o6NCh8vf3V2hoaJKdxtT6/fff1bhxY3l7e2vkyJFydXXVrFmz1KxZM23cuNG24Oq4ceM0efJk2/SAqKgo7dq1S3v27LGNWAsODtbvv/+uIUOGqFSpUjp79qzWrl2rEydO3HVdi3Xr1ql9+/YqU6aMxo0bp+vXr+uDDz5Qw4YNtWfPHpUqVUodOnSQl5eXvvjiCzVt2tTu+UuXLlWVKlVUtWpV2zk1bNhQxYoV08svv6w8efLoiy++UOfOnfXll1+qS5cuds9/7rnnVKhQIY0ZM0ZXr15Nts6SJUsqLi5OCxcuVJ8+fZLd75VXXlFkZKROnTqlqVOnSro1hSI+Pl6PPvqotmzZogEDBqhSpUr67bffNHXqVP31119atWqV3bE2btyopUuX6vnnn5e7u7s++ugjtWvXTjt37rSd78CBA7V8+XINHjxYlStX1oULF7Rlyxb98ccfSf47BAA43t36P5K0YMECXb58WSEhIYqOjtb777+vFi1a6LfffpOfn59tPx8fH5UtW1Y///yzhg8fnua65s2bp+joaA0YMEDu7u7y9fVVVFSUPv30U/Xo0UP9+/fX5cuXNWfOHLVt21Y7d+5UzZo173ncbt26qXTp0po8ebL27NmjTz/9VIULF9Zbb711z+cOGTJE+fPn19ixY/XPP/9o2rRpGjx4sJYuXWrbZ9SoUZoyZYo6duyotm3bat++fWrbtu091xu93ZIlS5QnTx498sgj8vT0VNmyZbV48eJEo53Hjx+vcePG6aGHHtKECRPk5uamHTt26Mcff1SbNm0kyTZ6v0qVKho1apTy5cunX3/9Vd9//7169uyZ4ppuN3HiRLm5uel///ufYmJi5ObmpoMHD2rVqlXq2rWrSpcurfDwcM2aNUtNmzbVwYMHVbRoUUlSXFycHnnkEa1fv17du3fX0KFDdfnyZa1du1YHDhxQ2bJl9cQTT2jKlCm6ePGifH19ba/7zTffKCoqKkWjj1LSDwkPD1eDBg1sIVahQoW0evVq9evXT1FRUYmWMkjqvO8mOjpa58+fT9Tu7e1t99xLly7p4YcfVrdu3dSjRw998cUXGjRokNzc3GwzL65fv65mzZrpyJEjGjx4sEqXLq1ly5apb9++ioiI0NChQ23H69evnz777DO1b99ezzzzjG7evKnNmzdr+/btqlOnjm2/LVu2aMWKFXruueeUN29eTZ8+XcHBwTpx4oQKFChwz/cYSJIBINVeffVVQ5Jx+fLlRI9du3bN7v6NGzeMqlWrGi1atEi07+nTpw1JxltvvZXi1162bJkhyfjpp59sbWPHjjUkGT169LhnPYZhGEuWLDEkGZs2bbK1zZs3z5BkHDt2zNZWsmTJRPudPXvWcHd3N1544QVb208//ZSopqZNmxqSjAULFtjaYmJiDH9/fyM4ONjW9u677xqSjFWrVtnarl+/blSsWDHRMZOSUPcvv/yS7D6dO3c23NzcjKNHj9raTp8+beTNm9do0qSJra1GjRpGhw4dkj3OpUuXDEnG22+/fdeaklKzZk2jcOHCxoULF2xt+/btM5ydnY3evXvb2nr06GEULlzYuHnzpq3tzJkzhrOzszFhwgRbW8uWLY1q1aoZ0dHRtrb4+HjjoYceMsqXL29rS3h/GjVqZHfM5ISFhRmFChUyJBkVK1Y0Bg4caISGhhoRERGJ9u3QoYNRsmTJRO0LFy40nJ2djc2bN9u1f/zxx4Yk4+eff7a1STIkGbt27bK1HT9+3PDw8DC6dOlia/Px8TFCQkLuWT8AIP0k1/85duyYIcnw9PQ0Tp06ZWvfsWOHIckYPnx4omO1adPGqFSp0n29fp48eYw+ffokel1vb2/j7NmzdvvevHnTiImJsWu7dOmS4efnZzz99NN27ZKMsWPH2u4n9Kvu3K9Lly5GgQIF7NpKlixpV1PC791WrVoZ8fHxtvbhw4cbLi4utt+nYWFhRq5cuYzOnTvbHW/cuHGGJLtj3k21atWMXr162e6PHj3aKFiwoBEbG2trO3z4sOHs7Gx06dLFiIuLs3t+Qo0RERFG3rx5jfr16xvXr19Pcp+kzjdB06ZNjaZNm9ruJ/QNy5Qpk6gvGh0dnaiOY8eOGe7u7nZ9nblz5xqSjPfeey/R6yXUdOjQIUOSMXPmTLvHH330UaNUqVJ2tSclpf2Qfv36GUWKFDHOnz9v9/zu3bsbPj4+tnO823nfq4akbkuWLLHtl9C3fvfdd21tMTExtj7mjRs3DMMwjGnTphmSjEWLFtn2u3HjhhEYGGh4eXkZUVFRhmEYxo8//mhIMp5//vlENd3+vkky3NzcjCNHjtja9u3bZ0gyPvjggxSdI5AUpu8BaXDhwgXlypUrycU1PT09bduXLl1SZGSkGjdunOQ0o/z580tSkp+MpEZSV+i4vZ6ET2ESpmalZOpT5cqV1bhxY9v9QoUK6YEHHtDff/99z+d6eXnZfULl5uamevXq2T33+++/V7FixewWO/Xw8FD//v3vefyUiIuL0w8//KDOnTvbrU1RpEgR9ezZU1u2bLENqc6XL59+//13HT58OMljeXp6ys3NTRs2bNClS5dSXMOZM2e0d+9e9e3b1+5TvOrVq6t169b6v//7P1vb448/rrNnz9pNW1y+fLni4+P1+OOPSzIXI//xxx/VrVs3Xb58WefPn9f58+d14cIFtW3bVocPH9a///5rV0P//v1TtGaYn5+f9u3bp4EDB+rSpUv6+OOP1bNnTxUuXFgTJ060jcC7m2XLlqlSpUqqWLGirbbz58+rRYsWkpRoFFxgYKBq165tu1+iRAl16tRJa9asUVxcnCTze7Njxw6dPn36nq8PAEgfd+v/SFLnzp1VrFgx2/169eqpfv36dr/nEuTPn99h/Z/g4GAVKlTIrs3FxcU2wiQ+Pl4XL17UzZs3VadOnRRP/b6zX9W4cWNduHAhRVOxBgwYYDcavXHjxoqLi9Px48clSevXr9fNmzf13HPP2T1vyJAhKapNMpdo+O233+wWne/Ro4fOnz+vNWvW2NpWrVql+Ph4jRkzJtG6Rgk1rl27VpcvX9bLL7+caI2te42qv5s+ffrY9UUlcx2uhDri4uJ04cIFeXl56YEHHrD73nz55ZcqWLBgku9JQk0VKlRQ/fr1tXjxYttjFy9e1OrVq9WrV68U1X6vfohhGPryyy/VsWNHGYZh17dp27atIiMjE/1MJXXed9OpUyetXbs20a158+Z2++XKlctuSqKbm5ueffZZnT17Vrt375Yk/d///Z/8/f3tfi5cXV31/PPP68qVK7ZlIr788ks5OTlp7Nixieq5831r1aqVypYta7tfvXp1eXt7p+jvASA5hFJAOvn222/VoEEDeXh4yNfXV4UKFdLMmTMVGRmZaN+EP/DT8sv+dqVLl07UdvHiRQ0dOlR+fn7y9PRUoUKFbPslVdOdSpQokagtf/78KQplihcvnujc7nzu8ePHVbZs2UT7lStX7p7HT4lz587p2rVreuCBBxI9VqlSJcXHx+vkyZOSpAkTJigiIkIVKlRQtWrV9OKLL2r//v22/d3d3fXWW29p9erV8vPzU5MmTTRlyhSFhYXdtYaEDmhyNZw/f942pa5du3by8fGxG96/dOlS1axZ03YFliNHjsgwDL322msqVKiQ3S2hY3H27Fm710nqZyM5RYoU0cyZM3XmzBkdOnRI06dPt039mzNnzj2ff/jwYf3++++Jakuo/87aypcvn+gYFSpU0LVr12zrb0yZMkUHDhxQQECA6tWrp3HjxtERAoBMJrn/z5Nad9EwjHTt/0jS/PnzVb16dds6kYUKFdJ3332Xov6PlLgPlPBhYkr6QPd6bkLf4M7+jq+vr23fe1m0aJHy5MmjMmXK6MiRIzpy5Ig8PDxUqlQpu5Dm6NGjcnZ2VuXKlZM91tGjRyXJNl3NUZL63sTHx2vq1KkqX7683N3dVbBgQRUqVEj79++3+94cPXpUDzzwwD2vjNi7d2/9/PPPtvd02bJlio2N1ZNPPpmiGu/VDzl37pwiIiI0e/bsRH2bp556SlLa+l2S2Wdu1apVotvt014lqWjRookuVpPQv0r4d3b8+HGVL18+UQCZcNXuhPfp6NGjKlq0qN0HpslJy98DQHJYUwpIgwIFCujmzZu6fPmy8ubNa2vfvHmzHn30UTVp0kQfffSRihQpIldXV82bN89ukcgECf+RFyxY0CF1JfWJTLdu3bR161a9+OKLqlmzpry8vBQfH6927dopPj7+nsdMbnRNSkbMpOW5VmjSpImOHj2qr776Sj/88IM+/fRTTZ06VR9//LGeeeYZSdKwYcPUsWNHrVq1SmvWrNFrr72myZMn68cff1StWrXSXIO7u7s6d+6slStX6qOPPlJ4eLh+/vlnTZo0ybZPwvftf//7n9q2bZvkce7s5N7Pp3UJnJycVKFCBVWoUEEdOnRQ+fLltXjxYtt7kZz4+HhVq1ZN7733XpKPBwQE3Hct3bp1U+PGjbVy5Ur98MMPevvtt/XWW29pxYoVtvXJAADpK7n+T2pcunQpXfs/ixYtUt++fdW5c2e9+OKLKly4sFxcXDR58mRbAHMvmbkPZBiGlixZoqtXryYZNp09e1ZXrlxJdlRbaiUXJMbFxSV5zkl9byZNmqTXXntNTz/9tCZOnChfX185Oztr2LBhKeqb3ql79+4aPny4Fi9erNGjR2vRokWqU6dOkh8GpkZCTU888USy621Wr17d7n5q+l2ZWVbr0yNrIJQC0qBixYqSzKvQ3P5L6Msvv5SHh4fWrFljd4ngefPmJXmcY8eOSbr1yYWjXbp0SevXr9f48eM1ZswYW3ty09OsULJkSR08eDDRJ6ZHjhxxyPELFSqk3Llz69ChQ4ke+/PPP+Xs7GwXkvj6+uqpp57SU089pStXrqhJkyYaN26cXRBTtmxZvfDCC3rhhRd0+PBh1axZU++++64WLVqU7DlKSraGggUL2n3q9fjjj2v+/Plav369/vjjDxmGYZu6J8k2DdHV1fWuV0BypDJlyih//vw6c+aMrS25jmnZsmW1b98+tWzZMkWfgif18/jXX38pd+7cdtMxihQpoueee07PPfeczp49qwcffFBvvPEGoRQAZJDk+j8Jkvv/PKkLgRw7dkw1atRweI0Jli9frjJlymjFihV2v4uSmqpkhYS+wZEjR+xG1Vy4cCFFo082btyoU6dOacKECYn6kZcuXdKAAQO0atUqPfHEEypbtqzi4+N18ODBZBd4T5iadeDAgbuOVs+fP78iIiIStR8/ftxumYS7Wb58uZo3b55o9HVERIRdUFm2bFnt2LFDsbGxcnV1TfZ4vr6+6tChgxYvXqxevXrp559/1rRp01JUi5SyfkjevHkVFxeXYf2u5Jw+fVpXr1616zf+9ddfkmT7d1ayZEnt379f8fHxdqOl/vzzT9vjkvn+rlmzJtEi8UBGYfoekAaBgYGSlOhyqS4uLnJycrKtgyOZQ2nvvNpYgt27d8vJycl2PEdL+FTjzk8x7ucXdXpr27at/v33X3399de2tujoaH3yyScOOb6Li4vatGmjr776ym76QHh4uEJDQ9WoUSN5e3tLMjuCt/Py8lK5cuUUExMjSbp27VqiK+KULVtWefPmte2TlCJFiqhmzZqaP3++XUfuwIED+uGHH/Twww/b7d+qVSv5+vpq6dKlWrp0qerVq2fXYS1cuLCaNWumWbNm2YVECe685PT92LFjR5JX59u5c6cuXLhg96ljnjx5kpwC0a1bN/37779Jfg+vX7+e6Pjbtm2zW4vh5MmT+uqrr9SmTRu5uLgoLi4u0esULlxYRYsWvev7DgBwrOT6PwlWrVplt6bhzp07tWPHjkQfHkRGRuro0aOJrhDnSEn1gXbs2KFt27al22vej5YtWypXrlyaOXOmXfuHH36YoucnTN178cUX9dhjj9nd+vfvbxvdLJlrfTk7O2vChAmJRiIlvD9t2rRR3rx5NXny5ER9ndvfw7Jly2r79u26ceOGre3bb7+1LYWQEi4uLon6psuWLUu0HmZwcLDOnz+f5Hty5/OffPJJHTx4UC+++KJcXFzUvXv3FNdzr36Ii4uLgoOD9eWXX+rAgQOJnp+Wftf9unnzpmbNmmW7f+PGDc2aNUuFChWyrYv18MMPKywszG4piJs3b+qDDz6Ql5eX7QrPwcHBMgxD48ePT/Q6jIBCRmCkFJAGZcqUUdWqVbVu3Trb5VclqUOHDnrvvffUrl079ezZU2fPntWMGTNUrlw5u7WJEqxdu1YNGzZMt0upent729Y9io2NVbFixfTDDz/YRmhlBs8++6w+/PBD9ejRQ0OHDlWRIkW0ePFi2yKbKV1vYu7cufr+++8TtQ8dOlSvv/661q5dq0aNGum5555Trly5NGvWLMXExGjKlCm2fStXrqxmzZqpdu3a8vX11a5du7R8+XINHjxYkvlJVMuWLdWtWzdVrlxZuXLl0sqVKxUeHn7Pzs/bb7+t9u3bKzAwUP369dP169f1wQcfyMfHR+PGjbPb19XVVUFBQfr888919epVvfPOO4mON2PGDDVq1EjVqlVT//79VaZMGYWHh2vbtm06deqU9u3bl6L37U4LFy7U4sWL1aVLF9WuXVtubm76448/NHfuXHl4eGj06NG2fWvXrq2lS5dqxIgRqlu3rry8vNSxY0c9+eST+uKLLzRw4ED99NNPatiwoeLi4vTnn3/qiy++0Jo1a+wuM1y1alW1bdvW7lLMkmydpMuXL6t48eJ67LHHVKNGDXl5eWndunX65Zdf9O6776bqPAEA9y+5/k+CcuXKqVGjRho0aJBiYmI0bdo0FShQQCNHjrTbb926dTIMQ506dUq3Wh955BGtWLFCXbp0UYcOHXTs2DF9/PHHqly5sq5cuZJur5tSfn5+Gjp0qN599109+uijateunfbt26fVq1erYMGCd+3/xMTE6Msvv1Tr1q0TLUqe4NFHH9X777+vs2fPqly5cnrllVc0ceJENW7cWEFBQXJ3d9cvv/yiokWLavLkyfL29tbUqVP1zDPPqG7duurZs6fy58+vffv26dq1a5o/f74k6ZlnntHy5cvVrl07devWTUePHtWiRYvsFsG+l0ceeUQTJkzQU089pYceeki//fabFi9enGikVe/evbVgwQKNGDFCO3fuVOPGjXX16lWtW7dOzz33nN3PT4cOHVSgQAEtW7ZM7du3V+HChVNcz736IZL05ptv6qefflL9+vXVv39/Va5cWRcvXtSePXu0bt06Xbx4McWvl5S//voryRH3fn5+at26te1+0aJF9dZbb+mff/5RhQoVtHTpUu3du1ezZ8+2jSYbMGCAZs2apb59+2r37t0qVaqUli9fbhtBljD1tnnz5nryySc1ffp0HT582La0x+bNm9W8eXNb/xdINxl4pT8gW3rvvfcMLy+vRJd7nTNnjlG+fHnD3d3dqFixojFv3jzbpYVvFxERYbi5uRmffvrpfb3usmXLDEnGTz/9ZGtLOP65c+cS7X/q1CmjS5cuRr58+QwfHx+ja9euxunTpxNd/jjhEsbHjh2ztZUsWdLo0KFDomMmd9nf22tq2rSpUaVKlUTP7dOnj1GyZEm7tr///tvo0KGD4enpaRQqVMh44YUXjC+//NKQZGzfvv2u70dC3cndTp48aRiGYezZs8do27at4eXlZeTOndto3ry5sXXrVrtjvf7660a9evWMfPnyGZ6enkbFihWNN954w3aJ3fPnzxshISFGxYoVjTx58hg+Pj5G/fr1jS+++OKuNSZYt26d0bBhQ8PT09Pw9vY2OnbsaBw8eDDJfdeuXWtIMpycnGzncKejR48avXv3Nvz9/Q1XV1ejWLFixiOPPGIsX7480fvzyy+/pKjG/fv3Gy+++KLx4IMPGr6+vkauXLmMIkWKGF27djX27Nljt++VK1eMnj17Gvny5TMk2X1fb9y4Ybz11ltGlSpVDHd3dyN//vxG7dq1jfHjxxuRkZG2/SQZISEhxqJFi2z/bmrVqmX3sxQTE2O8+OKLRo0aNYy8efMaefLkMWrUqGF89NFHKTonAIDjJNX/OXbsmCHJePvtt413333XCAgIMNzd3Y3GjRsb+/btS3SMxx9/3GjUqNF9v3aePHmMPn36JPm6d4qPjzcmTZpklCxZ0va75dtvv02yH3Jnnyi5flVyfaXba0ru925SfaWbN28ar732muHv7294enoaLVq0MP744w+jQIECxsCBA5N9HxL6SHPmzEl2nw0bNhiSjPfff9/WNnfuXKNWrVq238tNmzY11q5da/e8r7/+2njooYdsfZV69eoZS5Yssdvn3XffNYoVK2a4u7sbDRs2NHbt2pVs33DZsmWJaouOjjZeeOEFo0iRIoanp6fRsGFDY9u2bYmOYRiGce3aNeOVV14xSpcubbi6uhr+/v7GY489Zhw9ejTRcZ977jlDkhEaGprs+3KnlPRDEoSHhxshISFGQECArZaWLVsas2fPTtF5362G5G63vx8Jfetdu3YZgYGBhoeHh1GyZEnjww8/TLLWp556yihYsKDh5uZmVKtWzZg3b16i/W7evGm8/fbbRsWKFQ03NzejUKFCRvv27Y3du3cneo/udOfPPnC/nAyDMXlAWkRGRqpMmTKaMmWK+vXrd9/PnzZtmqZMmaKjR49mu8UQHWHatGkaPny4Tp06ZXd5aWQvTk5OCgkJSfF0BQCAtdLa/wkLC1Pp0qX1+eefp+tIqawqIiJC+fPn1+uvv65XXnnF6nKylOHDh2vOnDkKCwtT7ty5U/ScrNQPadasmc6fP5/kFEIgK2JNKSCNfHx8NHLkSL399tv3faWQ2NhYvffee3r11VcJpGSuM3S76OhozZo1S+XLlyeQAgAgE0lL/0cyP3SqVq0agZQS93+kW+t+NmvWLGOLyeKio6O1aNEiBQcHpziQAmAt1pQCHOCll17SSy+9dN/Pc3V11YkTJ9KhoqwpKChIJUqUUM2aNRUZGalFixbpzz//tC3QCQAAMo/U9n8kc20emJYuXarPPvtMDz/8sLy8vLRlyxYtWbJEbdq0UcOGDa0uL0s4e/as1q1bp+XLl+vChQsaOnSo1SUBSCFCKQCZRtu2bfXpp59q8eLFiouLU+XKlfX555/r8ccft7o0AACAdFG9enXlypVLU6ZMUVRUlG3x89dff93q0rKMgwcPqlevXipcuLCmT5+umjVrWl0SgBRiTSkAAAAAAABkONaUAgAAAAAAQIYjlAIAAAAAAECGy/ZrSsXHx+v06dPKmzevnJycrC4HAABkMQkrHXh7e+eYvgT9JwAAkBaGYejy5csqWrSonJ2THw+V7UOp06dPKyAgwOoyAABAFhcZGSlvb2+ry8gQ9J8AAIAjnDx5UsWLF0/28WwfSuXNm1eS+UbklI4kAABwnKioqBwX0NB/AgAAaZHQf0roUyQn24dSCUPOvb296VQBAACkAP0nAADgCPdaBoCFzgEAAAAAAJDhCKUAAAAAAACQ4QilAAAAAAAAkOEIpQAAAAAAAJDhCKUAAAAAAACQ4QilAAAAAAAAkOEIpQAAAAAAAJDhCKUAAAAAAACQ4QilAAAAAAAAkOEIpQAAAAAAAJDhCKUAAAAAAACQ4XJZXQAAAAAAAAAyRlyctHmzdOaMVKSI1Lix5OJiTS2EUgAAAAAAADnAihXS0KHSqVO32ooXl95/XwoKyvh6mL4HAAAAAACQza1YIT32mH0gJUn//mu2r1iR8TURSqXVqVPSn39aXQUAAAAAAECS4uLMEVKGkfixhLZhw8z9MhKhVFoFBEiVKknnzlldCQAAAAAAQCKbNyceIXU7w5BOnjT3y0iEUo5y5IjVFQAAAAAAACRy5oxj93MUQikAAAAAAIBsrEgRx+7nKIRSjuLkZHUFAAAAAAAAiTRuLOXNm/zjTk7m6kSNG2dcTRKhFAAAAAAAQLb2/ffS5ctJP5YwxmbaNMnFJcNKkkQoBQAAAAAAkG2dOCH17m1ut2snFS9u/3jx4tLy5VJQUMbXlivjXxIAAAAAAADpLTZW6t5dunhRql1bWrVKypXLvMremTPmGlKNG2f8CKkEhFKOwppSAAAAAAAgExk1Stq2TfLxkb74QnJ3N9ubNbO0LBum7zkKoRQAAAAAAMgkvv5aevddc3vePKlMGWvrSYrlodS///6rJ554QgUKFJCnp6eqVaumXbt22R43DENjxoxRkSJF5OnpqVatWunw4cMWVgwAAAAAAJB5/fOP1KePuT10qNSli6XlJMvSUOrSpUtq2LChXF1dtXr1ah08eFDvvvuu8ufPb9tnypQpmj59uj7++GPt2LFDefLkUdu2bRUdHW1h5QAAAAAAAJnPjRvS449LERFSvXrSlClWV5Q8S9eUeuuttxQQEKB58+bZ2kqXLm3bNgxD06ZN06uvvqpOnTpJkhYsWCA/Pz+tWrVK3bt3z/Ca7RjGrW2m7wEAAAAAAIuNHCnt3Cnlzy8tXSq5uVldUfIsHSn19ddfq06dOuratasKFy6sWrVq6ZNPPrE9fuzYMYWFhalVq1a2Nh8fH9WvX1/btm2zomR7t4dSAAAAAAAAFlqxQnr/fXN7/nypVClLy7knS0Opv//+WzNnzlT58uW1Zs0aDRo0SM8//7zmz58vSQoLC5Mk+fn52T3Pz8/P9tidYmJiFBUVZXcDAAAAAADIzv7+W3r6aXP7f/+TOna0tp6UsHT6Xnx8vOrUqaNJkyZJkmrVqqUDBw7o448/Vp+EFbnu0+TJkzV+/HhHlpk8RkoBAAAAAACLxcRI3bpJkZHSQw9J/8UsmZ6lI6WKFCmiypUr27VVqlRJJ06ckCT5+/tLksLDw+32CQ8Ptz12p1GjRikyMtJ2O3nyZDpU/h/WlAIAAAAAABZ74QVp926pQAHp888lV1erK0oZS0Ophg0b6tChQ3Ztf/31l0qWLCnJXPTc399f69evtz0eFRWlHTt2KDAwMMljuru7y9vb2+6WbgilAAAAAACAhZYulWbMMLcXLpQCAqyt535YOn1v+PDheuihhzRp0iR169ZNO3fu1OzZszV79mxJkpOTk4YNG6bXX39d5cuXV+nSpfXaa6+paNGi6ty5s5WlAwAAAAAAWOrwYal/f3P75Zel9u2tred+WRpK1a1bVytXrtSoUaM0YcIElS5dWtOmTVOvXr1s+4wcOVJXr17VgAEDFBERoUaNGun777+Xh4eHhZX/hzWlAAAAAACABa5fl7p2lS5flho3liZOtLqi++dkGNk7WYmKipKPj48iIyMdP5Xv5s1bEzV/+02qWtWxxwcAAJZL175EJpUTzxkAgKzm2Wel2bOlQoWkX3+VihWzuqJbUtqXsHRNqSwvVy4p4c3NDCO3AAAAAABAthcaagZSTk7SokWZK5C6H4RSjpK9B5wBAAAAAIBM4M8/pQEDzO1XXpHatLG2nrQglAIAAAAAAMgCrl0z15G6elVq1kwaN87qitKGUCqtnJysrgAAAAAAAOQAQ4ZIBw5Ifn7mFD4XF6srShtCKUdh+h4AAAAAAEgnCxZIc+eaY2MWL5aKFLG6orQjlAIAAAAAAMjEDh6UBg0yt8eOlVq2tLYeRyGUSquE6XuMlAIAAAAAAA529aq5jtS1a1KrVtKrr1pdkeMQSgEAAAAAAGRChiE995w5UqpIEXPaXlZfR+p2hFJpxULnAAAAAAAgHcybZ64l5ewsLVkiFS5sdUWORSjlKEzfAwAAAAAADvLbb1JIiLk9caLUtKm19aQHQikAAAAAAIBM5PJlcx2p6GipXTvp5Zetrih9EEqlFdP3AAAAAACAgxiGNHCgdOiQVKyYtHChOX0vO8qmp2UBpu8BAAAAAIA0mj1bCg01FzRfulQqWNDqitIPoRQAAAAAAEAm8Ouv0tCh5vakSVLDhtbWk94IpdIqYfoeI6UAAAAAAEAqRUVJ3bpJMTFShw7S//5ndUXpj1AKAAAAAADAQoYhPfOMdOSIFBAgzZ+ffdeRul0OOEUAAAAAAIDM66OPpGXLpFy5pC++kAoUsLqijEEolVZM3wMAAAAAAKm0e7c0YoS5/dZbUoMG1taTkQilAAAAAAAALBARIXXtKt24IXXqJA0fbnVFGYtQKq0YKQUAAAAAAO6TYUhPPy0dOyaVKiXNm3crYsgpCKUAAAAAAAAy2PTp0sqVkquruY5U/vxWV5TxCKUAAAAAAAAy0M6d0osvmtvvvivVrWttPVYhlEorpu8BAAAAAIAUunhR6tZNio2VHntMGjzY6oqsQygFAAAAAACQAQxDeuop6fhxqWxZ6dNPc946UrcjlAIAAAAAAMgA770nff215OZmriPl42N1RdYilEorpu8BAAAAAIB72LZNevllc3vaNOnBBy0tJ1MglAIAAAAAAEhHFy5Ijz8u3bxpfh040OqKMgdCqbRipBQAAAAAAEhGfLzUu7d08qRUvrw0e3bOXkfqdoRSAAAAAAAA6WTKFOn//k/y8JCWLZO8va2uKPMglAIAAAAAAEgHmzdLr75qbk+fLtWoYW09mQ2hVFoxfQ8AAAAAANzh7Fmpe3cpLk7q1Ut65hmrK8p8CKUAAAAAAAAcKD5eevJJ6fRpqWJF6eOPWUcqKYRSAAAAAAAADjRpkvTDD5Knp7mOlJeX1RVlToRSacX0PQAAkIFmzpyp6tWry9vbW97e3goMDNTq1attj0dHRyskJEQFChSQl5eXgoODFR4ebmHFAADkLD/9JI0da27PmCFVrWptPZkZoRQAAEAWUrx4cb355pvavXu3du3apRYtWqhTp076/fffJUnDhw/XN998o2XLlmnjxo06ffq0goKCLK4aAICcITxc6tnTnL7Xp4/01FNWV5S55bK6gGyDkVIAACADdOzY0e7+G2+8oZkzZ2r79u0qXry45syZo9DQULVo0UKSNG/ePFWqVEnbt29XgwYNrCgZAIAcIS7ODKTCwqTKlc1RUrg7RkqlFSuVAQAAi8TFxenzzz/X1atXFRgYqN27dys2NlatWrWy7VOxYkWVKFFC27Zts7BSAACyv4kTpR9/lHLnlpYvl/LksbqizI+RUgAAAFnMb7/9psDAQEVHR8vLy0srV65U5cqVtXfvXrm5uSlfvnx2+/v5+SksLCzZ48XExCgmJsZ2PyoqKr1KBwAgW1q3TpowwdyeNUuqVMnaerIKRkqlFQudAwCADPbAAw9o79692rFjhwYNGqQ+ffro4MGDqT7e5MmT5ePjY7sFBAQ4sFoAALK3M2ekXr3MWOCZZ6QnnrC6oqyDUAoAACCLcXNzU7ly5VS7dm1NnjxZNWrU0Pvvvy9/f3/duHFDERERdvuHh4fL398/2eONGjVKkZGRttvJkyfT+QwAAMgebt6UevSQzp6VqleXpk+3uqKshVDKURgpBQAALBIfH6+YmBjVrl1brq6uWr9+ve2xQ4cO6cSJEwoMDEz2+e7u7vL29ra7AQCAexs3Ttq4UfLykpYtkzw9ra4oa2FNqbRioXMAAJCBRo0apfbt26tEiRK6fPmyQkNDtWHDBq1Zs0Y+Pj7q16+fRowYIV9fX3l7e2vIkCEKDAzkynsAADjYmjXSpEnm9iefSBUqWFtPVkQoBQAAkIWcPXtWvXv31pkzZ+Tj46Pq1atrzZo1at26tSRp6tSpcnZ2VnBwsGJiYtS2bVt99NFHFlcNAED2cuqUuXaUYUgDB0rdu1tdUdbkZBjZe95ZVFSUfHx8FBkZmT5D0RNGSs2ZIz39tOOPDwAALJXufYlMKCeeMwAAKRUbK7VoIW3ZItWqJW3dKnl4WF1V5pLSvgRrSjnKsGFWVwAAAAAAANLZq6+agVTevNIXXxBIpQWhlKOwthQAAAAAANnat99KU6aY23PnSuXKWVtPVkcoBQAAAAAAcA8nTkh9+pjbgwdLjz1mbT3ZAaEUAAAAAADAXdy4IT3+uHTxolSnjvTOO1ZXlD0QSgEAAAAAANzFqFHS9u2Sj4+5jpS7u9UVZQ+WhlLjxo2Tk5OT3a1ixYq2x6OjoxUSEqICBQrIy8tLwcHBCg8Pt7BiAAAAAACQk3z1lfTee+b2vHlS6dLW1pOdWD5SqkqVKjpz5ozttmXLFttjw4cP1zfffKNly5Zp48aNOn36tIKCgiysFgAAAAAA5BTHjkl9+5rbw4ZJXbpYWU32k8vyAnLlkr+/f6L2yMhIzZkzR6GhoWrRooUkad68eapUqZK2b9+uBg0aZHSpAAAAAAAgh0hYRyoiQqpfX3rrLasryn4sHyl1+PBhFS1aVGXKlFGvXr104sQJSdLu3bsVGxurVq1a2fatWLGiSpQooW3btllVLgAAAAAAyAFefFH65Rcpf35p6VLJzc3qirIfS0dK1a9fX5999pkeeOABnTlzRuPHj1fjxo114MABhYWFyc3NTfny5bN7jp+fn8LCwpI9ZkxMjGJiYmz3o6Ki0qt8e05OGfM6AAAAAAAgXX35pTR9urm9YIFUsqS19WRXloZS7du3t21Xr15d9evXV8mSJfXFF1/I09MzVcecPHmyxo8f76gSU45QCgAAAACALO/oUenpp83tF1+UHnnE2nqyM8un790uX758qlChgo4cOSJ/f3/duHFDERERdvuEh4cnuQZVglGjRikyMtJ2O3nyZDpXDQAAAAAAsoPoaKlbNykqSnroIemNN6yuKHvLVKHUlStXdPToURUpUkS1a9eWq6ur1q9fb3v80KFDOnHihAIDA5M9hru7u7y9ve1uAAAAAAAA9/LCC9KePVKBAuY6Uq6uVleUvVk6fe9///ufOnbsqJIlS+r06dMaO3asXFxc1KNHD/n4+Khfv34aMWKEfH195e3trSFDhigwMDBzXnnPMKyuAAAAAAAApNLSpdJHH5nbCxdKxYtbW09OYGkoderUKfXo0UMXLlxQoUKF1KhRI23fvl2FChWSJE2dOlXOzs4KDg5WTEyM2rZtq48SfkIyG0IpAAAAAACypMOHpf79ze1Ro6TblsBGOnIyjOydpkRFRcnHx0eRkZHpM5UvYYFzb28pMtLxxwcAAJZK975EJpQTzxkAkHNdvy4FBkr79klNmkjr10u5LB3Ck/WltC+RqdaUytKyd7YHAAAAAEC2NHSoGUgVKiQtWUIglZEIpQAAAAAAQI60eLH0ySfmJKjFi6WiRa2uKGchlAIAAAAAADnOn39Kzz5rbr/6qtS6tbX15ESEUo7C9D0AAAAAALKEa9ekrl2lq1el5s2lsWOtrihnIpRyFEIpAAAAAACyhMGDpQMHJD8/KTRUcnGxuqKciVAKAAAAAADkGPPnS/PmSc7OZiDl7291RTkXoRQAAAAAAMgRfv9dGjTI3B43TmrRwtJycjxCKUdh+h4AAAAAAJnWlSvmOlLXr5uLmo8ebXVFIJRyFEIpAAAAAAAyJcOQnntO+uMPqWhRadEi1pHKDAilHIVQCgAAAACATGnuXGnhQnMdqSVLpMKFra4IEqEUAAAAAADIxvbvN6+2J0mvvy41aWJtPbiFUMpRGCkFAAAAAECmcvmyuY5UdLTUvr300ktWV4TbEUoBAAAAAIBsxzCkZ5+V/vpLKl5cWrDAnL6HzINvBwAAAAAAyHZmzzbXj3JxkT7/XCpY0OqKcCdCKUdh+h4AAAAAAJnCr79KQ4ea25MnSw0bWlsPkkYo5Sg3blhdAQAAAAAAOV5UlNStmxQTIz3yiPTCC1ZXhOQQSgEAAAAAgGzBMKRnnpGOHJFKlJDmz2cdqcyMbw0AAAAAAMgWZsyQli2TcuWSli6VfH2trgh3QygFAAAAAACyvF27pBEjzO0pU6QGDaytB/dGKAUAAAAAALK0iAhzHanYWKlzZ2nYMIsLQooQSgEAAAAAgCzLMKSnn5aOHZNKlZLmzpWcnKyuCilBKAUAAAAAALKs99+XVq6U3NzM9aTy57e6IqQUoRQAAAAAAMiSduyQXnzR3H73XalOHWvrwf0hlAIAAAAAAFnOxYvmOlI3b0pdu0ohIVZXhPtFKAUAAAAAALIUw5D69pVOnJDKlpU++YR1pLIiQikAAAAAAJClvPuu9M03kru7uY6Uj4/VFSE1CKUAAAAAAECWsXWr9PLL5va0aVKtWpaWgzQglAIAAAAAAFnC+fPS449LcXFS9+7Ss89aXRHSglAKAAAAAABkevHxUu/e0qlTUoUK0uzZrCOV1RFKAQAAAACATG/KFGn1asnDw1xHKm9eqytCWhFKAQAAAACATG3zZunVV83tDz6Qqle3th44BqEUAAAAAADItM6eNdePiouTnnhC6tfP6orgKIRSAAAAAAAgU4qLk558Ujp9WqpYUZo5k3WkshNCKQAAAAAAkClNmiT98IPk6WmuI+XlZXVFcCRCKQAAAAAAkOn89JM0bpy5/dFHUtWqlpaDdEAoBQAAAAAAMpWwMKlHDyk+Xurb17wh+yGUAgAAAAAAmUZcnNSzpxQebo6OmjHD6oqQXgilAAAAAABApjFhgjl1L08ecx2p3LmtrgjphVAKAAAAAABkCmvXShMnmtuzZplX3EP2RSgFAAAAAAAsd/q01KuXZBhS//7mNrI3QikAAAAAAGCpmzfNhc3PnZNq1JDef9/qipARCKUAAAAAAIClxo6VNm2SvLykL76QPD2trggZgVAKAAAAAABY5vvvpUmTzO1PP5UqVLC2HmQcQikAAAAAAGCJU6ekJ54wtwcNkh5/3Np6kLEIpQAAAAAAQIaLjZW6d5cuXJBq1ZLee8/qipDRCKUAAAAAAECGe/VV6eefJW9vadkyycPD6oqQ0QilAAAAAABAhvr2W2nKFHN77lypbFlr64E1CKUAAAAAAECGOXFC6tPH3B4yRAoOtrYeWIdQCgAAAAAAZIgbN8zFzC9elOrWld5+2+qKYCVCKQAAAAAAkCFeflnavl3Kl09aulRyd7e6Ilgp04RSb775ppycnDRs2DBbW3R0tEJCQlSgQAF5eXkpODhY4eHh1hUJAAAAAABSZdUqaepUc3vePKl0aUvLQSaQKUKpX375RbNmzVL16tXt2ocPH65vvvlGy5Yt08aNG3X69GkFBQVZVCUAAAAAAEiNY8ekvn3N7REjpM6drawGmYXlodSVK1fUq1cvffLJJ8qfP7+tPTIyUnPmzNF7772nFi1aqHbt2po3b562bt2q7du3W1gxAAAAAABIqZgYqVs3KTJSatBAevNNqytCZmF5KBUSEqIOHTqoVatWdu27d+9WbGysXXvFihVVokQJbdu2LdnjxcTEKCoqyu4GAAAAAACs8eKL0q5dkq+vuY6Uq6vVFSGzyGXli3/++efas2ePfvnll0SPhYWFyc3NTfny5bNr9/PzU1hYWLLHnDx5ssaPH+/oUgEAAAAAwH1avlz64ANze8ECqUQJa+tB5mLZSKmTJ09q6NChWrx4sTw8PBx23FGjRikyMtJ2O3nypMOODQAAAAAAUuboUalfP3N75EipQwdr60HmY1kotXv3bp09e1YPPvigcuXKpVy5cmnjxo2aPn26cuXKJT8/P924cUMRERF2zwsPD5e/v3+yx3V3d5e3t7fdDQAAILuYPHmy6tatq7x586pw4cLq3LmzDh06ZLdPs2bN5OTkZHcbOHCgRRUDAHKi6Gipa1cpKkpq2FB6/XWrK0JmZFko1bJlS/3222/au3ev7VanTh316tXLtu3q6qr169fbnnPo0CGdOHFCgYGBVpUNAABgqY0bNyokJETbt2/X2rVrFRsbqzZt2ujq1at2+/Xv319nzpyx3aZMmWJRxQCAnGjECOnXX6WCBaXPP2cdKSTNsjWl8ubNq6pVq9q15cmTRwUKFLC19+vXTyNGjJCvr6+8vb01ZMgQBQYGqkGDBlaUDAAAYLnvv//e7v5nn32mwoULa/fu3WrSpImtPXfu3HcdXQ4AQHpZulSaOdPcXrhQKl7c2nqQeVl+9b27mTp1qh555BEFBwerSZMm8vf314oVK6wuCwAAINOIjIyUJPn6+tq1L168WAULFlTVqlU1atQoXbt2LdljcPViAICj/PWX9Mwz5vbo0VK7dtbWg8zNyTAMw+oi0lNUVJR8fHwUGRmZPutLOTnd2s7ebyUAADmSI/oS8fHx2rhxozZv3qzjx4/r2rVrKlSokGrVqqVWrVopICAg1cd99NFHFRERoS1bttjaZ8+erZIlS6po0aLav3+/XnrpJdWrVy/ZD/fGjRuX5NWL063/BADIlq5flxo0kPbvl5o2ldatk3JZNj8LVkpp/4lQKq0IpQAAyNbS0pe4fv263n33Xc2cOVMXL15UzZo1VbRoUXl6eurixYs6cOCATp8+rTZt2mjMmDH3vUTBoEGDtHr1am3ZskXF7zI34scff1TLli115MgRlS1bNtHjMTExiomJsd2PiopSQEAAoRQA4L4MGCB98olUqJC0d69UtKjVFcEqKe0/kVkCAACkkwoVKigwMFCffPKJWrduLdckVnk9fvy4QkND1b17d73yyivq379/io49ePBgffvtt9q0adNdAylJql+/viQlG0q5u7vL3d09Ra8LAEBSFi82AyknJyk0lEAKKUMoBQAAkE5++OEHVapU6a77lCxZUqNGjdL//vc/nThx4p7HNAxDQ4YM0cqVK7VhwwaVLl36ns/Zu3evJKlIkSIpqhsAgPvx55/Ss8+a26+9JrVqZW09yDoIpQAAANLJvQKp27m6uiY5iulOISEhCg0N1VdffaW8efMqLCxMkuTj4yNPT08dPXpUoaGhevjhh1WgQAHt379fw4cPV5MmTVS9evVUnwsAAEm5dk167DHp6lWpRQtpzBirK0JWQigFAACQgW7evKlZs2Zpw4YNiouLU8OGDRUSEiIPD48UPX/mf9fYbtasmV37vHnz1LdvX7m5uWndunWaNm2arl69qoCAAAUHB+vVV1919KkAAKCQEOn33yU/P3MKn4uL1RUhKyGUcpTy5a2uAAAAZAHPP/+8/vrrLwUFBSk2NlYLFizQrl27tGTJkhQ9/17XqAkICNDGjRsdUSoAAHf12WfmzdlZWrJE8ve3uiJkNYRSaTVjhhkNV6lidSUAACATWrlypbp06WK7/8MPP+jQoUNy+e+j5LZt2973VfcAALDagQPSc8+Z2+PHS82bW1sPsiZnqwvI8pz/ewv//tvaOgAAQKY0d+5cde7cWadPn5YkPfjggxo4cKC+//57ffPNNxo5cqTq1q1rcZUAAKTclStS167S9etSmzbS6NFWV4SsilAqrRYvNr/u329tHQAAIFP65ptv1KNHDzVr1kwffPCBZs+eLW9vb73yyit67bXXFBAQoNDQUKvLBAAgRQxDGjTIvOJe0aLSokW3xmoA98vJuNfCBFlcVFSUfHx8FBkZKW9vb8e/gJPTre3s/VYCAJAjOaovERERoZEjR2rfvn36+OOPVatWLQdW6Vjp3n8CAGRZn34q9e9vLmj+009S48ZWV4TMKKV9CfJMAACADJAvXz7Nnj1bb7/9tnr37q0XX3xR0dHRVpcFAECK7d8vDRlibr/+OoEU0o5QCgAAIB2dOHFC3bp1U7Vq1dSrVy+VL19eu3fvVu7cuVWjRg2tXr3a6hIBALiny5fNdaSio6WHH5ZGjrS6ImQHhFJpdfv0PQAAgDv07t1bzs7Oevvtt1W4cGE9++yzcnNz0/jx47Vq1SpNnjxZ3bp1s7pMAACSZRjSgAHSX39JxYtL8+ezjhQcI5fVBWR5Tk6sJQUAAJK1a9cu7du3T2XLllXbtm1VunRp22OVKlXSpk2bNHv2bAsrBADg7mbNkj7/XMqVS1q6VCpY0OqKkF0QSgEAAKSj2rVra8yYMerTp4/WrVunatWqJdpnwIABFlQGAMC9/fqrNGyYuT15svTQQ5aWg2yGAXcAAADpaMGCBYqJidHw4cP177//atasWVaXBABAsuLipA0bpCVLpG+/lR57TIqJkTp2lF54werqkN0wUiqtWFMKAADcRcmSJbV8+XKrywAA4J5WrJCGDpVOnbJvL1RI+uwz/vyF4zFSKq1Y3Q0AACTj6tWr6bo/AACOsmKFOSrqzkBKks6dM0dPAY5GopJWRMUAACAZ5cqV05tvvqkzZ84ku49hGFq7dq3at2+v6dOnZ2B1AACY4uLMEVLJXcPLyclcVyouLkPLQg7A9D0AAIB0smHDBo0ePVrjxo1TjRo1VKdOHRUtWlQeHh66dOmSDh48qG3btilXrlwaNWqUnn32WatLBgDkQJs3Jz1CKoFhSCdPmvs1a5ZhZSEHIJQCAABIJw888IC+/PJLnThxQsuWLdPmzZu1detWXb9+XQULFlStWrX0ySefqH379nJxcbG6XABADrV/f8r2u8vAXyBVCKXSiul7AADgHkqUKKEXXnhBL3DZIgBAJvLvv9Ibb0izZ6ds/yJF0rce5DyEUmlFKAUAAAAAyELCw6U335RmzpRiYsw2d/db23dycpKKF5caN864GpEzsNB5WhFKAQAAAACygAsXpJdflsqUkaZNM0Ooxo2ljRul0FDzz9s7/8RNuD9tmsRMczgaoRQAAAAAANlYRIQ0dqxUurT01lvStWtS/frSDz+YgVSTJlJQkLR8uVSsmP1zixc324OCLCkd2RzT99KKkVIAAAAAgEzoyhVp+nTp7bfNYEqSataUJk6UOnRI/OdsUJDUqZN5lb0zZ8w1pBo3ZoQU0g+hVFoRSgEAAAAAMpHr16WPPjLXjTp/3myrXFmaMEHq0kVyvsucKRcXqVmzDCkTYPpemhFKAQCAFChVqpQmTJigEydOWF0KACCbiomRPvxQKltW+t//zECqXDlp8WJp/34pOPjugRSQ0fhxBAAAyADDhg3TihUrVKZMGbVu3Vqff/65YpK7zBEAAPchNlb69FOpfHlpyBBz6l3JktLcudIff0g9ezIFD5kToVRaMVIKAACkwLBhw7R3717t3LlTlSpV0pAhQ1SkSBENHjxYe/bssbo8AEAWFBcnLVggVawo9e8vnTwpFS1qTt376y/pqaekXCzag0yMUCqtCKUAAMB9ePDBBzV9+nSdPn1aY8eO1aeffqq6deuqZs2amjt3rgzDsLpEAEAmFx8vLV0qVa0q9ekj/f23VLiwNHWqdOSINGiQ5OZmdZXAvZGZAgAAZKDY2FitXLlS8+bN09q1a9WgQQP169dPp06d0ujRo7Vu3TqFhoZaXSYAIBMyDOnrr6UxY8w1oiTJ11d66SUpJETKk8fa+oD7lapQ6uTJk3JyclLx4sUlSTt37lRoaKgqV66sAQMGOLTATI+RUgAAIAX27NmjefPmacmSJXJ2dlbv3r01depUVaxY0bZPly5dVLduXQurBABkRoYhrVkjvfaatGuX2ebtLb3wgjRsmLkNZEWpmr7Xs2dP/fTTT5KksLAwtW7dWjt37tQrr7yiCRMmOLTATI9QCgAApEDdunV1+PBhzZw5U//++6/eeecdu0BKkkqXLq3u3btbVCEAIDP66SepUSOpfXszkMqTRxo9Wjp2zBwxRSCFrCxVI6UOHDigevXqSZK++OILVa1aVT///LN++OEHDRw4UGPGjHFokQAAAFnd33//rZIlS951nzx58mjevHkZVBEAIDPbutUcGfXjj+Z9Dw9zit5LL0mFCllbG+AoqRopFRsbK3d3d0nSunXr9Oijj0qSKlasqDNnzjiuuqyAkVIAACAFzp49qx07diRq37Fjh3YlzMUAAOR4u3ZJDz8sNWxoBlKurtLgwdLRo9I77xBIIXtJVShVpUoVffzxx9q8ebPWrl2rdu3aSZJOnz6tAgUKOLTATI9QCgAApEBISIhOnjyZqP3ff/9VSEiIBRUBADKT/fulLl2kunWl1aslFxepf3/zanoffCAVLWp1hYDjpSqUeuuttzRr1iw1a9ZMPXr0UI0aNSRJX3/9tW1aX45BKAUAAFLg4MGDevDBBxO116pVSwcPHrSgIgBAZvDnn1L37lKNGtKqVZKzs9S7t3TokDR7tlSihNUVAuknVWtKNWvWTOfPn1dUVJTy589vax8wYIBy587tsOKyBEIpAACQAu7u7goPD1eZMmXs2s+cOaNcuVLVJQMAZGFHj0oTJkiLFknx8Wbb449L48ZJd1wHA8i2UjVS6vr164qJibEFUsePH9e0adN06NAhFS5c2KEFAgAAZAdt2rTRqFGjFBkZaWuLiIjQ6NGj1bp1awsrAwBkpBMnpAEDzOBpwQIzkOrUSdq3T/r8cwIp5Cyp+liuU6dOCgoK0sCBAxUREaH69evL1dVV58+f13vvvadBgwY5us7MKyBAOn/e6ioAAEAm984776hJkyYqWbKkatWqJUnau3ev/Pz8tHDhQourAwCktzNnpEmTzCl5N26Ybe3amaOl6ta1tjbAKqkaKbVnzx41btxYkrR8+XL5+fnp+PHjWrBggaZPn+7QAjO9N9+0ugIAAJAFFCtWTPv379eUKVNUuXJl1a5dW++//75+++03BQQEWF0eACCdnDsn/e9/Upky0ocfmoFU8+bSli3mguYEUsjJUjVS6tq1a8qbN68k6YcfflBQUJCcnZ3VoEEDHT9+3KEFZnq+vuZXOpMAAOAe8uTJowEDBlhdBgAgA1y6JL3zjvT++9LVq2bbQw9JEydKLVpYWxuQWaQqlCpXrpxWrVqlLl26aM2aNRo+fLgk6ezZs/L29nZogZlewkLnhmFtHQAAIEs4ePCgTpw4oRsJczf+8+ijj1pUEQDAkaKipGnTpPfekxKWEaxd2wyj2rXjWlnA7VIVSo0ZM0Y9e/bU8OHD1aJFCwUGBkoyR00lrJGQYxBKAQCAFPj777/VpUsX/fbbb3JycpLxX9/B6b++RFxcnJXlAQDS6OpVacYM6a23pIsXzbZq1cww6tFHCaOApKRqTanHHntMJ06c0K5du7RmzRpbe8uWLTV16lSHFZcl8D8LAABIgaFDh6p06dI6e/ascufOrd9//12bNm1SnTp1tGHDBqvLAwCkUnS0OUWvTBnppZfMQOqBB8wr6e3da15Zjz8bgaSlaqSUJPn7+8vf31+nTp2SJBUvXlz16tVzWGFZDiOlAADAXWzbtk0//vijChYsKGdnZzk7O6tRo0aaPHmynn/+ef36669WlwgAuA83bkhz50qvvy79+6/ZVqaMNHas1LOnlCvVf20DOUeqRkrFx8drwoQJ8vHxUcmSJVWyZEnly5dPEydOVHx8vKNrzNwSIu/YWGvrAAAAmVpcXJztQjEFCxbU6dOnJUklS5bUoUOHrCwNAHAfbt6U5s0zR0MNGmQGUgEB0uzZ0p9/Sr17E0gBKZWqfyqvvPKK5syZozfffFMNGzaUJG3ZskXjxo1TdHS03njjDYcWmakljJA6d06Kj5ecU5XzAQCAbK5q1arat2+fSpcurfr162vKlClyc3PT7NmzVaZMGavLAwDcQ1yctHSpNG6cdPiw2ebvL73yitS/v+Tubml5QJaUqgRl/vz5+vTTTzVo0CBVr15d1atX13PPPadPPvlEn332WYqPM3PmTFWvXl3e3t7y9vZWYGCgVq9ebXs8OjpaISEhKlCggLy8vBQcHKzw8PDUlJx+zp+/tX3pknV1AACATO3VV1+1jSifMGGCjh07psaNG+v//u//NH36dIurAwAkJz5e+vJLqXp1qVcvM5AqWFB65x3p6FFp8GACKSC1UjVS6uLFi6pYsWKi9ooVK+piwmUGUqB48eJ68803Vb58eRmGofnz56tTp0769ddfVaVKFQ0fPlzfffedli1bJh8fHw0ePFhBQUH6+eefU1M2AACAZdq2bWvbLleunP78809dvHhR+fPnt12BDwCQeRiG9N130pgxUsKyf/nySS++KA0ZIv03IxtAGqRqpFSNGjX04YcfJmr/8MMPVb169RQfp2PHjnr44YdVvnx5VahQQW+88Ya8vLy0fft2RUZGas6cOXrvvffUokUL1a5dW/PmzdPWrVu1ffv21JSdPuhEAgCAe4iNjVWuXLl04MABu3ZfX18CKQDIZAxDWrtWCgyUOnY0A6m8ec1w6tgxafRoAinAUVI1UmrKlCnq0KGD1q1bp8DAQEnmFWVOnjyp//u//0tVIXFxcVq2bJmuXr2qwMBA7d69W7GxsWrVqpVtn4oVK6pEiRLatm2bGjRokKrXcTg6kgAA4B5cXV1VokQJxcXFWV0KAOAuNm2SXnvN/CpJnp7S88+bo6MKFLC2NiA7StVIqaZNm+qvv/5Sly5dFBERoYiICAUFBen333/XwoUL7+tYv/32m7y8vOTu7q6BAwdq5cqVqly5ssLCwuTm5qZ8+fLZ7e/n56ewsLBkjxcTE6OoqCi7GwAAgNVeeeUVjR49+r6WOgAAZIwdO6Q2baSmTc1Ayt1dGjpU+vtv6c03CaSA9JLqC1UWLVo00VX29u3bpzlz5mj27NkpPs4DDzygvXv3KjIyUsuXL1efPn20cePG1JalyZMna/z48al+/n1jpBQAAEiBDz/8UEeOHFHRokVVsmRJ5cmTx+7xPXv2WFQZAORcv/5qTsv79lvzfq5c0jPPmFfUK17c2tqAnCDVoZSjuLm5qVy5cpKk2rVr65dfftH777+vxx9/XDdu3FBERITdaKnw8HD5+/sne7xRo0ZpxIgRtvtRUVEKCAhIt/oJpQAAQEp07tzZ6hIAAP/5/Xdp7FjzqnqS5Ows9eljTt0rXdra2oCcxPJQ6k7x8fGKiYlR7dq15erqqvXr1ys4OFiSdOjQIZ04ccK2jlVS3N3d5W7V9TgJqAAAQDLGjh1rdQkAkOMdPiyNGyctWWIuaO7kJPXoYQZUFSpYXR2Q81gaSo0aNUrt27dXiRIldPnyZYWGhmrDhg1as2aNfHx81K9fP40YMUK+vr7y9vbWkCFDFBgYmHkWOZcIogAAAAAgk/vnH2niRGn+fCnhmhPBwdL48VKVKpaWBuRo9xVKBQUF3fXxiIiI+3rxs2fPqnfv3jpz5ox8fHxUvXp1rVmzRq1bt5YkTZ06Vc7OzgoODlZMTIzatm2rjz766L5eI90RSgEAgBRwdnaW0136DVyZDwAc79Qp6Y03pDlzpNhYs+2RR6QJE6RataytDcB9hlI+Pj73fLx3794pPt6cOXPu+riHh4dmzJihGTNmpPiYAAAAmdHKlSvt7sfGxurXX3/V/PnzM/YiLQCQA4SHS5MnSx9/LMXEmG2tW5thVGaaeAPkdPcVSs2bNy+96si6GCkFAABSoFOnTonaHnvsMVWpUkVLly5Vv379LKgKALKXCxekt9+WPvhAunbNbGvc2Jy617SptbUBSCzTLXSe5dweSl2/bl0dAAAgS2rQoIEGDBhgdRkAkKVFREhTp5q3y5fNtnr1pNdfl1q1YiwBkFk5W11AtrJ8udUVAACALOT69euaPn26ihUrZnUpAJAlXbkiTZoklS5tTs27fFmqWVP65htp+3Zzyh6BFJB5MVIqrW7/H84wrKsDAABkavnz57db6NwwDF2+fFm5c+fWokWLLKwMALKe69eljz6S3nxTOn/ebKtc2QymunSRnBl+AWQJhFJpdXsoxf98AAAgGVOnTrULpZydnVWoUCHVr19f+fPnt7AyAMg6YmKkTz4xR0edOWO2lSsnjR8vPf645OJibX0A7g+hlCMRSgEAgGT07dvX6hIAIMuKjZU++8xcsPzkSbOtZElp7FjpySelXPxlC2RJpChpxQRlAACQAvPmzdOyZcsStS9btkzz58+3oCIAyPzi4qQFC6SKFaUBA8xAqmhRc+reX39JTz1FIAVkZYRSjsSaUgAAIBmTJ09WwYIFE7UXLlxYkyZNsqAiAMi84uOlpUulqlWlPn2kv/+WChc2r6535Ig0aJDk5mZ1lQDSikw5rVjoHAAApMCJEydUunTpRO0lS5bUiRMnLKgIADIfw5C+/loaM0bav99s8/WVRo6UBg+W8uSxtj4AjkUolVZM3wMAAClQuHBh7d+/X6VKlbJr37dvnwoUKGBNUQCQSRiGtGaN9Npr0q5dZpu3t/TCC9KwYeY2gOyHUCqtbg+l4uOtqwMAAGRqPXr00PPPP6+8efOqSZMmkqSNGzdq6NCh6t69u8XVAYB1fvpJevVVaetW836ePNLQoWYg5etrbW0A0hehFAAAQAaYOHGi/vnnH7Vs2VK5/luVNz4+Xr1792ZNKQA50s8/myOjfvrJvO/hIYWESC+9JBUqZG1tADIGoVRaMVIKAACkgJubm5YuXarXX39de/fulaenp6pVq6aSJUtaXRoAZKhdu8ww6vvvzfuurtKzz0qjRplX1gOQcxBKpRULnQMAgPtQvnx5lS9f3uoyACDD7d8vjR0rrVpl3ndxkZ5+2py6V6KEpaUBsIiz1QVkK4RSAAAgGcHBwXrrrbcStU+ZMkVdu3a1oCIAyBh//il17y7VqGEGUs7O0pNPmu2zZxNIATkZoVRaMVIKAACkwKZNm/Twww8nam/fvr02bdpkQUUAkL6OHpX69JGqVJGWLjXbunWTDhyQFiyQypWztj4A1mP6niMRSgEAgGRcuXJFbm5uidpdXV0VFRVlQUUAkD5OnJBef12aN0+6edNs69RJmjBBql7d2toAZC6MlEqrIkVubRNKAQCAZFSrVk1LE4YK3Obzzz9X5cqVU3ycyZMnq27dusqbN68KFy6szp0769ChQ3b7REdHKyQkRAUKFJCXl5eCg4MVHh6e5nMAAEmKi5M2bJCWLDG/xsWZ7WfOSEOGSOXLS598YgZS7dpJO3ea0/YIpADciZFSaXV7KMXV9wAAQDJee+01BQUF6ejRo2rRooUkaf369VqyZImWLVuW4uNs3LhRISEhqlu3rm7evKnRo0erTZs2OnjwoPLkySNJGj58uL777jstW7ZMPj4+Gjx4sIKCgvTzzz+ny7kByDlWrJCGDpVOnbrVVrSoVKeO9MMPUnS02da8uTRxotSwoTV1AsgaCKXS6vY1pQAAAJLRsWNHrVq1SpMmTdLy5cvl6emp6tWra926dWratGmKj/N9wjXU//PZZ5+pcOHC2r17t5o0aaLIyEjNmTNHoaGhtvBr3rx5qlSpkrZv364GDRo49LwA5BwrVkiPPZZ4gsjp09LXX5vbDz1khlH//fcDAHdFKOVITN8DAAB30aFDB3Xo0CFR+4EDB1S1atVUHTMyMlKS5OvrK0navXu3YmNj1apVK9s+FStWVIkSJbRt2zZCKQCpEhdnjpC62588BQtKGzdKufgrE0AKsaaUIzF9DwAApNDly5c1e/Zs1atXTzVq1EjVMeLj4zVs2DA1bNjQFmqFhYXJzc1N+fLls9vXz89PYWFhSR4nJiZGUVFRdjcAuN3atfZT9pJy/ry0ZUvG1AMgeyCUSqvbp+8xUgoAANzDpk2b1Lt3bxUpUkTvvPOOWrRooe3bt6fqWCEhITpw4IA+//zzNNU0efJk+fj42G4BAQFpOh6A7MEwpM2bpWeekbp0SdlzzpxJ35oAZC8MrHQkQikAAJCEsLAwffbZZ5ozZ46ioqLUrVs3xcTEaNWqVfd15b3bDR48WN9++602bdqk4sWL29r9/f1148YNRURE2I2WCg8Pl7+/f5LHGjVqlEaMGGG7HxUVRTAF5GB//y0tWGDejh27v+fefh0oALgXRko5EqEUAAC4Q8eOHfXAAw9o//79mjZtmk6fPq0PPvgg1cczDEODBw/WypUr9eOPP6p06dJ2j9euXVuurq5av369re3QoUM6ceKEAgMDkzymu7u7vL297W4AcpbISOnTT6UmTaSyZaXx481AystLeuopaf16qXjx5K/z5OQkBQRIjRtnbN0AsjZGSjkSoRQAALjD6tWr9fzzz2vQoEEqX758mo8XEhKi0NBQffXVV8qbN69tnSgfHx95enrKx8dH/fr104gRI+Tr6ytvb28NGTJEgYGBLHIOwE5cnLlW1IIF0sqVUnS02e7kJLVqJfXpI3XuLOXJY7a//7559T0nJ/s/fRKCqmnTJBeXjDwDAFkdI6UciVAKAADcYcuWLbp8+bJq166t+vXr68MPP9T58+dTfbyZM2cqMjJSzZo1U5EiRWy3pUuX2vaZOnWqHnnkEQUHB6tJkyby9/fXihUrHHE6ALKB33+XRo40Rza1by8tWWIGUpUqSW++KZ04If3wg9Sr161ASpKCgqTly6VixeyPV7y42R4UlLHnASDrczKM7J2kREVFycfHR5GRkek3FD3ho4ExY8xxrgAAINtwVF/i6tWrWrp0qebOnaudO3cqLi5O7733np5++mnlzZvXgRWnXYb0nwBkqHPnzPBpwQJp9+5b7b6+Us+eUu/eUp06yU/Pu11cnLkA+pkz5hpSjRszQgqAvZT2JQilHCHhf+4lS6Tu3dPnNQAAgCXSoy9x6NAhzZkzRwsXLlRERIRat26tr7/+2iHHdgRCKSB7uHFD+u47af588+vNm2Z7rlxShw7m9LwOHSQ3N2vrBJD9pLQvwfQ9R2je3OoKAABAFvLAAw9oypQpOnXqlJYsWWJ1OQCyEcOQfvlFGjzYHMUUFCR99ZUZSNWuLU2fbo5wWrVK6tKFQAqAtVjo3BESRkpl70FnAADAwVxcXNS5c2d17tzZ6lIAZHGnTkmLFpnT8/7441Z70aLSE0+Y0/OqVLGuPgBICqGUIzj/N+AsPt7aOgAAAADkGFevmiOe5s+X1q279Rm5h4c5CqpPH/Mqeqz3BCCzIpRyBEZKAQAAAMgA8fHmIuPz50vLlklXrtx6rHFjM4jq2lViOTgAWQGhlCMkhFKMlAIAAACQDo4cMafmLVwo/fPPrfYyZcypeU8+aW4DQFZCKOUICdP3GCkFAAAAwEEiIqQvvjBHRW3deqs9b16pWzdzVFSjRrc+IweArIZQyhGYvgcAAADAAW7elNauNYOoVaukmBiz3dlZat3aDKI6dZJy57a0TABwCEIpR2ChcwAAAABp8NtvZhC1eLEUFnarvUoVM4jq1cu8kh4AZCeEUo7ASCkAAAAA9+nsWSk01Ayj9u691V6woNSzp7lW1IMPMj0PQPZFKOUILHQOAAAAIAViYqRvvjEXLV+92pyuJ0murlLHjmYQ1b695OZmbZ0AkBEIpRyBhc4BAAAAJMMwpJ07zRFRn38uXbp067G6dc3ped27SwUKWFcjAFiBUMoRmL4HAAAA4A4nT0oLF5qjog4dutVerJj05JPmqKhKlayrDwCsRijlCCx0DgAAAEDSlSvSihVmEPXjj7c+t/b0lIKDzSCqRQvJxcXaOgEgMyCUcgRGSgEAAAA5Vny8tHGjOT1v+XLp6tVbjzVrZgZRjz0m5c1rWYkAkCkRSjkCI6UAAACAHOevv8wRUQsXSidO3GovV84Mop58UipVyrLyACDTI5RyBEZKAQAAADnCpUvS0qVmGLVt2612Hx/p8cfNRcsDA2/9iQAASB6hlCMQSgEAAADZVmystGaNGUR9/bUUE2O2OztL7dqZo6IefdRcNwoAkHKEUo7A9D0AAAAg29m3z1wnavFi6ezZW+3Vqpkjonr1kvz9rasPALI6QilHYKQUAAAAkC2Eh5sh1Pz50v79t9oLFTJDqD59pBo1mJ4HAI5AKOUIjJQCAAAAsqzoaHNa3oIF0vffS3FxZrubmzktr3dvc5qeq6u1dQJAdkMo5QiMlAIAAACyFMOQtm83R0QtXSpFRNx6rH59c0TU449Lvr6WlQgA2Z6zlS8+efJk1a1bV3nz5lXhwoXVuXNnHTp0yG6f6OhohYSEqECBAvLy8lJwcLDCw8MtqjgZhFIAAABAlnD8uPT669IDD0gPPSTNmmUGUgEB0ujR0p9/mmHVoEEEUgCQ3iwNpTZu3KiQkBBt375da9euVWxsrNq0aaOrV6/a9hk+fLi++eYbLVu2TBs3btTp06cVFBRkYdVJYPoeAAAAkGlduSJ99pnUvLlUqpT02mvS4cNSnjzm1Lz166V//pHeeMMMqwAAGcPS6Xvff/+93f3PPvtMhQsX1u7du9WkSRNFRkZqzpw5Cg0NVYsWLSRJ8+bNU6VKlbR9+3Y1aNDAirITY6QUAAAAkKnExUkbNpjT8778Urp2zWx3cjLDqd69peBgycvL0jIBIEfLVGtKRUZGSpJ8/xsnu3v3bsXGxqpVq1a2fSpWrKgSJUpo27ZtSYZSMTExiomJsd2PiopK56p1a6QUoRQAAABgqUOHzCBq4ULp1Klb7eXLm+tEPfmkVKKEdfUBAG7JNKFUfHy8hg0bpoYNG6pq1aqSpLCwMLm5uSlfvnx2+/r5+SksLCzJ40yePFnjx49P73LtJYyUYvoeAAAAkOEuXpQ+/9wMo3buvNWeL5/UvbsZRtWvf6vbDgDIHDJNKBUSEqIDBw5oy5YtaTrOqFGjNGLECNv9qKgoBQQEpLW8u2P6HgAAAJChYmOl1aulBQukb76Rbtww211cpPbtzel5HTtKHh7W1gkASF6mCKUGDx6sb7/9Vps2bVLx4sVt7f7+/rpx44YiIiLsRkuFh4fL398/yWO5u7vL3d09vUu2x0LnAAAAQLozDGnvXnNEVGiodO7crcdq1jSDqJ49JT8/qyoEANwPS0MpwzA0ZMgQrVy5Uhs2bFDp0qXtHq9du7ZcXV21fv16BQcHS5IOHTqkEydOKDAw0IqSk8ZIKQAAACDdnDkjLV5shlEHDtxq9/OTevUyp+dVr25dfQCA1LE0lAoJCVFoaKi++uor5c2b17ZOlI+Pjzw9PeXj46N+/fppxIgR8vX1lbe3t4YMGaLAwMDMc+U9Sfr5Z/Pr229LY8daWwsAAACQDVy/Ln31lTk9b82aW5MS3N2lTp3MIKpNGylXppj7AQBIDUv/C585c6YkqVmzZnbt8+bNU9++fSVJU6dOlbOzs4KDgxUTE6O2bdvqo48+yuBK7+G338yvV69aWwcAAACQhRmGtHWrOSLqiy+k/y7OLUl66CFzel63blL+/NbVCABwHMun792Lh4eHZsyYoRkzZmRARQAAAAAy2j//mCOiFiyQjh691V6ihBlE9e4tlS9vWXkAgHTCYFcAAAAADhMXJ23ebK4DVaSI1LixeUW8O0VFScuXm0HUxo232r28pMceM6fnNWly65pCAIDsh1AKAAAAgEOsWCENHSqdOnWrrXhx6f33paAgM7Bav94MolasMNeNkszrBrVsaQZRXbpIefJYUz8AIGMRSgEAAABIsxUrzBFOd67Q8e+/ZnunTtIvv5j3EzzwgBlEPfGEFBCQsfUCAKxHKAUAAAAgTeLizBFSSS0Zm9C2apX5NX9+qUcPM4yqW9ccJQUAyJkIpQAAAACkyebN9lP2kjN+vPTSS5K7e/rXBADI/Fg2EAAAAECanDmTsv3KlyeQAgDcQigFAAAAIE2KFHHsfgCAnIFQCgAAAECaRETcfW0oJydzIfPGjTOsJABAFkAo5Qj9+1tdAQAAAJDhDEN65x0pKOjWguZ3hlMJ96dNk1xcMrQ8AEAmRyjlCM2bm1+deTsBAACQM9y4IfXrJ734ohlIPfustHSpVKyY/X7Fi0vLl5vBFQAAt+Pqe47wyy/m1/h4a+sAAAAAMsD581JwsLRpk/m57NSp0pAh5qio4GDzanxnzphrSDVuzAgpAEDSCKUc4fhxqysAAAAAMsQff0iPPCL9/beUN685Oqp9+1uPu7hIzZpZVh4AIAthvhkAAACAFFmzRmrQwAykSpeWtm2zD6QAALgfhFKOcLdLjQAAAADZwIcfSg8/LEVFSY0aSTt2SFWqWF0VACArI5QCAAAAkKzYWCkkxFwzKj5e6tNHWrdOKlTI6soAAFkda0o5AiOlAAAAkA1FREhdu5ohlJOT9Oab5tX26P4CAByBUMoR+K0MAACAbObIEXNB80OHpNy5pcWLpc6dra4KAJCdEEoBAAAAsLNhgxQUJF26JBUvLn3zjVSzptVVAQCyG9aUcgTDsLoCAAAAwCE+/VRq3doMpOrVk375hUAKAJA+CKUc4eZNqysAAAAA0iQuTnrhBal/f7N72727OWLK39/qygAA2RWhlCM8+6zVFQAAAACpFhUldeokvfeeeX/cOCk0VPL0tLQsAEA2x5pSjlC2rPnV29vaOgAAAID79M8/UseO0oEDkoeH9Nln0uOPW10VACAnIJQCAAAAcqitW80r6p07Z07T++orcx0pAAAyAtP3HMHJyfwaFcWi5wAAAMgSFi2Smjc3A6maNc0FzQmkAAAZiVDK0XbvtroCAAAAIFnx8dIrr0hPPinduGGOlNqyRSpe3OrKAAA5DaGUIySMlJKk69etqwMAAAC4i6tXpa5dpUmTzPujRklffinlyWNtXQCAnIk1pRzh9lAKAAAAyIT+/Vd69FFpzx7JzU365BOpd2+rqwIA5GSEUgAAAEA2t2uXGUidOSMVLCitXCk1amR1VQCAnI7pe47GqCkAAABkIsuWSU2amIFUlSrSzp0EUgCAzIFQyhFuv+IeoRQAAAAyAcOQJk6UunUzlz19+GFp61apdGmrKwMAwMT0PUe4efPWNqEUAAAALBYdLfXrJ4WGmveHDZPeeUdycbG0LAAA7BBKOcK1a7e2PT2tqwMAAAA5XliY1LmztGOHlCuXNGOGNGCA1VUBAJAYoZQjeHnd2ubjJwAAAFhk/37pkUekkyel/Pml5culFi2srgoAgKSxppQjlC9/azs+3ro6AAAAkGN9/bX00ENmIFWhgrR9O4EUACBzI5RylGLFzK+3L3oOAAAApDPDkN5+25yyd/Wq1LKlGUhVqGB1ZQAA3B2hlKM4//dWMlIKAAAAGeTGDXNB85EjzXBq4EBp9Wpz6h4AAJkda0o5CqEUAAAAMtD581JwsLRpk9kVnTpVGjKEi0EDALIOQilHIZQCAABABjl4UOrYUfr7b8nbW1q6VGrXzuqqAAC4P0zfc5SEj6QIpQAAQDrbtGmTOnbsqKJFi8rJyUmrVq2ye7xv375ycnKyu7Ujscg21qyRAgPNQKp0aWnbNgIpAEDWRCjlKAkjpVjoHAAApLOrV6+qRo0amjFjRrL7tGvXTmfOnLHdlixZkoEVIr18+KH08MNSVJTUqJG0Y4dUubLVVQEAkDpM33OUI0fMrwcPmtfiBQAASCft27dX+/bt77qPu7u7/P39M6gipLfYWGnYMOmjj8z7ffpIs2ZJ7u6WlgUAQJowUsrR+ve3ugIAAABt2LBBhQsX1gMPPKBBgwbpwoULVpeEVLp0yRwd9dFH5ooRb70lzZtHIAUAyPoYKQUAAJDNtGvXTkFBQSpdurSOHj2q0aNHq3379tq2bZtcXFwS7R8TE6OYmBjb/aioqIwsF3dx+LC5oPmhQ1KePNKiRVLnzlZXBQCAYxBKAQAAZDPdu3e3bVerVk3Vq1dX2bJltWHDBrVs2TLR/pMnT9b48eMzskSkwIYNUlCQOVIqIED6+mupZk2rqwIAwHGYvgcAAJDNlSlTRgULFtSRhDUw7zBq1ChFRkbabidPnszgCnGnTz+VWrc2A6l69aSdOwmkAADZDyOlAAAAsrlTp07pwoULKlKkSJKPu7u7y50FijKFuDhp5EjpvffM+927S3PnSp6e1tYFAEB6IJQCAADIYq5cuWI36unYsWPau3evfH195evrq/Hjxys4OFj+/v46evSoRo4cqXLlyqlt27YWVo17iYqSevaUvvvOvD9+vPTaa+bi5gAAZEeEUgAAAFnMrl271Lx5c9v9ESNGSJL69OmjmTNnav/+/Zo/f74iIiJUtGhRtWnTRhMnTmQ0VCb2zz/mguYHDkgeHtL8+VK3blZXBQBA+iKUAgAAyGKaNWsmwzCSfXzNmjUZWA3SautW84p6585J/v7SV1+Z60gBAJDdWbrQ+aZNm9SxY0cVLVpUTk5OWrVqld3jhmFozJgxKlKkiDw9PdWqVSsdPnzYmmIBAAAAB1u4UGre3AykataUfvmFQAoAkHNYGkpdvXpVNWrU0IwZM5J8fMqUKZo+fbo+/vhj7dixQ3ny5FHbtm0VHR2dwZUCAAAAjhMfL40eLfXuLd24IXXpIm3ZIhUvbnVlAABkHEun77Vv317t27dP8jHDMDRt2jS9+uqr6tSpkyRpwYIF8vPz06pVq9S9e/eMLBUAAABwiKtXzTBqxQrz/qhR0uuvS86WflwMAEDGy7S/+o4dO6awsDC1atXK1ubj46P69etr27ZtFlYGAAAApM6//0pNmpiBlJubuaD5pEkEUgCAnCnTLnQeFhYmSfLz87Nr9/Pzsz2WlJiYGMXExNjuR0VFpU+BAAAAwH3YtUt69FHpzBmpYEFp5UqpUSOrqwIAwDrZ7jOZyZMny8fHx3YLCAiwuiQAAADkcMuWSY0bm4FUlSrSzp0EUgAAZNpQyt/fX5IUHh5u1x4eHm57LCmjRo1SZGSk7Xby5Ml0rRMAAABIjmFIEydK3bpJ0dHSww9LW7dKpUtbXRkAANbLtKFU6dKl5e/vr/Xr19vaoqKitGPHDgUGBib7PHd3d3l7e9vdAAAAgIwWHS098YQ0Zox5f9gw6euvJbqnAACYLF1T6sqVKzpy5Ijt/rFjx7R37175+vqqRIkSGjZsmF5//XWVL19epUuX1muvvaaiRYuqc+fO1hWdHFdXKTbW6ioAAACQCYSFSZ07Szt2SLlySTNmSAMGWF0VAACZi6Wh1K5du9S8eXPb/REjRkiS+vTpo88++0wjR47U1atXNWDAAEVERKhRo0b6/vvv5eHhYVXJyXNysroCAAAAZAL79kkdO0onT0r580vLl0stWlhdFQAAmY+TYRiG1UWkp6ioKPn4+CgyMjJ9p/J5eEgJV/3L3m8pAAA5Sob1JTKRnHjOjvL111LPntLVq1KFCtK330rly1tdFQAAGSulfYlMu6ZUlnPzptUVAAAAwCKGIb39tjll7+pVqWVLaft2AikAAO6GUMpR4uKsrgAAAAAWuHFD6tdPGjnSDKcGDpRWrzan7gEAgORZuqYUAAAAkJWdPy8FB0ubNknOztK0adLgwSw3CgBAShBKAQAAAKlw8KC5oPnff0ve3tLSpVK7dlZXBQBA1kEoBQAAANynNWukbt2kqCipdGlzQfPKla2uCgCArIU1pQAAAID78OGH0sMPm4FUo0bSjh0EUgAApAahlKPUrWt1BQAAAEhHsbFSSIg0ZIgUHy/17SutWycVKmR1ZQAAZE2EUo7y/PNWVwAAAIB0cumSOTrqo4/MRcynTJHmzpXc3a2uDACArIs1pRylRQurKwAAAEA6OHzYXND80CEpTx5p8WKpUyerqwIAIOsjlHIUrvsLAACQ7WzYIAUFmSOlAgKkr7+Wata0uioAALIHpu85yu2h1LVr1tUBAAAAh/j0U6l1azOQql9f2rmTQAoAAEcilHKU21e4fOcd6+oAAABAmsTFSSNGSP37SzdvSj16SD/9JPn7W10ZAADZC9P3HMXF5db2li3W1QEAAIBUi4qSevaUvvvOvD9+vPTaa6zUAABAeiCUSg/x8VZXAAAAgPv0zz/mguYHDkgeHtL8+VK3blZXBQBA9kUolR7i4qyuAAAAAPfh55+lLl2kc+ekIkWkr76S6ta1uioAALI31pRKD4yUAgAAyDIWLpRatDADqVq1zAXNCaQAAEh/hFLpgZFSAAAAmV58vDR6tNS7t3TjhjlSavNmqXhxqysDACBnIJRKD82aWV0BAAAA7uLqValrV2nyZPP+qFHS8uVSnjzW1gUAQE5CKOVITZuaX0uXtrYOAAAAJOvUKalJE2nFCsnNTVqwQJo0SXKmZwwAQIZioXNHypfP/Mr0PQAAgEzpl1+kTp2kM2ekQoWklSulhg2trgoAgJyJz4McKeHjtZs3ra0DAAAAiSxbZo6QOnNGqlLFXNCcQAoAAOsQSjnSypXm1xEjrK0DAAAANoYhTZwodesmRUdLDz8sbd0qlSpldWUAAORsTN9LDzExVlcAAAAASdevS/36SUuWmPeHD5fefltycbG2LgAAQCgFAACAbCosTOrcWdqxQ8qVS/roI6l/f6urAgAACQilAAAAkO3s2yd17CidPCnlzy99+aXUvLnVVQEAgNuxppQj9eljfm3Rwto6AAAAcrCvvzYXMD95UqpQwRwpRSAFAEDmQyjlSLVrm18LFLC2DgAAgBzIMMz1ojp3lq5elVq2lLZvl8qXt7oyAACQFEIpR3JzM7/GxlpbBwAAQA5z44a5oPnIkWY4NWiQtHq1OXUPAABkTqwp5UiurubXVassLQMAACAnOX9eCgqSNm+WnJ2ladOkwYMlJyerKwMAAHfDSClHun2E1B9/WFcHAABADnHwoFS/vhlIeXtL330nDRlCIAUAQFZAKOVI3357a/vvv62rAwAAIAdYs0YKDDS7XWXKSNu2Se3aWV0VAABIKUIpR3rkkaS3AQAA4DCGIX3wgfTww1JUlNS4sXmFvcqVra4MAADcD0IpR+ra1f7+hQvW1AEAAJBNxcZKISHS889L8fFS377S2rVSwYJWVwYAAO4XoZQj5c5tf/+DD6ypAwAAIBu6dMkcHTVzprlm1JQp0ty5kru71ZUBAIDUIJRyJA8P+/vjx1tTBwAAQDZz+LC5ftS6dVKePNLKldKLL7KgOQAAWRmhVHpzcjJvf/1ldSUAAABZ0k8/mVfYO3RICgiQfv5Z6tTJ6qoAAEBaEUpllAcekB57TCpUSFq0yFyh89o1q6sCAADI1D75RGrTxpy6V7++tHOnVKOG1VUBAABHIJRytF9+Sf6xL7+Uzp+XnnxScnY2x57XrSu9+aY0f770229Sq1bSvHnm/vHxZngFAACQw8TFSSNGSAMGSDdvSj16mCOm/P2trgwAADhKLqsLyHbq1JEuX5by5k3Z/rt2mbfbrV8vPf106l5/+HDJ21uaOFHq3VsqVszs1bVrJ7m5SVu3Sk2aSBcvmj28mBhz/4cekiIjJS8vafNmqWpV8xzc3MzzWbvWvN6yk5PZG7xxQ/r9d3O7ZEnzUjg3bkgREZKrq+TnZ4Zqf/1ljhK7fcGHmzelXA7+0YuPl6Kj7RebNwzz3B39WrczjIxZzOLaNfN1PD2Tf13DMK+L7eNj3o+NNb+/Xl6Jj3e3uq9ckRYuNC9ndPvrSUm/5m+/mdfh9vCQatWSqlRJer+4ODOMPXPG/LlMcP26+ToJIezNm+ZXFxfze5dwLMMwf8aSW812xw7pxAlzBdyYGHP122LFpIEDzWM535bBR0WZPysJPxvXrpn/JooXN++fPWu+j3e+1rlz0rZtUseO9ue4ZIn5miVKmPNKPD1vHevmTfPck6s7PNz8HuXJY99+44ZZ37Fj5mO3/xV2+7+hS5fMYyf87J87Z35PmjdP+nt85ow0erTUrZtUpowUGmr+v+HjY+4fH2/uU7Cged/V1XyNfPnM13V1vXXcuDjzvb3TuXPmY3nzSv/3f+b/LYUKSS1bmt/vDRuk6tWlChXM/W//Ht9ec3z8rccvX5aWLZN8fc3/z27eNN+3O88xLs58vfz5zcd+/938MKBpU/v94uPtfyYk6fhx8/+zjJZR/48AWUhUlNSzp/Tdd+b9CROkV1/lnwoAANmNk2Fk76E4UVFR8vHxUWRkpLy9vTPuhR955FZPCgAcwckp+4+eLFVK+ueflO//6afS7Nlm+N2ypRmmJiU42AwAH3tMGjbMbKtVy/xL94MPpB9+MNvKlpW++MIM0554wgz85s41Q67atc25Q4Zh7l+pkhl6deli1vDLL+bo11q1zPtPPGHWN368tHu3ORL28mUzyNu6VWrb1vwre+FCadMmM9A8ftw8dt26UoMG0t9/S927mx8QvPGGGbC5ukobN0rNmkn16pkB5cqVUlCQGS4mFRRK9uHXxYvmBxJ3hvaHD0uTJkkjR5rvV5060unT5vPKlbt7IvDHH+awliNHzA83bg9SDcMMK/PnN+t3hGvXzPe1YcPEAaODWdaXsJCV5/zPP2b2f+CA+XnH/Plmjg4AALKOlPYlCKXSEx/nAQCsVLmydPBg8o9fvSq9/ro0fbq5fS8xMeYozL17zRCqWTNpzRpp8GD7/ZydzTBr505zhNvChbcemzbNDOA2bzZHAb7xhtm+aZMZ8uXLJ3XubKYRe/aY4Z2bm7R4sVStmnnpte3bzeMkmDMn9SOMU4BQKuPO+eefzZz33DmpSBHpq6/MjBYAAGQthFL/sbQjuWuX9N575qfOHh7SCy+Y02WcnMw/Er78MvnnPvig2RkHAAD39scfUsWK6XJoQinHn3NcnJlLnjljhk+NG5uziZ95xpy9XKuW9PXXt2ZCAwCArCWlfQnWlEpPdeqYPawEixcn3ufy5aTXRUmLmJjk169B5nCvNWTi4821nQzDnGKT1Jo7sbHmujqenvbtV6+aU3C8vc2fr8qVzf0iIsyef0SEuebQlSvm6IMVK8xe/5dfmpc3KlLEnNoTEGCu/VO6tPkx9YED5hSoMWPMUQqjRpkjGl55xRy9sHKluW6Pv78UGGiObli50hz5sHixuX7QX3+ZU3diY811z4oWlfr1sz/3kSPNuhJGQ3h6musj/d//3dqncWOpfHlzWlVWUayY9O+/VlcBZF/PPmtOa0Smt2KFNHSodOrUrba8ec1fWZI5E3XBgsRL7QEAgOyHkVIAsjfDMEO68uVvrcmU2hD49oW94+PNj/Hr1TPDtQQJC7cbhhnI+fmZi3wniI83X//OGuLj7df5cXZOXGtEhPlX2pkzUoEC5nZsrBkw/t//mWvrlCp1a/+bN80wsV07c+F3V1dz3+PHzZqfe+7We9Sly615Mu+8Y4aTZcpIy5dLq1dL48aZVwqdNUt66SXp5ZfNBdJXrDBXJE6wc6e54LuXV9KL7CenY0dz3s7Fi8nv07attGWL+dfs/v3St9+m/PjI/goUMNfcSgc5sS+RXue8YoW5tFtyvc+gIHPGZzovEwYAANIZ0/f+kxM7kgCQKVy6ZAZhzs5mUJcQsB07Zi54HRNjPu7re+s506aZo+oefvj+XmvPHnMh8pAQc/5PdLS5EPmcObeu9HfunLmPZF6p8fYr7Q0bJp08eWtadaFC5v6SGRRGRUk1a5prKUnmNLE//zS3d+wwF0BPiXz5zHARjle/vjm6Mh3kxL5EepxzXJyZm98+QupOAQHmfxHJrdcPAACyBkKp/+TEjiQA5EjXrkm5c6ftGDdvmqPOHnpIKljQHMGW3JCNsDBzqnT+/PbtixZJ779vBlwlSphthmGOanNzsx8Bd/Om+Re6r6+54Li7u1SlitSjx63j5c0rXbggPf+8uZh31apmyHe76GhzlJCPj/T991KLFmZd4eHmqLezZ6WffjKn6J48KX38sRm27d9vXrUwXz6pTx8zaNuzx9z33DkzQPv5Z/M1ypQxrwZ4L61amc87dsysOzkhIdKMGeb2sGH2C5enxrFj9iMFHSgn9iXS45w3bDBnY9/LTz+Za+gDAICsi1DqPzmxIwkAyCbSMt3UUW4P+8aONdeI277dDO3+/dcM7fz9E9d5+bIZfAUEmCPTJDM8W7DAnFKaENgluHnTHB5z5owZ3hUsKG3bZq5F17evuU/x4lKDBuZrvfiieYx9+6TWrdP1fcqJfYn0OOclS6SePe+9X2iofS4LAACyHkKp/+TEjiQAAJlCVJR59Vk3t7Qd59o16ZtvzGmdefM6prb7kBP7EoyUAgAAaZHSvgTLSAIAgPTh7Z32QEoyR2o9/rglgRQcp3Fjc7BbcoPanJzMgXWNG2dsXQAAwDqEUgAAAEh3Li7mcmtS4mAq4f60aSxyDgBATpIlQqkZM2aoVKlS8vDwUP369bVz506rSwIAAMB9CgqSli+XihWzby9e3GwPCrKmLgAAYI1MH0otXbpUI0aM0NixY7Vnzx7VqFFDbdu21dmzZ60uDQAAAPcpKEj65x9z7ajQUPPrsWMEUgAA5ESZfqHz+vXrq27duvrwww8lSfHx8QoICNCQIUP08ssv3/P5OXFxUgAA4Dg5sS+RE88ZAAA4TrZY6PzGjRvavXu3WrVqZWtzdnZWq1attG3btiSfExMTo6ioKLsbAAAAAAAAMpdMHUqdP39ecXFx8vPzs2v38/NTWFhYks+ZPHmyfHx8bLeAgICMKBUAAAAAAAD3IVOHUqkxatQoRUZG2m4nT560uiQAAAAAAADcIZfVBdxNwYIF5eLiovDwcLv28PBw+fv7J/kcd3d3ubu7Z0R5AAAAAAAASKVMPVLKzc1NtWvX1vr1621t8fHxWr9+vQIDAy2sDAAAAAAAAGmRqUdKSdKIESPUp08f1alTR/Xq1dO0adN09epVPfXUU1aXBgAAAAAAgFTK9KHU448/rnPnzmnMmDEKCwtTzZo19f333yda/BwAAAAAAABZR6YPpSRp8ODBGjx4sNVlAAAAAAAAwEEy9ZpSAAAAAAAAyJ4IpQAAAAAAAJDhCKUAAAAAAACQ4bLEmlJpYRiGJCkqKsriSgAAQFaUE/sQ9J8AAEBaJPQhEvoUycn2odTly5clSQEBARZXAgAAkDXQfwIAAI5w+fJl+fj4JPu4k3Gv2CqLi4+P1+nTp5U3b145OTk5/PhRUVEKCAjQyZMn5e3t7fDjI/X43mRefG8yL743mRffG+skdJW8vb3TpS+RGaV3/0nKeT/TnG/2ltPOV8p558z5Zn857ZzT+3wNw9Dly5dVtGhROTsnv3JUth8p5ezsrOLFi6f763h7e+eIH9ysiO9N5sX3JvPie5N58b1BRsio/pOU836mOd/sLaedr5Tzzpnzzf5y2jmn5/nebYRUAhY6BwAAAAAAQIYjlAIAAAAAAECGI5RKI3d3d40dO1bu7u5Wl4I78L3JvPjeZF58bzIvvjfIbnLazzTnm73ltPOVct45c77ZX04758xyvtl+oXMAAAAAAABkPoyUAgAAAAAAQIYjlAIAAAAAAECGI5QCAAAAAABAhiOUSqMZM2aoVKlS8vDwUP36/9/e3UdFVed/AH8Pz+A4PIkz2Ao+gEigpqA2aFkLu6CuoVmksTZunlxMU3Y3k9ZMPR4XKzdLK7I8YmuulKXo+kSK4AMrPvOkLKKSWoEeV1FRRGE+vz/6ebdRQIZkphnfr3PmHO79fu6d74cPd+Z7v9y5MxD79++3dpfsRmpqKvr374/27dujY8eOGDlyJMrKykxibty4gcmTJ8PX1xdqtRqjR4/GuXPnTGLOnDmD4cOHw8PDAx07dsT06dNRX19vEpObm4t+/frB1dUVQUFBWLFiRVunZ1cWLFgAlUqF5ORkZR1rYz3ff/89fv/738PX1xfu7u7o1asXDh48qLSLCN588034+/vD3d0dMTExKC8vN9nHxYsXkZiYCI1GAy8vL0yYMAE1NTUmMUVFRXjsscfg5uaGzp074+2337ZIfraqoaEBs2bNQteuXeHu7o7u3btj3rx5+OmtHVkbsifmjpHWrFmDnj17ws3NDb169cLmzZst1NP7x5ycV6xYAZVKZfJwc3OzYG9/nl27dmHEiBHo1KkTVCoVMjMz77mNLb+nm5tvbm7uXfVVqVSoqqqyTId/ppaMwxtjq8dxa/K15WM4LS0NvXv3hkajgUajgV6vx5YtW5rdxlZre5u5OdtyfRvT2PlaY6xSZ6FWy8jIEBcXF1m+fLkcPXpUXnrpJfHy8pJz585Zu2t2ITY2VtLT06WkpEQKCgpk2LBhEhAQIDU1NUpMUlKSdO7cWbKzs+XgwYPy6KOPSlRUlNJeX18v4eHhEhMTI0eOHJHNmzdLhw4d5PXXX1diTp06JR4eHvLnP/9Zjh07JkuWLBFHR0fZunWrRfO1Vfv375cuXbpI7969Zdq0acp61sY6Ll68KIGBgTJ+/HjZt2+fnDp1SrKysuTEiRNKzIIFC8TT01MyMzOlsLBQnnrqKenatavU1tYqMXFxcdKnTx/Jz8+X3bt3S1BQkIwdO1Zpv3z5smi1WklMTJSSkhJZvXq1uLu7y9KlSy2ary2ZP3+++Pr6ysaNG6WiokLWrFkjarVa3n//fSWGtSF7Ye4YKS8vTxwdHeXtt9+WY8eOyRtvvCHOzs5SXFxs4Z63nrk5p6eni0ajkcrKSuVRVVVl4V633ubNm2XmzJmydu1aASDr1q1rNt7W39PNzTcnJ0cASFlZmUmNGxoaLNPhn6kl4/A72fJx3Jp8bfkY3rBhg2zatEmOHz8uZWVl8te//lWcnZ2lpKSk0Xhbru1t5uZsy/W9U1Pna3eyVp05KfUzDBgwQCZPnqwsNzQ0SKdOnSQ1NdWKvbJf58+fFwCyc+dOERGprq4WZ2dnWbNmjRJTWloqAGTv3r0i8uMAwsHBweQFJC0tTTQajdTV1YmIyGuvvSZhYWEmz/Xcc89JbGxsW6dk865evSrBwcGybds2GTJkiPIix9pYz4wZM2Tw4MFNthuNRtHpdPLOO+8o66qrq8XV1VVWr14tIiLHjh0TAHLgwAElZsuWLaJSqeT7778XEZGPPvpIvL29lVrdfu6QkJD7nZLdGD58uLz44osm655++mlJTEwUEdaG7Iu5Y6SEhAQZPny4ybqBAwfKH//4xzbt5/1kbs7p6eni6elpod61rZZM0tjTe7o5k1KXLl2ySJ/a2p3j8MbYw3F8W0vytadjWETE29tbli1b1mibPdX2p5rL2V7q29T5WmOsVWd+fK+Vbt68iUOHDiEmJkZZ5+DggJiYGOzdu9eKPbNfly9fBgD4+PgAAA4dOoRbt26Z1KBnz54ICAhQarB371706tULWq1WiYmNjcWVK1dw9OhRJean+7gdwzre2+TJkzF8+PC7fn+sjfVs2LABkZGRePbZZ9GxY0f07dsXn376qdJeUVGBqqoqk9+rp6cnBg4caFIbLy8vREZGKjExMTFwcHDAvn37lJjHH38cLi4uSkxsbCzKyspw6dKltk7TJkVFRSE7OxvHjx8HABQWFmLPnj0YOnQoANaG7Edrxki2/nrf2nFhTU0NAgMD0blzZ8THxyvvf/bI1mvcWo888gj8/f3xm9/8Bnl5edbuTqvdOQ5vjD3VuCX5AvZxDDc0NCAjIwPXrl2DXq9vNMaeagu0LGfAPurb1PlaY6xVZ05KtdKFCxfQ0NBgckINAFqt1mY+K25LjEYjkpOTMWjQIISHhwMAqqqq4OLiAi8vL5PYn9agqqqq0Rrdbmsu5sqVK6itrW2LdOxCRkYGDh8+jNTU1LvaWBvrOXXqFNLS0hAcHIysrCxMmjQJU6dOxWeffQbgf7/b5l67qqqq0LFjR5N2Jycn+Pj4mFU/MpWSkoIxY8agZ8+ecHZ2Rt++fZGcnIzExEQArA3Zj9aMkZr6u7WVv9nW5BwSEoLly5dj/fr1+Pzzz2E0GhEVFYXvvvvOEl22uAftPd3f3x8ff/wxvv76a3z99dfo3LkznnjiCRw+fNjaXTNbY+Pwxtj6cXxbS/O19WO4uLgYarUarq6uSEpKwrp16/Dwww83GmsvtTUnZ1uvL9D8+VpjrFVnpzbdO9F9MnnyZJSUlGDPnj3W7goBOHv2LKZNm4Zt27bZ9A3/7JHRaERkZCT+9re/AQD69u2LkpISfPzxxzAYDFbu3YPtyy+/xKpVq/DPf/4TYWFhKCgoQHJyMjp16sTaED2A9Hq9yX/oo6KiEBoaiqVLl2LevHlW7BndDyEhIQgJCVGWo6KicPLkSSxatAgrV660Ys/M96CNw1uar60fwyEhISgoKMDly5fx1VdfwWAwYOfOnU1O0tgDc3K29fra0vkar5RqpQ4dOsDR0fGubxM7d+4cdDqdlXpln6ZMmYKNGzciJycHv/rVr5T1Op0ON2/eRHV1tUn8T2ug0+kardHttuZiNBoN3N3d73c6duHQoUM4f/48+vXrBycnJzg5OWHnzp1YvHgxnJycoNVqWRsr8ff3v+uNNTQ0FGfOnAHwv99tc69dOp0O58+fN2mvr6/HxYsXzaofmZo+fbpytVSvXr0wbtw4/OlPf1L+e8XakL1ozRipqb9bW/mbvR/jwttXUJ44caItumh1fE8HBgwYYHP1bWoc3hhbP44B8/K9k60dwy4uLggKCkJERARSU1PRp08fvP/++43G2kNtAfNyvpOt1fde52sNDQ13bWOtOnNSqpVcXFwQERGB7OxsZZ3RaER2dnazn0ullhMRTJkyBevWrcOOHTvQtWtXk/aIiAg4Ozub1KCsrAxnzpxRaqDX61FcXGxyErdt2zZoNBrlxF2v15vs43YM69i06OhoFBcXo6CgQHlERkYiMTFR+Zm1sY5Bgwbd9RXGx48fR2BgIACga9eu0Ol0Jr/XK1euYN++fSa1qa6uxqFDh5SYHTt2wGg0YuDAgUrMrl27cOvWLSVm27ZtCAkJgbe3d5vlZ8uuX78OBwfTt11HR0cYjUYArA3Zj9aMkWz99f5+jAsbGhpQXFwMf3//tuqmVdl6je+HgoICm6nvvcbhjbHlGrcm3zvZ+jFsNBpRV1fXaJst17Y5zeV8J1ur773O1xwdHe/axmp1btPbqNu5jIwMcXV1lRUrVsixY8dk4sSJ4uXlZbNfFflLM2nSJPH09JTc3FyTr+K8fv26EpOUlCQBAQGyY8cOOXjwoOj1etHr9Up7fX29hIeHy29/+1spKCiQrVu3ip+fn7z++utKzO2vKJ4+fbqUlpbKhx9+aFNfUfxLcee3ObA21rF//35xcnKS+fPnS3l5uaxatUo8PDzk888/V2IWLFggXl5esn79eikqKpL4+Hjp2rWr1NbWKjFxcXHSt29f2bdvn+zZs0eCg4Nl7NixSnt1dbVotVoZN26clJSUSEZGhnh4eMjSpUstmq8tMRgM8tBDD8nGjRuloqJC1q5dKx06dJDXXntNiWFtyF7ca4w0btw4SUlJUeLz8vLEyclJFi5cKKWlpTJ79myb+7pxc3OeO3euZGVlycmTJ+XQoUMyZswYcXNzk6NHj1orBbNcvXpVjhw5IkeOHBEA8u6778qRI0fk9OnTIiKSkpIi48aNU+Jt/T3d3HwXLVokmZmZUl5eLsXFxTJt2jRxcHCQ7du3WysFs7RkHG5Px3Fr8rXlYzglJUV27twpFRUVUlRUJCkpKaJSqeSbb74REfuq7W3m5mzL9W3Knedrv5Q6c1LqZ1qyZIkEBASIi4uLDBgwQPLz863dJbsBoNFHenq6ElNbWysvv/yyeHt7i4eHh4waNUoqKytN9vPtt9/K0KFDxd3dXTp06CB/+ctf5NatWyYxOTk58sgjj4iLi4t069bN5DmoZe58kWNtrOdf//qXhIeHi6urq/Ts2VM++eQTk3aj0SizZs0SrVYrrq6uEh0dLWVlZSYx//3vf2Xs2LGiVqtFo9HIH/7wB7l69apJTGFhoQwePFhcXV3loYcekgULFrR5brbsypUrMm3aNAkICBA3Nzfp1q2bzJw5U+rq6pQY1obsSXNjpCFDhojBYDCJ//LLL6VHjx7i4uIiYWFhsmnTJgv3+OczJ+fk5GQlVqvVyrBhw+Tw4cNW6HXr5OTkNDpOu52jwWCQIUOG3LWNrb6nm5vvW2+9Jd27dxc3Nzfx8fGRJ554Qnbs2GGdzrdCS8bh9nQctyZfWz6GX3zxRQkMDBQXFxfx8/OT6OhoZXJGxL5qe5u5OdtyfZty5/naL6XOKhGRtr0Wi4iIiIiIiIiIyBTvKUVERERERERERBbHSSkiIiIiIiIiIrI4TkoREREREREREZHFcVKKiIiIiIiIiIgsjpNSRERERERERERkcZyUIiIiIiIiIiIii+OkFBERERERERERWRwnpYiIiIiIiIiIyOI4KUVENqFLly547733Whyfm5sLlUqF6urqNusTEREREZlHpVIhMzPT2t0gol8ITkoR0X2lUqmafcyZM6dV+z1w4AAmTpzY4vioqChUVlbC09OzVc9njk8//RR9+vSBWq2Gl5cX+vbti9TUVKV9/PjxGDlyZJv3g4iIiKg548ePb3R8FhcXZ+2uEdEDysnaHSAi+1JZWan8/MUXX+DNN99EWVmZsk6tVis/iwgaGhrg5HTvlyI/Pz+z+uHi4gKdTmfWNq2xfPlyJCcnY/HixRgyZAjq6upQVFSEkpKSNn9uIiIiInPFxcUhPT3dZJ2rq6uVekNEDzpeKUVE95VOp1Menp6eUKlUyvJ//vMftG/fHlu2bEFERARcXV2xZ88enDx5EvHx8dBqtVCr1ejfvz+2b99ust87P76nUqmwbNkyjBo1Ch4eHggODsaGDRuU9js/vrdixQp4eXkhKysLoaGhUKvViIuLM5lEq6+vx9SpU+Hl5QVfX1/MmDEDBoOh2aucNmzYgISEBEyYMAFBQUEICwvD2LFjMX/+fADAnDlz8Nlnn2H9+vXKfyNzc3MBAGfPnkVCQgK8vLzg4+OD+Ph4fPvtt8q+b19hNXfuXPj5+UGj0SApKQk3b95sXXGIiIjogefq6moyXtPpdPD29gbw4/gqLS0NQ4cOhbu7O7p164avvvrKZPvi4mL8+te/hru7O3x9fTFx4kTU1NSYxCxfvhxhYWFwdXWFv78/pkyZYtJ+4cKFJsdwRPRg4aQUEVlcSkoKFixYgNLSUvTu3Rs1NTUYNmwYsrOzceTIEcTFxWHEiBE4c+ZMs/uZO3cuEhISUFRUhGHDhiExMREXL15sMv769etYuHAhVq5ciV27duHMmTN49dVXlfa33noLq1atQnp6OvLy8nDlypV73vNAp9MhPz8fp0+fbrT91VdfRUJCgjIBVllZiaioKNy6dQuxsbFo3749du/ejby8PGWi7KeTTtnZ2SgtLUVubi5Wr16NtWvXYu7cuc32iYiIiKi1Zs2ahdGjR6OwsBCJiYkYM2YMSktLAQDXrl1DbGwsvL29ceDAAaxZswbbt283mXRKS0vD5MmTMXHiRBQXF2PDhg0ICgoyeQ5zx3BEZMeEiKiNpKeni6enp7Kck5MjACQzM/Oe24aFhcmSJUuU5cDAQFm0aJGyDEDeeOMNZbmmpkYAyJYtW0ye69KlS0pfAMiJEyeUbT788EPRarXKslarlXfeeUdZrq+vl4CAAImPj2+ynz/88IM8+uijAkB69OghBoNBvvjiC2loaFBiDAbDXftYuXKlhISEiNFoVNbV1dWJu7u7ZGVlKdv5+PjItWvXlJi0tDRRq9Um+yciIiJqCYPBII6OjtKuXTuTx/z580Xkx/FVUlKSyTYDBw6USZMmiYjIJ598It7e3lJTU6O0b9q0SRwcHKSqqkpERDp16iQzZ85ssg/3GsMR0YOF95QiIouLjIw0Wa6pqcGcOXOwadMmVFZWor6+HrW1tfe8Uqp3797Kz+3atYNGo8H58+ebjPfw8ED37t2VZX9/fyX+8uXLOHfuHAYMGKC0Ozo6IiIiAkajscl9+vv7Y+/evSgpKcGuXbvw73//GwaDAcuWLcPWrVvh4ND4BamFhYU4ceIE2rdvb7L+xo0bOHnypLLcp08feHh4KMt6vR41NTU4e/YsAgMDm+wXERERUWOefPJJpKWlmazz8fFRftbr9SZter0eBQUFAIDS0lL06dMH7dq1U9oHDRoEo9GIsrIyqFQq/PDDD4iOjm62D+aO4YjIfnFSiogs7qcDGeDHj7ht27YNCxcuRFBQENzd3fHMM8/c895Jzs7OJssqlarZCaTG4kXEzN43Ljw8HOHh4Xj55ZeRlJSExx57DDt37sSTTz7ZaHxNTQ0iIiKwatWqu9rMvak7ERERUUu1a9furo/T3S/u7u4tijN3DEdE9ov3lCIiq8vLy8P48eMxatQo9OrVCzqdzuSG35bg6ekJrVaLAwcOKOsaGhpw+PBhs/f18MMPA/jxvgvAj98E2NDQYBLTr18/lJeXo2PHjggKCjJ5eHp6KnGFhYWora1VlvPz86FWq9G5c2ez+0VERER0L/n5+Xcth4aGAgBCQ0NRWFiojHGAH8dxDg4OCAkJQfv27dGlSxdkZ2dbtM9EZLs4KUVEVhccHIy1a9eioKAAhYWFeP75563y37JXXnkFqampWL9+PcrKyjBt2jRcunQJKpWqyW0mTZqEefPmIS8vD6dPn0Z+fj5eeOEF+Pn5KZe/d+nSBUVFRSgrK8OFCxdw69YtJCYmokOHDoiPj8fu3btRUVGB3NxcTJ06Fd99952y/5s3b2LChAk4duwYNm/ejNmzZ2PKlClNfiyQiIiIqDl1dXWoqqoyeVy4cEFpX7NmDZYvX47jx49j9uzZ2L9/v3Ij88TERLi5ucFgMKCkpAQ5OTl45ZVXMG7cOGi1WgA/fvPw3//+dyxevBjl5eU4fPgwlixZYpVcieiXj2c1RGR17777Lry9vREVFYURI0YgNjYW/fr1s3g/ZsyYgbFjx+KFF16AXq+HWq1GbGws3NzcmtwmJiYG+fn5ePbZZ9GjRw+MHj0abm5uyM7Ohq+vLwDgpZdeQkhICCIjI+Hn54e8vDx4eHhg165dCAgIwNNPP43Q0FBMmDABN27cgEajUfYfHR2N4OBgPP7443juuefw1FNPYc6cOW39qyAiIiI7tXXrVvj7+5s8Bg8erLTPnTsXGRkZ6N27N/7xj39g9erVylXgHh4eyMrKwsWLF9G/f38888wziI6OxgcffKBsbzAY8N577+Gjjz5CWFgYfve736G8vNzieRKRbVDJ/bqhChGRnTEajQgNDUVCQgLmzZtn8ecfP348qqurkZmZafHnJiIiogePSqXCunXrMHLkSGt3hYgeELzRORHR/zt9+jS++eYbDBkyBHV1dfjggw9QUVGB559/3tpdIyIiIiIisjv8+B4R0f9zcHDAihUr0L9/fwwaNAjFxcXYvn27cnNPIiIiIiIiun/48T0iIiIiIiIiIrI4XilFREREREREREQWx0kpIiIiIiIiIiKyOE5KERERERERERGRxXFSioiIiIiIiIiILI6TUkREREREREREZHGclCIiIiIiIiIiIovjpBQREREREREREVkcJ6WIiIiIiIiIiMjiOClFREREREREREQW938AeVS+9bkvXQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load saved metrics\n",
    "loss_train_list = np.load(\"loss_train_list_q.npy\")\n",
    "acc_train_list = np.load(\"acc_train_list_q.npy\")\n",
    "\n",
    "steps = range(len(loss_list))\n",
    "epochs = range(len(acc_list))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot (a) Training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(steps, loss_train_list, color='red')\n",
    "plt.xlabel(\"Training Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"(a) Training Loss over Steps\")\n",
    "\n",
    "# Plot (b) Accuracy per epoch\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, acc_train_list, marker='o', color='blue')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"(b) Training Accuracy per Epoch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_metrics_quantum.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
